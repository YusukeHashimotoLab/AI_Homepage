---
title: "ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹å…¥é–€:ãƒ‡ãƒ¼ã‚¿ã§ææ–™é–‹ç™ºã‚’åŠ é€Ÿã™ã‚‹"
level: "beginner"
target_audience: "undergraduate"
learning_objectives:
  - ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹(MI)ã®åŸºæœ¬æ¦‚å¿µã¨é‡è¦æ€§ã‚’ç†è§£ã™ã‚‹
  - æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤ã¨ææ–™ç§‘å­¦ã¸ã®å¿œç”¨æ–¹æ³•ã‚’ç¿’å¾—ã™ã‚‹
  - ææ–™ãƒ‡ãƒ¼ã‚¿ã®åé›†ã€å‰å‡¦ç†ã€ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®æ‰‹æ³•ã‚’å­¦ã¶
  - æ•™å¸«ã‚ã‚Šå­¦ç¿’ã«ã‚ˆã‚‹ææ–™ç‰©æ€§äºˆæ¸¬ã®å®Ÿè·µçš„ã‚¹ã‚­ãƒ«ã‚’èº«ã«ã¤ã‘ã‚‹
  - ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®åŸºæœ¬ã‚’ç†è§£ã™ã‚‹
  - å®Ÿè·µçš„ãªMIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é€²ã‚æ–¹ã‚’ç¿’å¾—ã™ã‚‹
topics: ["materials_informatics", "machine_learning", "data_science", "property_prediction", "bayesian_optimization"]
version: "3.0"
created_at: "2025-10-16"
updated_at: "2025-10-16"
reviewed_by: "scholar-agent, content-agent, academic-reviewer-agent, tutor-agent, data-agent, design-agent, maintenance-agent"
phase: "9_final_publication"
quality_score: "93/100"
publication_status: "published"
word_count: "10000+"
exercises: "25+"
diagrams: "5+"
---

# ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹å…¥é–€:ãƒ‡ãƒ¼ã‚¿ã§ææ–™é–‹ç™ºã‚’åŠ é€Ÿã™ã‚‹

## å­¦ç¿’ç›®æ¨™

ã“ã®è¨˜äº‹ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™:

1. **æ¦‚å¿µç†è§£**: ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹(MI)ã¨ã¯ä½•ã‹ã€ãªãœé‡è¦ã‹ã‚’èª¬æ˜ã§ãã‚‹
2. **æŠ€è¡“åŸºç¤**: æ©Ÿæ¢°å­¦ç¿’ã®åŸºæœ¬åŸç†ã¨ææ–™ç§‘å­¦ã¸ã®å¿œç”¨æ–¹æ³•ã‚’ç†è§£ã™ã‚‹
3. **å®Ÿè·µã‚¹ã‚­ãƒ«**: Pythonã¨matminerã€scikit-learnã‚’ä½¿ã£ãŸææ–™ç‰©æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
4. **é«˜åº¦ãªæ‰‹æ³•**: ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®åŸºæœ¬æ¦‚å¿µ
5. **å•é¡Œè§£æ±º**: å®Ÿéš›ã®ææ–™é–‹ç™ºèª²é¡Œã«MIã‚’é©ç”¨ã™ã‚‹èƒ½åŠ›

**æ¨å¥¨å­¦ç¿’æ™‚é–“**: 6-9æ™‚é–“(ã‚³ãƒ¼ãƒ‰å®Ÿè·µã‚’å«ã‚€)
**å‰æçŸ¥è­˜**: åŸºç¤åŒ–å­¦ã€åŸºç¤ç‰©ç†ã€é«˜æ ¡æ•°å­¦(é–¢æ•°ã€ã‚°ãƒ©ãƒ•)

---

## 1. ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã¨ã¯ä½•ã‹?

**ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å­¦ã¶ã“ã¨** (15åˆ†):
- ğŸ¯ MIãŒãªãœææ–™é–‹ç™ºã‚’é©æ–°ã™ã‚‹ã®ã‹
- ğŸ“Š å¾“æ¥ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã®å…·ä½“çš„ãªé•ã„
- ğŸ”¬ å®Ÿä¾‹:ãƒªãƒã‚¦ãƒ ã‚¤ã‚ªãƒ³é›»æ± ã®é€²åŒ–
- ğŸ’¡ ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®ä»•çµ„ã¿

### 1.1 ææ–™é–‹ç™ºã®é©å‘½

æ–°ã—ã„ææ–™ã®é–‹ç™ºã«ã¯ã€å¾“æ¥10-20å¹´ã¨ã„ã†é•·ã„æ™‚é–“ãŒã‹ã‹ã£ã¦ã„ã¾ã—ãŸã€‚ã—ã‹ã—ã€**ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹(Materials Informatics, MI)**ã¯ã€ã“ã®é–‹ç™ºæœŸé–“ã‚’2-5å¹´ã«çŸ­ç¸®ã™ã‚‹å¯èƒ½æ€§ã‚’ç§˜ã‚ã¦ã„ã¾ã™[^1]ã€‚

**å…·ä½“ä¾‹:ãƒªãƒã‚¦ãƒ ã‚¤ã‚ªãƒ³é›»æ± ã®é€²åŒ–**

ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã‚„EV(é›»æ°—è‡ªå‹•è»Š)ã«ä½¿ã‚ã‚Œã‚‹ãƒªãƒã‚¦ãƒ ã‚¤ã‚ªãƒ³é›»æ± ã®å®¹é‡ã¯ã€éå»30å¹´é–“ã§ç´„3å€ã«å‘ä¸Šã—ã¾ã—ãŸã€‚ã“ã®é€²åŒ–ã®èƒŒæ™¯ã«ã¯ã€MIã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªææ–™æ¢ç´¢ãŒã‚ã‚Šã¾ã™ã€‚å¾“æ¥ã¯ç ”ç©¶è€…ã®çµŒé¨“ã¨ç›´æ„Ÿã«åŸºã¥ã„ã¦ææ–™ã‚’è©¦ä½œã—ã¦ã„ã¾ã—ãŸãŒã€ç¾åœ¨ã¯æ©Ÿæ¢°å­¦ç¿’ã§æ•°ä¸‡ç¨®é¡ã®å€™è£œã‹ã‚‰æœ€é©ãªçµ„æˆã‚’äºˆæ¸¬ã—ã€å®Ÿé¨“å›æ•°ã‚’å¤§å¹…ã«å‰Šæ¸›ã—ã¦ã„ã¾ã™ã€‚

> ğŸ’¡ **Key Point**
>
> MIã®æœ¬è³ªã¯ã€Œå®Ÿé¨“ã‚’ç½®ãæ›ãˆã‚‹ã€ã“ã¨ã§ã¯ãªãã€ã€Œå®Ÿé¨“ã‚’è³¢ãé¸ã¶ã€ã“ã¨ã§ã™ã€‚
> ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’ã—ã€æœ€ã‚‚æœ‰æœ›ãªå€™è£œã«å®Ÿé¨“ãƒªã‚½ãƒ¼ã‚¹ã‚’é›†ä¸­ã•ã›ã¾ã™ã€‚

### 1.2 MIã®å®šç¾©

ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã¨ã¯ã€**ææ–™ç§‘å­¦ã¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã‚’èåˆã—ãŸç ”ç©¶åˆ†é‡**ã§ã™[^2]ã€‚å…·ä½“çš„ã«ã¯ã€ä»¥ä¸‹ã®è¦ç´ ã‚’çµ±åˆã—ã¾ã™:

- **ææ–™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**: å®Ÿé¨“ãƒ»è¨ˆç®—ã§å¾—ã‚‰ã‚ŒãŸå¤§é‡ã®ææ–™ç‰©æ€§ãƒ‡ãƒ¼ã‚¿
- **æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **: ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã€æ–°ææ–™ã®ç‰¹æ€§ã‚’äºˆæ¸¬
- **è¨ˆç®—ææ–™ç§‘å­¦**: ç¬¬ä¸€åŸç†è¨ˆç®—(DFT)ã«ã‚ˆã‚‹ææ–™ç‰©æ€§ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- **å®Ÿé¨“æœ€é©åŒ–**: ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ãªã©ã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªå®Ÿé¨“è¨ˆç”»

**MIã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¯ãƒ«**:

```mermaid
graph TD
    A[ææ–™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹] --> B[ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°]
    B --> C[æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«è¨“ç·´]
    C --> D[æ–°ææ–™ã®äºˆæ¸¬]
    D --> E[å®Ÿé¨“æ¤œè¨¼]
    E --> F[ãƒ‡ãƒ¼ã‚¿è¿½åŠ ]
    F --> A
    style D fill:#4caf50,stroke:#2e7d32,color:#fff
    style E fill:#2196f3,stroke:#1565c0,color:#fff
```

*å›³1: MIãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ¦‚å¿µå›³ã€‚äºˆæ¸¬ã¨å®Ÿé¨“ã‚’ç¹°ã‚Šè¿”ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’æ”¹å–„ã—ã¾ã™ã€‚*

### 1.3 ãªãœä»ŠMIãªã®ã‹?

MIãŒè¿‘å¹´æ€¥é€Ÿã«ç™ºå±•ã—ã¦ã„ã‚‹èƒŒæ™¯ã«ã¯ã€ä»¥ä¸‹ã®æŠ€è¡“çš„é€²æ­©ãŒã‚ã‚Šã¾ã™:

#### 1. å¤§è¦æ¨¡ææ–™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ•´å‚™(2010å¹´ä»£ã€œ)

- **Materials Project**: 14ä¸‡ä»¥ä¸Šã®ææ–™ãƒ‡ãƒ¼ã‚¿[^3]
- **OQMD**: 100ä¸‡ä»¥ä¸Šã®è¨ˆç®—ãƒ‡ãƒ¼ã‚¿[^4]
- **NOMAD**: 1å„„ä»¥ä¸Šã®ç¬¬ä¸€åŸç†è¨ˆç®—çµæœ[^5]

#### 2. æ©Ÿæ¢°å­¦ç¿’ã®é€²åŒ–(2015å¹´ã€œ)

- æ·±å±¤å­¦ç¿’ã®ææ–™ç§‘å­¦ã¸ã®å¿œç”¨
- ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(CGCNN, MEGNet)ã®ç™»å ´[^6]
- å°ãƒ‡ãƒ¼ã‚¿å‘ã‘æ‰‹æ³•(ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã€è»¢ç§»å­¦ç¿’)ã®æˆç†Ÿ[^7]

#### 3. è¨ˆç®—è³‡æºã®å¢—å¤§

- GPUã«ã‚ˆã‚‹è¨ˆç®—ã®é«˜é€ŸåŒ–
- ã‚¯ãƒ©ã‚¦ãƒ‰ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®æ™®åŠ

#### 4. ã‚ªãƒ¼ãƒ—ãƒ³ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®æµ¸é€

- ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ‡ãƒ¼ã‚¿ã®å…¬é–‹ãŒæ¨™æº–åŒ–
- å†ç¾å¯èƒ½ãªç ”ç©¶ç’°å¢ƒã®æ•´å‚™

### 1.4 å¾“æ¥ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã®æ¯”è¼ƒ

ææ–™é–‹ç™ºã«ã¯æ­´å²çš„ã«3ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒã‚ã‚Šã¾ã™:

| ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ | ä¸»ãªæ‰‹æ³• | é•·æ‰€ | çŸ­æ‰€ | é–‹ç™ºæœŸé–“ |
|-----------|---------|------|------|---------|
| **ç†è«–é§†å‹•å‹** | ç¬¬ä¸€åŸç†è¨ˆç®—ã€ç†è«–ãƒ¢ãƒ‡ãƒ« | ç‰©ç†çš„æ ¹æ‹ ãŒæ˜ç¢º | è¤‡é›‘ç³»ã§ã¯è¨ˆç®—å›°é›£ | 5-10å¹´ |
| **çµŒé¨“é§†å‹•å‹** | è©¦è¡ŒéŒ¯èª¤ã€ç ”ç©¶è€…ã®ç›´æ„Ÿ | å®Ÿé¨“ã§ç›´æ¥æ¤œè¨¼ | ä½“ç³»çš„ãªçŸ¥è­˜è“„ç©ãŒå›°é›£ | 10-20å¹´ |
| **ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹(MI)** | æ©Ÿæ¢°å­¦ç¿’ã€çµ±è¨ˆè§£æ | å¤§é‡å€™è£œã‚’é«˜é€Ÿè©•ä¾¡ | ãƒ‡ãƒ¼ã‚¿ä¾å­˜ã€å¤–æŒ¿å›°é›£ | 2-5å¹´ |

> âš ï¸ **é‡è¦ãªæ³¨æ„ç‚¹**
>
> MIã¯ä¸‡èƒ½ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
> - è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²å¤–ã§ã¯ç²¾åº¦ãŒä½ä¸‹
> - åã£ãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã¯åã£ãŸãƒ¢ãƒ‡ãƒ«ãŒã§ãã‚‹
> - æœ€çµ‚çš„ãªå®Ÿé¨“æ¤œè¨¼ã¯ä¸å¯æ¬ 

---

### ğŸ“Š ã‚»ã‚¯ã‚·ãƒ§ãƒ³1ã®ã¾ã¨ã‚

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ**:
- âœ“ MIã¯ææ–™ç§‘å­¦ã¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®èåˆ
- âœ“ é–‹ç™ºæœŸé–“ã‚’2-5å¹´ã«çŸ­ç¸®å¯èƒ½(å¾“æ¥10-20å¹´)
- âœ“ ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§å¤§é‡å€™è£œã‚’åŠ¹ç‡è©•ä¾¡
- âœ“ å®Ÿé¨“ã‚’ç½®ãæ›ãˆã‚‹ã®ã§ã¯ãªãã€å”èª¿ã™ã‚‹

**æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¸**: æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤ã‚’å­¦ã³ã€MIã®å¿ƒè‡“éƒ¨ã‚’ç†è§£ã—ã¾ã™ â†’

---
**å­¦ç¿’é€²æ—**: â– â– â–¡â–¡â–¡â–¡â–¡â–¡â–¡â–¡ 10% (Section 1/10å®Œäº†)
**æ¨å®šæ®‹ã‚Šæ™‚é–“**: 5-8æ™‚é–“
---

## 2. æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤:MIã®å¿ƒè‡“éƒ¨

**ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å­¦ã¶ã“ã¨** (30åˆ†):
- ğŸ¤– æ©Ÿæ¢°å­¦ç¿’ã¨ã¯ä½•ã‹(æ–™ç†ã®æ¯”å–©ã§ç†è§£)
- ğŸ“ˆ æ•™å¸«ã‚ã‚Šå­¦ç¿’ã®æ•°å­¦çš„å®šç¾©ã¨å®Ÿè£…
- ğŸ”§ ä¸»è¦ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ¯”è¼ƒã¨é¸ã³æ–¹
- âš ï¸ æ©Ÿæ¢°å­¦ç¿’ã®é™ç•Œã¨æ³¨æ„ç‚¹

### 2.1 æ©Ÿæ¢°å­¦ç¿’ã¨ã¯?

**æ©Ÿæ¢°å­¦ç¿’(Machine Learning)**ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦äºˆæ¸¬ã‚’è¡Œã†æŠ€è¡“ã§ã™ã€‚

**æ¯”å–©ã§ç†è§£ã™ã‚‹:æ–™ç†ã®ãƒ¬ã‚·ãƒ”ä½œã‚Š**

å¤šãã®æ–™ç†ãƒ‡ãƒ¼ã‚¿(ææ–™ã®çµ„ã¿åˆã‚ã›ã¨å‘³)ã‹ã‚‰ã€ã€Œç¾å‘³ã—ã„æ–™ç†ã‚’ä½œã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ã‚’å­¦ç¿’ã—ã¾ã™ã€‚æ–°ã—ã„ææ–™ã®çµ„ã¿åˆã‚ã›ã§ã‚‚ã€éå»ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰å‘³ã‚’äºˆæ¸¬ã§ãã¾ã™ã€‚ã“ã‚ŒãŒæ©Ÿæ¢°å­¦ç¿’ã®åŸºæœ¬ã§ã™ã€‚

### 2.2 æ•™å¸«ã‚ã‚Šå­¦ç¿’:äºˆæ¸¬ã®åŸºæœ¬

MIã§æœ€ã‚‚ä½¿ã‚ã‚Œã‚‹ã®ãŒ**æ•™å¸«ã‚ã‚Šå­¦ç¿’(Supervised Learning)**ã§ã™ã€‚

**æ•°å­¦çš„å®šç¾©**:

å…¥åŠ›ç‰¹å¾´é‡ $\mathbf{x}$ ã‹ã‚‰å‡ºåŠ› $y$ ã‚’äºˆæ¸¬ã™ã‚‹é–¢æ•° $f$ ã‚’å­¦ç¿’ã—ã¾ã™:

$$
y = f(\mathbf{x}) + \epsilon
$$

*(æ•°å¼ã®èª¬æ˜: äºˆæ¸¬å€¤yã¯ã€å…¥åŠ›xã‚’é–¢æ•°fã§å¤‰æ›ã—ãŸå€¤ã«ã€èª¤å·®Îµã‚’åŠ ãˆãŸã‚‚ã®ã¨ã—ã¦è¡¨ã•ã‚Œã¾ã™)*

ã“ã“ã§ $\epsilon$ ã¯äºˆæ¸¬èª¤å·®ã§ã™ã€‚

**ææ–™ç§‘å­¦ã§ã®å…·ä½“ä¾‹**:

```python
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
# pip install numpy scikit-learn matminer pymatgen

import numpy as np
from sklearn.ensemble import RandomForestRegressor
from matminer.featurizers.composition import ElementProperty
from pymatgen.core import Composition

# Step 1: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
compositions = ["LiCoO2", "LiNiO2", "LiMnO2", "LiFePO4"]
capacities = [274, 275, 285, 170]  # ç†è«–å®¹é‡(mAh/g)

# Step 2: ç‰¹å¾´é‡ã®ç”Ÿæˆ(matminerã§è‡ªå‹•è¨ˆç®—)
featurizer = ElementProperty.from_preset("magpie")
X_train = []
for comp in compositions:
    features = featurizer.featurize(Composition(comp))
    X_train.append(features)
X_train = np.array(X_train)
y_train = np.array(capacities)

# Step 3: ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Step 4: æ–°ææ–™ã®äºˆæ¸¬
new_material = Composition("LiCoO2")
X_new = np.array([featurizer.featurize(new_material)])
predicted_capacity = model.predict(X_new)
print(f"äºˆæ¸¬å®¹é‡: {predicted_capacity[0]:.1f} mAh/g")
```

**å‡ºåŠ›ä¾‹**:
```
äºˆæ¸¬å®¹é‡: 274.3 mAh/g
```

> ğŸ’¡ **åˆå­¦è€…ã¸ã®ãƒ’ãƒ³ãƒˆ**
>
> ã“ã®ã‚³ãƒ¼ãƒ‰ã¯4ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å®Œçµ:
> 1. ãƒ‡ãƒ¼ã‚¿æº–å‚™(ææ–™åã¨å®¹é‡)
> 2. ç‰¹å¾´é‡è¨ˆç®—(ææ–™ã‚’æ•°å€¤åŒ–)
> 3. ãƒ¢ãƒ‡ãƒ«è¨“ç·´(ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’)
> 4. äºˆæ¸¬(æ–°ææ–™ã®å®¹é‡ã‚’æ¨å®š)

### 2.3 ä¸»è¦ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ¯”è¼ƒ

**å›³:ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é¸æŠã‚¬ã‚¤ãƒ‰**

```mermaid
graph TD
    Start[ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¯?] --> Small{50å€‹æœªæº€}
    Start --> Medium{50-500å€‹}
    Start --> Large{1000å€‹ä»¥ä¸Š}

    Small --> Linear[ç·šå½¢å›å¸°<br/>ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°]
    Medium --> RF[ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ<br/>å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°]
    Large --> DL[ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ<br/>GNN]

    style RF fill:#4caf50,stroke:#2e7d32,color:#fff
    style Linear fill:#2196f3,stroke:#1565c0,color:#fff
    style DL fill:#ff9800,stroke:#e65100,color:#fff
```

*å›³2: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«åŸºã¥ãã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã€‚åˆå­¦è€…ã¯ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã‹ã‚‰å§‹ã‚ã‚‹ã“ã¨ã‚’æ¨å¥¨ã€‚*

| ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  | MIä½¿ç”¨é »åº¦ | ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º | è§£é‡ˆå¯èƒ½æ€§ |
|------------|----------|------------|-----------|
| **ç·šå½¢å›å¸°** | â˜…â˜…â˜…â˜†â˜† | å°(10-50) | â˜…â˜…â˜…â˜…â˜… |
| **ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ** | â˜…â˜…â˜…â˜…â˜… | ä¸­(50-500) | â˜…â˜…â˜…â˜†â˜† |
| **ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°** | â˜…â˜…â˜…â˜…â˜† | å°-ä¸­(10-200) | â˜…â˜…â˜…â˜…â˜† |
| **ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ** | â˜…â˜…â˜…â˜†â˜† | å¤§(1000+) | â˜…â˜†â˜†â˜†â˜† |
| **ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ** | â˜…â˜…â˜…â˜…â˜† | å¤§(1000+) | â˜…â˜†â˜†â˜†â˜† |

<details>
<summary>ğŸ“Š è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º(è¨ˆç®—ã‚³ã‚¹ãƒˆå«ã‚€)</summary>

| ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  | ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º | è¨ˆç®—ã‚³ã‚¹ãƒˆ | è§£é‡ˆå¯èƒ½æ€§ | MIä½¿ç”¨é »åº¦ |
|------------|------------|----------|-----------|----------|
| **ç·šå½¢å›å¸°** | å°(10-50) | ä½ | â˜…â˜…â˜…â˜…â˜… | â˜…â˜…â˜…â˜†â˜† |
| **ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ** | ä¸­(50-500) | ä¸­ | â˜…â˜…â˜…â˜†â˜† | â˜…â˜…â˜…â˜…â˜… |
| **ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°** | å°-ä¸­(10-200) | é«˜ | â˜…â˜…â˜…â˜…â˜† | â˜…â˜…â˜…â˜…â˜† |
| **ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ** | å¤§(1000+) | é«˜ | â˜…â˜†â˜†â˜†â˜† | â˜…â˜…â˜…â˜†â˜† |
| **ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ** | å¤§(1000+) | éå¸¸ã«é«˜ | â˜…â˜†â˜†â˜†â˜† | â˜…â˜…â˜…â˜…â˜† |

</details>

> ğŸ’¡ **åˆå¿ƒè€…ã¸ã®æ¨å¥¨**
>
> ã¾ãšã¯**ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ**ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†ã€‚
> - éå­¦ç¿’ã—ã«ãã„
> - éç·šå½¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚‚æ‰ãˆã‚‰ã‚Œã‚‹
> - ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚‚åˆ†æã§ãã‚‹

### 2.4 æ©Ÿæ¢°å­¦ç¿’ã®é™ç•Œã¨æ³¨æ„ç‚¹

âš ï¸ **ã‚ˆãã‚ã‚‹èª¤è§£**: ã€Œæ©Ÿæ¢°å­¦ç¿’ã¯ä¸‡èƒ½ã§ã€ã©ã‚“ãªå•é¡Œã‚‚è§£ã‘ã‚‹ã€

**ç¾å®Ÿ**:

**1. å¤–æŒ¿ã®å›°é›£æ€§**

è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²å¤–(ä¾‹: èç‚¹300-1000 Kã§è¨“ç·´ â†’ 2000 Kã®äºˆæ¸¬)ã¯ç²¾åº¦ãŒä½ã„

**2. ãƒ‡ãƒ¼ã‚¿ä¾å­˜**

åã£ãŸãƒ‡ãƒ¼ã‚¿ã‚„èª¤å·®ã®å¤§ãã„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã¯è‰¯ã„ãƒ¢ãƒ‡ãƒ«ãŒä½œã‚Œãªã„

**3. ç‰©ç†æ³•å‰‡ã®ç„¡è¦–**

ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ãªã—ã«æ§‹ç¯‰ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ç†±åŠ›å­¦çš„ã«ä¸å¯èƒ½ãªææ–™ã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ãŒã‚ã‚‹

**å¯¾ç­–**:
- âœ“ äºˆæ¸¬ã¯è¨“ç·´ç¯„å›²å†…ã«é™å®š
- âœ“ å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚æ¤œè¨¼ã‚’å¿…ãšå®Ÿæ–½
- âœ“ ææ–™ç§‘å­¦ã®çŸ¥è­˜ã‚’ãƒ¢ãƒ‡ãƒ«ã«çµ±åˆ(ç‰©ç†çš„åˆ¶ç´„ã®å°å…¥)

---

### ğŸ“Š ã‚»ã‚¯ã‚·ãƒ§ãƒ³2ã®ã¾ã¨ã‚

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ**:
- âœ“ æ©Ÿæ¢°å­¦ç¿’ã¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã¦äºˆæ¸¬
- âœ“ æ•™å¸«ã‚ã‚Šå­¦ç¿’: $y = f(\mathbf{x}) + \epsilon$
- âœ“ ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã§ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é¸ã¶
- âœ“ ä¸‡èƒ½ã§ã¯ãªã„ - å¤–æŒ¿ã€ãƒ‡ãƒ¼ã‚¿å“è³ªã€ç‰©ç†æ³•å‰‡ã®åˆ¶ç´„ã‚ã‚Š

**æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¸**: ææ–™ãƒ‡ãƒ¼ã‚¿ã®ç†è§£ã¨å‰å‡¦ç†ã®å®Ÿè·µ â†’

---
**å­¦ç¿’é€²æ—**: â– â– â– â–¡â–¡â–¡â–¡â–¡â–¡â–¡ 20% (Section 2/10å®Œäº†)
**æ¨å®šæ®‹ã‚Šæ™‚é–“**: 4-7æ™‚é–“
---

## 3. ææ–™ãƒ‡ãƒ¼ã‚¿ã®ç†è§£ã¨å‰å‡¦ç†

**ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å­¦ã¶ã“ã¨** (40åˆ†):
- ğŸ“¦ ææ–™ãƒ‡ãƒ¼ã‚¿ã®ç‰¹æ€§(å°è¦æ¨¡ã€é«˜æ¬¡å…ƒã€ä¸å‡è¡¡)
- ğŸŒ Materials Projectã®ä½¿ã„æ–¹(APIã‚­ãƒ¼å–å¾—ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ã¾ã§)
- ğŸ”¢ ææ–™è¨˜è¿°å­(descriptor)ã®ç¨®é¡ã¨è¨ˆç®—æ–¹æ³•
- ğŸ§¹ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 3.1 ææ–™ãƒ‡ãƒ¼ã‚¿ã®ç‰¹æ€§

ææ–™ç§‘å­¦ãƒ‡ãƒ¼ã‚¿ã¯ã€ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚„è‡ªç„¶è¨€èªãƒ‡ãƒ¼ã‚¿ã¨å¤§ããç•°ãªã‚‹ç‰¹æ€§ã‚’æŒã¡ã¾ã™:

**ç‰¹å¾´1: å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿**

- å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿: é€šå¸¸10-100ã‚µãƒ³ãƒ—ãƒ«(é«˜ã‚³ã‚¹ãƒˆ)
- ç”»åƒèªè­˜: æ•°ç™¾ä¸‡ã‚µãƒ³ãƒ—ãƒ«
- **å¯¾ç­–**: è»¢ç§»å­¦ç¿’ã€ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã€ç¬¬ä¸€åŸç†è¨ˆç®—ãƒ‡ãƒ¼ã‚¿ã§ã®è£œå®Œ[^7]

**ç‰¹å¾´2: é«˜æ¬¡å…ƒç‰¹å¾´é‡**

- çµæ™¶æ§‹é€ : åŸå­åº§æ¨™ã€æ ¼å­å®šæ•°ã€ç©ºé–“ç¾¤ãªã©æ•°ç™¾ã®å¤‰æ•°
- **å¯¾ç­–**: ç‰¹å¾´é‡é¸æŠã€æ¬¡å…ƒå‰Šæ¸›(PCA)

**ç‰¹å¾´3: ä¸å‡è¡¡ãªãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ**

- å®‰å®šææ–™ã¯å¤šã„ãŒã€ç‰¹ç•°ãªç‰©æ€§ã‚’æŒã¤ææ–™ã¯å°‘ãªã„
- **å¯¾ç­–**: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã€é‡ã¿ä»˜ã‘å­¦ç¿’

### 3.2 ææ–™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ´»ç”¨

#### Materials Projectã®ä½¿ã„æ–¹

Materials Projectã¯ã€14ä¸‡ä»¥ä¸Šã®ç„¡æ©ŸåŒ–åˆç‰©ã®è¨ˆç®—ææ–™ç‰©æ€§ãƒ‡ãƒ¼ã‚¿ã‚’æä¾›ã™ã‚‹æœ€å¤§ç´šã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã™[^3]ã€‚

```python
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
# pip install mp-api pymatgen

from mp_api.client import MPRester
import os

# APIã‚­ãƒ¼ã®å–å¾—ã¨è¨­å®š
# æ–¹æ³•1: ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿(æ¨å¥¨)
api_key = os.getenv("MP_API_KEY")

if not api_key:
    print("âš ï¸ Materials Project APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    print("\nã€APIã‚­ãƒ¼å–å¾—æ–¹æ³•ã€‘:")
    print("1. https://materialsproject.org/api ã«ã‚¢ã‚¯ã‚»ã‚¹")
    print("2. ç„¡æ–™ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ(30ç§’)")
    print("3. API Keyã‚’ã‚³ãƒ”ãƒ¼")
    print("4. ç’°å¢ƒå¤‰æ•°ã«è¨­å®š: export MP_API_KEY='your_key_here'")
    print("\nã€ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã€‘ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§å®Ÿè¡Œã—ã¾ã™\n")

    # ãƒ‡ãƒ¢ç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
    docs_demo = [
        {"formula_pretty": "LiCoO2", "band_gap": 2.20, "formation_energy_per_atom": -2.194},
        {"formula_pretty": "Li2CoO3", "band_gap": 3.12, "formation_energy_per_atom": -2.456},
        {"formula_pretty": "LiCo2O4", "band_gap": 1.85, "formation_energy_per_atom": -1.987}
    ]

    for doc in docs_demo:
        print(f"{doc['formula_pretty']}: "
              f"Band Gap = {doc['band_gap']:.2f} eV, "
              f"Formation Energy = {doc['formation_energy_per_atom']:.3f} eV/atom")
else:
    # å®Ÿéš›ã®APIå‘¼ã³å‡ºã—
    with MPRester(api_key) as mpr:
        # Li-Co-Oç³»ã®ææ–™ã‚’æ¤œç´¢
        docs = mpr.materials.summary.search(
            elements=["Li", "Co", "O"],
            num_elements=(3, 3),  # 3å…ƒç´ ç³»ã®ã¿
            fields=["material_id", "formula_pretty", "band_gap", "formation_energy_per_atom"]
        )

        for doc in docs[:5]:  # æœ€åˆã®5ä»¶
            print(f"{doc.formula_pretty}: "
                  f"Band Gap = {doc.band_gap:.2f} eV, "
                  f"Formation Energy = {doc.formation_energy_per_atom:.3f} eV/atom")
```

**å‡ºåŠ›ä¾‹**:
```
LiCoO2: Band Gap = 2.20 eV, Formation Energy = -2.194 eV/atom
Li2CoO3: Band Gap = 3.12 eV, Formation Energy = -2.456 eV/atom
LiCo2O4: Band Gap = 1.85 eV, Formation Energy = -1.987 eV/atom
```

> ğŸ’¡ **åˆå­¦è€…ã¸ã®ãƒ’ãƒ³ãƒˆ**
>
> APIã‚­ãƒ¼ãŒãªãã¦ã‚‚ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§å­¦ç¿’ã§ãã¾ã™ã€‚
> å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€ç„¡æ–™ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã—ã¦APIã‚­ãƒ¼ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚

#### ä¸»è¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ¯”è¼ƒ

| ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ | è¦æ¨¡ | ä¸»ãªç‰©æ€§ | åˆå¿ƒè€…å‘ã‘ |
|------------|------|---------|----------|
| **Materials Project** | 14ä¸‡+ | å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã€ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã€å¼¾æ€§å®šæ•° | â˜…â˜…â˜…â˜…â˜… |
| **OQMD** | 100ä¸‡+ | å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã€å®‰å®šæ€§ | â˜…â˜…â˜…â˜…â˜† |
| **AFLOW** | 300ä¸‡+ | ç†±åŠ›å­¦ã€å¼¾æ€§ã€é›»å­æ§‹é€  | â˜…â˜…â˜…â˜†â˜† |
| **NOMAD** | 1å„„è¨ˆç®—+ | DFTå‡ºåŠ›ã€MDè»Œè·¡ | â˜…â˜…â˜…â˜†â˜† |

### 3.3 ææ–™è¨˜è¿°å­(Descriptor)

æ©Ÿæ¢°å­¦ç¿’ã¯æ•°å€¤ã—ã‹æ‰±ãˆãªã„ãŸã‚ã€ææ–™ã‚’**è¨˜è¿°å­(Descriptor)**ã§æ•°å€¤åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

#### è¨˜è¿°å­ã®ç¨®é¡

##### 1. çµ„æˆè¨˜è¿°å­(Compositional Descriptors)

å…ƒç´ ã®ç‰©ç†åŒ–å­¦çš„æ€§è³ªã‹ã‚‰è¨ˆç®—:

$$
\text{å¹³å‡åŸå­ç•ªå·} = \sum_{i} x_i Z_i
$$

*(æ•°å¼ã®èª¬æ˜: å¹³å‡åŸå­ç•ªå·ã¯ã€å„å…ƒç´ ã®ãƒ¢ãƒ«åˆ†ç‡x_iã¨åŸå­ç•ªå·Z_iã®ç©ã®ç·å’Œã¨ã—ã¦è¨ˆç®—ã•ã‚Œã¾ã™)*

ã“ã“ã§ $x_i$ ã¯å…ƒç´  $i$ ã®ãƒ¢ãƒ«åˆ†ç‡ã€$Z_i$ ã¯åŸå­ç•ªå·ã§ã™ã€‚

**ä¾‹**: LiCoO2
- Li(Z=3), Co(Z=27), O(Z=8)
- å¹³å‡åŸå­ç•ªå· = (1Ã—3 + 1Ã—27 + 2Ã—8) / 4 = 11.5

##### 2. æ§‹é€ è¨˜è¿°å­(Structural Descriptors)

çµæ™¶æ§‹é€ ã‹ã‚‰è¨ˆç®—:
- æ ¼å­å®šæ•°(a, b, c)
- çµåˆé•·
- é…ä½æ•°
- ç©ºé–“ç¾¤ç•ªå·

##### 3. é›»å­çš„è¨˜è¿°å­(Electronic Descriptors)

DFTè¨ˆç®—ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹:
- çŠ¶æ…‹å¯†åº¦(DOS)
- ãƒãƒ³ãƒ‰æ§‹é€ 
- é›»è·åˆ†å¸ƒ

#### matminerã«ã‚ˆã‚‹è‡ªå‹•è¨˜è¿°å­è¨ˆç®—

```python
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
# pip install matminer pymatgen mp-api

from matminer.featurizers.composition import ElementProperty, Stoichiometry
from matminer.featurizers.structure import SiteStatsFingerprint
from pymatgen.core import Composition, Structure, Lattice
import numpy as np

# çµ„æˆè¨˜è¿°å­ã®ä¾‹
comp = Composition("Fe2O3")
featurizer_comp = ElementProperty.from_preset("magpie")
features_comp = featurizer_comp.featurize(comp)
feature_labels = featurizer_comp.feature_labels()

print(f"çµ„æˆè¨˜è¿°å­æ•°: {len(features_comp)}")
print(f"ä¾‹: {feature_labels[0]} = {features_comp[0]:.3f}")

# çµæ™¶æ§‹é€ è¨˜è¿°å­ã®ä¾‹(CIFãƒ•ã‚¡ã‚¤ãƒ«ä¸è¦ã«ã™ã‚‹)
print("\nçµæ™¶æ§‹é€ è¨˜è¿°å­ã®è¨ˆç®—:")

# æ–¹æ³•1: Materials Projectã‹ã‚‰å–å¾—(APIã‚­ãƒ¼ãŒã‚ã‚‹å ´åˆ)
try:
    from mp_api.client import MPRester
    api_key = os.getenv("MP_API_KEY")
    if api_key:
        with MPRester(api_key) as mpr:
            structure = mpr.get_structure_by_material_id("mp-19770")  # Fe2O3
        print("Materials Projectã‹ã‚‰æ§‹é€ ã‚’å–å¾—ã—ã¾ã—ãŸ")
    else:
        raise ValueError("APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“")
except:
    # æ–¹æ³•2: ã‚³ãƒ¼ãƒ‰ã§ç›´æ¥æ§‹ç¯‰(åˆå­¦è€…ã«ã‚‚å®Ÿè¡Œå¯èƒ½)
    print("æ§‹é€ ã‚’ç›´æ¥ç”Ÿæˆã—ã¾ã™(APIã‚­ãƒ¼ä¸è¦)")

    # Fe2O3(hematite)ã®ç°¡ç•¥æ§‹é€ ã‚’æ‰‹å‹•å®šç¾©
    lattice = Lattice.hexagonal(a=5.035, c=13.747)
    species = ["Fe", "Fe", "Fe", "Fe", "O", "O", "O", "O", "O", "O"]
    coords = [
        [0, 0, 0.355], [0, 0, 0.855], [0.333, 0.667, 0.522], [0.667, 0.333, 0.022],
        [0.306, 0, 0.25], [0, 0.306, 0.25], [0.694, 0.694, 0.25],
        [0.694, 0, 0.75], [0, 0.694, 0.75], [0.306, 0.306, 0.75]
    ]
    structure = Structure(lattice, species, coords)

featurizer_struct = SiteStatsFingerprint.from_preset("CrystalNNFingerprint_ops")
features_struct = featurizer_struct.featurize(structure)

print(f"æ§‹é€ è¨˜è¿°å­æ•°: {len(features_struct)}")
```

**å‡ºåŠ›ä¾‹**:
```
çµ„æˆè¨˜è¿°å­æ•°: 132
ä¾‹: MagpieData mean AtomicWeight = 36.267

çµæ™¶æ§‹é€ è¨˜è¿°å­ã®è¨ˆç®—:
æ§‹é€ ã‚’ç›´æ¥ç”Ÿæˆã—ã¾ã™(APIã‚­ãƒ¼ä¸è¦)
æ§‹é€ è¨˜è¿°å­æ•°: 61
```

### 3.4 ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

#### 1. å¤–ã‚Œå€¤ã®æ¤œå‡ºã¨é™¤å»

```python
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
# pip install pandas numpy

import pandas as pd
import numpy as np

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ(CSVãƒ•ã‚¡ã‚¤ãƒ«ä¸è¦)
np.random.seed(42)
n_samples = 100

df = pd.DataFrame({
    "composition": [f"Material_{i}" for i in range(n_samples)],
    "formation_energy": np.random.normal(-2.0, 0.5, n_samples)
})

# æ„å›³çš„ã«å¤–ã‚Œå€¤ã‚’è¿½åŠ 
df.loc[5, "formation_energy"] = -10.0  # å¤–ã‚Œå€¤
df.loc[50, "formation_energy"] = 5.0   # å¤–ã‚Œå€¤

print("å…ƒã®ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ:")
print(df["formation_energy"].describe())

# å››åˆ†ä½ç¯„å›²(IQR)æ³•ã«ã‚ˆã‚‹å¤–ã‚Œå€¤æ¤œå‡º
Q1 = df["formation_energy"].quantile(0.25)
Q3 = df["formation_energy"].quantile(0.75)
IQR = Q3 - Q1

# å¤–ã‚Œå€¤ã®é™¤å»
outlier_mask = (df["formation_energy"] < Q1 - 1.5*IQR) | \
               (df["formation_energy"] > Q3 + 1.5*IQR)
df_clean = df[~outlier_mask]

print(f"\né™¤å»å‰: {len(df)} ã‚µãƒ³ãƒ—ãƒ«")
print(f"é™¤å»å¾Œ: {len(df_clean)} ã‚µãƒ³ãƒ—ãƒ« ({len(df) - len(df_clean)} å€‹ã®å¤–ã‚Œå€¤ã‚’é™¤å»)")
print(f"é™¤å»ã•ã‚ŒãŸå¤–ã‚Œå€¤: {df.loc[outlier_mask, 'formation_energy'].values}")
```

> âš ï¸ **æ³¨æ„: å¤–ã‚Œå€¤é™¤å»ã®ãƒªã‚¹ã‚¯**
>
> æ©Ÿæ¢°çš„ãªé™¤å»ã¯å±é™ºã§ã™ã€‚é™¤å»å‰ã«ä»¥ä¸‹ã‚’ç¢ºèª:
> - æ¸¬å®š/è¨ˆç®—ã‚¨ãƒ©ãƒ¼ã‹?
> - æœ¬å½“ã«ç‰¹ç•°ãªææ–™ã‹?
> - ç‰©ç†çš„ã«ã‚ã‚Šå¾—ãªã„å€¤ã‹?

#### 2. æ­£è¦åŒ–(Normalization)

ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒ«ã®ç‰¹å¾´é‡ã‚’0-1ã®ç¯„å›²ã«æ­£è¦åŒ–:

$$
x_{\text{norm}} = \frac{x - x_{\min}}{x_{\max} - x_{\min}}
$$

*(æ•°å¼ã®èª¬æ˜: æ­£è¦åŒ–ã¯ã€å…ƒã®å€¤xã‹ã‚‰æœ€å°å€¤ã‚’å¼•ãã€æœ€å¤§å€¤ã¨æœ€å°å€¤ã®å·®ã§å‰²ã‚‹ã“ã¨ã§ã€0ã‹ã‚‰1ã®ç¯„å›²ã«å¤‰æ›ã—ã¾ã™)*

```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_normalized = scaler.fit_transform(X)
```

#### 3. æ¬ æå€¤ã®å‡¦ç†

```python
# å¹³å‡å€¤ã§è£œå®Œ
df["band_gap"].fillna(df["band_gap"].mean(), inplace=True)

# ã¾ãŸã¯ã€æ¬ æå€¤ã‚’å«ã‚€è¡Œã‚’å‰Šé™¤
df_complete = df.dropna()
```

---

### ğŸ“Š ã‚»ã‚¯ã‚·ãƒ§ãƒ³3ã®ã¾ã¨ã‚

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ**:
- âœ“ ææ–™ãƒ‡ãƒ¼ã‚¿ã¯å°è¦æ¨¡ãƒ»é«˜æ¬¡å…ƒãƒ»ä¸å‡è¡¡
- âœ“ Materials Projectã§14ä¸‡ä»¥ä¸Šã®ææ–™ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
- âœ“ è¨˜è¿°å­ã§ææ–™ã‚’æ•°å€¤åŒ–(çµ„æˆã€æ§‹é€ ã€é›»å­çš„)
- âœ“ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†: å¤–ã‚Œå€¤é™¤å»ã€æ­£è¦åŒ–ã€æ¬ æå€¤å‡¦ç†

**æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¸**: æ•™å¸«ã‚ã‚Šå­¦ç¿’ã§ææ–™ç‰©æ€§ã‚’äºˆæ¸¬ â†’

---
**å­¦ç¿’é€²æ—**: â– â– â– â– â–¡â–¡â–¡â–¡â–¡â–¡ 30% (Section 3/10å®Œäº†)
**æ¨å®šæ®‹ã‚Šæ™‚é–“**: 3-6æ™‚é–“
---

## 4. æ•™å¸«ã‚ã‚Šå­¦ç¿’ã«ã‚ˆã‚‹ææ–™ç‰©æ€§äºˆæ¸¬

**ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å­¦ã¶ã“ã¨** (50åˆ†):
- ğŸ¯ å›å¸°å•é¡Œ: å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ã®å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- ğŸ·ï¸ åˆ†é¡å•é¡Œ: é‡‘å±ãƒ»éé‡‘å±ã®åˆ¤åˆ¥
- ğŸ“Š æ€§èƒ½è©•ä¾¡æŒ‡æ¨™(MAE, RMSE, RÂ², Precision, Recall)
- ğŸ” éå­¦ç¿’ã®è¨ºæ–­ã¨å¯¾ç­–

### 4.1 å›å¸°å•é¡Œ:å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã®äºˆæ¸¬

å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼(Formation Energy)ã¯ã€ææ–™ã®ç†±åŠ›å­¦çš„å®‰å®šæ€§ã‚’ç¤ºã™é‡è¦ãªæŒ‡æ¨™ã§ã™ã€‚

$$
E_{\text{form}} = E_{\text{compound}} - \sum_i n_i E_i^{\text{element}}
$$

*(æ•°å¼ã®èª¬æ˜: å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã¯ã€åŒ–åˆç‰©ã®å…¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‹ã‚‰ã€å„æ§‹æˆå…ƒç´ i(å€‹æ•°n_i)ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®åˆè¨ˆã‚’å¼•ã„ãŸå€¤ã¨ã—ã¦è¨ˆç®—ã•ã‚Œã¾ã™)*

ã“ã“ã§ $E_{\text{compound}}$ ã¯åŒ–åˆç‰©ã®å…¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ã€$E_i^{\text{element}}$ ã¯å…ƒç´  $i$ ã®åŸºæº–ã‚¨ãƒãƒ«ã‚®ãƒ¼ã§ã™ã€‚

#### Step 1-2: ãƒ‡ãƒ¼ã‚¿æº–å‚™ã¨ç‰¹å¾´é‡ç”Ÿæˆ

```python
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
# pip install pandas numpy matminer scikit-learn matplotlib

import pandas as pd
import numpy as np
from matminer.datasets import load_dataset
from matminer.featurizers.composition import ElementProperty
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt

# Step 1: ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿(matminerå†…è”µãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ)
df = load_dataset("formation_energy")
print(f"ãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}")
print(df.head())

# Step 2: ç‰¹å¾´é‡ã®ç”Ÿæˆ
featurizer = ElementProperty.from_preset("magpie")
df["features"] = df["composition"].apply(lambda x: featurizer.featurize(x))
```

ğŸ’¡ **ã“ã“ã¾ã§ã§é”æˆ**: ææ–™ã‚’æ©Ÿæ¢°å­¦ç¿’ãŒç†è§£ã§ãã‚‹æ•°å€¤ã«å¤‰æ›

#### Step 3-4: ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã¨è©•ä¾¡

```python
# Step 3: è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
X = np.array(df["features"].tolist())
y = df["formation_energy_per_atom"].values

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)} ã‚µãƒ³ãƒ—ãƒ«")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test)} ã‚µãƒ³ãƒ—ãƒ«")

# Step 4: ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
model = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42)
model.fit(X_train, y_train)
```

ğŸ’¡ **ã“ã“ã¾ã§ã§é”æˆ**: äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰å®Œäº†

#### Step 5-6: æ€§èƒ½è©•ä¾¡ã¨å¯è¦–åŒ–

> ğŸ“± **ãƒ¢ãƒã‚¤ãƒ«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸**:
> ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯é•·ã„ãŸã‚ã€æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™ã€‚
> ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã¾ãŸã¯ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆã§ã®é–²è¦§ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

```python
# Step 5: æ€§èƒ½è©•ä¾¡
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"\næ€§èƒ½è©•ä¾¡:")
print(f"MAE (Mean Absolute Error): {mae:.3f} eV/atom")
print(f"RÂ² Score: {r2:.3f}")

# Step 6: äº¤å·®æ¤œè¨¼
cv_scores = cross_val_score(
    model, X_train, y_train, cv=5,
    scoring='neg_mean_absolute_error',
    random_state=42
)
print(f"5-Fold CV MAE: {-cv_scores.mean():.3f} Â± {cv_scores.std():.3f} eV/atom")

# Step 7: çµæœã®å¯è¦–åŒ–
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],
         'r--', lw=2, label='Perfect prediction')
plt.xlabel("Actual Formation Energy (eV/atom)")
plt.ylabel("Predicted Formation Energy (eV/atom)")
plt.title(f"Formation Energy Prediction (RÂ² = {r2:.3f})")
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig("formation_energy_prediction.png", dpi=300)
plt.show()
```

ğŸ’¡ **æœ€çµ‚æˆæœ**: MAE 0.187 eV/atom ã®é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«

**å‡ºåŠ›ä¾‹**:
```
ãƒ‡ãƒ¼ã‚¿æ•°: 3938
è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 3150 ã‚µãƒ³ãƒ—ãƒ«
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 788 ã‚µãƒ³ãƒ—ãƒ«

æ€§èƒ½è©•ä¾¡:
MAE (Mean Absolute Error): 0.187 eV/atom
RÂ² Score: 0.876
5-Fold CV MAE: 0.195 Â± 0.012 eV/atom
```

> âœ… **ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™!**
>
> å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã€RÂ² = 0.876 ã®ç²¾åº¦ã‚’é”æˆã—ã¾ã—ãŸã€‚
> ã“ã‚Œã¯å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã®æ€§èƒ½ã§ã™ã€‚

### 4.2 åˆ†é¡å•é¡Œ:é‡‘å±ãƒ»éé‡‘å±ã®åˆ¤åˆ¥

ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ãŒ0 eVã®ææ–™ã¯é‡‘å±ã€> 0 eVã®ææ–™ã¯éé‡‘å±ã§ã™ã€‚

```python
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
# pip install seaborn

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
df_gap = load_dataset("band_gap")
df_gap["is_metal"] = (df_gap["band_gap"] == 0).astype(int)  # 0=éé‡‘å±, 1=é‡‘å±

# ç‰¹å¾´é‡ç”Ÿæˆ
featurizer = ElementProperty.from_preset("magpie")
X = np.array([featurizer.featurize(comp) for comp in df_gap["composition"]])
y = df_gap["is_metal"].values

# è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# æ±ºå®šæœ¨åˆ†é¡å™¨ã®è¨“ç·´
clf = DecisionTreeClassifier(max_depth=10, random_state=42)
clf.fit(X_train, y_train)

# äºˆæ¸¬ã¨è©•ä¾¡
y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred, target_names=["Non-metal", "Metal"]))

# æ··åŒè¡Œåˆ—ã®å¯è¦–åŒ–
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=["Non-metal", "Metal"],
            yticklabels=["Non-metal", "Metal"])
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.title("Confusion Matrix: Metallic Classification")
plt.tight_layout()
plt.savefig("metallic_classification.png", dpi=300)
plt.show()
```

### 4.3 ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½è©•ä¾¡æŒ‡æ¨™

#### å›å¸°å•é¡Œã®æŒ‡æ¨™

**1. Mean Absolute Error (MAE)**

$$
\text{MAE} = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|
$$

*(æ•°å¼ã®èª¬æ˜: MAEã¯ã€å®Ÿæ¸¬å€¤y_iã¨äºˆæ¸¬å€¤y_hatã®å·®ã®çµ¶å¯¾å€¤ã‚’ã€å…¨ã‚µãƒ³ãƒ—ãƒ«nã§å¹³å‡ã—ãŸå€¤ã§ã™)*

**è§£é‡ˆ**: äºˆæ¸¬å€¤ã¨å®Ÿæ¸¬å€¤ã®å¹³å‡çš„ãªèª¤å·®ã€‚ä¾‹: MAE = 0.2 eV/atom â†’ äºˆæ¸¬ã¯å¹³å‡Â±0.2 eVã®èª¤å·®

**2. Root Mean Square Error (RMSE)**

$$
\text{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}
$$

*(æ•°å¼ã®èª¬æ˜: RMSEã¯ã€èª¤å·®ã®äºŒä¹—å¹³å‡ã®å¹³æ–¹æ ¹ã§ã™ã€‚å¤§ããªèª¤å·®ã«æ•æ„Ÿã«åå¿œã—ã¾ã™)*

**è§£é‡ˆ**: MAEã‚ˆã‚Šå¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’å—ã‘ã‚„ã™ã„ã€‚å¤§ããªèª¤å·®ã«ãƒšãƒŠãƒ«ãƒ†ã‚£

**3. RÂ² Score(æ±ºå®šä¿‚æ•°)**

$$
R^2 = 1 - \frac{\sum_i(y_i - \hat{y}_i)^2}{\sum_i(y_i - \bar{y})^2}
$$

*(æ•°å¼ã®èª¬æ˜: RÂ²ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ãŒãƒ‡ãƒ¼ã‚¿ã®ã°ã‚‰ã¤ãã‚’ã©ã‚Œã ã‘èª¬æ˜ã§ãã‚‹ã‹ã‚’ç¤ºã™æŒ‡æ¨™ã§ã™)*

**è§£é‡ˆ**:
- RÂ² = 1.0: å®Œç’§ãªäºˆæ¸¬
- RÂ² = 0.9: éå¸¸ã«è‰¯ã„
- RÂ² = 0.7-0.9: è‰¯ã„
- RÂ² < 0.5: æ”¹å–„ãŒå¿…è¦

#### åˆ†é¡å•é¡Œã®æŒ‡æ¨™

**æ··åŒè¡Œåˆ—(Confusion Matrix)**:

|  | äºˆæ¸¬: Positive | äºˆæ¸¬: Negative |
|--|--------------|--------------|
| **å®Ÿéš›: Positive** | TP(True Positive) | FN(False Negative) |
| **å®Ÿéš›: Negative** | FP(False Positive) | TN(True Negative) |

**ç²¾åº¦(Accuracy)**:

$$
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
$$

*(æ•°å¼ã®èª¬æ˜: å…¨äºˆæ¸¬ã®ã†ã¡ã€æ­£ã—ãäºˆæ¸¬ã§ããŸå‰²åˆ)*

**é©åˆç‡(Precision)**:

$$
\text{Precision} = \frac{TP}{TP + FP}
$$

*(æ•°å¼ã®èª¬æ˜: Positiveã¨äºˆæ¸¬ã—ãŸã†ã¡ã€å®Ÿéš›ã«Positiveã ã£ãŸå‰²åˆ)*

**å†ç¾ç‡(Recall)**:

$$
\text{Recall} = \frac{TP}{TP + FN}
$$

*(æ•°å¼ã®èª¬æ˜: å®Ÿéš›ã®Positiveã®ã†ã¡ã€æ­£ã—ãæ¤œå‡ºã§ããŸå‰²åˆ)*

### 4.4 éå­¦ç¿’ã®è¨ºæ–­ã¨å¯¾ç­–

âš ï¸ **éå­¦ç¿’(Overfitting)**: ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’æš—è¨˜ã—ã¦ã—ã¾ã„ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ç¾è±¡

**è¨ºæ–­æ–¹æ³•**:

```python
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯æ—¢ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¸ˆã¿
# æ³¨: ã“ã®ã‚³ãƒ¼ãƒ‰ã¯Section 4.1ã®å¾Œã«å®Ÿè¡Œã—ã¦ãã ã•ã„

from sklearn.model_selection import learning_curve

# å­¦ç¿’æ›²ç·šã®è¨ˆç®—
train_sizes, train_scores, val_scores = learning_curve(
    model, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 10),
    scoring='neg_mean_absolute_error',
    random_state=42
)

# å¯è¦–åŒ–
plt.figure(figsize=(8, 6))
plt.plot(train_sizes, -train_scores.mean(axis=1), 'o-', label='Training error')
plt.plot(train_sizes, -val_scores.mean(axis=1), 's-', label='Validation error')
plt.xlabel("Training examples")
plt.ylabel("MAE (eV/atom)")
plt.title("Learning Curve: Overfitting Diagnosis")
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

**åˆ¤æ–­åŸºæº–**:
- è¨“ç·´èª¤å·® â†“â†“ ã‹ã¤ æ¤œè¨¼èª¤å·® â†‘ â†’ **éå­¦ç¿’**
- ä¸¡æ–¹â†“ â†’ é©åˆ‡ãªå­¦ç¿’
- ä¸¡æ–¹é«˜ã„ â†’ **éå°‘å­¦ç¿’(underfitting)**(ãƒ¢ãƒ‡ãƒ«ãŒå˜ç´”ã™ãã‚‹)

**å¯¾ç­–**:

**1. æ­£å‰‡åŒ–(Regularization)**

```python
from sklearn.linear_model import Ridge

# L2æ­£å‰‡åŒ–
model = Ridge(alpha=1.0)  # alphaãŒå¤§ãã„ã»ã©æ­£å‰‡åŒ–ãŒå¼·ã„
```

**2. äº¤å·®æ¤œè¨¼(Cross-Validation)**

```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')
print(f"CV MAE: {-scores.mean():.3f} Â± {scores.std():.3f}")
```

**3. æ—©æœŸåœæ­¢(Early Stopping)**(ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã§ä½¿ç”¨)

**4. ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ**
- ç¬¬ä¸€åŸç†è¨ˆç®—ãƒ‡ãƒ¼ã‚¿ã§è£œå®Œ
- è»¢ç§»å­¦ç¿’ã®æ´»ç”¨

---

### ğŸ“Š ã‚»ã‚¯ã‚·ãƒ§ãƒ³4ã®ã¾ã¨ã‚

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ**:
- âœ“ å›å¸°: å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ã§ RÂ² = 0.876 é”æˆ
- âœ“ åˆ†é¡: é‡‘å±ãƒ»éé‡‘å±åˆ¤åˆ¥ã§æ··åŒè¡Œåˆ—ã‚’æ´»ç”¨
- âœ“ è©•ä¾¡æŒ‡æ¨™: MAE, RMSE, RÂ², Precision, Recall
- âœ“ éå­¦ç¿’è¨ºæ–­: å­¦ç¿’æ›²ç·šã§è¨“ç·´èª¤å·®ã¨æ¤œè¨¼èª¤å·®ã‚’æ¯”è¼ƒ

**æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¸**: ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨GNNã®åŸºç¤ â†’

---
**å­¦ç¿’é€²æ—**: â– â– â– â– â– â–¡â–¡â–¡â–¡â–¡ 40% (Section 4/10å®Œäº†)
**æ¨å®šæ®‹ã‚Šæ™‚é–“**: 2-5æ™‚é–“
---

## 5. ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯

> âš ï¸ **ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦**
>
> ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯**ã‚„ã‚„é«˜åº¦ãªå†…å®¹**ã‚’å«ã¿ã¾ã™ã€‚
> åˆã‚ã¦èª­ã‚€æ–¹ã¯ã€Section 6(ãƒ™ã‚¤ã‚ºæœ€é©åŒ–)ã«é€²ã‚“ã§ã‹ã‚‰æˆ»ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚
>
> **å‰æçŸ¥è­˜**: ç·šå½¢ä»£æ•°ã€å¾®åˆ†ã€Section 2-4ã®å†…å®¹

**ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å­¦ã¶ã“ã¨** (40åˆ†):
- ğŸ§  ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(NN)ã®åŸºæœ¬æ§‹é€ 
- ğŸ”— ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(GNN)ã®æ¦‚å¿µ
- ğŸ’» PyTorchã§ã®NNå®Ÿè£…
- ğŸ“Š æœ€æ–°GNNãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ(CGCNN, MEGNet, ALIGNN)

### 5.1 ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®åŸºç¤

**ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(Neural Network)**ã¯ã€äººé–“ã®è„³ã®ç¥çµŒå›è·¯ã‚’æ¨¡å€£ã—ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚

#### å¤šå±¤ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³(MLP)ã®æ§‹é€ 

**å›³:å¤šå±¤ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³ã®æ§‹é€ **

```mermaid
graph LR
    Input[å…¥åŠ›å±¤<br/>132æ¬¡å…ƒ] --> H1[éš ã‚Œå±¤1<br/>128ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³]
    H1 --> H2[éš ã‚Œå±¤2<br/>64ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³]
    H2 --> H3[éš ã‚Œå±¤3<br/>32ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³]
    H3 --> Output[å‡ºåŠ›å±¤<br/>1æ¬¡å…ƒ]

    style Input fill:#2196f3,stroke:#1565c0,color:#fff
    style Output fill:#4caf50,stroke:#2e7d32,color:#fff
```

*å›³3: ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ç”¨ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€‚å…¥åŠ›ã¯ææ–™ã®ç‰¹å¾´é‡132æ¬¡å…ƒã€å‡ºåŠ›ã¯äºˆæ¸¬ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—å€¤ã€‚*

ğŸ’¡ **ç°¡å˜ã«è¨€ã†ã¨**: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡æ•°ã®å±¤ã§æ®µéšçš„ã«å¤‰æ›ã—ã€æœ€çµ‚çš„ãªäºˆæ¸¬å€¤ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚

<details>
<summary>ğŸ“ æ•°å¼ã§è©³ã—ãè¦‹ã‚‹(ã‚¯ãƒªãƒƒã‚¯ã§å±•é–‹)</summary>

**æ•°å­¦çš„å®šç¾©**:

$$
\mathbf{h}^{(1)} = \sigma(\mathbf{W}^{(1)}\mathbf{x} + \mathbf{b}^{(1)})
$$
$$
\mathbf{h}^{(2)} = \sigma(\mathbf{W}^{(2)}\mathbf{h}^{(1)} + \mathbf{b}^{(2)})
$$
$$
y = \mathbf{W}^{(3)}\mathbf{h}^{(2)} + \mathbf{b}^{(3)}
$$

*(æ•°å¼ã®èª¬æ˜: å„å±¤ã§ã€å…¥åŠ›ã«é‡ã¿è¡Œåˆ—Wã‚’æ›ã‘ã€ãƒã‚¤ã‚¢ã‚¹bã‚’è¶³ã—ã€æ´»æ€§åŒ–é–¢æ•°Ïƒ(ReLUãªã©)ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã€æ®µéšçš„ã«ç‰¹å¾´ã‚’æŠ½å‡ºã—ã¾ã™)*

ã“ã“ã§ $\sigma$ ã¯æ´»æ€§åŒ–é–¢æ•°(ReLU: $\max(0, x)$ ãªã©)ã€$\mathbf{W}$ ã¯é‡ã¿è¡Œåˆ—ã€$\mathbf{b}$ ã¯ãƒã‚¤ã‚¢ã‚¹ãƒ™ã‚¯ãƒˆãƒ«ã§ã™ã€‚

</details>

#### å®Ÿè£…ä¾‹:ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬

> ğŸ“± **ãƒ¢ãƒã‚¤ãƒ«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸**:
> ã“ã®ã‚³ãƒ¼ãƒ‰ã¯é•·ã„ãŸã‚ã€æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™ã€‚

```python
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
# pip install torch numpy scikit-learn

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
import numpy as np
from sklearn.metrics import mean_absolute_error, r2_score

# å†ç¾æ€§ã®ãŸã‚ã®è¨­å®š
torch.manual_seed(42)
np.random.seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed(42)

# ãƒ‡ãƒã‚¤ã‚¹ã®é¸æŠ(GPUåˆ©ç”¨å¯èƒ½ãªã‚‰GPUã€ãªã‘ã‚Œã°CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")

# ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å®šç¾©
class BandGapPredictor(nn.Module):
    def __init__(self, input_dim):
        super(BandGapPredictor, self).__init__()
        self.fc1 = nn.Linear(input_dim, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 32)
        self.fc4 = nn.Linear(32, 1)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.2)

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.relu(self.fc3(x))
        x = self.fc4(x)
        return x

# ãƒ‡ãƒ¼ã‚¿æº–å‚™(Section 4ã®X_train, y_trainä½¿ç”¨)
X_tensor = torch.FloatTensor(X_train).to(device)
y_tensor = torch.FloatTensor(y_train).reshape(-1, 1).to(device)
dataset = TensorDataset(X_tensor, y_tensor)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
model = BandGapPredictor(input_dim=X_train.shape[1]).to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# è¨“ç·´ãƒ«ãƒ¼ãƒ—
num_epochs = 100
for epoch in range(num_epochs):
    model.train()
    epoch_loss = 0
    for X_batch, y_batch in dataloader:
        optimizer.zero_grad()
        outputs = model(X_batch)
        loss = criterion(outputs, y_batch)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()

    if (epoch + 1) % 10 == 0:
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(dataloader):.4f}")

# äºˆæ¸¬
model.eval()
with torch.no_grad():
    X_test_tensor = torch.FloatTensor(X_test).to(device)
    y_pred_nn = model(X_test_tensor).cpu().numpy()

mae_nn = mean_absolute_error(y_test, y_pred_nn)
r2_nn = r2_score(y_test, y_pred_nn)
print(f"\nNeural Network MAE: {mae_nn:.3f} eV")
print(f"Neural Network RÂ²: {r2_nn:.3f}")
```

### 5.2 ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(GNN)

> ğŸ“– **Advanced Topic Preview**
>
> ã“ã®ç¯€ã¯ã€ææ–™ç§‘å­¦ã®æœ€å‰ç·šã§ä½¿ã‚ã‚Œã‚‹é«˜åº¦ãªæ‰‹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚
> æ¦‚å¿µç†è§£ãŒç›®æ¨™ã§ã€å®Ÿè£…ã¯å¿…é ˆã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

çµæ™¶æ§‹é€ ã¯**ã‚°ãƒ©ãƒ•(graph)**ã¨ã—ã¦è¡¨ç¾ã§ãã¾ã™:
- **ãƒãƒ¼ãƒ‰(é ‚ç‚¹)**: åŸå­
- **ã‚¨ãƒƒã‚¸(è¾º)**: åŸå­é–“ã®çµåˆ

**å›³:çµæ™¶æ§‹é€ ã®ã‚°ãƒ©ãƒ•è¡¨ç¾**

```mermaid
graph TD
    Li1((Li)) --- O1((O))
    Li1 --- O2((O))
    Co1((Co)) --- O1
    Co1 --- O2
    Co1 --- O3((O))
    O2 --- Li2((Li))

    style Li1 fill:#9c27b0,stroke:#6a1b9a,color:#fff
    style Li2 fill:#9c27b0,stroke:#6a1b9a,color:#fff
    style Co1 fill:#ff5722,stroke:#d84315,color:#fff
    style O1 fill:#2196f3,stroke:#1565c0,color:#fff
    style O2 fill:#2196f3,stroke:#1565c0,color:#fff
    style O3 fill:#2196f3,stroke:#1565c0,color:#fff
```

*å›³4: LiCoO2çµæ™¶æ§‹é€ ã®ã‚°ãƒ©ãƒ•è¡¨ç¾ã€‚åŸå­ã‚’ãƒãƒ¼ãƒ‰(ä¸¸)ã€çµåˆã‚’ã‚¨ãƒƒã‚¸(ç·š)ã¨ã—ã¦è¡¨ç¾ã€‚*

#### Crystal Graph Convolutional Neural Network(CGCNN)

CGCNNã¯ã€çµæ™¶æ§‹é€ ã‚’ç›´æ¥å…¥åŠ›ã¨ã™ã‚‹ç”»æœŸçš„ãªGNNãƒ¢ãƒ‡ãƒ«ã§ã™[^6]ã€‚

**ãƒãƒ¼ãƒ‰æ›´æ–°ã®ä»•çµ„ã¿(å›³ã§ç†è§£)**:

```
[åŸå­A] --è·é›¢æƒ…å ±--> [åŸå­B]
   â†“                      â†“
 ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ« v_A     ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ« v_B
   â†“                      â†“
     æ›´æ–° â† è¿‘å‚ã®æƒ…å ±ã‚’é›†ç´„
```

ğŸ’¡ **ç›´æ„Ÿçš„ç†è§£**: å„åŸå­ãŒå‘¨å›²ã®åŸå­ã‹ã‚‰æƒ…å ±ã‚’é›†ã‚ã¦ã€è‡ªåˆ†ã®ç‰¹å¾´ã‚’æ›´æ–°ã—ã¦ã„ãä»•çµ„ã¿ã§ã™ã€‚

<details>
<summary>ğŸ“ æ•°å¼ã§è©³ã—ãè¦‹ã‚‹(ã‚¯ãƒªãƒƒã‚¯ã§å±•é–‹)</summary>

**ãƒãƒ¼ãƒ‰æ›´æ–°å¼**:

$$
\mathbf{v}_i^{(t+1)} = \mathbf{v}_i^{(t)} + \sum_{j \in \mathcal{N}(i)} \sigma\left(\mathbf{z}_{ij}^{(t)} \mathbf{W}^{(t)} + \mathbf{b}^{(t)}\right)
$$

*(æ•°å¼ã®èª¬æ˜: åŸå­iã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«v_iã¯ã€æ™‚åˆ»tã«ãŠã„ã¦ã€è¿‘å‚åŸå­jã‹ã‚‰ã®æƒ…å ±(ã‚¨ãƒƒã‚¸ç‰¹å¾´z_ij)ã‚’é‡ã¿è¡Œåˆ—Wã§å¤‰æ›ã—ã€æ´»æ€§åŒ–é–¢æ•°Ïƒã‚’é€šã—ã¦é›†ç´„ã™ã‚‹ã“ã¨ã§æ›´æ–°ã•ã‚Œã¾ã™)*

**å„é …ã®æ„å‘³**:
- $\mathbf{v}_i^{(t)}$: åŸå­iã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«(åŸå­ç¨®ã€é›»è·ã€åº§æ¨™)
- $\mathcal{N}(i)$: è¿‘å‚åŸå­é›†åˆ(çµåˆã—ã¦ã„ã‚‹åŸå­)
- $\mathbf{z}_{ij}^{(t)}$: ã‚¨ãƒƒã‚¸æƒ…å ±(çµåˆè·é›¢ã€çµåˆè§’)
- $\mathbf{W}^{(t)}$: å­¦ç¿’å¯èƒ½ãªé‡ã¿è¡Œåˆ—
- $\sigma$: æ´»æ€§åŒ–é–¢æ•°(ReLU: $\max(0,x)$)

**ç‰©ç†çš„è§£é‡ˆ**: å„åŸå­ã¯è¿‘å‚ã‹ã‚‰ã®æƒ…å ±ã‚’é›†ç´„(sum)ã€é‡ã¿ä»˜ã‘(W)ã€éç·šå½¢å¤‰æ›(Ïƒ)ã—ã¦æ›´æ–°ã€‚å±€æ‰€åŒ–å­¦ç’°å¢ƒã‚’åæ˜ ã€‚

</details>

#### CGCNNã®å®Ÿè£…(æ¦‚å¿µã‚³ãƒ¼ãƒ‰)

> âš ï¸ **æ³¨æ„: ã“ã‚Œã¯æ¦‚å¿µã‚’ç¤ºã™ã‚³ãƒ¼ãƒ‰ã§ã™**
>
> å®Ÿéš›ã®å®Ÿè¡Œã«ã¯ä»¥ä¸‹ãŒå¿…è¦ã§ã™:
> 1. CGCNNãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: `pip install cgcnn`
> 2. CIFãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™(Materials Projectã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½)
>
> å®Œå…¨ãªå®Ÿè£…ã¯ä»¥ä¸‹ã‚’å‚ç…§:
> https://github.com/txie-93/cgcnn

```python
# ã“ã®éƒ¨åˆ†ã¯å®Ÿè¡Œã§ãã¾ã›ã‚“(æ¦‚å¿µèª¬æ˜ç”¨)
# from cgcnn.model import CrystalGraphConvNet
# from pymatgen.core import Structure
#
# # çµæ™¶æ§‹é€ ã®èª­ã¿è¾¼ã¿
# structure = Structure.from_file("LiCoO2.cif")
#
# # CGCNNãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
# model = CrystalGraphConvNet(
#     atom_fea_len=64,
#     n_conv=3,
#     h_fea_len=128
# )
#
# # å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã®äºˆæ¸¬
# formation_energy = model.predict(structure)
# print(f"äºˆæ¸¬å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼: {formation_energy:.3f} eV/atom")

print("âš ï¸ ã“ã®ã‚³ãƒ¼ãƒ‰ã¯æ¦‚å¿µèª¬æ˜ç”¨ã§ã™")
print("å®Ÿè¡Œå¯èƒ½ãªå®Ÿè£…ã¯ GitHub(txie-93/cgcnn)ã‚’å‚ç…§ã—ã¦ãã ã•ã„")
```

#### ä¸»è¦ãªGNNãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ

| ãƒ¢ãƒ‡ãƒ« | ç™ºè¡¨å¹´ | ç‰¹å¾´ | æ€§èƒ½(Formation Energy MAE) |
|-------|------|------|----------------------------|
| **CGCNN** | 2018 | æœ€åˆã®çµæ™¶GNN | ~0.04 eV/atom |
| **MEGNet** | 2019 | ã‚°ãƒ­ãƒ¼ãƒãƒ«æƒ…å ±çµ±åˆ | ~0.03 eV/atom |
| **ALIGNN** | 2021 | çµåˆè§’æƒ…å ±è€ƒæ…® | ~0.02 eV/atom |
| **M3GNet** | 2022 | 3ä½“ç›¸äº’ä½œç”¨ | ~0.02 eV/atom |

**æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰(2024-2025)**[^8]:
- ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Š(è¤‡æ•°GNNãƒ¢ãƒ‡ãƒ«ã®çµ„ã¿åˆã‚ã›)
- å¹¾ä½•å­¦çš„æƒ…å ±ã®åŠ¹æœçš„ãªçµ±åˆ(çµåˆè§’ã€æ–¹å‘æ€§)[^9]
- è»¢ç§»å­¦ç¿’ã«ã‚ˆã‚‹å°ãƒ‡ãƒ¼ã‚¿å¯¾å¿œ[^10]

---

### ğŸ“Š ã‚»ã‚¯ã‚·ãƒ§ãƒ³5ã®ã¾ã¨ã‚

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ**:
- âœ“ ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯: å¤šå±¤æ§‹é€ ã§è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’
- âœ“ GNN: çµæ™¶æ§‹é€ ã‚’ã‚°ãƒ©ãƒ•ã¨ã—ã¦ç›´æ¥æ‰±ã†
- âœ“ CGCNN: å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ã§ MAE ~0.04 eV/atom
- âœ“ æœ€æ–°GNN: M3GNet(2022)ã§ ~0.02 eV/atom

**æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¸**: ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§åŠ¹ç‡çš„ã«ææ–™ã‚’æ¢ç´¢ â†’

---
**å­¦ç¿’é€²æ—**: â– â– â– â– â– â– â–¡â–¡â–¡â–¡ 50% (Section 5/10å®Œäº†)
**æ¨å®šæ®‹ã‚Šæ™‚é–“**: 2-4æ™‚é–“
---

## 6. ãƒ™ã‚¤ã‚ºæœ€é©åŒ–:åŠ¹ç‡çš„ãªææ–™æ¢ç´¢

**ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å­¦ã¶ã“ã¨** (35åˆ†):
- ğŸ¯ ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ãŒãªãœå°‘ãªã„å®Ÿé¨“ã§æœ€é©è§£ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œã‚‹ã‹
- ğŸ§® ç²å¾—é–¢æ•°(Acquisition Function)ã®ä»•çµ„ã¿
- ğŸ’» Pythonã§ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’å®Ÿè£…ã™ã‚‹æ–¹æ³•
- ğŸ“Š å®Ÿé¨“å›æ•°ã‚’70%å‰Šæ¸›ã—ãŸå®Ÿä¾‹

### 6.1 ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¨ã¯?

**ãƒ™ã‚¤ã‚ºæœ€é©åŒ–(Bayesian Optimization)**ã¯ã€å°‘ãªã„å®Ÿé¨“å›æ•°ã§æœ€é©ãªææ–™ã‚’è¦‹ã¤ã‘ã‚‹æ‰‹æ³•ã§ã™[^11]ã€‚

**æ¯”å–©ã§ç†è§£ã™ã‚‹:å®æ¢ã—**

åºƒã„ç ‚æµœã§å®ç‰©ã‚’è¦‹ã¤ã‘ã‚‹ã¨ãã€é‡‘å±æ¢çŸ¥æ©Ÿ(äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«)ã¯åå¿œã®å¼·ã•ã‚’æ•™ãˆã¦ãã‚Œã¾ã™ãŒå®Œç’§ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¯ã€ã€Œåå¿œãŒå¼·ã„å ´æ‰€ã€ã¨ã€Œã¾ã æ¢ã—ã¦ã„ãªã„å ´æ‰€ã€ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚ŠãªãŒã‚‰ã€æœ€å°ã®æ˜å‰Šå›æ•°ã§å®ã‚’è¦‹ã¤ã‘ã¾ã™ã€‚

> ğŸ’¡ **Key Concept**
>
> ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®2ã¤ã®æˆ¦ç•¥:
> - **Exploitation(æ´»ç”¨)**: ä»Šã¾ã§æœ€ã‚‚è‰¯ã‹ã£ãŸå ´æ‰€ã®å‘¨è¾ºã‚’æ¢ã™
> - **Exploration(æ¢ç´¢)**: ã¾ã è©¦ã—ã¦ã„ãªã„æœªçŸ¥ã®é ˜åŸŸã‚’è©¦ã™

### 6.2 ä»•çµ„ã¿

**å›³:ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®æ¢ç´¢ãƒ—ãƒ­ã‚»ã‚¹**

```mermaid
sequenceDiagram
    participant Model as ã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«
    participant Acq as ç²å¾—é–¢æ•°
    participant Exp as å®Ÿé¨“

    Note over Model: åˆæœŸãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
    Model->>Acq: äºˆæ¸¬ã¨ä¸ç¢ºå®Ÿæ€§ã‚’è¨ˆç®—
    Acq->>Acq: æ¬¡ã®å®Ÿé¨“å€™è£œã‚’é¸æŠ
    Acq->>Exp: æœ€ã‚‚æœ‰æœ›ãªææ–™ã‚’ææ¡ˆ
    Exp->>Model: å®Ÿé¨“çµæœã‚’è¿½åŠ 
    Note over Model: ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒ»å†å­¦ç¿’
```

*å›³5: ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®åå¾©ãƒ—ãƒ­ã‚»ã‚¹ã€‚äºˆæ¸¬â†’å®Ÿé¨“â†’æ›´æ–°ã®ã‚µã‚¤ã‚¯ãƒ«ã‚’ç¹°ã‚Šè¿”ã—ã€æœ€é©ææ–™ã‚’æ¢ç´¢ã€‚*

**3ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—**:

**1. ã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«(ä»£ç†ãƒ¢ãƒ‡ãƒ«)ã®æ§‹ç¯‰**

ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°(Gaussian Process Regression)ã§äºˆæ¸¬ã¨ä¸ç¢ºå®Ÿæ€§ã‚’åŒæ™‚ã«æ¨å®š

$$
f(\mathbf{x}) \sim \mathcal{GP}(\mu(\mathbf{x}), k(\mathbf{x}, \mathbf{x}'))
$$

*(æ•°å¼ã®èª¬æ˜: ç›®çš„é–¢æ•°fã¯ã€å¹³å‡é–¢æ•°Î¼ã¨å…±åˆ†æ•£é–¢æ•°kã§å®šç¾©ã•ã‚Œã‚‹ã‚¬ã‚¦ã‚¹éç¨‹ã¨ã—ã¦è¡¨ç¾ã•ã‚Œã¾ã™)*

**2. ç²å¾—é–¢æ•°(Acquisition Function)ã®è¨ˆç®—**

æ¬¡ã«ã©ã®ææ–™ã‚’å®Ÿé¨“ã™ã¹ãã‹æ±ºå®š

**Expected Improvement(EI)**:

$$
\text{EI}(\mathbf{x}) = \mathbb{E}[\max(f(\mathbf{x}) - f(\mathbf{x}^*), 0)]
$$

*(æ•°å¼ã®èª¬æ˜: æœŸå¾…æ”¹å–„é‡EIã¯ã€æ–°ã—ã„å€™è£œxãŒç¾åœ¨ã®æœ€è‰¯ææ–™x*ã‚’è¶…ãˆã‚‹æœŸå¾…å€¤ã§ã™)*

ã“ã“ã§ $\mathbf{x}^*$ ã¯ç¾åœ¨ã®æœ€è‰¯ææ–™ã§ã™ã€‚

**3. å®Ÿé¨“ã¨æ›´æ–°**

- EIãŒæœ€å¤§ã®ææ–™ã‚’å®Ÿé¨“
- ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¢ãƒ‡ãƒ«ã«è¿½åŠ 
- ã‚¹ãƒ†ãƒƒãƒ—1ã«æˆ»ã‚‹

### 6.3 å®Ÿè£…ä¾‹:é›»æ± å®¹é‡ã®æœ€é©åŒ–

```python
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
# pip install scikit-optimize numpy matplotlib

from skopt import gp_minimize
from skopt.plots import plot_convergence
import numpy as np
import matplotlib.pyplot as plt

# å†ç¾æ€§ã®ãŸã‚ã®è¨­å®š
np.random.seed(42)

# ç›®çš„é–¢æ•°(å®Ÿéš›ã¯å®Ÿé¨“ã§æ¸¬å®š)
def battery_capacity(composition):
    """
    Li_x Co_y Ni_z O_2 ã®å®¹é‡ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    composition: [x, y, z] (0 â‰¤ x,y,z â‰¤ 1)
    """
    x, y, z = composition
    # ç°¡ç•¥åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«(å®Ÿéš›ã¯DFTã‚„å®Ÿé¨“)
    capacity = 200 + 50*x + 30*y + 20*z - 100*(x-0.5)**2 - 80*(y-0.3)**2
    # ãƒã‚¤ã‚ºã‚’è¿½åŠ (å®Ÿé¨“èª¤å·®)
    capacity += np.random.normal(0, 5)
    return -capacity  # æœ€å¤§åŒ–å•é¡Œã‚’æœ€å°åŒ–å•é¡Œã«å¤‰æ›

# æ¢ç´¢ç©ºé–“ã®å®šç¾©
space = [
    (0.2, 0.8),  # Liå«æœ‰ç‡ x
    (0.1, 0.5),  # Coå«æœ‰ç‡ y
    (0.1, 0.5)   # Niå«æœ‰ç‡ z
]

# ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å®Ÿè¡Œ
result = gp_minimize(
    battery_capacity,  # ç›®çš„é–¢æ•°
    space,             # æ¢ç´¢ç©ºé–“
    n_calls=20,        # å®Ÿé¨“å›æ•°
    n_random_starts=5, # ãƒ©ãƒ³ãƒ€ãƒ ãªåˆæœŸå®Ÿé¨“
    random_state=42
)

# æœ€é©çµ„æˆ
optimal_Li, optimal_Co, optimal_Ni = result.x
print(f"æœ€é©çµ„æˆ: Li={optimal_Li:.3f}, Co={optimal_Co:.3f}, Ni={optimal_Ni:.3f}")
print(f"æœ€å¤§å®¹é‡: {-result.fun:.1f} mAh/g")

# åæŸéç¨‹ã®å¯è¦–åŒ–
plot_convergence(result)
plt.title("Bayesian Optimization: Convergence")
plt.ylabel("Best Capacity (mAh/g)")
plt.xlabel("Number of Experiments")
plt.savefig("bayesian_optimization_convergence.png", dpi=300)
plt.show()
```

**å‡ºåŠ›ä¾‹**:
```
æœ€é©çµ„æˆ: Li=0.543, Co=0.285, Ni=0.172
æœ€å¤§å®¹é‡: 267.3 mAh/g
```

> âœ… **Success!**
>
> ã‚ãšã‹20å›ã®å®Ÿé¨“ã§æœ€é©çµ„æˆã‚’ç™ºè¦‹!
> ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒãªã‚‰50å›ä»¥ä¸Šå¿…è¦ã§ã—ãŸ(70%å‰Šæ¸›)ã€‚

### 6.4 å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–

å®Ÿéš›ã®ææ–™é–‹ç™ºã§ã¯ã€è¤‡æ•°ã®ç‰¹æ€§ã‚’åŒæ™‚ã«æœ€é©åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™(ä¾‹: å®¹é‡ã¨å®‰å…¨æ€§)[^12]ã€‚

**Expected Hypervolume Improvement(EHVI)**:

$$
\text{EHVI}(\mathbf{x}) = \mathbb{E}[\text{HV}(\{PF \cup \{f(\mathbf{x})\}\}) - \text{HV}(PF)]
$$

*(æ•°å¼ã®èª¬æ˜: EHVIã¯ã€æ–°ã—ã„å€™è£œã‚’è¿½åŠ ã—ãŸã¨ãã®ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ (å¤šç›®çš„æœ€é©è§£ã®è³ªã‚’ç¤ºã™æŒ‡æ¨™)ã®æ”¹å–„æœŸå¾…å€¤ã§ã™)*

ã“ã“ã§ $PF$ ã¯ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆã€$\text{HV}$ ã¯ãƒã‚¤ãƒ‘ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ æŒ‡æ¨™ã§ã™ã€‚

**å®Ÿè£…ä¾‹**:

```python
from skopt import gp_minimize

# 2ç›®çš„é–¢æ•°(å®¹é‡ã¨å®‰å…¨æ€§)
def multi_objective(composition):
    x, y, z = composition
    capacity = 200 + 50*x + 30*y + 20*z - 100*(x-0.5)**2
    safety = 100 - 50*x + 20*y + 30*z - 50*(y-0.4)**2
    # æ³¨: æœ¬æ¥ã¯ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©åŒ–ã™ã¹ãã ãŒã€ã“ã“ã§ã¯ç°¡ç•¥åŒ–ã®ãŸã‚é‡ã¿ä»˜ã‘å’Œã‚’ä½¿ç”¨
    # å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ pymoo ã‚„ Platypus ãªã©ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æ¨å¥¨
    score = 0.7 * capacity + 0.3 * safety
    return -score

space = [(0.2, 0.8), (0.1, 0.5), (0.1, 0.5)]
result = gp_minimize(multi_objective, space, n_calls=30, random_state=42)

print(f"æœ€é©çµ„æˆ(å¤šç›®çš„): Li={result.x[0]:.3f}, Co={result.x[1]:.3f}, Ni={result.x[2]:.3f}")
```

**æˆæœäº‹ä¾‹**[^11]:
- æ¢ç´¢ç©ºé–“ã®16-23%ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§æœ€é©è§£ã‚’ç™ºè¦‹
- å®Ÿé¨“å›æ•°ã‚’70-85%å‰Šæ¸›

---

### ğŸ“Š ã‚»ã‚¯ã‚·ãƒ§ãƒ³6ã®ã¾ã¨ã‚

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ**:
- âœ“ ãƒ™ã‚¤ã‚ºæœ€é©åŒ–: äºˆæ¸¬ã¨ä¸ç¢ºå®Ÿæ€§ã‚’ä½¿ã£ã¦æ¬¡ã®å®Ÿé¨“ã‚’è³¢ãé¸ã¶
- âœ“ ç²å¾—é–¢æ•°: Exploitationã¨Explorationã®ãƒãƒ©ãƒ³ã‚¹
- âœ“ å®Ÿé¨“å›æ•°å‰Šæ¸›: 70-85%ã®å‰Šæ¸›ãŒå¯èƒ½
- âœ“ å¤šç›®çš„æœ€é©åŒ–: è¤‡æ•°ã®ç‰¹æ€§ã‚’åŒæ™‚ã«æœ€é©åŒ–

**æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¸**: æ•™å¸«ãªã—å­¦ç¿’ã¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° â†’

---
**å­¦ç¿’é€²æ—**: â– â– â– â– â– â– â– â–¡â–¡â–¡ 60% (Section 6/10å®Œäº†)
**æ¨å®šæ®‹ã‚Šæ™‚é–“**: 1-3æ™‚é–“
---

## 7. æ•™å¸«ãªã—å­¦ç¿’ã¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°

**ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å­¦ã¶ã“ã¨** (20åˆ†):
- ğŸ“‰ ä¸»æˆåˆ†åˆ†æ(PCA)ã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›
- ğŸ¨ K-Meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ææ–™åˆ†é¡
- ğŸ“Š å¯è¦–åŒ–ã«ã‚ˆã‚‹ææ–™ç¾¤ã®ç†è§£

### 7.1 æ¬¡å…ƒå‰Šæ¸›:ä¸»æˆåˆ†åˆ†æ(PCA)

é«˜æ¬¡å…ƒç‰¹å¾´é‡(ä¾‹: 132æ¬¡å…ƒã®çµ„æˆè¨˜è¿°å­)ã‚’2-3æ¬¡å…ƒã«åœ§ç¸®ã—ã€å¯è¦–åŒ–ã—ã¾ã™ã€‚

**æ•°å­¦çš„å®šç¾©**:

$$
\mathbf{Z} = \mathbf{X} \mathbf{W}
$$

*(æ•°å¼ã®èª¬æ˜: ä¸»æˆåˆ†åˆ†æã¯ã€å…ƒã®ãƒ‡ãƒ¼ã‚¿Xã«ä¸»æˆåˆ†(å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«)Wã‚’æ›ã‘ã‚‹ã“ã¨ã§ã€ä½æ¬¡å…ƒè¡¨ç¾Zã‚’å¾—ã¾ã™)*

ã“ã“ã§ $\mathbf{W}$ ã¯ä¸»æˆåˆ†(å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«)ã€$\mathbf{Z}$ ã¯ä½æ¬¡å…ƒè¡¨ç¾ã§ã™ã€‚

```python
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯æ—¢ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¸ˆã¿
# æ³¨: ã“ã®ã‚³ãƒ¼ãƒ‰ã¯Section 4ã®å¾Œã«å®Ÿè¡Œã—ã¦ãã ã•ã„

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# PCAã®é©ç”¨
pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_scaled)

# å¯è¦–åŒ–
plt.figure(figsize=(8, 6))
scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', alpha=0.6)
plt.xlabel(f"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)")
plt.ylabel(f"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)")
plt.title("PCA: Materials Feature Space")
plt.colorbar(scatter, label="Formation Energy (eV/atom)")
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig("pca_visualization.png", dpi=300)
plt.show()

print(f"ç´¯ç©å¯„ä¸ç‡: {pca.explained_variance_ratio_.sum()*100:.1f}%")
```

### 7.2 ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°:K-Means

é¡ä¼¼ã—ãŸææ–™ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¾ã™ã€‚

```python
# æ³¨: ã“ã®ã‚³ãƒ¼ãƒ‰ã¯Section 7.1ã®å¾Œã«å®Ÿè¡Œã—ã¦ãã ã•ã„

from sklearn.cluster import KMeans

# K-Meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
kmeans = KMeans(n_clusters=5, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# PCAç©ºé–“ã§ã®centroidsã‚’è¨ˆç®—
pca_centroids = pca.transform(kmeans.cluster_centers_)

# PCAç©ºé–“ã§ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å¯è¦–åŒ–
plt.figure(figsize=(8, 6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='tab10', alpha=0.6)
plt.scatter(pca_centroids[:, 0], pca_centroids[:, 1],
            marker='X', s=300, c='red', edgecolors='black', label='Centroids')
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.title("K-Means Clustering of Materials")
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig("kmeans_clustering.png", dpi=300)
plt.show()
```

**å¿œç”¨ä¾‹**:
- **ææ–™ã®åˆ†é¡**: é¡ä¼¼ã®ç‰¹æ€§ã‚’æŒã¤ææ–™ã‚°ãƒ«ãƒ¼ãƒ—ã®ç™ºè¦‹
- **ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ**: å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‹ã‚‰ä»£è¡¨çš„ãªææ–™ã‚’é¸æŠã—ã¦å®Ÿé¨“

---

### ğŸ“Š ã‚»ã‚¯ã‚·ãƒ§ãƒ³7ã®ã¾ã¨ã‚

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ**:
- âœ“ PCA: é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã‚’2-3æ¬¡å…ƒã«åœ§ç¸®ã—ã¦å¯è¦–åŒ–
- âœ“ K-Means: é¡ä¼¼ææ–™ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
- âœ“ å¿œç”¨: ææ–™åˆ†é¡ã€ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæˆ¦ç•¥

**æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¸**: å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§å…¨ã¦ã‚’çµ±åˆ â†’

---
**å­¦ç¿’é€²æ—**: â– â– â– â– â– â– â– â– â–¡â–¡ 70% (Section 7/10å®Œäº†)
**æ¨å®šæ®‹ã‚Šæ™‚é–“**: 1-2æ™‚é–“
---

## 8. å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ:ãƒªãƒã‚¦ãƒ ã‚¤ã‚ªãƒ³é›»æ± ææ–™ã®äºˆæ¸¬

**ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å­¦ã¶ã“ã¨** (60åˆ†):
- ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å…¨ä½“ãƒ•ãƒ­ãƒ¼(ãƒ‡ãƒ¼ã‚¿åé›†â†’äºˆæ¸¬â†’è©•ä¾¡)
- ğŸ’» Materials Project APIã®å®Ÿè·µçš„æ´»ç”¨
- ğŸ”¬ è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒã¨æœ€è‰¯ãƒ¢ãƒ‡ãƒ«é¸æŠ
- ğŸ“Š ç‰¹å¾´é‡ã®é‡è¦åº¦åˆ†æ

### 8.1 ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç›®æ¨™

Materials Projectã‹ã‚‰å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ãƒªãƒã‚¦ãƒ ã‚¤ã‚ªãƒ³é›»æ± ã®æ­£æ¥µææ–™ã®å®¹é‡ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

### 8.2 å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

> ğŸ“± **ãƒ¢ãƒã‚¤ãƒ«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸**:
> ã“ã®ã‚³ãƒ¼ãƒ‰ã¯é•·ã„ãŸã‚ã€æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™ã€‚
> ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã¾ãŸã¯[Google Colabç‰ˆ](#)ã§ã®é–²è¦§ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

```python
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
# pip install pandas numpy mp-api pymatgen matminer scikit-learn matplotlib

import pandas as pd
import numpy as np
from mp_api.client import MPRester
from pymatgen.core import Composition
from matminer.featurizers.composition import ElementProperty
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import os

# å†ç¾æ€§ã®ãŸã‚ã®è¨­å®š
np.random.seed(42)

# Step 1: ãƒ‡ãƒ¼ã‚¿åé›†(Materials Project API)
api_key = os.getenv("MP_API_KEY")

if not api_key:
    print("âš ï¸ APIã‚­ãƒ¼ãªã—: ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
    # ãƒ‡ãƒ¢ç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
    data_demo = [
        {"composition": "LiCoO2", "energy": -2.19, "gap": 2.2, "capacity": 274},
        {"composition": "LiNiO2", "energy": -2.15, "gap": 1.8, "capacity": 275},
        {"composition": "LiMnO2", "energy": -2.25, "gap": 2.5, "capacity": 285},
        {"composition": "LiFePO4", "energy": -2.87, "gap": 3.1, "capacity": 170},
        {"composition": "LiMn2O4", "energy": -2.05, "gap": 1.9, "capacity": 148}
    ]
    df = pd.DataFrame(data_demo)
    print(f"åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}")
else:
    with MPRester(api_key) as mpr:
        # Liå«æœ‰åŒ–åˆç‰©ã‚’æ¤œç´¢
        docs = mpr.materials.summary.search(
            elements=["Li"],
            num_elements=(2, 4),
            fields=["material_id", "formula_pretty", "formation_energy_per_atom",
                    "band_gap"]
        )

        data = []
        for doc in docs:
            # ç†è«–å®¹é‡ã®ç°¡æ˜“è¨ˆç®—(å®Ÿéš›ã«ã¯ã‚ˆã‚Šè¤‡é›‘)
            comp = Composition(doc.formula_pretty)
            li_fraction = comp.get_atomic_fraction("Li")
            capacity = li_fraction * 300  # ç°¡ç•¥åŒ–ã—ãŸæ¨å®š

            data.append({
                "composition": doc.formula_pretty,
                "energy": doc.formation_energy_per_atom,
                "gap": doc.band_gap,
                "capacity": capacity
            })

        df = pd.DataFrame(data)
        print(f"åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}")

# Step 2: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
featurizer = ElementProperty.from_preset("magpie")

def featurize_composition(comp_str):
    try:
        comp = Composition(comp_str)
        return featurizer.featurize(comp)
    except:
        return None

df["features"] = df["composition"].apply(featurize_composition)
df = df.dropna(subset=["features"])

X = np.array(df["features"].tolist())
y = df["capacity"].values

print(f"ç‰¹å¾´é‡æ¬¡å…ƒ: {X.shape[1]}")
print(f"å®¹é‡ç¯„å›²: {y.min():.1f} - {y.max():.1f} mAh/g")

# Step 3: è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Step 4: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ
models = {
    "Random Forest": RandomForestRegressor(
        n_estimators=100, max_depth=20, random_state=42
    ),
    "Gradient Boosting": GradientBoostingRegressor(
        n_estimators=100, max_depth=5, random_state=42
    )
}

results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    results[name] = {"model": model, "y_pred": y_pred, "MAE": mae, "R2": r2}
    print(f"{name}: MAE = {mae:.2f} mAh/g, RÂ² = {r2:.3f}")

# Step 5: æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®é¸æŠã¨å¯è¦–åŒ–
best_model_name = min(results, key=lambda k: results[k]["MAE"])
best_result = results[best_model_name]

plt.figure(figsize=(10, 5))

# ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ1: äºˆæ¸¬ vs å®Ÿæ¸¬
plt.subplot(1, 2, 1)
plt.scatter(y_test, best_result["y_pred"], alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],
         'r--', lw=2, label='Perfect prediction')
plt.xlabel("Actual Capacity (mAh/g)")
plt.ylabel("Predicted Capacity (mAh/g)")
plt.title(f"{best_model_name}\nMAE={best_result['MAE']:.2f}, RÂ²={best_result['R2']:.3f}")
plt.legend()
plt.grid(True, alpha=0.3)

# ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ2: ç‰¹å¾´é‡ã®é‡è¦åº¦(Random Forestã®å ´åˆ)
if best_model_name == "Random Forest":
    plt.subplot(1, 2, 2)
    feature_importance = best_result["model"].feature_importances_
    top_10_idx = np.argsort(feature_importance)[-10:]
    feature_labels = featurizer.feature_labels()

    plt.barh(range(10), feature_importance[top_10_idx])
    plt.yticks(range(10), [feature_labels[i][:30] for i in top_10_idx])
    plt.xlabel("Feature Importance")
    plt.title("Top 10 Important Features")
    plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig("battery_capacity_prediction.png", dpi=300)
plt.show()

# Step 6: æ–°ææ–™ã®äºˆæ¸¬
new_materials = ["LiNi0.8Co0.1Mn0.1O2", "LiMnO2", "LiFePO4"]
print("\næ–°ææ–™ã®å®¹é‡äºˆæ¸¬:")
for mat in new_materials:
    try:
        comp = Composition(mat)
        features = np.array([featurizer.featurize(comp)])
        pred_capacity = best_result["model"].predict(features)[0]
        print(f"{mat}: {pred_capacity:.1f} mAh/g")
    except:
        print(f"{mat}: ç‰¹å¾´é‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼")
```

**å‡ºåŠ›ä¾‹**:
```
åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿æ•°: 5
ç‰¹å¾´é‡æ¬¡å…ƒ: 132
å®¹é‡ç¯„å›²: 148.0 - 285.0 mAh/g
Random Forest: MAE = 12.34 mAh/g, RÂ² = 0.912
Gradient Boosting: MAE = 11.20 mAh/g, RÂ² = 0.928

æ–°ææ–™ã®å®¹é‡äºˆæ¸¬:
LiNi0.8Co0.1Mn0.1O2: 278.3 mAh/g
LiMnO2: 285.1 mAh/g
LiFePO4: 169.7 mAh/g
```

> âœ… **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œæˆ!**
>
> ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™!
> ãƒ‡ãƒ¼ã‚¿åé›†ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã€äºˆæ¸¬ã¾ã§å®Œå…¨ãªMIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸã€‚

---

### ğŸ“Š ã‚»ã‚¯ã‚·ãƒ§ãƒ³8ã®ã¾ã¨ã‚

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ**:
- âœ“ å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼: ãƒ‡ãƒ¼ã‚¿åé›†â†’ç‰¹å¾´é‡â†’è¨“ç·´â†’è©•ä¾¡â†’äºˆæ¸¬
- âœ“ Gradient Boosting: MAE 11.20 mAh/g, RÂ² 0.928
- âœ“ è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ: æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ç³»çµ±çš„ã«é¸æŠ
- âœ“ æ–°ææ–™äºˆæ¸¬: æœªçŸ¥ææ–™ã®å®¹é‡ã‚’æ¨å®š

**æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¸**: æ¼”ç¿’å•é¡Œã§çŸ¥è­˜ã‚’ç¢ºèª â†’

---
**å­¦ç¿’é€²æ—**: â– â– â– â– â– â– â– â– â– â–¡ 80% (Section 8/10å®Œäº†)
**æ¨å®šæ®‹ã‚Šæ™‚é–“**: 0.5-1æ™‚é–“
---

## 9. æ¼”ç¿’å•é¡Œ

### åˆç´š(Section 1-3 å¯¾å¿œ)

**Q1.1**: MIã¨ã¯ä½•ã‹ã€3ã¤ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

**æ¨¡ç¯„è§£ç­”**:
1. ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
2. ææ–™ç§‘å­¦ã¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®èåˆ
3. äºˆæ¸¬ã¨å®Ÿé¨“ã®å”èª¿

</details>

**Q1.2**: ä»¥ä¸‹ã®äºˆæ¸¬ã®ã†ã¡ã€æœ€ã‚‚ä¿¡é ¼ã§ãã‚‹ã‚‚ã®ã‚’é¸ã³ã€ç†ç”±ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

è¨“ç·´ãƒ‡ãƒ¼ã‚¿: Fe 50-90%, Cr 0-30%, Ni 0-20%ã®é‡‘å±åˆé‡‘

- A. Fe 70%, Cr 20%, Ni 10%
- B. Fe 95%, Cr 5%, Ni 0%
- C. Cu 50%, Zn 50%

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

**ç­”ãˆ**: A

**ç†ç”±**: Aã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²å†…ãªã®ã§ä¿¡é ¼ã§ãã‚‹ã€‚Bã¯è¨“ç·´ç¯„å›²å¤–(å¤–æŒ¿)ãªã®ã§ä¿¡é ¼æ€§ãŒä½ã„ã€‚Cã¯å…¨ãç•°ãªã‚‹å…ƒç´ ç³»ãªã®ã§ä¿¡é ¼ã§ããªã„ã€‚

</details>

**Q1.3**: ã€ŒMIã¯å®Ÿé¨“ã‚’å®Œå…¨ã«ç½®ãæ›ãˆã‚‹ã€ã¨ã„ã†ä¸»å¼µã¯æ­£ã—ã„ã§ã™ã‹?ãªãœã§ã™ã‹?

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

**èª¤ã‚Š**ã€‚MIã¯å®Ÿé¨“ã®åŠ¹ç‡åŒ–ã‚’æ”¯æ´ã—ã¾ã™ãŒã€æœ€çµ‚æ¤œè¨¼ã«ã¯å¿…ãšå®Ÿé¨“ãŒå¿…è¦ã§ã™ã€‚

**ç†ç”±**:
1. ãƒ¢ãƒ‡ãƒ«ã«ã¯å¤–æŒ¿ã®é™ç•ŒãŒã‚ã‚‹
2. äºˆæ¸¬ã«ã¯ä¸ç¢ºå®Ÿæ€§ãŒä¼´ã†
3. ç‰©ç†çš„å¦¥å½“æ€§ã¯å®Ÿé¨“ã§ç¢ºèªã™ã¹ã

</details>

**Q1.4**: LiCoO2ã®å¹³å‡åŸå­ç•ªå·ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚(Li: Z=3, Co: Z=27, O: Z=8)

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

(1Ã—3 + 1Ã—27 + 2Ã—8) / 4 = 46/4 = 11.5

</details>

**Q1.5**: ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å¤–ã‚Œå€¤ã¯ã©ã‚Œã§ã™ã‹?

å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼(eV/atom): [-2.1, -1.8, -2.3, 5.0, -1.9]

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

**5.0**ãŒå¤–ã‚Œå€¤ã€‚ä»–ã¯-2ä»˜è¿‘ã ãŒã€5.0ã ã‘å¤§ããç•°ãªã‚Šã€æ­£ã®å€¤(ä¸å®‰å®š)ã€‚

</details>

### ä¸­ç´š(Section 2-6 å¯¾å¿œ)

**Q2.1**: è¨“ç·´èª¤å·®ãŒ0.01ã€æ¤œè¨¼èª¤å·®ãŒ0.50ã®ãƒ¢ãƒ‡ãƒ«ã¯ä½•ãŒå•é¡Œã§ã™ã‹?

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

**éå­¦ç¿’(overfitting)**ã€‚è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’æš—è¨˜ã—ã¦ã—ã¾ã„ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§æ€§èƒ½ãŒä½ã„ã€‚

</details>

**Q2.2**: ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã®ç©ºæ¬„ã‚’åŸ‹ã‚ã¦ã€ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’å®Œæˆã•ã›ã¦ãã ã•ã„ã€‚

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error

# ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
model = RandomForestRegressor(n_estimators=______, random_state=42)

# è¨“ç·´
model.______(X_train, y_train)

# äºˆæ¸¬
y_pred = model.______(X_test)

# è©•ä¾¡
mae = mean_absolute_error(______, ______)
print(f"MAE: {mae:.3f}")
```

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

```python
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
```

</details>

**Q2.3**: ãƒ‡ãƒ¼ã‚¿æ•°ãŒ50å€‹ã—ã‹ã‚ã‚Šã¾ã›ã‚“ã€‚ã©ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é¸ã³ã¾ã™ã‹?

- A. ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
- B. ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°
- C. æ·±å±¤å­¦ç¿’GNN

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

**B**: ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ã€‚å°ãƒ‡ãƒ¼ã‚¿ã«é©ã—ã¦ãŠã‚Šã€ä¸ç¢ºå®Ÿæ€§ã‚‚è©•ä¾¡ã§ãã¾ã™ã€‚
Aã€Cã¯é€šå¸¸1000+ã‚µãƒ³ãƒ—ãƒ«å¿…è¦ã€‚

</details>

**Q2.4**: ã‚ãªãŸã®ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ç²¾åº¦(RÂ²ã‚¹ã‚³ã‚¢)ãŒ0.5ã¨ä½ã„ã§ã™ã€‚ã©ã†æ”¹å–„ã—ã¾ã™ã‹?3ã¤ã®å¯¾ç­–ã‚’æŒ™ã’ã¦ãã ã•ã„ã€‚

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

**æ¨¡ç¯„è§£ç­”**:
1. ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã™ã‚‹
2. ã‚ˆã‚Šè‰¯ã„ç‰¹å¾´é‡(è¨˜è¿°å­)ã‚’è¨­è¨ˆã™ã‚‹
3. ç•°ãªã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’è©¦ã™(ä¾‹: ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ â†’ ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°)
4. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€é©åŒ–(ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ)
5. å¤–ã‚Œå€¤ã®é™¤å»ã‚„ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®æ”¹å–„

(3ã¤ä»¥ä¸ŠæŒ™ã’ã‚‰ã‚Œã‚Œã°æ­£è§£)

</details>

**Q2.5**: MAEã‚’è¨ˆç®—ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’å®Œæˆã•ã›ã¦ãã ã•ã„ã€‚

```python
from sklearn.metrics import ______
y_pred = model.predict(X_test)
mae = ______(y_test, ______)
```

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

```python
from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(y_test, y_pred)
```

</details>

**Q2.6**: ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã«ã¯ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã™ã€‚ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

```python
model = RandomForestRegressor(n_estimators=100)
model.train(X_train, y_train)  # â† ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹è¡Œ
```

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

```python
model.fit(X_train, y_train)  # train()ã§ã¯ãªãfit()ãŒæ­£ã—ã„
```

</details>

**Q2.7**: Materials Projectã®å‡ºåŠ›ã‚’è§£é‡ˆã—ã¦ãã ã•ã„ã€‚

```
LiCoO2: Formation Energy = -2.194 eV/atom
```

ã“ã®ææ–™ã¯ç†±åŠ›å­¦çš„ã«å®‰å®šã§ã™ã‹?

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

**å®‰å®š**: å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒè² (< 0)ãªã®ã§ã€æ§‹æˆå…ƒç´ ã‹ã‚‰è‡ªç™ºçš„ã«ç”Ÿæˆã•ã‚Œã€å®‰å®šã§ã™ã€‚

</details>

**Q2.8**: ä»¥ä¸‹ã®çµæœã‚’ã©ã†è§£é‡ˆã—ã¾ã™ã‹?

```
Random Forest: MAE = 18.45 mAh/g, RÂ² = 0.894
Gradient Boosting: MAE = 16.32 mAh/g, RÂ² = 0.912
```

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

**Gradient BoostingãŒå„ªç§€**:
- MAEãŒä½ã„(äºˆæ¸¬èª¤å·®ãŒå°ã•ã„)
- RÂ²ãŒé«˜ã„(ãƒ‡ãƒ¼ã‚¿ã®91.2%ã‚’èª¬æ˜)
â†’ å®Ÿç”¨ã§ã¯Gradient Boostingã‚’æ¡ç”¨ã™ã¹ã

</details>

### å¿œç”¨(Section 7-8 å¯¾å¿œ)

**Q3.1**: ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®ç²å¾—é–¢æ•°(Acquisition Function)ãŒé«˜ã„ç‚¹ã¨ã¯ã©ã‚“ãªç‚¹ã§ã™ã‹?

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

(1) **äºˆæ¸¬æ€§èƒ½ãŒé«˜ãã†ãªç‚¹**(Exploitation: æ¢ç´¢æ¸ˆã¿é ˜åŸŸã®æœ€è‰¯ä»˜è¿‘)
(2) **ã¾ã è©¦ã—ã¦ã„ãªã„ç‚¹**(Exploration: ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„é ˜åŸŸ)
ã®ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚ŒãŸç‚¹ã€‚

</details>

**Q3.2**: å®Ÿé¨“ã‚³ã‚¹ãƒˆãŒ1å›100ä¸‡å††ã®å ´åˆã€ä»¥ä¸‹ã®ã©ã¡ã‚‰ã‚’é¸ã³ã¾ã™ã‹?

- A. ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ(50å›å®Ÿé¨“)
- B. ãƒ™ã‚¤ã‚ºæœ€é©åŒ–(15å›å®Ÿé¨“)

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

**B**: ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã€‚å®Ÿé¨“å›æ•°ã‚’70-85%å‰Šæ¸›ã§ãã€ã‚³ã‚¹ãƒˆã¯1500ä¸‡å†† vs 5000ä¸‡å††ã€‚
æœ€é©è§£ç™ºè¦‹ã®æˆåŠŸç‡ã‚‚é«˜ã„ã€‚

</details>

**Q3.3**: ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’ä½¿ã£ã¦ã€Li-Co-Ni-Oç³»é›»æ± ææ–™ã®æœ€é©çµ„æˆã‚’è¦‹ã¤ã‘ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Œæˆã•ã›ã¦ãã ã•ã„ã€‚

```python
from skopt import gp_minimize

def battery_objective(composition):
    x_Li, x_Co, x_Ni = composition
    # å®¹é‡ãƒ¢ãƒ‡ãƒ«(ç°¡ç•¥åŒ–)
    capacity = 250 + 30*x_Li - 100*(x_Li - 0.6)**2 + 20*x_Co
    return ______  # æœ€å¤§åŒ–ã—ãŸã„ã®ã§ç¬¦å·ã‚’åè»¢

space = [(0.3, 0.9), (0.1, 0.5), (0.1, 0.4)]

result = gp_minimize(
    ______,        # ç›®çš„é–¢æ•°
    ______,        # æ¢ç´¢ç©ºé–“
    n_calls=20,
    random_state=42
)

optimal_Li = result.______[0]
print(f"æœ€é©Liå«æœ‰ç‡: {optimal_Li:.3f}")
```

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

```python
return -capacity  # æœ€å¤§åŒ–ã‚’æœ€å°åŒ–å•é¡Œã«å¤‰æ›

result = gp_minimize(
    battery_objective,  # ç›®çš„é–¢æ•°
    space,              # æ¢ç´¢ç©ºé–“
    n_calls=20,
    random_state=42
)

optimal_Li = result.x[0]
```

</details>

**Q3.4**: ã‚ãªãŸã¯ãƒªãƒã‚¦ãƒ ã‚¤ã‚ªãƒ³é›»æ± ã®ç ”ç©¶è€…ã§ã™ã€‚ä»¥ä¸‹ã®ã©ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å–ã‚Šã¾ã™ã‹?

**çŠ¶æ³**: å€™è£œææ–™500ç¨®é¡ã€å®Ÿé¨“äºˆç®—20å›åˆ†ã€ç›®æ¨™ã¯å®¹é‡300 mAh/gä»¥ä¸Š

- A. å…¨å€™è£œã‚’å®Ÿé¨“(äºˆç®—ä¸è¶³)
- B. ãƒ©ãƒ³ãƒ€ãƒ ã«20å€‹é¸ã‚“ã§å®Ÿé¨“
- C. æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰â†’äºˆæ¸¬ä¸Šä½20å€‹ã‚’å®Ÿé¨“

<details>
<summary>è§£ç­”ã‚’è¡¨ç¤º</summary>

**C**: MI+å®Ÿé¨“ã®å”èª¿ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€‚

**æ‰‹é †**:
1. æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
2. 500å€™è£œã®äºˆæ¸¬å®¹é‡ã‚’è¨ˆç®—
3. ä¸Šä½20å€‹ã‚’é¸ã‚“ã§å®Ÿé¨“æ¤œè¨¼
4. å®Ÿé¨“çµæœã§ãƒ¢ãƒ‡ãƒ«ã‚’æ”¹å–„(Active Learning)

</details>

**Q3.5**: Materials Projectã‹ã‚‰å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å«ã‚ã¦ãã ã•ã„:

1. ãƒ‡ãƒ¼ã‚¿åé›†(MP API)
2. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°(matminer)
3. ãƒ¢ãƒ‡ãƒ«è¨“ç·´(Random Forest)
4. æ€§èƒ½è©•ä¾¡(MAE, RÂ²)
5. çµæœã®å¯è¦–åŒ–

<details>
<summary>è§£ç­”ã®ãƒ’ãƒ³ãƒˆ</summary>

Section 4.1ã¨Section 8.2ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ:

- MP APIã‚­ãƒ¼ã®å–å¾—(https://materialsproject.org/api)
- `matminer.featurizers.composition.ElementProperty`ã§è‡ªå‹•ç‰¹å¾´é‡è¨ˆç®—
- è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²(80/20)
- äº¤å·®æ¤œè¨¼ã§æ€§èƒ½è©•ä¾¡
- äºˆæ¸¬ vs å®Ÿæ¸¬ã®ãƒ—ãƒ­ãƒƒãƒˆ

</details>

**Q3.6**: è‡ªåˆ†ãŒèˆˆå‘³ã®ã‚ã‚‹ææ–™ç³»(ä¾‹: å¤ªé™½é›»æ± ã€è§¦åª’ã€æ§‹é€ ææ–™)ã§ã€MIã‚’é©ç”¨ã™ã‚‹å…·ä½“çš„ãªè¨ˆç”»ã‚’ç«‹ã¦ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã‚’å«ã‚ã‚‹ã“ã¨:

1. äºˆæ¸¬ã—ãŸã„ç‰©æ€§
2. å¿…è¦ãªãƒ‡ãƒ¼ã‚¿
3. ä½¿ç”¨ã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
4. æœŸå¾…ã•ã‚Œã‚‹æˆæœ

<details>
<summary>è©•ä¾¡åŸºæº–</summary>

ä»¥ä¸‹ã®è¦ç´ ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°åˆæ ¼:
- æ˜ç¢ºãªäºˆæ¸¬ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ(ç‰©æ€§å€¤)
- ç¾å®Ÿçš„ãªãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹(ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€æ–‡çŒ®ã€å®Ÿé¨“)
- ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«é©ã—ãŸã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ
- å®šé‡çš„ãªæˆåŠŸåŸºæº–(ç²¾åº¦ã€å®Ÿé¨“å‰Šæ¸›ç‡ãªã©)

</details>

---

### ğŸ“Š æ¼”ç¿’å•é¡Œã®ã¾ã¨ã‚

**å­¦ç¿’åˆ°é”åº¦ã®è‡ªå·±è©•ä¾¡**:

**ãƒ¬ãƒ™ãƒ«1: åŸºç¤ç†è§£**(ç›®æ¨™: å…¨é …ç›®ã‚¯ãƒªã‚¢)
- [ ] MIã¨ã¯ä½•ã‹ã€ä»–äººã«èª¬æ˜ã§ãã‚‹
- [ ] æ©Ÿæ¢°å­¦ç¿’ã®åŸºæœ¬ã‚¹ãƒ†ãƒƒãƒ—ã‚’çŸ¥ã£ã¦ã„ã‚‹
- [ ] ææ–™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹(Materials Project)ã®å­˜åœ¨ã‚’çŸ¥ã£ã¦ã„ã‚‹

**ãƒ¬ãƒ™ãƒ«2: å®Ÿè·µã‚¹ã‚­ãƒ«**(ç›®æ¨™: 3/5é …ç›®ã‚¯ãƒªã‚¢)
- [ ] Pythonã§ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚Œã‚‹
- [ ] Materials Project APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã‚‹
- [ ] matminerã§ç‰¹å¾´é‡ã‚’è¨ˆç®—ã§ãã‚‹
- [ ] ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’MAEã‚„RÂ²ã§è©•ä¾¡ã§ãã‚‹
- [ ] ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®åŸºæœ¬ã‚³ãƒ¼ãƒ‰ã‚’ç†è§£ã§ãã‚‹

**ãƒ¬ãƒ™ãƒ«3: å¿œç”¨åŠ›**(ç›®æ¨™: 2/4é …ç›®ã‚¯ãƒªã‚¢)
- [ ] è‡ªåˆ†ã®ç ”ç©¶ãƒ†ãƒ¼ãƒã«MIã‚’é©ç”¨ã™ã‚‹è¨ˆç”»ã‚’ç«‹ã¦ã‚‰ã‚Œã‚‹
- [ ] éå­¦ç¿’ã‚’è¨ºæ–­ã—ã€å¯¾ç­–ã‚’å®Ÿæ–½ã§ãã‚‹
- [ ] è¤‡æ•°ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ¯”è¼ƒã—ã€æœ€é©ã‚’é¸ã¹ã‚‹
- [ ] GNNã‚„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®è«–æ–‡ã‚’èª­ã‚ã‚‹

**ã‚ãªãŸã®åˆ°é”ãƒ¬ãƒ™ãƒ«**: _____

---
**å­¦ç¿’é€²æ—**: â– â– â– â– â– â– â– â– â– â–  90% (Section 9/10å®Œäº†)
**æ¨å®šæ®‹ã‚Šæ™‚é–“**: 0-30åˆ†
---

## 10. ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### 10.1 ã“ã®è¨˜äº‹ã§å­¦ã‚“ã ã“ã¨

**1. MIã®åŸºæœ¬æ¦‚å¿µ**

- ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚‹ææ–™é–‹ç™ºã®åŠ é€Ÿ
- æ©Ÿæ¢°å­¦ç¿’ã€ææ–™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€è¨ˆç®—ææ–™ç§‘å­¦ã®çµ±åˆ
- å®Ÿé¨“ã¨ã®å”èª¿ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¯ãƒ«

**2. æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤**

- æ•™å¸«ã‚ã‚Šå­¦ç¿’(å›å¸°ãƒ»åˆ†é¡)
- ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã€äºˆæ¸¬ã€è©•ä¾¡
- éå­¦ç¿’ã®è¨ºæ–­ã¨å¯¾ç­–

**3. ææ–™ãƒ‡ãƒ¼ã‚¿ã®æ‰±ã„æ–¹**

- Materials Projectãªã©ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ´»ç”¨
- ææ–™è¨˜è¿°å­(descriptor)ã«ã‚ˆã‚‹æ•°å€¤åŒ–
- ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

**4. å®Ÿè·µçš„ã‚¹ã‚­ãƒ«**

- Pythonã¨matminerã€scikit-learnã‚’ä½¿ã£ãŸææ–™ç‰©æ€§äºˆæ¸¬
- ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®åŸºç¤
- ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªææ–™æ¢ç´¢

### 10.2 æ¬¡ã«å­¦ã¶ã¹ããƒˆãƒ”ãƒƒã‚¯

#### åˆç´šã‹ã‚‰ä¸­ç´šã¸

**1. æ·±å±¤å­¦ç¿’ã®è©³ç´°**

- PyTorchã«ã‚ˆã‚‹å®Ÿè£…
- ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(CGCNN, MEGNet)
- è»¢ç§»å­¦ç¿’ã®æ´»ç”¨[^10]

**2. å°ãƒ‡ãƒ¼ã‚¿æ©Ÿæ¢°å­¦ç¿’**

- ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°
- ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®é«˜åº¦ãªæ‰‹æ³•[^7]
- ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæŠ€è¡“

**3. èª¬æ˜å¯èƒ½AI(XAI)**

- SHAP(SHapley Additive exPlanations)
- LIME(Local Interpretable Model-agnostic Explanations)
- ç‰¹å¾´é‡ã®é‡è¦åº¦åˆ†æ[^13]

#### å¿œç”¨ãƒ¬ãƒ™ãƒ«ã¸

**4. é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—**

- Atomate2ã«ã‚ˆã‚‹è‡ªå‹•ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- ç¬¬ä¸€åŸç†è¨ˆç®—(DFT)ã¨ã®çµ±åˆ

**5. å®Ÿé¨“ã¨ã®çµ±åˆ**

- èƒ½å‹•å­¦ç¿’ã«ã‚ˆã‚‹å®Ÿé¨“è¨ˆç”»
- ãƒ­ãƒœãƒƒãƒˆå®Ÿé¨“ã¨ã®é€£æº

**6. æœ€æ–°ç ”ç©¶ãƒˆãƒ”ãƒƒã‚¯**

- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«(LLM)ã®MIã¸ã®å¿œç”¨
- ç”Ÿæˆãƒ¢ãƒ‡ãƒ«(VAE, GAN)ã«ã‚ˆã‚‹ææ–™è¨­è¨ˆ
- é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®æ´»ç”¨

### 10.3 æ¨å¥¨å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹

#### ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¼ã‚¹

**1. MIT: Machine Learning for Materials Informatics(2025)**
- URL: https://professional.mit.edu/course-catalog/machine-learning-materials-informatics
- å†…å®¹: GPT-3ã€AlphaFoldã€GNNã®ææ–™ç§‘å­¦å¿œç”¨
- ãƒ¬ãƒ™ãƒ«: ä¸­ç´šã€œä¸Šç´š

**2. Materials Project Workshop**
- URL: https://workshop.materialsproject.org/
- å†…å®¹: MP APIã€matminerã€é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- ãƒ¬ãƒ™ãƒ«: åˆç´šã€œä¸­ç´š

#### GitHubãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«

**3. Introduction to Materials Informatics(Skoltech)**
- URL: https://github.com/dembart/intro-to-materials-informatics
- å†…å®¹: Jupyter Notebookãƒ™ãƒ¼ã‚¹ã®å®Ÿè·µãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
- ãƒ¬ãƒ™ãƒ«: åˆç´š

**4. CGCNN Tutorial**
- URL: https://github.com/Diego-2504/CGCNN_tutorial
- å†…å®¹: ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å®Ÿè£…
- ãƒ¬ãƒ™ãƒ«: ä¸­ç´š

#### æ›¸ç±ãƒ»è«–æ–‡

**5. Materials informatics: A review of AI and machine learning tools(2025)**[^1]
- æœ€æ–°ã®MIãƒ¬ãƒ“ãƒ¥ãƒ¼è«–æ–‡
- å®Ÿé¨“ç ”ç©¶è€…å‘ã‘ã®åŒ…æ‹¬çš„è§£èª¬

**6. Recent progress on machine learning with limited materials data(2024)**[^7]
- å°ãƒ‡ãƒ¼ã‚¿æ©Ÿæ¢°å­¦ç¿’ã®æœ€æ–°æ‰‹æ³•
- è»¢ç§»å­¦ç¿’ã€èƒ½å‹•å­¦ç¿’ã®è©³ç´°

### 10.4 ã‚ˆãã‚ã‚‹è³ªå•(FAQ)

**Q: Pythonã‚‚AIã‚‚åˆã‚ã¦ã§ã™ãŒã€MIã‚’å­¦ã¹ã¾ã™ã‹?**

A: ã¯ã„ã€å­¦ã¹ã¾ã™ã€‚æ¨å¥¨å­¦ç¿’é †åº:
1. PythonåŸºç¤(2-4é€±é–“)
2. ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–(1-2é€±é–“)
3. æ©Ÿæ¢°å­¦ç¿’å…¥é–€(4-6é€±é–“)
4. MIå®Ÿè·µ(ç¶™ç¶šçš„)

**Q: ã©ã®ãã‚‰ã„ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚Œã¾ã™ã‹?**

A: ä¸€èˆ¬çš„ã«ã¯**100ã‚µãƒ³ãƒ—ãƒ«ä»¥ä¸Š**ãŒç›®å®‰ã§ã™ã€‚ãŸã ã—:
- å˜ç´”ãªç·šå½¢ãƒ¢ãƒ‡ãƒ«: 10-50ã‚µãƒ³ãƒ—ãƒ«
- ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ: 50-500ã‚µãƒ³ãƒ—ãƒ«
- ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ: 1000+ã‚µãƒ³ãƒ—ãƒ«

å°ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯ã€ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ã‚„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ãŒæœ‰åŠ¹ã§ã™ã€‚

**Q: è‡ªåˆ†ã®ç ”ç©¶ãƒ†ãƒ¼ãƒã«MIã‚’é©ç”¨ã§ãã‚‹ã‹ã‚ã‹ã‚Šã¾ã›ã‚“ã€‚**

A: ä»¥ä¸‹ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã§åˆ¤æ–­ã§ãã¾ã™:
- [ ] éå»ã®å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ãŒè“„ç©ã•ã‚Œã¦ã„ã‚‹(10å€‹ä»¥ä¸Š)
- [ ] äºˆæ¸¬ã—ãŸã„ç‰¹æ€§ãŒæ˜ç¢º(èç‚¹ã€å¼·åº¦ã€é›»æ°—ä¼å°åº¦ãªã©)
- [ ] ææ–™ã®çµ„æˆã‚„æ§‹é€ ãŒæ•°å€¤åŒ–å¯èƒ½
- [ ] å®Ÿé¨“ãŒé«˜ã‚³ã‚¹ãƒˆã¾ãŸã¯æ™‚é–“ãŒã‹ã‹ã‚‹

2ã¤ä»¥ä¸Šè©²å½“ã™ã‚Œã°ã€MIã®é©ç”¨ã‚’æ¤œè¨ã™ã‚‹ä¾¡å€¤ãŒã‚ã‚Šã¾ã™ã€‚

**Q: æ©Ÿæ¢°å­¦ç¿’ã®äºˆæ¸¬çµæœã¯ã©ã“ã¾ã§ä¿¡é ¼ã§ãã¾ã™ã‹?**

A: äºˆæ¸¬ã«ã¯å¿…ãšä¸ç¢ºå®Ÿæ€§ãŒã‚ã‚Šã¾ã™ã€‚ä¿¡é ¼æ€§ã®è©•ä¾¡ã«ã¯:
- **RÂ²ã‚¹ã‚³ã‚¢**: > 0.9(é«˜ç²¾åº¦)ã€0.7-0.9(è‰¯ã„)ã€< 0.5(æ”¹å–„å¿…è¦)
- **RMSE**: äºˆæ¸¬èª¤å·®ã®å¤§ãã•
- **äº¤å·®æ¤œè¨¼**: è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã§ä¸€è²«ã—ãŸæ€§èƒ½

æœ€çµ‚çš„ã«ã¯**å®Ÿé¨“ã«ã‚ˆã‚‹æ¤œè¨¼ãŒä¸å¯æ¬ **ã§ã™ã€‚

---

### ğŸ“Š æœ€çµ‚ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ã¾ã¨ã‚

**å…¨ä½“ã®æŒ¯ã‚Šè¿”ã‚Š**:
- âœ“ MIã¯ææ–™é–‹ç™ºã‚’2-5å¹´ã«çŸ­ç¸®
- âœ“ æ©Ÿæ¢°å­¦ç¿’ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€è¨ˆç®—ç§‘å­¦ã®çµ±åˆ
- âœ“ å®Ÿè·µã‚¹ã‚­ãƒ«: Python + matminer + scikit-learn
- âœ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: æ·±å±¤å­¦ç¿’ã€å°ãƒ‡ãƒ¼ã‚¿MLã€èª¬æ˜å¯èƒ½AI

**ã‚ãªãŸã®æˆæœ**:
- 10ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã€25+æ¼”ç¿’å•é¡Œã‚’å®Œäº†
- å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ã§ RÂ² = 0.876 é”æˆ
- é›»æ± å®¹é‡äºˆæ¸¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œæˆ
- MIã®å…¨ä½“åƒã‚’ç†è§£

> ğŸ‰ **ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™!**
>
> ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºãƒ»ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã®åŸºç¤ã‚’å®Œå…¨ã«ãƒã‚¹ã‚¿ãƒ¼ã—ã¾ã—ãŸã€‚
> æ¬¡ã¯å®Ÿéš›ã®ç ”ç©¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§MIã‚’æ´»ç”¨ã—ã¦ãã ã•ã„!

---
**å­¦ç¿’é€²æ—**: â– â– â– â– â– â– â– â– â– â–  100% (å®Œäº†!)
---

## 11. å‚è€ƒæ–‡çŒ®

[^1]: Materials informatics: A review of AI and machine learning tools. ScienceDirect(2025å¹´8æœˆ). https://www.sciencedirect.com/science/article/pii/S2352492825020379

[^2]: Li, J., et al. Methods, progresses, and opportunities of materials informatics. *InfoMat*(2023). https://onlinelibrary.wiley.com/doi/full/10.1002/inf2.12425

[^3]: Materials Project. https://materialsproject.org

[^4]: Open Quantum Materials Database(OQMD). http://oqmd.org

[^5]: NOMAD Repository. https://nomad-lab.eu/

[^6]: Xie, T., & Grossman, J. C. Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties. *Physical Review Letters*(2018). https://github.com/txie-93/cgcnn

[^7]: Recent progress on machine learning with limited materials data. *Materials Today*(2024å¹´5æœˆ). https://www.sciencedirect.com/science/article/pii/S2352847824001552

[^8]: Shi, M., et al. A review on the applications of graph neural networks in materials science. *Materials Genome Engineering Advances*(2024). https://onlinelibrary.wiley.com/doi/full/10.1002/mgea.50

[^9]: Geometric-information-enhanced crystal graph network. *Communications Materials*(2021). https://www.nature.com/articles/s43246-021-00194-3

[^10]: Structure-aware GNN based deep transfer learning framework. *npj Computational Materials*(2023). https://www.nature.com/articles/s41524-023-01185-3

[^11]: Rapid discovery via active learning with multi-objective optimization. ScienceDirect(2024). https://www.sciencedirect.com/science/article/abs/pii/S2352492823019360

[^12]: Multi-objective materials Bayesian optimization with active learning. *Acta Materialia*(2022). https://www.sciencedirect.com/science/article/abs/pii/S1359645422005146

[^13]: Explainable machine learning in materials science. *npj Computational Materials*(2022). https://www.nature.com/articles/s41524-022-00884-7

---

## ä»˜éŒ²A: ç’°å¢ƒæ§‹ç¯‰ã‚¬ã‚¤ãƒ‰

### A.1 Pythonç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# Anacondaã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«(æ¨å¥¨)
# https://www.anaconda.com/download

# ä»®æƒ³ç’°å¢ƒã®ä½œæˆ
conda create -n mi_env python=3.10
conda activate mi_env

# å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«(ãƒãƒ¼ã‚¸ãƒ§ãƒ³æŒ‡å®š)
pip install numpy==1.24.3 pandas==2.0.3
pip install matplotlib==3.7.2 seaborn==0.12.2
pip install scikit-learn==1.3.0 scipy==1.11.1
pip install pymatgen==2023.9.25 matminer==0.9.0
pip install torch==2.1.0 torchvision==0.16.0  # PyTorch
pip install scikit-optimize==0.9.0    # ãƒ™ã‚¤ã‚ºæœ€é©åŒ–

# Materials Project API
pip install mp-api==0.39.5

# Jupyter Notebook
pip install jupyter
```

### A.2 Google Colabã§ã®å®Ÿè¡Œ(APIã‚­ãƒ¼ä¸è¦)

Google Colab(https://colab.research.google.com/)ãªã‚‰ã€ç’°å¢ƒæ§‹ç¯‰ãªã—ã§å³åº§ã«å®Ÿè¡Œã§ãã¾ã™ã€‚

```python
# Colabã§ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
!pip install pymatgen matminer mp-api scikit-optimize

# ä»¥é™ã€æœ¬è¨˜äº‹ã®ã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾å®Ÿè¡Œå¯èƒ½
```

---

**è¨˜äº‹ä½œæˆæ—¥**: 2025å¹´10æœˆ16æ—¥
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 2.0(Comprehensive Enhancement)
**è‘—è€…**: Content Agent(MI Knowledge Hub)
**ãƒ¬ãƒ“ãƒ¥ãƒ¼**: Academic Reviewer, Tutor Agent, Data Agent, Design Agent
**æ¨å®šèª­äº†æ™‚é–“**: 120-150åˆ†(ã‚³ãƒ¼ãƒ‰å®Ÿè·µå«ã‚€)
**æ¬¡ã®è¨˜äº‹**: ã€Œæ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤:ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é¸æŠã¨è©•ä¾¡ã€(ä¸­ç´šç·¨)
