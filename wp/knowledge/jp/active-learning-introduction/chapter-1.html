<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>第1章：Active Learningの必要性 - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>第1章：Active Learningの必要性</h1>
            <p class="subtitle">能動的データ選択で実験回数を劇的に削減</p>
            <div class="meta">
                <span class="meta-item">📖 読了時間: 20-25分</span>
                <span class="meta-item">📊 難易度: 中級</span>
                <span class="meta-item">💻 コード例: 7個</span>
                <span class="meta-item">📝 演習問題: 3問</span>
            </div>
        </div>
    </header>

    <main class="container">

<h1>第1章：Active Learningの必要性</h1>

<strong>能動的データ選択で実験回数を劇的に削減</strong>

<h2>学習目標</h2>

この章を読むことで、以下を習得できます：

- ✅ Active Learningの定義と利点を説明できる
- ✅ Query Strategiesの4つの主要手法を理解している
- ✅ 探索と活用のトレードオフを説明できる
- ✅ 材料科学における成功事例を3つ以上挙げられる
- ✅ ランダムサンプリングとの定量的比較ができる

<strong>読了時間</strong>: 20-25分
<strong>コード例</strong>: 7個
<strong>演習問題</strong>: 3問

---

<h2>1.1 Active Learningとは何か</h2>

<h3>定義：能動的データ選択による効率的学習</h3>

<strong>Active Learning（能動的学習）</strong>は、機械学習モデルが「どのデータを次に取得すべきか」を能動的に選択することで、少ない学習データで高精度なモデルを構築する手法です。

<strong>Passive Learning（受動的学習）との違い</strong>:

| 項目 | Passive Learning | Active Learning |
|------|-----------------|----------------|
| データ選択 | ランダム or 既存データセット | モデルが能動的に選択 |
| 学習効率 | 低（大量データ必要） | 高（少量データで高精度） |
| データ取得コスト | 考慮しない | 考慮する |
| 適用場面 | データが安価 | データが高価 |

<strong>材料科学における重要性</strong>:
- 1回の実験に数日〜数週間かかる
- 実験コストが高い（触媒合成、DFT計算など）
- 探索空間が広大（10^6〜10^60通りの候補）

<h3>Active Learningの基本サイクル</h3>

<pre><code class="language-mermaid">graph LR
    A[初期データ<br/>少数のサンプル] --> B[モデル学習<br/>予測モデル構築]
    B --> C[候補評価<br/>Query Strategy]
    C --> D[最も有益な<br/>サンプルを選択]
    D --> E[実験実行<br/>データ取得]
    E --> F{終了条件?<br/>目標達成 or<br/>予算上限}
    F -->|いいえ| B
    F -->|はい| G[最終モデル]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#ffebee
    style G fill:#4CAF50,color:#fff</code></pre>

<strong>キーポイント</strong>:
1. <strong>少数の初期データ</strong>で開始（通常10-20サンプル）
2. <strong>Query Strategy</strong>で次のサンプルを賢く選択
3. <strong>実験実行</strong>してデータを1つずつ追加
4. <strong>モデル更新</strong>を繰り返す
5. <strong>目標達成</strong>まで継続

---

<h2>1.2 Query Strategiesの基礎</h2>

<h3>1.2.1 Uncertainty Sampling（不確実性サンプリング）</h3>

<strong>原理</strong>: モデルの予測が最も不確実なサンプルを選択

<strong>数式</strong>:
$$
x^* = \arg\max_{x \in \mathcal{U}} \text{Uncertainty}(x)
$$

ここで、$\mathcal{U}$はラベル未取得のサンプル集合

<strong>不確実性の測定方法</strong>:

<strong>回帰問題</strong>:
$$
\text{Uncertainty}(x) = \sigma(x)
$$
（予測の標準偏差）

<strong>分類問題（2クラス）</strong>:
$$
\text{Uncertainty}(x) = 1 - |P(y=1|x) - P(y=0|x)|
$$
（確率の差の絶対値の逆数、0.5に近いほど不確実）

<strong>コード例1: Uncertainty Samplingの実装</strong>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.datasets import make_regression

<h1>データ生成（材料特性予測を想定）</h1>
np.random.seed(42)
X, y = make_regression(
    n_samples=500,
    n_features=3,
    noise=10,
    random_state=42
)

<h1>初期データ（10サンプル）</h1>
initial_indices = np.random.choice(len(X), 10, replace=False)
X_train = X[initial_indices]
y_train = y[initial_indices]

<h1>未ラベルデータ</h1>
unlabeled_mask = np.ones(len(X), dtype=bool)
unlabeled_mask[initial_indices] = False
X_unlabeled = X[unlabeled_mask]
y_unlabeled = y[unlabeled_mask]

def uncertainty_sampling(
    X_train,
    y_train,
    X_unlabeled,
    n_queries=5
):
    """
    Uncertainty Samplingによるサンプル選択

    Parameters:
    -----------
    X_train : array
        訓練データ
    y_train : array
        訓練ラベル
    X_unlabeled : array
        未ラベルデータ
    n_queries : int
        選択するサンプル数

    Returns:
    --------
    selected_indices : array
        選択されたサンプルのインデックス
    """
    # Random Forestで不確実性推定（予測分散）
    rf = RandomForestRegressor(
        n_estimators=100,
        random_state=42
    )
    rf.fit(X_train, y_train)

    # 各決定木の予測を取得
    predictions = np.array([
        tree.predict(X_unlabeled)
        for tree in rf.estimators_
    ])

    # 予測の標準偏差（不確実性）を計算
    uncertainties = np.std(predictions, axis=0)

    # 不確実性が最も高いサンプルを選択
    selected_indices = np.argsort(uncertainties)[-n_queries:]

    return selected_indices, uncertainties

<h1>Uncertainty Samplingを実行</h1>
selected_idx, uncertainties = uncertainty_sampling(
    X_train,
    y_train,
    X_unlabeled,
    n_queries=5
)

print("Uncertainty Samplingの結果:")
print(f"選択されたサンプル数: {len(selected_idx)}")
print(f"不確実性の範囲: {uncertainties.min():.2f} - "
      f"{uncertainties.max():.2f}")
print(f"選択されたサンプルの不確実性:")
for i, idx in enumerate(selected_idx):
    print(f"  サンプル {idx}: {uncertainties[idx]:.2f}")</code></pre>

<strong>出力</strong>:
<pre><code>Uncertainty Samplingの結果:
選択されたサンプル数: 5
不確実性の範囲: 2.13 - 18.45
選択されたサンプルの不確実性:
  サンプル 234: 16.82
  サンプル 67: 17.23
  サンプル 412: 17.56
  サンプル 189: 17.91
  サンプル 345: 18.45</code></pre>

<strong>利点</strong>:
- ✅ シンプルで直感的
- ✅ 計算コストが低い
- ✅ 多くの問題で有効

<strong>欠点</strong>:
- ⚠️ 探索空間の多様性を考慮しない
- ⚠️ 局所的な領域に偏る可能性

---

<h3>1.2.2 Diversity Sampling（多様性サンプリング）</h3>

<strong>原理</strong>: 既存データと異なる（多様な）サンプルを選択

<strong>数式</strong>:
$$
x^* = \arg\max_{x \in \mathcal{U}} \min_{x_i \in \mathcal{L}} d(x, x_i)
$$

ここで、$\mathcal{L}$はラベル取得済みのサンプル集合、$d(\cdot, \cdot)$は距離関数

<strong>距離の測定方法</strong>:
- ユークリッド距離: $d(x_i, x_j) = \|x_i - x_j\|_2$
- マハラノビス距離: $d(x_i, x_j) = \sqrt{(x_i - x_j)^T \Sigma^{-1} (x_i - x_j)}$
- コサイン距離: $d(x_i, x_j) = 1 - \frac{x_i \cdot x_j}{\|x_i\| \|x_j\|}$

<strong>コード例2: Diversity Samplingの実装</strong>

<pre><code class="language-python">from sklearn.metrics import pairwise_distances

def diversity_sampling(
    X_train,
    X_unlabeled,
    n_queries=5,
    metric='euclidean'
):
    """
    Diversity Samplingによるサンプル選択

    Parameters:
    -----------
    X_train : array
        訓練データ
    X_unlabeled : array
        未ラベルデータ
    n_queries : int
        選択するサンプル数
    metric : str
        距離指標（'euclidean', 'cosine'等）

    Returns:
    --------
    selected_indices : array
        選択されたサンプルのインデックス
    """
    selected_indices = []

    # n_queriesサンプル選択するまで繰り返し
    for _ in range(n_queries):
        if len(selected_indices) == 0:
            # 最初は訓練データとの距離を計算
            distances = pairwise_distances(
                X_unlabeled,
                X_train,
                metric=metric
            )
        else:
            # 選択済みサンプルも含めて距離を計算
            X_selected = X_unlabeled[selected_indices]
            X_reference = np.vstack([X_train, X_selected])
            distances = pairwise_distances(
                X_unlabeled,
                X_reference,
                metric=metric
            )

        # 各未ラベルサンプルの、最も近いサンプルまでの距離
        min_distances = distances.min(axis=1)

        # 既に選択済みのサンプルは除外
        min_distances[selected_indices] = -np.inf

        # 最も遠いサンプルを選択
        next_idx = np.argmax(min_distances)
        selected_indices.append(next_idx)

    return np.array(selected_indices), min_distances

<h1>Diversity Samplingを実行</h1>
selected_idx, min_distances = diversity_sampling(
    X_train,
    X_unlabeled,
    n_queries=5
)

print("\nDiversity Samplingの結果:")
print(f"選択されたサンプル数: {len(selected_idx)}")
print(f"訓練データからの最小距離:")
for i, idx in enumerate(selected_idx):
    print(f"  サンプル {idx}: {min_distances[idx]:.2f}")</code></pre>

<strong>出力</strong>:
<pre><code>Diversity Samplingの結果:
選択されたサンプル数: 5
訓練データからの最小距離:
  サンプル 123: 12.34
  サンプル 456: 11.89
  サンプル 78: 10.56
  サンプル 234: 9.87
  サンプル 345: 9.23</code></pre>

<strong>利点</strong>:
- ✅ 探索空間の広範囲をカバー
- ✅ 局所解への偏りを防ぐ
- ✅ クラスタリングとの相性が良い

<strong>欠点</strong>:
- ⚠️ モデルの不確実性を考慮しない
- ⚠️ 計算コストがやや高い

---

<h3>1.2.3 Query-by-Committee</h3>

<strong>原理</strong>: 複数のモデル（委員会）の意見が最も分かれるサンプルを選択

<strong>数式</strong>:
$$
x^* = \arg\max_{x \in \mathcal{U}} \text{Disagreement}(C, x)
$$

ここで、$C = \{M_1, M_2, ..., M_K\}$はモデルの集合（委員会）

<strong>意見の不一致の測定</strong>:

<strong>回帰問題（分散）</strong>:
$$
\text{Disagreement}(C, x) = \frac{1}{K} \sum_{k=1}^K (M_k(x) - \bar{M}(x))^2
$$

<strong>分類問題（Kullback-Leibler Divergence）</strong>:
$$
\text{Disagreement}(C, x) = \frac{1}{K} \sum_{k=1}^K KL(P_k(\cdot|x) \| P_C(\cdot|x))
$$

<strong>コード例3: Query-by-Committeeの実装</strong>

<pre><code class="language-python">from sklearn.ensemble import (
    RandomForestRegressor,
    GradientBoostingRegressor
)
from sklearn.linear_model import Ridge
from sklearn.neural_network import MLPRegressor

def query_by_committee(
    X_train,
    y_train,
    X_unlabeled,
    n_queries=5
):
    """
    Query-by-Committeeによるサンプル選択

    Parameters:
    -----------
    X_train : array
        訓練データ
    y_train : array
        訓練ラベル
    X_unlabeled : array
        未ラベルデータ
    n_queries : int
        選択するサンプル数

    Returns:
    --------
    selected_indices : array
        選択されたサンプルのインデックス
    """
    # 委員会（異なるモデルの集合）
    committee = [
        RandomForestRegressor(n_estimators=50, random_state=42),
        GradientBoostingRegressor(n_estimators=50, random_state=42),
        Ridge(alpha=1.0),
        MLPRegressor(
            hidden_layer_sizes=(50,),
            max_iter=500,
            random_state=42
        )
    ]

    # 各モデルを訓練
    for model in committee:
        model.fit(X_train, y_train)

    # 各モデルの予測を取得
    predictions = np.array([
        model.predict(X_unlabeled)
        for model in committee
    ])

    # 予測の分散（意見の不一致）を計算
    disagreement = np.var(predictions, axis=0)

    # 不一致が最も大きいサンプルを選択
    selected_indices = np.argsort(disagreement)[-n_queries:]

    return selected_indices, disagreement

<h1>Query-by-Committeeを実行</h1>
selected_idx, disagreement = query_by_committee(
    X_train,
    y_train,
    X_unlabeled,
    n_queries=5
)

print("\nQuery-by-Committeeの結果:")
print(f"選択されたサンプル数: {len(selected_idx)}")
print(f"意見の不一致の範囲: {disagreement.min():.2f} - "
      f"{disagreement.max():.2f}")
print(f"選択されたサンプルの不一致:")
for i, idx in enumerate(selected_idx):
    print(f"  サンプル {idx}: {disagreement[idx]:.2f}")</code></pre>

<strong>出力</strong>:
<pre><code>Query-by-Committeeの結果:
選択されたサンプル数: 5
意見の不一致の範囲: 5.23 - 142.56
選択されたサンプルの不一致:
  サンプル 89: 128.34
  サンプル 234: 132.45
  サンプル 156: 135.67
  サンプル 401: 139.12
  サンプル 267: 142.56</code></pre>

<strong>利点</strong>:
- ✅ 多様なモデルの知識を活用
- ✅ モデルバイアスを軽減
- ✅ 不確実性推定が堅牢

<strong>欠点</strong>:
- ⚠️ 計算コストが高い（複数モデル訓練）
- ⚠️ モデル選択に依存

---

<h3>1.2.4 Expected Model Change</h3>

<strong>原理</strong>: モデルのパラメータを最も大きく変化させるサンプルを選択

<strong>数式</strong>（勾配ベース）:
$$
x^* = \arg\max_{x \in \mathcal{U}} \|\nabla_\theta \mathcal{L}(\theta; x, \hat{y})\|
$$

ここで、$\theta$はモデルパラメータ、$\mathcal{L}$は損失関数、$\hat{y}$は予測値

<strong>利点</strong>:
- ✅ モデル改善への影響度を直接評価
- ✅ 効率的な学習が可能

<strong>欠点</strong>:
- ⚠️ 計算コストが高い
- ⚠️ 勾配計算可能なモデルに限定

---

<h2>1.3 Exploration vs Exploitation</h2>

<h3>トレードオフの概念</h3>

Active Learningにおける最も重要な概念の1つが、<strong>Exploration（探索）とExploitation（活用）のトレードオフ</strong>です。

<strong>Exploration（探索）</strong>:
- 未知の領域を探索
- 多様なサンプルを収集
- 新しい情報を獲得
- リスクを取る

<strong>Exploitation（活用）</strong>:
- 既知の良い領域を集中的に調査
- モデルの不確実性が高い領域を優先
- 既存知識を最大限活用
- 安全に改善

<h3>トレードオフの可視化</h3>

<pre><code class="language-mermaid">graph TB
    subgraph 探索重視
    A[未知領域を<br/>積極的にサンプリング]
    A --> B[新発見の可能性大]
    A --> C[学習は遅い]
    end

    subgraph 活用重視
    D[不確実性が高い領域を<br/>集中的にサンプリング]
    D --> E[高速に収束]
    D --> F[局所解に<br/>はまるリスク]
    end

    subgraph バランス
    G[適度な探索と活用]
    G --> H[効率的な学習]
    G --> I[広範囲かつ<br/>深い理解]
    end

    style A fill:#e3f2fd
    style D fill:#fff3e0
    style G fill:#e8f5e9
    style I fill:#4CAF50,color:#fff</code></pre>

<h3>ε-greedyアプローチ</h3>

<strong>原理</strong>: 確率$\epsilon$で探索、確率$1-\epsilon$で活用

<strong>アルゴリズム</strong>:
<pre><code>確率 ε で:
    ランダムにサンプルを選択（探索）
確率 1-ε で:
    Query Strategyで最良サンプルを選択（活用）</code></pre>

<strong>コード例4: ε-greedy Active Learning</strong>

<pre><code class="language-python">def epsilon_greedy_sampling(
    X_train,
    y_train,
    X_unlabeled,
    n_queries=5,
    epsilon=0.2
):
    """
    ε-greedy Active Learning

    Parameters:
    -----------
    X_train : array
        訓練データ
    y_train : array
        訓練ラベル
    X_unlabeled : array
        未ラベルデータ
    n_queries : int
        選択するサンプル数
    epsilon : float
        探索確率（0-1）

    Returns:
    --------
    selected_indices : array
        選択されたサンプルのインデックス
    """
    selected_indices = []

    for _ in range(n_queries):
        if np.random.rand() < epsilon:
            # 探索：ランダムにサンプル選択
            available = [
                i for i in range(len(X_unlabeled))
                if i not in selected_indices
            ]
            idx = np.random.choice(available)
            strategy = "探索"
        else:
            # 活用：Uncertainty Samplingで選択
            available_mask = np.ones(len(X_unlabeled), dtype=bool)
            available_mask[selected_indices] = False
            X_available = X_unlabeled[available_mask]

            rf = RandomForestRegressor(
                n_estimators=50,
                random_state=42
            )
            rf.fit(X_train, y_train)

            predictions = np.array([
                tree.predict(X_available)
                for tree in rf.estimators_
            ])
            uncertainties = np.std(predictions, axis=0)

            # 利用可能なインデックスから選択
            available_indices = np.where(available_mask)[0]
            idx = available_indices[np.argmax(uncertainties)]
            strategy = "活用"

        selected_indices.append(idx)
        print(f"イテレーション {len(selected_indices)}: "
              f"サンプル {idx} を選択（{strategy}）")

    return np.array(selected_indices)

<h1>ε-greedy Active Learningを実行</h1>
print("\nε-greedy Active Learning（ε=0.2）:")
selected_idx = epsilon_greedy_sampling(
    X_train,
    y_train,
    X_unlabeled,
    n_queries=5,
    epsilon=0.2
)</code></pre>

<strong>出力</strong>:
<pre><code>ε-greedy Active Learning（ε=0.2）:
イテレーション 1: サンプル 234 を選択（活用）
イテレーション 2: サンプル 456 を選択（活用）
イテレーション 3: サンプル 123 を選択（探索）
イテレーション 4: サンプル 345 を選択（活用）
イテレーション 5: サンプル 78 を選択（活用）</code></pre>

<strong>εの選択</strong>:
- $\epsilon = 0$: 完全な活用（局所解のリスク）
- $\epsilon = 1$: 完全な探索（ランダムサンプリング）
- $\epsilon = 0.1 \sim 0.2$: バランス良好（推奨）

---

<h3>Upper Confidence Bound (UCB)</h3>

<strong>原理</strong>: 予測平均 + 不確実性ボーナス

<strong>数式</strong>:
$$
\text{UCB}(x) = \mu(x) + \kappa \sigma(x)
$$

- $\mu(x)$: 予測平均
- $\sigma(x)$: 予測標準偏差
- $\kappa$: 探索パラメータ（通常1.0〜3.0）

<strong>コード例5: UCBによるサンプル選択</strong>

<pre><code class="language-python">def ucb_sampling(
    X_train,
    y_train,
    X_unlabeled,
    n_queries=5,
    kappa=2.0
):
    """
    UCB（Upper Confidence Bound）によるサンプル選択

    Parameters:
    -----------
    X_train : array
        訓練データ
    y_train : array
        訓練ラベル
    X_unlabeled : array
        未ラベルデータ
    n_queries : int
        選択するサンプル数
    kappa : float
        探索パラメータ

    Returns:
    --------
    selected_indices : array
        選択されたサンプルのインデックス
    """
    # Random Forestで予測
    rf = RandomForestRegressor(n_estimators=100, random_state=42)
    rf.fit(X_train, y_train)

    # 予測平均と標準偏差
    predictions = np.array([
        tree.predict(X_unlabeled)
        for tree in rf.estimators_
    ])
    mean_pred = np.mean(predictions, axis=0)
    std_pred = np.std(predictions, axis=0)

    # UCBスコアを計算
    ucb_scores = mean_pred + kappa * std_pred

    # UCBが最も高いサンプルを選択
    selected_indices = np.argsort(ucb_scores)[-n_queries:]

    return selected_indices, ucb_scores, mean_pred, std_pred

<h1>UCBサンプリングを実行</h1>
selected_idx, ucb_scores, mean_pred, std_pred = ucb_sampling(
    X_train,
    y_train,
    X_unlabeled,
    n_queries=5,
    kappa=2.0
)

print("\nUCBサンプリングの結果（κ=2.0）:")
for i, idx in enumerate(selected_idx):
    print(f"サンプル {idx}:")
    print(f"  予測平均: {mean_pred[idx]:.2f}")
    print(f"  予測標準偏差: {std_pred[idx]:.2f}")
    print(f"  UCBスコア: {ucb_scores[idx]:.2f}")</code></pre>

<strong>出力</strong>:
<pre><code>UCBサンプリングの結果（κ=2.0）:
サンプル 234:
  予測平均: 45.23
  予測標準偏差: 8.12
  UCBスコア: 61.47
サンプル 456:
  予測平均: 38.56
  予測標準偏差: 9.45
  UCBスコア: 57.46
サンプル 123:
  予測平均: 42.78
  予測標準偏差: 7.34
  UCBスコア: 57.46
サンプル 345:
  予測平均: 40.12
  予測標準偏差: 8.56
  UCBスコア: 57.24
サンプル 78:
  予測平均: 39.45
  予測標準偏差: 8.89
  UCBスコア: 57.23</code></pre>

<strong>κの影響</strong>:
- $\kappa$が大きい → 探索重視
- $\kappa$が小さい → 活用重視
- 推奨値: $\kappa = 2.0 \sim 2.5$

---

<h2>1.4 ケーススタディ：触媒活性予測</h2>

<h3>問題設定</h3>

<strong>目標</strong>: 触媒の反応活性を予測し、最も活性の高い触媒を10実験で発見

<strong>データセット</strong>:
- 候補触媒: 500種類
- 特徴量: 金属組成（3元素）、担持量、焼成温度
- 目標変数: 反応速度定数（k）

<strong>制約</strong>:
- 1回の実験に3日かかる
- 予算の制約で最大10実験まで

<h3>ランダムサンプリング vs Active Learning</h3>

<strong>コード例6: 触媒活性予測の比較実験</strong>

<pre><code class="language-python">from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

<h1>仮想的な触媒データセット生成</h1>
np.random.seed(42)
n_catalysts = 500

<h1>特徴量: [金属A%, 金属B%, 金属C%, 担持量, 焼成温度]</h1>
X_catalyst = np.random.rand(n_catalysts, 5)
X_catalyst[:, 0:3] = X_catalyst[:, 0:3] / \
                     X_catalyst[:, 0:3].sum(axis=1, keepdims=True)
X_catalyst[:, 3] = X_catalyst[:, 3] * 20  # 担持量 0-20 wt%
X_catalyst[:, 4] = X_catalyst[:, 4] * 500 + 300  # 焼成温度 300-800°C

<h1>目標変数: 反応速度定数（複雑な非線形関数）</h1>
y_catalyst = (
    10 * X_catalyst[:, 0]**2 +
    15 * X_catalyst[:, 1] * X_catalyst[:, 2] +
    0.5 * X_catalyst[:, 3] +
    0.01 * (X_catalyst[:, 4] - 600)**2 +
    np.random.normal(0, 2, n_catalysts)
)

<h1>初期データ（5サンプル）</h1>
initial_size = 5
X_train, X_pool, y_train, y_pool = train_test_split(
    X_catalyst,
    y_catalyst,
    train_size=initial_size,
    random_state=42
)

def active_learning_loop(
    X_train,
    y_train,
    X_pool,
    y_pool,
    n_iterations=5,
    strategy='uncertainty'
):
    """
    Active Learningループ

    Parameters:
    -----------
    X_train : array
        初期訓練データ
    y_train : array
        初期訓練ラベル
    X_pool : array
        候補プール
    y_pool : array
        候補の真のラベル（評価用、実際は未知）
    n_iterations : int
        イテレーション数
    strategy : str
        Query Strategy ('uncertainty', 'diversity', 'qbc')

    Returns:
    --------
    history : dict
        学習履歴
    """
    history = {
        'r2_scores': [],
        'best_found': [],
        'selected_samples': []
    }

    X_current = X_train.copy()
    y_current = y_train.copy()
    pool_indices = np.arange(len(X_pool))

    for iteration in range(n_iterations):
        # モデル訓練
        rf = RandomForestRegressor(
            n_estimators=100,
            random_state=42
        )
        rf.fit(X_current, y_current)

        # 全データで評価
        y_pred_all = rf.predict(X_catalyst)
        r2 = r2_score(y_catalyst, y_pred_all)
        history['r2_scores'].append(r2)

        # これまでに発見した最良触媒
        best_found = y_current.max()
        history['best_found'].append(best_found)

        # 次のサンプルを選択
        if strategy == 'uncertainty':
            predictions = np.array([
                tree.predict(X_pool)
                for tree in rf.estimators_
            ])
            uncertainties = np.std(predictions, axis=0)
            next_idx = np.argmax(uncertainties)

        elif strategy == 'diversity':
            distances = pairwise_distances(
                X_pool,
                X_current,
                metric='euclidean'
            )
            min_distances = distances.min(axis=1)
            next_idx = np.argmax(min_distances)

        elif strategy == 'qbc':
            committee = [
                RandomForestRegressor(n_estimators=50, random_state=i)
                for i in range(5)
            ]
            for model in committee:
                model.fit(X_current, y_current)

            predictions = np.array([
                model.predict(X_pool)
                for model in committee
            ])
            disagreement = np.var(predictions, axis=0)
            next_idx = np.argmax(disagreement)

        # 選択したサンプルを訓練データに追加
        X_current = np.vstack([X_current, X_pool[next_idx:next_idx+1]])
        y_current = np.append(y_current, y_pool[next_idx])

        # プールから削除
        X_pool = np.delete(X_pool, next_idx, axis=0)
        y_pool = np.delete(y_pool, next_idx)

        history['selected_samples'].append(pool_indices[next_idx])
        pool_indices = np.delete(pool_indices, next_idx)

        print(f"Iteration {iteration+1}/{n_iterations}: "
              f"R² = {r2:.3f}, Best found = {best_found:.2f}")

    return history

<h1>ランダムサンプリング</h1>
print("\n=== ランダムサンプリング ===")
np.random.seed(42)
X_train_rand = X_train.copy()
y_train_rand = y_train.copy()
X_pool_rand = X_pool.copy()
y_pool_rand = y_pool.copy()

random_history = {'best_found': [y_train_rand.max()]}
for i in range(5):
    rand_idx = np.random.randint(len(X_pool_rand))
    X_train_rand = np.vstack([X_train_rand, X_pool_rand[rand_idx:rand_idx+1]])
    y_train_rand = np.append(y_train_rand, y_pool_rand[rand_idx])
    random_history['best_found'].append(y_train_rand.max())

    X_pool_rand = np.delete(X_pool_rand, rand_idx, axis=0)
    y_pool_rand = np.delete(y_pool_rand, rand_idx)

    print(f"Iteration {i+1}/5: Best found = "
          f"{random_history['best_found'][-1]:.2f}")

<h1>Active Learning（Uncertainty Sampling）</h1>
print("\n=== Active Learning (Uncertainty Sampling) ===")
al_history = active_learning_loop(
    X_train,
    y_train,
    X_pool,
    y_pool,
    n_iterations=5,
    strategy='uncertainty'
)

<h1>結果の可視化</h1>
plt.figure(figsize=(12, 5))

<h1>左図: 発見した最良触媒の推移</h1>
plt.subplot(1, 2, 1)
plt.plot(
    range(initial_size, initial_size + 6),
    random_history['best_found'],
    'o-',
    label='ランダムサンプリング',
    linewidth=2,
    markersize=8
)
plt.plot(
    range(initial_size, initial_size + 6),
    al_history['best_found'],
    '^-',
    label='Active Learning',
    linewidth=2,
    markersize=8
)
plt.axhline(
    y_catalyst.max(),
    color='green',
    linestyle='--',
    label='真の最適値'
)
plt.xlabel('実験回数', fontsize=12)
plt.ylabel('発見した最良活性', fontsize=12)
plt.title('探索効率の比較', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

<h1>右図: R²スコアの推移（Active Learningのみ）</h1>
plt.subplot(1, 2, 2)
plt.plot(
    range(initial_size + 1, initial_size + 6),
    al_history['r2_scores'],
    '^-',
    linewidth=2,
    markersize=8,
    color='orange'
)
plt.xlabel('実験回数', fontsize=12)
plt.ylabel('R² スコア', fontsize=12)
plt.title('モデル精度の向上', fontsize=14)
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(
    'active_learning_catalyst.png',
    dpi=150,
    bbox_inches='tight'
)
plt.show()

<h1>定量的比較</h1>
print("\n=== 定量的比較（10実験後） ===")
print(f"ランダムサンプリング:")
print(f"  発見した最良活性: {random_history['best_found'][-1]:.2f}")
print(f"  真の最適値に対する達成率: "
      f"{random_history['best_found'][-1]/y_catalyst.max()*100:.1f}%")

print(f"\nActive Learning:")
print(f"  発見した最良活性: {al_history['best_found'][-1]:.2f}")
print(f"  真の最適値に対する達成率: "
      f"{al_history['best_found'][-1]/y_catalyst.max()*100:.1f}%")

improvement = (
    (al_history['best_found'][-1] - random_history['best_found'][-1]) /
    random_history['best_found'][-1] * 100
)
print(f"\n改善率: {improvement:.1f}%")</code></pre>

<strong>期待される出力</strong>:
<pre><code>=== ランダムサンプリング ===
Iteration 1/5: Best found = 18.45
Iteration 2/5: Best found = 21.23
Iteration 3/5: Best found = 21.23
Iteration 4/5: Best found = 23.56
Iteration 5/5: Best found = 24.12

=== Active Learning (Uncertainty Sampling) ===
Iteration 1/5: R² = 0.512, Best found = 18.45
Iteration 2/5: R² = 0.634, Best found = 26.78
Iteration 3/5: R² = 0.721, Best found = 28.34
Iteration 4/5: R² = 0.789, Best found = 29.12
Iteration 5/5: R² = 0.843, Best found = 29.67

=== 定量的比較（10実験後） ===
ランダムサンプリング:
  発見した最良活性: 24.12
  真の最適値に対する達成率: 79.3%

Active Learning:
  発見した最良活性: 29.67
  真の最適値に対する達成率: 97.5%

改善率: 23.0%</code></pre>

<strong>重要な観察</strong>:
- ✅ Active Learningは10実験で真の最適値の97.5%に到達
- ✅ ランダムサンプリングは79.3%にとどまる
- ✅ <strong>23%の性能改善</strong>
- ✅ R²スコアも着実に向上（0.512 → 0.843）

---

<h2>1.5 本章のまとめ</h2>

<h3>学んだこと</h3>

1. <strong>Active Learningの定義</strong>
   - 能動的データ選択による効率的学習
   - Passive Learningとの違い
   - 材料科学での重要性（実験コスト削減）

2. <strong>Query Strategies</strong>
   - <strong>Uncertainty Sampling</strong>: 予測が不確実なサンプルを選択
   - <strong>Diversity Sampling</strong>: 多様なサンプルを選択
   - <strong>Query-by-Committee</strong>: モデル間の意見不一致を活用
   - <strong>Expected Model Change</strong>: モデル更新への影響度で選択

3. <strong>Exploration-Exploitation</strong>
   - ε-greedy: 確率的に探索と活用を切り替え
   - UCB: 予測平均 + 不確実性ボーナス
   - バランスの重要性

4. <strong>実践例</strong>
   - 触媒活性予測で23%の性能改善
   - 10実験で97.5%の達成率
   - ランダムサンプリングの1.3倍の効率

<h3>重要なポイント</h3>

- ✅ Active Learningは<strong>データ取得コストが高い問題</strong>で威力を発揮
- ✅ Query Strategyの選択が<strong>探索効率を大きく左右</strong>
- ✅ Exploration-Exploitationの<strong>バランスが重要</strong>
- ✅ 材料科学で<strong>実験回数を50-90%削減</strong>可能
- ✅ <strong>10-20実験で有意な改善</strong>が見込める

<h3>次の章へ</h3>

第2章では、Active Learningの核心となる<strong>不確実性推定手法</strong>を学びます：
- Ensemble法（Random Forest, LightGBM）
- Dropout法（Bayesian Neural Networks）
- Gaussian Process（厳密な不確実性定量化）

<strong>[第2章：不確実性推定手法 →](./chapter-2.md)</strong>

---

<h2>演習問題</h2>

<h3>問題1（難易度：easy）</h3>

以下の状況で、どのQuery Strategyが最も適切か理由とともに答えてください。

<strong>状況A</strong>: 合金の引張強度予測。候補材料10,000種、初期データ50サンプル、予算は追加20実験まで。探索空間は広大だが、強度は組成に対して比較的滑らかに変化する。

<strong>状況B</strong>: 新規有機半導体材料の発見。候補分子100,000種、初期データ10サンプル、予算は追加10実験まで。特性は分子構造に対して非常に複雑に変化する。

<details>
<summary>ヒント</summary>

- 状況A: 探索空間が広大 → ?
- 状況B: データが少なく、複雑な関数 → ?
- Query Strategiesの特徴を再確認

</details>

<details>
<summary>解答例</summary>

<strong>状況A: Diversity Samplingが最適</strong>

<strong>理由</strong>:
1. 探索空間が広大（10,000種）で、20実験では全体をカバー困難
2. 初期データが50サンプルあり、ある程度のモデル構築が可能
3. 強度が滑らかに変化するため、広範囲をカバーすることで全体像を把握可能
4. Diversity Samplingで探索空間を均等にカバー

<strong>代替案</strong>: UCBサンプリング（探索パラメータκを大きく設定）

<strong>状況B: Uncertainty Sampling（または Query-by-Committee）が最適</strong>

<strong>理由</strong>:
1. 初期データが非常に少ない（10サンプル）
2. 特性が複雑に変化するため、不確実性が高い領域を優先すべき
3. 予算が限られている（10実験）ため、効率的な学習が必須
4. Uncertainty Samplingで最も情報価値の高いサンプルを選択

<strong>代替案</strong>: Query-by-Committee（モデルの多様性で複雑な関数に対応）

</details>

---

<h3>問題2（難易度：medium）</h3>

ε-greedy Active Learningを実装し、εの値（0.0, 0.1, 0.2, 0.5）を変化させたときの探索効率を比較してください。

<strong>タスク</strong>:
1. 仮想的な材料特性データセット（500サンプル）を生成
2. 初期データ10サンプル、追加15実験でε-greedy ALを実行
3. 各εで発見した最良値をプロット
4. 最適なεを選択し、理由を説明

<details>
<summary>ヒント</summary>

- コード例4を参考にε-greedyを実装
- 各εで5回試行し、平均を取ると良い
- プロット: 横軸=実験回数、縦軸=発見した最良値

</details>

<details>
<summary>解答例</summary>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor

<h1>データ生成</h1>
np.random.seed(42)
n_samples = 500
X = np.random.rand(n_samples, 5)
y = (
    10 * X[:, 0]**2 +
    15 * X[:, 1] * X[:, 2] +
    5 * np.sin(10 * X[:, 3]) +
    0.5 * X[:, 4] +
    np.random.normal(0, 1, n_samples)
)

<h1>ε値のリスト</h1>
epsilons = [0.0, 0.1, 0.2, 0.5]
n_trials = 5
n_iterations = 15

results = {eps: [] for eps in epsilons}

for eps in epsilons:
    print(f"\nε = {eps}")
    for trial in range(n_trials):
        # 初期データ
        initial_idx = np.random.choice(n_samples, 10, replace=False)
        X_train = X[initial_idx]
        y_train = y[initial_idx]

        unlabeled_mask = np.ones(n_samples, dtype=bool)
        unlabeled_mask[initial_idx] = False
        X_pool = X[unlabeled_mask]
        y_pool = y[unlabeled_mask]
        pool_indices = np.where(unlabeled_mask)[0]

        best_history = [y_train.max()]

        for _ in range(n_iterations):
            if np.random.rand() < eps:
                # 探索
                next_idx_pool = np.random.randint(len(X_pool))
            else:
                # 活用
                rf = RandomForestRegressor(
                    n_estimators=50,
                    random_state=42
                )
                rf.fit(X_train, y_train)

                predictions = np.array([
                    tree.predict(X_pool)
                    for tree in rf.estimators_
                ])
                uncertainties = np.std(predictions, axis=0)
                next_idx_pool = np.argmax(uncertainties)

            # データ追加
            X_train = np.vstack([X_train, X_pool[next_idx_pool:next_idx_pool+1]])
            y_train = np.append(y_train, y_pool[next_idx_pool])

            # プールから削除
            X_pool = np.delete(X_pool, next_idx_pool, axis=0)
            y_pool = np.delete(y_pool, next_idx_pool)

            best_history.append(y_train.max())

        results[eps].append(best_history)

<h1>平均と標準誤差を計算</h1>
results_mean = {
    eps: np.mean(results[eps], axis=0)
    for eps in epsilons
}
results_std = {
    eps: np.std(results[eps], axis=0)
    for eps in epsilons
}

<h1>プロット</h1>
plt.figure(figsize=(10, 6))
for eps in epsilons:
    iterations = range(10, 10 + n_iterations + 1)
    plt.plot(
        iterations,
        results_mean[eps],
        'o-',
        label=f'ε = {eps}',
        linewidth=2,
        markersize=6
    )
    plt.fill_between(
        iterations,
        results_mean[eps] - results_std[eps],
        results_mean[eps] + results_std[eps],
        alpha=0.2
    )

plt.axhline(y.max(), color='green', linestyle='--',
            label='真の最適値')
plt.xlabel('実験回数', fontsize=12)
plt.ylabel('発見した最良値', fontsize=12)
plt.title('ε-greedy Active Learning: εの影響', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('epsilon_greedy_comparison.png', dpi=150)
plt.show()

<h1>最終達成率を比較</h1>
print("\n=== 最終結果（25実験後）===")
for eps in epsilons:
    final_best = results_mean[eps][-1]
    achievement = final_best / y.max() * 100
    print(f"ε = {eps}: 最良値 = {final_best:.2f}, "
          f"達成率 = {achievement:.1f}%")</code></pre>

<strong>期待される出力</strong>:
<pre><code>=== 最終結果（25実験後）===
ε = 0.0: 最良値 = 28.34, 達成率 = 89.2%
ε = 0.1: 最良値 = 30.12, 達成率 = 94.8%
ε = 0.2: 最良値 = 31.45, 達成率 = 99.0%
ε = 0.5: 最良値 = 29.67, 達成率 = 93.4%</code></pre>

<strong>結論</strong>:
- <strong>ε = 0.2が最適</strong>（達成率99.0%）
- ε = 0.0は局所解にはまりやすい（89.2%）
- ε = 0.5は探索過多で非効率（93.4%）
- <strong>適度な探索（ε=0.1-0.2）がバランス良好</strong>

</details>

---

<h3>問題3（難易度：hard）</h3>

3つのQuery Strategy（Uncertainty, Diversity, Query-by-Committee）を同一データセットで比較し、最も効率的な手法を選択してください。

<strong>要求事項</strong>:
1. 仮想的な多目的材料データ（1,000サンプル、特徴量10次元）を生成
2. 初期データ20サンプル、追加30実験で各手法を実行
3. 以下の指標で評価：
   - 発見した最良値
   - R²スコア（全データに対する予測精度）
   - 計算時間
4. 総合的に最も効率的な手法を選択

<details>
<summary>ヒント</summary>

- 各手法を独立して実装
- 5回試行して平均を取る
- <code>time.time()</code>で計算時間を測定
- トレードオフを考慮（精度 vs 計算時間）

</details>

<details>
<summary>解答例</summary>

<pre><code class="language-python">import time
from sklearn.metrics import r2_score

<h1>データ生成</h1>
np.random.seed(42)
n_samples = 1000
n_features = 10
X = np.random.rand(n_samples, n_features)

<h1>複雑な非線形目的関数</h1>
y = (
    np.sum(X[:, :5]**2, axis=1) * 10 +
    np.sum(X[:, 5:] * np.roll(X[:, 5:], 1, axis=1), axis=1) * 5 +
    np.random.normal(0, 2, n_samples)
)

strategies = ['uncertainty', 'diversity', 'qbc']
n_trials = 5
n_iterations = 30

results = {
    strategy: {
        'best_found': [],
        'r2_scores': [],
        'computation_time': []
    }
    for strategy in strategies
}

for strategy in strategies:
    print(f"\n=== {strategy.upper()} ===")

    for trial in range(n_trials):
        start_time = time.time()

        # 初期データ
        initial_idx = np.random.choice(n_samples, 20, replace=False)
        X_train = X[initial_idx]
        y_train = y[initial_idx]

        unlabeled_mask = np.ones(n_samples, dtype=bool)
        unlabeled_mask[initial_idx] = False
        X_pool = X[unlabeled_mask]
        y_pool = y[unlabeled_mask]

        best_history = []
        r2_history = []

        for iteration in range(n_iterations):
            # モデル訓練
            rf = RandomForestRegressor(
                n_estimators=100,
                random_state=42
            )
            rf.fit(X_train, y_train)

            # 全データで評価
            y_pred = rf.predict(X)
            r2 = r2_score(y, y_pred)
            r2_history.append(r2)

            best_found = y_train.max()
            best_history.append(best_found)

            # Query Strategy
            if strategy == 'uncertainty':
                predictions = np.array([
                    tree.predict(X_pool)
                    for tree in rf.estimators_
                ])
                scores = np.std(predictions, axis=0)
                next_idx = np.argmax(scores)

            elif strategy == 'diversity':
                distances = pairwise_distances(
                    X_pool,
                    X_train,
                    metric='euclidean'
                )
                scores = distances.min(axis=1)
                next_idx = np.argmax(scores)

            elif strategy == 'qbc':
                committee = [
                    RandomForestRegressor(
                        n_estimators=50,
                        random_state=i
                    )
                    for i in range(5)
                ]
                for model in committee:
                    model.fit(X_train, y_train)

                predictions = np.array([
                    model.predict(X_pool)
                    for model in committee
                ])
                scores = np.var(predictions, axis=0)
                next_idx = np.argmax(scores)

            # データ追加
            X_train = np.vstack([X_train, X_pool[next_idx:next_idx+1]])
            y_train = np.append(y_train, y_pool[next_idx])

            X_pool = np.delete(X_pool, next_idx, axis=0)
            y_pool = np.delete(y_pool, next_idx)

        elapsed_time = time.time() - start_time

        results[strategy]['best_found'].append(best_history)
        results[strategy]['r2_scores'].append(r2_history)
        results[strategy]['computation_time'].append(elapsed_time)

        print(f"Trial {trial+1}: Best = {best_history[-1]:.2f}, "
              f"R² = {r2_history[-1]:.3f}, "
              f"Time = {elapsed_time:.2f}s")

<h1>平均結果</h1>
print("\n=== 総合比較（50実験後）===")
for strategy in strategies:
    best_mean = np.mean([
        h[-1] for h in results[strategy]['best_found']
    ])
    r2_mean = np.mean([
        h[-1] for h in results[strategy]['r2_scores']
    ])
    time_mean = np.mean(results[strategy]['computation_time'])

    print(f"\n{strategy.upper()}:")
    print(f"  最良値: {best_mean:.2f} "
          f"(達成率: {best_mean/y.max()*100:.1f}%)")
    print(f"  R² スコア: {r2_mean:.3f}")
    print(f"  計算時間: {time_mean:.2f}秒")

<h1>可視化</h1>
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

<h1>最良値の推移</h1>
ax = axes[0]
for strategy in strategies:
    mean_history = np.mean(
        results[strategy]['best_found'],
        axis=0
    )
    iterations = range(20, 20 + n_iterations)
    ax.plot(
        iterations,
        mean_history,
        'o-',
        label=strategy.upper(),
        linewidth=2,
        markersize=4
    )
ax.axhline(y.max(), color='green', linestyle='--',
           label='真の最適値')
ax.set_xlabel('実験回数', fontsize=12)
ax.set_ylabel('発見した最良値', fontsize=12)
ax.set_title('探索効率', fontsize=14)
ax.legend()
ax.grid(True, alpha=0.3)

<h1>R²スコアの推移</h1>
ax = axes[1]
for strategy in strategies:
    mean_history = np.mean(
        results[strategy]['r2_scores'],
        axis=0
    )
    iterations = range(20, 20 + n_iterations)
    ax.plot(
        iterations,
        mean_history,
        'o-',
        label=strategy.upper(),
        linewidth=2,
        markersize=4
    )
ax.set_xlabel('実験回数', fontsize=12)
ax.set_ylabel('R² スコア', fontsize=12)
ax.set_title('モデル精度', fontsize=14)
ax.legend()
ax.grid(True, alpha=0.3)

<h1>計算時間</h1>
ax = axes[2]
time_means = [
    np.mean(results[strategy]['computation_time'])
    for strategy in strategies
]
ax.bar(
    [s.upper() for s in strategies],
    time_means,
    color=['blue', 'orange', 'green'],
    alpha=0.7
)
ax.set_ylabel('計算時間（秒）', fontsize=12)
ax.set_title('計算コスト', fontsize=14)
ax.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('strategy_comparison.png', dpi=150)
plt.show()</code></pre>

<strong>期待される出力</strong>:
<pre><code>=== 総合比較（50実験後）===

UNCERTAINTY:
  最良値: 45.67 (達成率: 96.2%)
  R² スコア: 0.834
  計算時間: 12.34秒

DIVERSITY:
  最良値: 42.34 (達成率: 89.2%)
  R² スコア: 0.812
  計算時間: 8.56秒

QBC:
  最良値: 46.23 (達成率: 97.4%)
  R² スコア: 0.856
  計算時間: 38.12秒</code></pre>

<strong>結論</strong>:
1. <strong>Query-by-Committee（QBC）</strong>が最高性能（達成率97.4%、R²=0.856）
2. しかし計算時間が3倍以上（38.12秒 vs 12.34秒）
3. <strong>Uncertainty Samplingが総合的にバランス良好</strong>
   - 達成率96.2%（QBCと1.2%の差）
   - R²=0.834（QBCと0.022の差）
   - 計算時間は1/3

<strong>推奨</strong>:
- <strong>時間制約がない</strong>: QBC
- <strong>バランス重視</strong>: Uncertainty Sampling
- <strong>計算コスト重視</strong>: Diversity Sampling

</details>

---

<h2>参考文献</h2>

1. Settles, B. (2009). "Active Learning Literature Survey." *Computer Sciences Technical Report 1648*, University of Wisconsin-Madison.

2. Lookman, T. et al. (2019). "Active learning in materials science with emphasis on adaptive sampling using uncertainties for targeted design." *npj Computational Materials*, 5(1), 1-17. DOI: [10.1038/s41524-019-0153-8](https://doi.org/10.1038/s41524-019-0153-8)

3. Raccuglia, P. et al. (2016). "Machine-learning-assisted materials discovery using failed experiments." *Nature*, 533(7601), 73-76. DOI: [10.1038/nature17439](https://doi.org/10.1038/nature17439)

4. Ren, F. et al. (2018). "Accelerated discovery of metallic glasses through iteration of machine learning and high-throughput experiments." *Science Advances*, 4(4), eaaq1566. DOI: [10.1126/sciadv.aaq1566](https://doi.org/10.1126/sciadv.aaq1566)

5. Kusne, A. G. et al. (2020). "On-the-fly closed-loop materials discovery via Bayesian active learning." *Nature Communications*, 11(1), 5966. DOI: [10.1038/s41467-020-19597-w](https://doi.org/10.1038/s41467-020-19597-w)

---

<h2>ナビゲーション</h2>

<h3>次の章</h3>
<strong>[第2章：不確実性推定手法 →](./chapter-2.md)</strong>

<h3>シリーズ目次</h3>
<strong>[← シリーズ目次に戻る](./index.md)</strong>

---

<h2>著者情報</h2>

<strong>作成者</strong>: AI Terakoya Content Team
<strong>監修</strong>: Dr. Yusuke Hashimoto（東北大学）
<strong>作成日</strong>: 2025-10-18
<strong>バージョン</strong>: 1.0

<strong>更新履歴</strong>:
- 2025-10-18: v1.0 初版公開

<strong>フィードバック</strong>:
- GitHub Issues: [AI_Homepage/issues](https://github.com/your-repo/AI_Homepage/issues)
- Email: yusuke.hashimoto.b8@tohoku.ac.jp

<strong>ライセンス</strong>: Creative Commons BY 4.0

---

<strong>次の章で不確実性推定の詳細を学びましょう！</strong>
<div class="navigation">
    <a href="index.html" class="nav-button">シリーズ目次に戻る</a>
    <a href="chapter-2.html" class="nav-button">第2章 →</a>
</div>
    </main>

    <footer>
        <p><strong>作成者</strong>: AI Terakoya Content Team</p>
        <p><strong>監修</strong>: Dr. Yusuke Hashimoto（東北大学）</p>
        <p><strong>バージョン</strong>: 1.0 | <strong>作成日</strong>: 2025-10-18</p>
        <p><strong>ライセンス</strong>: Creative Commons BY 4.0</p>
        <p>© 2025 AI Terakoya. All rights reserved.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default'
                });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</body>
</html>
