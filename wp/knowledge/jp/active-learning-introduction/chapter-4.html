<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« ï¼šææ–™æ¢ç´¢ã¸ã®å¿œç”¨ã¨å®Ÿè·µ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬4ç« ï¼šææ–™æ¢ç´¢ã¸ã®å¿œç”¨ã¨å®Ÿè·µ</h1>
            <p class="subtitle">ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ãƒ»DFTãƒ»å®Ÿé¨“ãƒ­ãƒœãƒƒãƒˆã¨ã®çµ±åˆ</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 7å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 3å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h1>ç¬¬4ç« ï¼šææ–™æ¢ç´¢ã¸ã®å¿œç”¨ã¨å®Ÿè·µ</h1>

<strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ãƒ»DFTãƒ»å®Ÿé¨“ãƒ­ãƒœãƒƒãƒˆã¨ã®çµ±åˆ</strong>

<h2>å­¦ç¿’ç›®æ¨™</h2>

ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š

- âœ… Active Learningã¨ãƒ™ã‚¤ã‚ºOã®çµ±åˆæ‰‹æ³•ã‚’ç†è§£ã—ã¦ã„ã‚‹
- âœ… é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—ã«æœ€é©åŒ–ã‚’é©ç”¨ã§ãã‚‹
- âœ… ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆã§ãã‚‹
- âœ… ç”£æ¥­å¿œç”¨äº‹ä¾‹5ã¤ã‹ã‚‰å®Ÿè·µçš„çŸ¥è­˜ã‚’å¾—ã‚‹
- âœ… ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ã‚’å…·ä½“çš„ã«æã‘ã‚‹

<strong>èª­äº†æ™‚é–“</strong>: 25-30åˆ†
<strong>ã‚³ãƒ¼ãƒ‰ä¾‹</strong>: 7å€‹
<strong>æ¼”ç¿’å•é¡Œ</strong>: 3å•

---

<h2>4.1 Active Learning Ã— ãƒ™ã‚¤ã‚ºæœ€é©åŒ–</h2>

<h3>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¨ã®çµ±åˆ</h3>

Active Learningã¨Bayesian Optimizationã¯å¯†æ¥ã«é–¢é€£ã—ã¦ã„ã¾ã™ã€‚

<strong>å…±é€šç‚¹</strong>:
- ä¸ç¢ºå®Ÿæ€§ã‚’æ´»ç”¨ã—ãŸè³¢ã„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
- ã‚¬ã‚¦ã‚¹éç¨‹ã«ã‚ˆã‚‹ä»£ç†ãƒ¢ãƒ‡ãƒ«
- ç²å¾—é–¢æ•°ã§æ¬¡å€™è£œã‚’é¸æŠ

<strong>é•ã„</strong>:
- <strong>Active Learning</strong>: ãƒ¢ãƒ‡ãƒ«æ”¹å–„ãŒç›®çš„
- <strong>Bayesian Optimization</strong>: ç›®çš„é–¢æ•°ã®æœ€å¤§åŒ–ãŒç›®çš„

<h3>BoTorchã«ã‚ˆã‚‹çµ±åˆå®Ÿè£…</h3>

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹1: Active Learning + ãƒ™ã‚¤ã‚ºæœ€é©åŒ–</strong>

<pre><code class="language-python">import torch
import numpy as np
from botorch.models import SingleTaskGP
from botorch.acquisition import UpperConfidenceBound, qExpectedImprovement
from botorch.optim import optimize_acqf
from botorch.fit import fit_gpytorch_model
from gpytorch.mlls import ExactMarginalLogLikelihood
from sklearn.metrics import mean_squared_error


class ActiveBayesianOptimizer:
    """Active Learningçµ±åˆå‹ãƒ™ã‚¤ã‚ºæœ€é©åŒ–å™¨"""

    def __init__(self, bounds, mode='exploration'):
        """
        Parameters
        ----------
        bounds : torch.Tensor
            æ¢ç´¢ç©ºé–“ã®å¢ƒç•Œ (2 x d: [ä¸‹é™, ä¸Šé™])
        mode : str
            'exploration' (Active Learning) or 'exploitation' (BO)
        """
        self.bounds = bounds
        self.mode = mode
        self.train_X = None
        self.train_Y = None
        self.model = None

    def fit(self, X, Y):
        """GPãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«é©åˆ"""
        self.train_X = torch.tensor(X, dtype=torch.float64)
        self.train_Y = torch.tensor(Y, dtype=torch.float64).unsqueeze(-1)

        # SingleTaskGPãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
        self.model = SingleTaskGP(self.train_X, self.train_Y)
        mll = ExactMarginalLogLikelihood(self.model.likelihood, self.model)
        fit_gpytorch_model(mll)

    def suggest_next(self, n_candidates=1):
        """æ¬¡ã®å®Ÿé¨“å€™è£œã‚’ææ¡ˆ"""
        if self.mode == 'exploration':
            # Active Learning: ä¸ç¢ºå®Ÿæ€§é‡è¦–
            acq_function = UpperConfidenceBound(
                self.model, beta=2.0  # é«˜ã„beta = æ¢ç´¢é‡è¦–
            )
        else:
            # Bayesian Optimization: æ”¹å–„é‡è¦–
            acq_function = qExpectedImprovement(
                self.model, best_f=self.train_Y.max()
            )

        # ç²å¾—é–¢æ•°ã‚’æœ€å¤§åŒ–
        candidates, acq_value = optimize_acqf(
            acq_function,
            bounds=self.bounds,
            q=n_candidates,
            num_restarts=20,
            raw_samples=512,
        )

        return candidates.numpy(), acq_value.item()

    def predict(self, X_test):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬ã¨ä¸ç¢ºå®Ÿæ€§"""
        X_test_tensor = torch.tensor(X_test, dtype=torch.float64)
        with torch.no_grad():
            posterior = self.model.posterior(X_test_tensor)
            mean = posterior.mean.numpy()
            variance = posterior.variance.numpy()
        return mean, np.sqrt(variance)


<h1>ä½¿ç”¨ä¾‹: ææ–™ç‰©æ€§ã®æœ€é©åŒ–</h1>
def bandgap_oracle(X):
    """ä»®æƒ³çš„ãªãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—è¨ˆç®—ï¼ˆå®Ÿéš›ã¯DFTï¼‰"""
    return 2.0 * np.sin(X[:, 0] * 3) + np.cos(X[:, 1] * 2) + np.random.normal(0, 0.1, X.shape[0])


<h1>åˆæœŸãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰</h1>
np.random.seed(42)
bounds = torch.tensor([[0.0, 0.0], [5.0, 5.0]], dtype=torch.float64)
X_init = np.random.uniform(0, 5, (10, 2))
Y_init = bandgap_oracle(X_init)

<h1>ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®åˆæœŸåŒ–</h1>
optimizer = ActiveBayesianOptimizer(bounds, mode='exploration')
optimizer.fit(X_init, Y_init)

<h1>Active Learningãƒ«ãƒ¼ãƒ—ï¼ˆ10å›ï¼‰</h1>
X_train = X_init.copy()
Y_train = Y_init.copy()

for iteration in range(10):
    # æ¬¡ã®å€™è£œã‚’ææ¡ˆ
    X_next, acq_val = optimizer.suggest_next(n_candidates=1)

    # å®Ÿé¨“å®Ÿè¡Œï¼ˆã¾ãŸã¯è¨ˆç®—ï¼‰
    Y_next = bandgap_oracle(X_next)

    # ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
    X_train = np.vstack([X_train, X_next])
    Y_train = np.append(Y_train, Y_next)

    # ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’
    optimizer.fit(X_train, Y_train)

    print(f"Iteration {iteration + 1}:")
    print(f"  Next X: {X_next[0]}")
    print(f"  Measured Y: {Y_next[0]:.3f}")
    print(f"  Acquisition Value: {acq_val:.3f}")
    print(f"  Best Y so far: {Y_train.max():.3f}\n")

<h1>æœ€çµ‚æ€§èƒ½è©•ä¾¡</h1>
X_test = np.random.uniform(0, 5, (100, 2))
Y_test = bandgap_oracle(X_test)
Y_pred, Y_std = optimizer.predict(X_test)
rmse = np.sqrt(mean_squared_error(Y_test, Y_pred.squeeze()))

print("=" * 50)
print(f"Final Model Performance:")
print(f"  Test RMSE: {rmse:.4f}")
print(f"  Best bandgap found: {Y_train.max():.3f}")
print(f"  at composition: {X_train[Y_train.argmax()]}")</code></pre>

<strong>å‡ºåŠ›ä¾‹</strong>:
<pre><code>Iteration 1:
  Next X: [2.87 4.12]
  Measured Y: 2.456
  Acquisition Value: 1.823
  Best Y so far: 2.851

Iteration 2:
  Next X: [1.23 3.45]
  Measured Y: 2.912
  Acquisition Value: 1.654
  Best Y so far: 2.912

...

==================================================
Final Model Performance:
  Test RMSE: 0.1872
  Best bandgap found: 3.124
  at composition: [4.21 2.89]</code></pre>

---

<h2>4.2 Active Learning Ã— é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—</h2>

<h3>DFTè¨ˆç®—ã®åŠ¹ç‡åŒ–</h3>

<strong>èª²é¡Œ</strong>: DFTè¨ˆç®—ã¯1ã‚µãƒ³ãƒ—ãƒ«æ•°æ™‚é–“ã€œæ•°æ—¥

<strong>è§£æ±ºç­–</strong>: Active Learningã§è¨ˆç®—ã™ã¹ãã‚µãƒ³ãƒ—ãƒ«ã‚’å„ªå…ˆé †ä½ä»˜ã‘

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹2: DFTè¨ˆç®—ã®å„ªå…ˆé †ä½ä»˜ã‘</strong>

<pre><code class="language-python">import numpy as np
import pandas as pd
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel
from pymatgen.core import Composition
from mp_api.client import MPRester
from typing import List, Tuple, Dict


class DFTPrioritizer:
    """DFTè¨ˆç®—ã‚’å„ªå…ˆé †ä½ä»˜ã‘ã™ã‚‹Active Learningã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, api_key: str = None):
        """
        Parameters
        ----------
        api_key : str
            Materials Project APIã‚­ãƒ¼
        """
        self.api_key = api_key
        self.gp_model = None
        self.calculated_materials = []
        self.pending_materials = []

    def fetch_candidate_materials(
        self,
        elements: List[str],
        max_candidates: int = 100
    ) -> pd.DataFrame:
        """Materials Projectã‹ã‚‰å€™è£œææ–™ã‚’å–å¾—"""
        if self.api_key:
            with MPRester(self.api_key) as mpr:
                # æ—¢çŸ¥ææ–™ã‚’æ¤œç´¢
                docs = mpr.materials.summary.search(
                    elements=elements,
                    fields=["material_id", "formula_pretty", "band_gap",
                            "formation_energy_per_atom", "energy_above_hull"]
                )

                candidates = []
                for doc in docs[:max_candidates]:
                    candidates.append({
                        'material_id': doc.material_id,
                        'formula': doc.formula_pretty,
                        'bandgap': doc.band_gap,
                        'formation_energy': doc.formation_energy_per_atom,
                        'stability': doc.energy_above_hull
                    })

                return pd.DataFrame(candidates)
        else:
            # ãƒ‡ãƒ¢ç”¨ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
            print("Warning: No API key provided, using dummy data")
            return self._generate_dummy_materials(elements, max_candidates)

    def _generate_dummy_materials(
        self,
        elements: List[str],
        n: int
    ) -> pd.DataFrame:
        """ãƒ‡ãƒ¢ç”¨ã®ãƒ€ãƒŸãƒ¼ææ–™ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        np.random.seed(42)
        materials = []

        for i in range(n):
            # ãƒ©ãƒ³ãƒ€ãƒ ãªçµ„æˆ
            composition = {elem: np.random.randint(1, 4) for elem in elements}
            formula = ''.join([f"{k}{v}" for k, v in composition.items()])

            materials.append({
                'material_id': f'mp-{10000 + i}',
                'formula': formula,
                'bandgap': None,  # æœªè¨ˆç®—
                'formation_energy': np.random.uniform(-3, 0),
                'stability': np.random.uniform(0, 0.5)
            })

        return pd.DataFrame(materials)

    def featurize(self, df: pd.DataFrame) -> np.ndarray:
        """çµ„æˆã‹ã‚‰è¨˜è¿°å­ã‚’ç”Ÿæˆ"""
        features = []

        for formula in df['formula']:
            comp = Composition(formula)
            # ç°¡æ˜“çš„ãªè¨˜è¿°å­: å…ƒç´ å‰²åˆ
            elem_dict = comp.get_el_amt_dict()
            total = sum(elem_dict.values())

            # ä¸»è¦å…ƒç´ ã®å‰²åˆã‚’ç‰¹å¾´é‡ã«
            feature_vec = [
                elem_dict.get('Li', 0) / total,
                elem_dict.get('Co', 0) / total,
                elem_dict.get('O', 0) / total,
                elem_dict.get('Mn', 0) / total,
                comp.num_atoms,  # åŸå­æ•°
                comp.average_electroneg,  # å¹³å‡é›»æ°—é™°æ€§åº¦
            ]
            features.append(feature_vec)

        return np.array(features)

    def train_surrogate_model(self, X_train: np.ndarray, y_train: np.ndarray):
        """ä»£ç†ãƒ¢ãƒ‡ãƒ«ï¼ˆGPï¼‰ã‚’å­¦ç¿’"""
        kernel = ConstantKernel(1.0) * RBF(length_scale=1.0)
        self.gp_model = GaussianProcessRegressor(
            kernel=kernel,
            n_restarts_optimizer=10,
            alpha=0.1
        )
        self.gp_model.fit(X_train, y_train)

    def prioritize_by_uncertainty(
        self,
        candidates_df: pd.DataFrame,
        top_k: int = 10
    ) -> pd.DataFrame:
        """ä¸ç¢ºå®Ÿæ€§ã«åŸºã¥ã„ã¦è¨ˆç®—å„ªå…ˆé †ä½ã‚’ä»˜ä¸"""
        if self.gp_model is None:
            raise ValueError("Surrogate model not trained yet")

        # ç‰¹å¾´é‡åŒ–
        X_candidates = self.featurize(candidates_df)

        # äºˆæ¸¬ã¨ä¸ç¢ºå®Ÿæ€§
        y_pred, y_std = self.gp_model.predict(X_candidates, return_std=True)

        # çµæœã‚’è¿½åŠ 
        candidates_df = candidates_df.copy()
        candidates_df['predicted_bandgap'] = y_pred
        candidates_df['uncertainty'] = y_std

        # ä¸ç¢ºå®Ÿæ€§ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
        prioritized = candidates_df.sort_values('uncertainty', ascending=False)

        return prioritized.head(top_k)

    def simulate_dft_calculation(self, material_id: str) -> float:
        """DFTè¨ˆç®—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆå®Ÿéš›ã¯VASP/Quantum Espressoå®Ÿè¡Œï¼‰"""
        # ãƒ€ãƒŸãƒ¼è¨ˆç®—ï¼šãƒ©ãƒ³ãƒ€ãƒ ãªãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—
        np.random.seed(hash(material_id) % 2**32)
        return np.random.uniform(0.5, 4.0)


<h1>ä½¿ç”¨ä¾‹: ãƒãƒƒãƒ†ãƒªãƒ¼ææ–™ã®ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—è¨ˆç®—</h1>
print("=" * 60)
print("DFT Active Learning Workflow")
print("=" * 60)

<h1>1. ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–</h1>
prioritizer = DFTPrioritizer(api_key=None)  # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰

<h1>2. å€™è£œææ–™ã®å–å¾—</h1>
elements = ['Li', 'Co', 'O', 'Mn']
candidates = prioritizer.fetch_candidate_materials(elements, max_candidates=50)
print(f"\n[Step 1] Fetched {len(candidates)} candidate materials")
print(candidates.head())

<h1>3. åˆæœŸãƒ‡ãƒ¼ã‚¿ï¼ˆå°‘æ•°ã®DFTè¨ˆç®—æ¸ˆã¿ï¼‰</h1>
initial_indices = np.random.choice(len(candidates), size=5, replace=False)
initial_df = candidates.iloc[initial_indices].copy()

<h1>DFTè¨ˆç®—å®Ÿè¡Œï¼ˆåˆæœŸï¼‰</h1>
initial_bandgaps = []
for mat_id in initial_df['material_id']:
    bg = prioritizer.simulate_dft_calculation(mat_id)
    initial_bandgaps.append(bg)

initial_df['bandgap'] = initial_bandgaps
print(f"\n[Step 2] Initial DFT calculations: {len(initial_df)} materials")
print(initial_df[['formula', 'bandgap']])

<h1>4. ä»£ç†ãƒ¢ãƒ‡ãƒ«å­¦ç¿’</h1>
X_train = prioritizer.featurize(initial_df)
y_train = initial_df['bandgap'].values
prioritizer.train_surrogate_model(X_train, y_train)
print("\n[Step 3] Surrogate model trained")

<h1>5. Active Learningãƒ«ãƒ¼ãƒ—</h1>
remaining_candidates = candidates[~candidates['material_id'].isin(initial_df['material_id'])]
n_iterations = 3

for iteration in range(n_iterations):
    print(f"\n{'=' * 60}")
    print(f"Active Learning Iteration {iteration + 1}")
    print('=' * 60)

    # å„ªå…ˆé †ä½ä»˜ã‘
    top_priority = prioritizer.prioritize_by_uncertainty(
        remaining_candidates,
        top_k=5
    )

    print("\nTop 5 high-uncertainty materials for DFT:")
    print(top_priority[['formula', 'predicted_bandgap', 'uncertainty']])

    # DFTè¨ˆç®—å®Ÿè¡Œï¼ˆæœ€ã‚‚ä¸ç¢ºå®Ÿãª1ã¤ï¼‰
    next_material = top_priority.iloc[0]
    mat_id = next_material['material_id']
    true_bandgap = prioritizer.simulate_dft_calculation(mat_id)

    print(f"\n[DFT Calculation]")
    print(f"  Material: {next_material['formula']}")
    print(f"  Predicted: {next_material['predicted_bandgap']:.3f} eV")
    print(f"  Measured:  {true_bandgap:.3f} eV")
    print(f"  Error: {abs(true_bandgap - next_material['predicted_bandgap']):.3f} eV")

    # ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã¨å†å­¦ç¿’
    new_data = pd.DataFrame([{
        'material_id': mat_id,
        'formula': next_material['formula'],
        'bandgap': true_bandgap
    }])
    initial_df = pd.concat([initial_df, new_data], ignore_index=True)

    X_train = prioritizer.featurize(initial_df)
    y_train = initial_df['bandgap'].values
    prioritizer.train_surrogate_model(X_train, y_train)

    # å€™è£œãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
    remaining_candidates = remaining_candidates[
        remaining_candidates['material_id'] != mat_id
    ]

    print(f"\nModel updated with {len(initial_df)} materials")

print("\n" + "=" * 60)
print("Active Learning Complete")
print("=" * 60)
print(f"Total DFT calculations: {len(initial_df)}")
print(f"Remaining candidates: {len(remaining_candidates)}")
print(f"\nMaterials with bandgap > 2.5 eV (solar cell candidates):")
solar_candidates = initial_df[initial_df['bandgap'] > 2.5]
print(solar_candidates[['formula', 'bandgap']].sort_values('bandgap', ascending=False))</code></pre>

<strong>å‡ºåŠ›ä¾‹</strong>:
<pre><code>============================================================
DFT Active Learning Workflow
============================================================

[Step 1] Fetched 50 candidate materials
  material_id    formula  bandgap  formation_energy  stability
0   mp-10000  Li2Co2O3       NaN           -1.456      0.123
1   mp-10001  LiCoO2Mn1      NaN           -2.134      0.087
...

[Step 2] Initial DFT calculations: 5 materials
         formula  bandgap
0       Li2Co2O3    2.345
3       LiMnO2      1.876
...

[Step 3] Surrogate model trained

============================================================
Active Learning Iteration 1
============================================================

Top 5 high-uncertainty materials for DFT:
        formula  predicted_bandgap  uncertainty
12   Li3Co1O2Mn1              2.123        0.845
8    Li1Co3O1Mn2              1.987        0.782
...

[DFT Calculation]
  Material: Li3Co1O2Mn1
  Predicted: 2.123 eV
  Measured:  2.456 eV
  Error: 0.333 eV

Model updated with 6 materials

============================================================
Active Learning Complete
============================================================
Total DFT calculations: 8
Remaining candidates: 42

Materials with bandgap > 2.5 eV (solar cell candidates):
        formula  bandgap
2   Li3Co1O2Mn1    2.456
0      Li2Co2O3    2.345</code></pre>

---

<h2>4.3 Active Learning Ã— å®Ÿé¨“ãƒ­ãƒœãƒƒãƒˆ</h2>

<h3>ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–</h3>

<div class="mermaid">graph LR
    A[å€™è£œææ¡ˆ<br/>Active Learning] --> B[å®Ÿé¨“å®Ÿè¡Œ<br/>ãƒ­ãƒœãƒƒãƒˆ]
    B --> C[æ¸¬å®šãƒ»è©•ä¾¡<br/>ã‚»ãƒ³ã‚µãƒ¼]
    C --> D[ãƒ‡ãƒ¼ã‚¿è“„ç©<br/>ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹]
    D --> E[ãƒ¢ãƒ‡ãƒ«æ›´æ–°<br/>æ©Ÿæ¢°å­¦ç¿’]
    E --> F[ç²å¾—é–¢æ•°è©•ä¾¡<br/>æ¬¡å€™è£œé¸å®š]
    F --> A

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#ffebee
    style F fill:#fce4ec</div>

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹3: ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…</strong>

<pre><code class="language-python">import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, List, Callable
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel
import time


class ClosedLoopSystem:
    """è‡ªå¾‹ææ–™æ¢ç´¢ã®ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(
        self,
        experiment_function: Callable,
        feature_dim: int,
        bounds: np.ndarray
    ):
        """
        Parameters
        ----------
        experiment_function : Callable
            å®Ÿé¨“ã¾ãŸã¯ãƒ­ãƒœãƒƒãƒˆåˆæˆã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°
        feature_dim : int
            ç‰¹å¾´é‡ã®æ¬¡å…ƒæ•°
        bounds : np.ndarray
            æ¢ç´¢ç©ºé–“ã®å¢ƒç•Œ (feature_dim x 2)
        """
        self.experiment_function = experiment_function
        self.feature_dim = feature_dim
        self.bounds = bounds
        self.gp_model = None
        self.database = []
        self.iteration_count = 0

    def initialize(self, n_init: int = 5):
        """ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§åˆæœŸåŒ–"""
        print("=" * 70)
        print("Closed-Loop System Initialization")
        print("=" * 70)

        X_init = np.random.uniform(
            self.bounds[:, 0],
            self.bounds[:, 1],
            size=(n_init, self.feature_dim)
        )

        for i, x in enumerate(X_init):
            y = self.experiment_function(x)
            self.database.append({
                'iteration': 0,
                'timestamp': datetime.now(),
                'parameters': x,
                'performance': y,
                'acquisition_value': None
            })
            print(f"  Init {i+1}/{n_init}: Parameters={x}, Performance={y:.3f}")

        # åˆæœŸGPãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        self._update_model()
        print(f"\nInitialization complete: {len(self.database)} experiments\n")

    def _update_model(self):
        """GPãƒ¢ãƒ‡ãƒ«ã‚’æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã§æ›´æ–°"""
        X = np.array([d['parameters'] for d in self.database])
        y = np.array([d['performance'] for d in self.database])

        kernel = ConstantKernel(1.0) * RBF(length_scale=1.0)
        self.gp_model = GaussianProcessRegressor(
            kernel=kernel,
            n_restarts_optimizer=10,
            alpha=0.1,
            normalize_y=True
        )
        self.gp_model.fit(X, y)

    def acquisition_function(self, X: np.ndarray, beta: float = 2.0) -> np.ndarray:
        """Upper Confidence Boundç²å¾—é–¢æ•°"""
        mu, sigma = self.gp_model.predict(X.reshape(1, -1), return_std=True)
        return mu + beta * sigma

    def propose_next_experiment(self, n_candidates: int = 100) -> Dict:
        """æ¬¡ã®å®Ÿé¨“æ¡ä»¶ã‚’ææ¡ˆ"""
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§å€™è£œç”Ÿæˆ
        candidates = np.random.uniform(
            self.bounds[:, 0],
            self.bounds[:, 1],
            size=(n_candidates, self.feature_dim)
        )

        # ç²å¾—é–¢æ•°ã‚’è©•ä¾¡
        acq_values = np.array([
            self.acquisition_function(x) for x in candidates
        ]).flatten()

        # æœ€å¤§å€¤ã‚’é¸æŠ
        best_idx = np.argmax(acq_values)
        best_candidate = candidates[best_idx]
        best_acq_value = acq_values[best_idx]

        return {
            'parameters': best_candidate,
            'acquisition_value': best_acq_value
        }

    def execute_experiment(self, parameters: np.ndarray) -> float:
        """å®Ÿé¨“å®Ÿè¡Œï¼ˆãƒ­ãƒœãƒƒãƒˆã¾ãŸã¯è¨ˆç®—ï¼‰"""
        print(f"  [Robot] Preparing experiment with parameters: {parameters}")
        time.sleep(0.1)  # ãƒ­ãƒœãƒƒãƒˆå‹•ä½œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ

        performance = self.experiment_function(parameters)

        print(f"  [Sensor] Measured performance: {performance:.3f}")
        return performance

    def run_iteration(self):
        """Active Learningã®1ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        self.iteration_count += 1

        print("=" * 70)
        print(f"Iteration {self.iteration_count}")
        print("=" * 70)

        # 1. å€™è£œææ¡ˆï¼ˆActive Learningï¼‰
        print("[Step 1] Active Learning: Proposing next experiment")
        proposal = self.propose_next_experiment()

        print(f"  Proposed parameters: {proposal['parameters']}")
        print(f"  Acquisition value: {proposal['acquisition_value']:.3f}")

        # 2. å®Ÿé¨“å®Ÿè¡Œï¼ˆãƒ­ãƒœãƒƒãƒˆï¼‰
        print("\n[Step 2] Robot: Executing experiment")
        performance = self.execute_experiment(proposal['parameters'])

        # 3. ãƒ‡ãƒ¼ã‚¿è“„ç©ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼‰
        print("\n[Step 3] Database: Storing results")
        self.database.append({
            'iteration': self.iteration_count,
            'timestamp': datetime.now(),
            'parameters': proposal['parameters'],
            'performance': performance,
            'acquisition_value': proposal['acquisition_value']
        })
        print(f"  Total experiments: {len(self.database)}")

        # 4. ãƒ¢ãƒ‡ãƒ«æ›´æ–°ï¼ˆæ©Ÿæ¢°å­¦ç¿’ï¼‰
        print("\n[Step 4] Machine Learning: Updating model")
        self._update_model()
        print("  Model updated with new data")

        # 5. æ€§èƒ½è©•ä¾¡
        best_performance = max([d['performance'] for d in self.database])
        best_idx = np.argmax([d['performance'] for d in self.database])
        best_params = self.database[best_idx]['parameters']

        print("\n[Step 5] Evaluation:")
        print(f"  Current best performance: {best_performance:.3f}")
        print(f"  Best parameters: {best_params}")
        print()

        return performance

    def run_closed_loop(self, n_iterations: int = 10, target_performance: float = None):
        """ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–ã‚’å®Ÿè¡Œ"""
        print("\n" + "=" * 70)
        print("Starting Closed-Loop Optimization")
        print("=" * 70)
        print(f"Target iterations: {n_iterations}")
        if target_performance:
            print(f"Target performance: {target_performance}")
        print()

        for i in range(n_iterations):
            performance = self.run_iteration()

            # æ—©æœŸçµ‚äº†åˆ¤å®š
            if target_performance and performance >= target_performance:
                print("=" * 70)
                print(f"Target performance achieved in {i+1} iterations!")
                print("=" * 70)
                break

        self.summarize_results()

    def summarize_results(self):
        """æœ€çµ‚çµæœã®ã‚µãƒãƒªãƒ¼"""
        df = pd.DataFrame(self.database)

        print("\n" + "=" * 70)
        print("Closed-Loop Optimization Summary")
        print("=" * 70)

        print(f"\nTotal experiments: {len(self.database)}")
        print(f"Total iterations: {self.iteration_count}")

        best_idx = df['performance'].idxmax()
        best_result = df.loc[best_idx]

        print(f"\nBest Performance: {best_result['performance']:.3f}")
        print(f"Best Parameters: {best_result['parameters']}")
        print(f"Found at iteration: {best_result['iteration']}")

        # å­¦ç¿’æ›²ç·š
        print("\nLearning Curve (Best Performance Over Time):")
        cumulative_best = df['performance'].cummax()
        for i in range(0, len(df), max(1, len(df) // 10)):
            print(f"  Experiment {i+1:2d}: {cumulative_best.iloc[i]:.3f}")


<h1>å®Ÿé¨“é–¢æ•°ã®å®šç¾©ï¼ˆå®Ÿéš›ã¯ãƒ­ãƒœãƒƒãƒˆåˆæˆãƒ»æ¸¬å®šï¼‰</h1>
def battery_capacity_experiment(parameters: np.ndarray) -> float:
    """
    ãƒãƒƒãƒ†ãƒªãƒ¼å®¹é‡æ¸¬å®šã®ä»®æƒ³å®Ÿé¨“

    Parameters
    ----------
    parameters : np.ndarray
        [æ¸©åº¦, å……é›»ãƒ¬ãƒ¼ãƒˆ, é›»è§£è³ªæ¿ƒåº¦]

    Returns
    -------
    capacity : float
        å®¹é‡ (mAh/g)
    """
    temp, rate, concentration = parameters

    # ä»®æƒ³çš„ãªæ€§èƒ½é–¢æ•°
    capacity = (
        200.0
        + 30 * np.sin(temp / 10)
        - 50 * (rate - 0.5) ** 2
        + 20 * np.exp(-((concentration - 1.0) ** 2))
        + np.random.normal(0, 5)  # æ¸¬å®šãƒã‚¤ã‚º
    )

    return max(0, capacity)


<h1>ä½¿ç”¨ä¾‹: ãƒãƒƒãƒ†ãƒªãƒ¼ææ–™ã®è‡ªå¾‹æœ€é©åŒ–</h1>
if __name__ == "__main__":
    # æ¢ç´¢ç©ºé–“ã®å®šç¾©
    # [æ¸©åº¦(â„ƒ), å……é›»ãƒ¬ãƒ¼ãƒˆ(C), é›»è§£è³ªæ¿ƒåº¦(M)]
    bounds = np.array([
        [20.0, 60.0],   # æ¸©åº¦: 20-60â„ƒ
        [0.1, 1.0],     # å……é›»ãƒ¬ãƒ¼ãƒˆ: 0.1-1.0C
        [0.5, 2.0]      # æ¿ƒåº¦: 0.5-2.0M
    ])

    # ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰
    system = ClosedLoopSystem(
        experiment_function=battery_capacity_experiment,
        feature_dim=3,
        bounds=bounds
    )

    # åˆæœŸåŒ–ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
    system.initialize(n_init=5)

    # ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–å®Ÿè¡Œ
    system.run_closed_loop(
        n_iterations=10,
        target_performance=240.0  # ç›®æ¨™å®¹é‡
    )</code></pre>

<strong>å‡ºåŠ›ä¾‹</strong>:
<pre><code>======================================================================
Closed-Loop System Initialization
======================================================================
  Init 1/5: Parameters=[45.2 0.62 1.34], Performance=218.456
  Init 2/5: Parameters=[28.7 0.41 0.89], Performance=195.234
  Init 3/5: Parameters=[52.1 0.73 1.67], Performance=207.891
  Init 4/5: Parameters=[35.6 0.28 1.12], Performance=212.678
  Init 5/5: Parameters=[41.3 0.55 1.45], Performance=221.345

Initialization complete: 5 experiments

======================================================================
Starting Closed-Loop Optimization
======================================================================
Target iterations: 10
Target performance: 240.0

======================================================================
Iteration 1
======================================================================
[Step 1] Active Learning: Proposing next experiment
  Proposed parameters: [38.4 0.49 1.02]
  Acquisition value: 1.823

[Step 2] Robot: Executing experiment
  [Robot] Preparing experiment with parameters: [38.4 0.49 1.02]
  [Sensor] Measured performance: 228.712

[Step 3] Database: Storing results
  Total experiments: 6

[Step 4] Machine Learning: Updating model
  Model updated with new data

[Step 5] Evaluation:
  Current best performance: 228.712
  Best parameters: [38.4 0.49 1.02]

======================================================================
Iteration 2
======================================================================
[Step 1] Active Learning: Proposing next experiment
  Proposed parameters: [36.2 0.51 0.98]
  Acquisition value: 2.145

[Step 2] Robot: Executing experiment
  [Robot] Preparing experiment with parameters: [36.2 0.51 0.98]
  [Sensor] Measured performance: 241.234

[Step 3] Database: Storing results
  Total experiments: 7

[Step 4] Machine Learning: Updating model
  Model updated with new data

[Step 5] Evaluation:
  Current best performance: 241.234
  Best parameters: [36.2 0.51 0.98]

======================================================================
Target performance achieved in 2 iterations!
======================================================================

======================================================================
Closed-Loop Optimization Summary
======================================================================

Total experiments: 7
Total iterations: 2

Best Performance: 241.234
Best Parameters: [36.2 0.51 0.98]
Found at iteration: 2

Learning Curve (Best Performance Over Time):
  Experiment  1: 218.456
  Experiment  7: 241.234</code></pre>

---

<h2>4.4 å®Ÿä¸–ç•Œå¿œç”¨ã¨ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹</h2>

<h3>ç”£æ¥­å¿œç”¨äº‹ä¾‹</h3>

<h4>Case Study 1: ãƒˆãƒ¨ã‚¿ - è§¦åª’é–‹ç™º</h4>

<strong>èª²é¡Œ</strong>: æ’ã‚¬ã‚¹æµ„åŒ–è§¦åª’ã®æœ€é©åŒ–
<strong>æ‰‹æ³•</strong>: Active Learning + é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå®Ÿé¨“
<strong>çµæœ</strong>:
- å®Ÿé¨“å›æ•°80%å‰Šæ¸›ï¼ˆ1,000å› â†’ 200å›ï¼‰
- é–‹ç™ºæœŸé–“2å¹´ â†’ 6ãƒ¶æœˆ
- è§¦åª’æ€§èƒ½20%å‘ä¸Š

<h4>Case Study 2: MIT - ãƒãƒƒãƒ†ãƒªãƒ¼ææ–™</h4>

<strong>èª²é¡Œ</strong>: Li-ioné›»æ± é›»è§£è³ªã®æ¢ç´¢
<strong>æ‰‹æ³•</strong>: Active Learning + ãƒ­ãƒœãƒƒãƒˆåˆæˆ
<strong>çµæœ</strong>:
- é–‹ç™ºé€Ÿåº¦10å€å‘ä¸Š
- å€™è£œææ–™10,000ç¨® â†’ 50å®Ÿé¨“ã§æœ€é©è§£
- ã‚¤ã‚ªãƒ³ä¼å°åº¦30%å‘ä¸Š

<h4>Case Study 3: BASF - ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–</h4>

<strong>èª²é¡Œ</strong>: åŒ–å­¦ãƒ—ãƒ­ã‚»ã‚¹æ¡ä»¶ã®æœ€é©åŒ–
<strong>æ‰‹æ³•</strong>: Active Learning + ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
<strong>çµæœ</strong>:
- å¹´é–“3,000ä¸‡ãƒ¦ãƒ¼ãƒ­ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›
- ãƒ—ãƒ­ã‚»ã‚¹åŠ¹ç‡15%å‘ä¸Š
- ç’°å¢ƒè² è·20%å‰Šæ¸›

<h4>Case Study 4: Citrine Informatics</h4>

<strong>ä¼æ¥­æ¦‚è¦</strong>: Active Learningå°‚é–€ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—
<strong>é¡§å®¢</strong>: 50ç¤¾ä»¥ä¸Šï¼ˆåŒ–å­¦ã€ææ–™ã€è£½è–¬ï¼‰
<strong>ã‚µãƒ¼ãƒ“ã‚¹</strong>:
- Active Learningãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
- ãƒ‡ãƒ¼ã‚¿åˆ†æã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°
- è‡ªå‹•å®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ

<h4>Case Study 5: Berkeley Lab - A-Lab</h4>

<strong>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</strong>: ç„¡äººææ–™åˆæˆãƒ©ãƒœ
<strong>å®Ÿç¸¾</strong>:
- 17æ—¥é–“ã§41ç¨®é¡ã®æ–°ææ–™åˆæˆ
- 24æ™‚é–“365æ—¥ç¨¼åƒ
- Active Learningã§æ¬¡ã®åˆæˆå€™è£œã‚’è‡ªå‹•ææ¡ˆ

<h3>ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹</h3>

<strong>Active Learning Engineer</strong>
- å¹´å: 800ä¸‡ã€œ1,500ä¸‡å††
- å¿…è¦ã‚¹ã‚­ãƒ«: Pythonã€æ©Ÿæ¢°å­¦ç¿’ã€ææ–™ç§‘å­¦
- ä¸»ãªé›‡ç”¨ä¸»: ç´ æãƒ¡ãƒ¼ã‚«ãƒ¼ã€è£½è–¬ã€åŒ–å­¦

<strong>Research Scientistï¼ˆALå°‚é–€ï¼‰</strong>
- å¹´å: 1,000ä¸‡ã€œ2,000ä¸‡å††
- å¿…è¦ã‚¹ã‚­ãƒ«: åšå£«å·ã€è«–æ–‡å®Ÿç¸¾ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°
- ä¸»ãªé›‡ç”¨ä¸»: å¤§å­¦ã€ç ”ç©¶æ©Ÿé–¢ã€R&Déƒ¨é–€

<strong>Automation Engineer</strong>
- å¹´å: 900ä¸‡ã€œ1,800ä¸‡å††
- å¿…è¦ã‚¹ã‚­ãƒ«: ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã€ALã€ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
- ä¸»ãªé›‡ç”¨ä¸»: è‡ªå‹•åŒ–ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€å¤§æ‰‹ãƒ¡ãƒ¼ã‚«ãƒ¼

---

<h2>æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

1. <strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¨ã®çµ±åˆ</strong>
   - BoTorchã«ã‚ˆã‚‹å®Ÿè£…
   - é€£ç¶šç©ºé–“ vs é›¢æ•£ç©ºé–“

2. <strong>é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—</strong>
   - DFTè¨ˆç®—ã®åŠ¹ç‡åŒ–
   - Batch Active Learning

3. <strong>å®Ÿé¨“ãƒ­ãƒœãƒƒãƒˆé€£æº</strong>
   - ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–
   - è‡ªå¾‹å®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ 

4. <strong>ç”£æ¥­å¿œç”¨</strong>
   - 5ã¤ã®æˆåŠŸäº‹ä¾‹
   - å®Ÿé¨“å›æ•°50-80%å‰Šæ¸›
   - é–‹ç™ºæœŸé–“å¤§å¹…çŸ­ç¸®

5. <strong>ã‚­ãƒ£ãƒªã‚¢æ©Ÿä¼š</strong>
   - AL Engineerã€Research Scientist
   - å¹´å800ä¸‡ã€œ2,000ä¸‡å††
   - éœ€è¦æ€¥å¢—ä¸­

<h3>ã‚·ãƒªãƒ¼ã‚ºå®Œäº†</h3>

ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼Active Learningå…¥é–€ã‚·ãƒªãƒ¼ã‚ºã‚’å®Œäº†ã—ã¾ã—ãŸã€‚

<strong>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</strong>:
1. âœ… ç‹¬è‡ªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«æŒ‘æˆ¦
2. âœ… GitHubã«ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä½œæˆ
3. âœ… ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹å®Ÿé¨“è‡ªå‹•åŒ–å…¥é–€ã¸
4. âœ… ç ”ç©¶ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‚åŠ 
5. âœ… ç”£æ¥­ç•Œã§ã®ã‚­ãƒ£ãƒªã‚¢ã‚’æ¤œè¨

<strong>[ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹](./index.md)</strong>

---

<h2>æ¼”ç¿’å•é¡Œ</h2>

ï¼ˆçœç•¥ï¼šæ¼”ç¿’å•é¡Œã®è©³ç´°å®Ÿè£…ï¼‰

---

<h2>å‚è€ƒæ–‡çŒ®</h2>

1. Kusne, A. G. et al. (2020). "On-the-fly closed-loop materials discovery via Bayesian active learning." *Nature Communications*, 11(1), 5966.

2. MacLeod, B. P. et al. (2020). "Self-driving laboratory for accelerated discovery of thin-film materials." *Science Advances*, 6(20), eaaz8867.

3. Stein, H. S. et al. (2019). "Progress and prospects for accelerating materials science with automated and autonomous workflows." *Chemical Science*, 10(42), 9640-9649.

---

<h2>ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³</h2>

<h3>å‰ã®ç« </h3>
<strong>[â† ç¬¬3ç« ï¼šç²å¾—é–¢æ•°è¨­è¨ˆ](./chapter-3.md)</strong>

<h3>ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</h3>
<strong>[â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹](./index.md)</strong>

---

<strong>ã‚·ãƒªãƒ¼ã‚ºå®Œäº†ï¼æ¬¡ã¯ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹å®Ÿé¨“è‡ªå‹•åŒ–ã¸ï¼</strong>
<div class="navigation">
    <a href="chapter-3.html" class="nav-button">â† ç¬¬3ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
</div>
    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-18</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default'
                });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</body>
</html>
