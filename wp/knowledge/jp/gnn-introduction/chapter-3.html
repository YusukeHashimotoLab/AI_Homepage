<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬3ç« ï¼šPyTorch Geometricå®Ÿè·µ - åˆ†å­ãƒ»ææ–™ç‰¹æ€§äºˆæ¸¬ã®å®Ÿè£… - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬3ç« ï¼šPyTorch Geometricå®Ÿè·µ - åˆ†å­ãƒ»ææ–™ç‰¹æ€§äºˆæ¸¬ã®å®Ÿè£…</h1>
            <p class="subtitle">å®Ÿãƒ‡ãƒ¼ã‚¿ã§å­¦ã¶ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ§‹ç¯‰ã¨è©•ä¾¡</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 10å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 3å•</span>
            </div>
        </div>
    </header>

    <main class="container">
        <h1>ç¬¬3ç« ï¼šPyTorch Geometricå®Ÿè·µ - åˆ†å­ãƒ»ææ–™ç‰¹æ€§äºˆæ¸¬ã®å®Ÿè£…</h1>
<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š
- PyTorch Geometricç’°å¢ƒã‚’æ§‹ç¯‰ã—ã€GNNãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã„ã“ãªã›ã‚‹
- QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§åˆ†å­ç‰¹æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã§ãã‚‹
- Materials Projectãƒ‡ãƒ¼ã‚¿ã§çµæ™¶ç‰¹æ€§äºˆæ¸¬ã‚’å®Ÿè¡Œã§ãã‚‹
- ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’é©ç”¨ã§ãã‚‹
- äºˆæ¸¬çµæœã‚’å¯è¦–åŒ–ã—ã€æ€§èƒ½ã‚’è©•ä¾¡ã§ãã‚‹</p>
<p><strong>èª­äº†æ™‚é–“</strong>: 25-30åˆ†
<strong>ã‚³ãƒ¼ãƒ‰ä¾‹</strong>: 10å€‹
<strong>æ¼”ç¿’å•é¡Œ</strong>: 3å•</p>
<hr />
<h2>3.1 ç’°å¢ƒæ§‹ç¯‰ï¼šPyTorch Geometricã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</h2>
<h3>3.1.1 PyTorch Geometricã¨ã¯</h3>
<p><strong>PyTorch Geometric (PyG)</strong>ã¯ã€PyTorchä¸Šã§å‹•ä½œã™ã‚‹ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å°‚ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚</p>
<p><strong>ä¸»ãªç‰¹å¾´</strong>:
- ğŸš€ <strong>é«˜é€Ÿ</strong>: GPUã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªã‚°ãƒ©ãƒ•å‡¦ç†
- ğŸ“¦ <strong>è±Šå¯Œãªãƒ¢ãƒ‡ãƒ«</strong>: GCNã€GATã€GraphSAGEã€SchNetãªã©30ç¨®é¡ä»¥ä¸Š
- ğŸ§ª <strong>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</strong>: QM9ã€ZINCã€OGBï¼ˆOpen Graph Benchmarkï¼‰ãŒçµ„ã¿è¾¼ã¿æ¸ˆã¿
- ğŸ› ï¸ <strong>æŸ”è»Ÿæ€§</strong>: ã‚«ã‚¹ã‚¿ãƒ ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚„ãƒ¢ãƒ‡ãƒ«ã‚’ç°¡å˜ã«å®Ÿè£…å¯èƒ½</p>
<h3>3.1.2 ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †</h3>
<p><strong>Option 1: Condaç’°å¢ƒï¼ˆæ¨å¥¨ï¼‰</strong></p>
<pre class="codehilite"><code class="language-bash"># 1. Python 3.9ä»¥ä¸Šã®ç’°å¢ƒã‚’ä½œæˆ
conda create -n gnn-env python=3.10
conda activate gnn-env

# 2. PyTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆCUDAç‰ˆæ¨å¥¨ï¼‰
# CPUç‰ˆã®å ´åˆ:
conda install pytorch torchvision torchaudio cpuonly -c pytorch

# GPUç‰ˆã®å ´åˆï¼ˆCUDA 11.8ï¼‰:
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

# 3. PyTorch Geometricã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
conda install pyg -c pyg

# 4. è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install rdkit matplotlib seaborn pandas scikit-learn
</code></pre>

<p><strong>Option 2: pipã§ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</strong></p>
<pre class="codehilite"><code class="language-bash"># 1. ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆ
python -m venv gnn-env
source gnn-env/bin/activate  # macOS/Linux
# gnn-env\Scripts\activate  # Windows

# 2. PyTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install torch torchvision torchaudio

# 3. PyTorch Geometricã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install torch-geometric

# 4. ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-2.0.0+cpu.html

# 5. è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install rdkit matplotlib seaborn pandas scikit-learn
</code></pre>

<p><strong>Option 3: Google Colabï¼ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸è¦ï¼‰</strong></p>
<pre class="codehilite"><code class="language-python"># Google Colabã§ã¯ä»¥ä¸‹ã‚’å®Ÿè¡Œ
!pip install torch-geometric
!pip install rdkit
</code></pre>

<h3>3.1.3 ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª</h3>
<pre class="codehilite"><code class="language-python">import torch
import torch_geometric
from torch_geometric.data import Data
from rdkit import Chem
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

print(&quot;===== ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª =====&quot;)
print(f&quot;PyTorch version: {torch.__version__}&quot;)
print(f&quot;PyTorch Geometric version: {torch_geometric.__version__}&quot;)
print(f&quot;CUDA available: {torch.cuda.is_available()}&quot;)
if torch.cuda.is_available():
    print(f&quot;CUDA version: {torch.version.cuda}&quot;)
    print(f&quot;GPU: {torch.cuda.get_device_name(0)}&quot;)

# ç°¡å˜ãªã‚°ãƒ©ãƒ•ã‚’ä½œæˆã—ã¦ãƒ†ã‚¹ãƒˆ
edge_index = torch.tensor([[0, 1, 1, 2],
                           [1, 0, 2, 1]], dtype=torch.long)
x = torch.tensor([[-1], [0], [1]], dtype=torch.float)
data = Data(x=x, edge_index=edge_index)

print(f&quot;\nãƒ†ã‚¹ãƒˆã‚°ãƒ©ãƒ•ä½œæˆæˆåŠŸ!&quot;)
print(f&quot;ãƒãƒ¼ãƒ‰æ•°: {data.num_nodes}&quot;)
print(f&quot;ã‚¨ãƒƒã‚¸æ•°: {data.num_edges}&quot;)
print(&quot;âœ… PyTorch Geometricç’°å¢ƒã®æ§‹ç¯‰å®Œäº†!&quot;)
</code></pre>

<p><strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›</strong>:</p>
<pre class="codehilite"><code>===== ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª =====
PyTorch version: 2.0.0
PyTorch Geometric version: 2.3.0
CUDA available: True
CUDA version: 11.8
GPU: NVIDIA GeForce RTX 3090

ãƒ†ã‚¹ãƒˆã‚°ãƒ©ãƒ•ä½œæˆæˆåŠŸ!
ãƒãƒ¼ãƒ‰æ•°: 3
ã‚¨ãƒƒã‚¸æ•°: 4
âœ… PyTorch Geometricç’°å¢ƒã®æ§‹ç¯‰å®Œäº†!
</code></pre>

<h3>3.1.4 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°</h3>
<table>
<thead>
<tr>
<th>ã‚¨ãƒ©ãƒ¼</th>
<th>åŸå› </th>
<th>è§£æ±ºæ–¹æ³•</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ImportError: No module named 'torch_geometric'</code></td>
<td>PyGæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</td>
<td><code>pip install torch-geometric</code></td>
</tr>
<tr>
<td><code>OSError: [WinError 126] DLLèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼</code> (Windows)</td>
<td>C++å†é ’å¸ƒå¯èƒ½ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¸è¶³</td>
<td>Microsoft Visual C++ Redistributableã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</td>
</tr>
<tr>
<td><code>RuntimeError: CUDA out of memory</code></td>
<td>GPU ãƒ¡ãƒ¢ãƒªä¸è¶³</td>
<td>ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å‰Šæ¸›ã€CPUç‰ˆPyTorchä½¿ç”¨</td>
</tr>
<tr>
<td><code>ImportError: cannot import name 'Data'</code></td>
<td>ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸ä¸€è‡´</td>
<td>PyTorchã¨PyGã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèª</td>
</tr>
</tbody>
</table>
<hr />
<h2>3.2 PyTorch Geometricã®åŸºæœ¬ï¼šãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¨DataLoader</h2>
<h3>3.2.1 Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹é€ </h3>
<p>PyTorch Geometricã§ã¯ã€ã‚°ãƒ©ãƒ•ã‚’<code>Data</code>ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§è¡¨ç¾ã—ã¾ã™ã€‚</p>
<pre class="codehilite"><code class="language-python">from torch_geometric.data import Data
import torch

# ã‚¨ã‚¿ãƒãƒ¼ãƒ«åˆ†å­ (C2H5OH) ã‚’ã‚°ãƒ©ãƒ•ã§è¡¨ç¾
# C: ç‚­ç´ ï¼ˆãƒãƒ¼ãƒ‰0, 1ï¼‰
# O: é…¸ç´ ï¼ˆãƒãƒ¼ãƒ‰2ï¼‰
# H: æ°´ç´ ï¼ˆãƒãƒ¼ãƒ‰3-7ï¼‰

# ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆåŸå­ç•ªå·ã‚’ä½¿ç”¨ï¼‰
x = torch.tensor([
    [6],   # C (ç‚­ç´ )
    [6],   # C (ç‚­ç´ )
    [8],   # O (é…¸ç´ )
    [1],   # H (æ°´ç´ )
    [1],   # H (æ°´ç´ )
    [1],   # H (æ°´ç´ )
    [1],   # H (æ°´ç´ )
    [1],   # H (æ°´ç´ )
], dtype=torch.float)

# ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆçµåˆé–¢ä¿‚ï¼‰
# å„çµåˆã¯åŒæ–¹å‘ï¼ˆç„¡å‘ã‚°ãƒ©ãƒ•ï¼‰
edge_index = torch.tensor([
    [0, 1, 1, 0, 0, 2, 2, 0, 0, 3, 3, 0, 1, 4, 4, 1, 1, 5, 5, 1, 2, 6, 6, 2],
    [1, 0, 2, 2, 3, 0, 0, 3, 4, 1, 1, 4, 5, 1, 1, 5, 6, 2, 2, 6, 7, 2, 2, 7]
], dtype=torch.long)

# ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆçµåˆã‚¿ã‚¤ãƒ—: 1=å˜çµåˆï¼‰
edge_attr = torch.ones(edge_index.size(1), 1)

# åˆ†å­ãƒ¬ãƒ™ãƒ«ã®ç‰¹å¾´ï¼ˆç›®çš„å¤‰æ•°ï¼‰
y = torch.tensor([[156.0]], dtype=torch.float)  # æ²¸ç‚¹ (Â°C)

# Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
ethanol = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)

print(&quot;===== ã‚¨ã‚¿ãƒãƒ¼ãƒ«åˆ†å­ã®ã‚°ãƒ©ãƒ•è¡¨ç¾ =====&quot;)
print(f&quot;ãƒãƒ¼ãƒ‰æ•°ï¼ˆåŸå­æ•°ï¼‰: {ethanol.num_nodes}&quot;)
print(f&quot;ã‚¨ãƒƒã‚¸æ•°ï¼ˆçµåˆæ•°Ã—2ï¼‰: {ethanol.num_edges}&quot;)
print(f&quot;ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®å½¢çŠ¶: {ethanol.x.shape}&quot;)
print(f&quot;ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å½¢çŠ¶: {ethanol.edge_index.shape}&quot;)
print(f&quot;ç›®çš„å¤‰æ•°ï¼ˆæ²¸ç‚¹ï¼‰: {ethanol.y.item()} Â°C&quot;)

# ã‚°ãƒ©ãƒ•ã®åŸºæœ¬çµ±è¨ˆ
print(f&quot;\n===== ã‚°ãƒ©ãƒ•ã®çµ±è¨ˆæƒ…å ± =====&quot;)
print(f&quot;å¹³å‡æ¬¡æ•°ï¼ˆçµåˆæ•°ï¼‰: {ethanol.num_edges / ethanol.num_nodes:.2f}&quot;)
print(f&quot;å­¤ç«‹ãƒãƒ¼ãƒ‰: {ethanol.contains_isolated_nodes()}&quot;)
print(f&quot;è‡ªå·±ãƒ«ãƒ¼ãƒ—: {ethanol.contains_self_loops()}&quot;)
</code></pre>

<p><strong>å‡ºåŠ›</strong>:</p>
<pre class="codehilite"><code>===== ã‚¨ã‚¿ãƒãƒ¼ãƒ«åˆ†å­ã®ã‚°ãƒ©ãƒ•è¡¨ç¾ =====
ãƒãƒ¼ãƒ‰æ•°ï¼ˆåŸå­æ•°ï¼‰: 8
ã‚¨ãƒƒã‚¸æ•°ï¼ˆçµåˆæ•°Ã—2ï¼‰: 24
ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®å½¢çŠ¶: torch.Size([8, 1])
ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å½¢çŠ¶: torch.Size([2, 24])
ç›®çš„å¤‰æ•°ï¼ˆæ²¸ç‚¹ï¼‰: 156.0 Â°C

===== ã‚°ãƒ©ãƒ•ã®çµ±è¨ˆæƒ…å ± =====
å¹³å‡æ¬¡æ•°ï¼ˆçµåˆæ•°ï¼‰: 3.00
å­¤ç«‹ãƒãƒ¼ãƒ‰: False
è‡ªå·±ãƒ«ãƒ¼ãƒ—: False
</code></pre>

<h3>3.2.2 RDKitã‹ã‚‰ã‚°ãƒ©ãƒ•ã¸ã®å¤‰æ›</h3>
<p>RDKitã¯SMILESï¼ˆåˆ†å­ã®æ–‡å­—åˆ—è¡¨ç¾ï¼‰ã‹ã‚‰åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã§ãã¾ã™ã€‚</p>
<pre class="codehilite"><code class="language-python">from rdkit import Chem
from rdkit.Chem import Draw
from torch_geometric.data import Data
import torch

def mol_to_graph(smiles):
    &quot;&quot;&quot;
    SMILESæ–‡å­—åˆ—ã‹ã‚‰PyTorch Geometricã®Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ

    Parameters:
    -----------
    smiles : str
        åˆ†å­ã®SMILESè¡¨ç¾

    Returns:
    --------
    data : torch_geometric.data.Data
        ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿
    &quot;&quot;&quot;
    # SMILESã‹ã‚‰åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None

    # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆåŸå­ã®ç‰¹æ€§ï¼‰
    atom_features = []
    for atom in mol.GetAtoms():
        # åŸå­ç•ªå·ã‚’ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆC, N, O, F, ãã®ä»–ï¼‰
        atom_type = [0] * 5
        if atom.GetAtomicNum() == 6:    # C
            atom_type[0] = 1
        elif atom.GetAtomicNum() == 7:  # N
            atom_type[1] = 1
        elif atom.GetAtomicNum() == 8:  # O
            atom_type[2] = 1
        elif atom.GetAtomicNum() == 9:  # F
            atom_type[3] = 1
        else:
            atom_type[4] = 1

        # å½¢å¼é›»è·ã¨èŠ³é¦™æ—æ€§ã‚’è¿½åŠ 
        formal_charge = atom.GetFormalCharge()
        is_aromatic = int(atom.GetIsAromatic())

        atom_features.append(atom_type + [formal_charge, is_aromatic])

    x = torch.tensor(atom_features, dtype=torch.float)

    # ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆçµåˆé–¢ä¿‚ï¼‰
    edge_indices = []
    for bond in mol.GetBonds():
        i = bond.GetBeginAtomIdx()
        j = bond.GetEndAtomIdx()
        edge_indices += [[i, j], [j, i]]  # ç„¡å‘ã‚°ãƒ©ãƒ•ãªã®ã§åŒæ–¹å‘

    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()

    data = Data(x=x, edge_index=edge_index)
    return data, mol

# ãƒ†ã‚¹ãƒˆ: ã„ãã¤ã‹ã®åˆ†å­ã‚’ã‚°ãƒ©ãƒ•ã«å¤‰æ›
smiles_list = [
    (&quot;C&quot;, &quot;ãƒ¡ã‚¿ãƒ³&quot;),
    (&quot;CCO&quot;, &quot;ã‚¨ã‚¿ãƒãƒ¼ãƒ«&quot;),
    (&quot;c1ccccc1&quot;, &quot;ãƒ™ãƒ³ã‚¼ãƒ³&quot;),
    (&quot;CC(=O)O&quot;, &quot;é…¢é…¸&quot;),
]

print(&quot;===== SMILESã‹ã‚‰ã‚°ãƒ©ãƒ•ã¸ã®å¤‰æ› =====&quot;)
for smiles, name in smiles_list:
    data, mol = mol_to_graph(smiles)
    print(f&quot;\n{name} ({smiles}):&quot;)
    print(f&quot;  ãƒãƒ¼ãƒ‰æ•°: {data.num_nodes}&quot;)
    print(f&quot;  ã‚¨ãƒƒã‚¸æ•°: {data.num_edges}&quot;)
    print(f&quot;  ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡æ¬¡å…ƒ: {data.x.shape[1]}&quot;)

# åˆ†å­æ§‹é€ ã®å¯è¦–åŒ–
import matplotlib.pyplot as plt
from rdkit.Chem import Draw

fig, axes = plt.subplots(1, 4, figsize=(16, 4))
for i, (smiles, name) in enumerate(smiles_list):
    _, mol = mol_to_graph(smiles)
    img = Draw.MolToImage(mol, size=(300, 300))
    axes[i].imshow(img)
    axes[i].set_title(f&quot;{name}\n{smiles}&quot;, fontsize=12)
    axes[i].axis('off')

plt.tight_layout()
plt.show()
</code></pre>

<h3>3.2.3 DataLoaderã®ä½¿ç”¨</h3>
<p>è¤‡æ•°ã®ã‚°ãƒ©ãƒ•ã‚’ãƒãƒƒãƒå‡¦ç†ã™ã‚‹ã«ã¯<code>DataLoader</code>ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚</p>
<pre class="codehilite"><code class="language-python">from torch_geometric.data import Data, DataLoader
import torch

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆï¼ˆ10å€‹ã®åˆ†å­ï¼‰
dataset = []
for i in range(10):
    num_nodes = torch.randint(5, 15, (1,)).item()  # 5-14åŸå­
    x = torch.randn(num_nodes, 7)  # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆ7æ¬¡å…ƒï¼‰

    # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚¨ãƒƒã‚¸ã‚’ç”Ÿæˆ
    edge_index = torch.randint(0, num_nodes, (2, num_nodes * 2))

    # ç›®çš„å¤‰æ•°ï¼ˆä¾‹: HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—ï¼‰
    y = torch.randn(1)

    data = Data(x=x, edge_index=edge_index, y=y)
    dataset.append(data)

# DataLoaderã‚’ä½œæˆï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚º=4ï¼‰
loader = DataLoader(dataset, batch_size=4, shuffle=True)

print(&quot;===== DataLoaderã®ä½¿ç”¨ =====&quot;)
print(f&quot;ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: {len(dataset)}&quot;)
print(f&quot;ãƒãƒƒãƒæ•°: {len(loader)}&quot;)

# æœ€åˆã®ãƒãƒƒãƒã‚’ç¢ºèª
for batch in loader:
    print(f&quot;\næœ€åˆã®ãƒãƒƒãƒ:&quot;)
    print(f&quot;  ãƒãƒƒãƒå†…ã®åˆ†å­æ•°: {batch.num_graphs}&quot;)
    print(f&quot;  ç·ãƒãƒ¼ãƒ‰æ•°: {batch.num_nodes}&quot;)
    print(f&quot;  ç·ã‚¨ãƒƒã‚¸æ•°: {batch.num_edges}&quot;)
    print(f&quot;  ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®å½¢çŠ¶: {batch.x.shape}&quot;)
    print(f&quot;  ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {batch.batch}&quot;)
    print(f&quot;  ç›®çš„å¤‰æ•°ã®å½¢çŠ¶: {batch.y.shape}&quot;)
    break
</code></pre>

<p><strong>å‡ºåŠ›ä¾‹</strong>:</p>
<pre class="codehilite"><code>===== DataLoaderã®ä½¿ç”¨ =====
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: 10
ãƒãƒƒãƒæ•°: 3

æœ€åˆã®ãƒãƒƒãƒ:
  ãƒãƒƒãƒå†…ã®åˆ†å­æ•°: 4
  ç·ãƒãƒ¼ãƒ‰æ•°: 38
  ç·ã‚¨ãƒƒã‚¸æ•°: 76
  ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®å½¢çŠ¶: torch.Size([38, 7])
  ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: tensor([0, 0, 0, ..., 3, 3, 3])
  ç›®çš„å¤‰æ•°ã®å½¢çŠ¶: torch.Size([4, 1])
</code></pre>

<p><strong>é‡è¦</strong>: <code>batch</code>ãƒ†ãƒ³ã‚½ãƒ«ã¯å„ãƒãƒ¼ãƒ‰ãŒã©ã®åˆ†å­ã«å±ã™ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ï¼ˆ0, 0, 0, 1, 1, 2, 2, 2, 3, ...ï¼‰ã€‚</p>
<hr />
<h2>3.3 QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§åˆ†å­ç‰¹æ€§äºˆæ¸¬</h2>
<h3>3.3.1 QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¦‚è¦</h3>
<p><strong>QM9</strong>ã¯134,000å€‹ã®æœ‰æ©Ÿå°åˆ†å­ã®é‡å­åŒ–å­¦è¨ˆç®—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚</p>
<p><strong>å«ã¾ã‚Œã‚‹ç‰¹æ€§</strong>:
- HOMOï¼ˆæœ€é«˜è¢«å è»Œé“ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰
- LUMOï¼ˆæœ€ä½éå è»Œé“ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰
- ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆHOMO-LUMOã‚®ãƒ£ãƒƒãƒ—ï¼‰
- åŒæ¥µå­ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ
- å†…éƒ¨ã‚¨ãƒãƒ«ã‚®ãƒ¼
- ã‚¨ãƒ³ã‚¿ãƒ«ãƒ”ãƒ¼ã€è‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼ã€ç†±å®¹é‡ãªã©</p>
<h3>3.3.2 QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿</h3>
<pre class="codehilite"><code class="language-python">from torch_geometric.datasets import QM9
import torch

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå›ã®ã¿ã€ç´„1GBï¼‰
dataset = QM9(root='./data/QM9')

print(&quot;===== QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ =====&quot;)
print(f&quot;åˆ†å­æ•°: {len(dataset)}&quot;)
print(f&quot;ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡æ¬¡å…ƒ: {dataset.num_node_features}&quot;)
print(f&quot;ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡æ¬¡å…ƒ: {dataset.num_edge_features}&quot;)
print(f&quot;ç›®çš„å¤‰æ•°æ•°: {dataset.num_classes}&quot;)

# æœ€åˆã®åˆ†å­ã‚’ç¢ºèª
data = dataset[0]
print(f&quot;\næœ€åˆã®åˆ†å­:&quot;)
print(f&quot;  åŸå­æ•°: {data.num_nodes}&quot;)
print(f&quot;  çµåˆæ•°: {data.num_edges // 2}&quot;)
print(f&quot;  ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡: {data.x.shape}&quot;)
print(f&quot;  ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡: {data.edge_attr.shape}&quot;)
print(f&quot;  ç›®çš„å¤‰æ•°ï¼ˆ19ç¨®é¡ï¼‰: {data.y.shape}&quot;)

# ç›®çš„å¤‰æ•°ã®ä¸€éƒ¨ã‚’è¡¨ç¤º
target_names = ['mu', 'alpha', 'homo', 'lumo', 'gap', 'r2', 'zpve',
                'U0', 'U', 'H', 'G', 'Cv']
print(f&quot;\nä¸»è¦ãªç‰¹æ€§å€¤:&quot;)
for i, name in enumerate(target_names):
    print(f&quot;  {name}: {data.y[0, i].item():.4f}&quot;)
</code></pre>

<h3>3.3.3 Graph Convolutional Networkï¼ˆGCNï¼‰ã®å®Ÿè£…</h3>
<pre class="codehilite"><code class="language-python">import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, global_mean_pool

class GCN_QM9(torch.nn.Module):
    &quot;&quot;&quot;
    QM9åˆ†å­ç‰¹æ€§äºˆæ¸¬ç”¨ã®Graph Convolutional Network

    Architecture:
    - 3å±¤ã®GCNConv
    - Global mean pooling
    - 2å±¤ã®å…¨çµåˆå±¤
    &quot;&quot;&quot;
    def __init__(self, num_node_features, num_classes, hidden_channels=64):
        super(GCN_QM9, self).__init__()

        # GCNå±¤
        self.conv1 = GCNConv(num_node_features, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.conv3 = GCNConv(hidden_channels, hidden_channels)

        # å…¨çµåˆå±¤
        self.lin1 = torch.nn.Linear(hidden_channels, hidden_channels // 2)
        self.lin2 = torch.nn.Linear(hidden_channels // 2, num_classes)

    def forward(self, x, edge_index, batch):
        &quot;&quot;&quot;
        Parameters:
        -----------
        x : torch.Tensor (num_nodes, num_node_features)
            ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡
        edge_index : torch.Tensor (2, num_edges)
            ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        batch : torch.Tensor (num_nodes,)
            ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

        Returns:
        --------
        out : torch.Tensor (batch_size, num_classes)
            äºˆæ¸¬å€¤
        &quot;&quot;&quot;
        # GCNå±¤1ï¼ˆç•³ã¿è¾¼ã¿ + æ´»æ€§åŒ– + ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆï¼‰
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.2, training=self.training)

        # GCNå±¤2
        x = self.conv2(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.2, training=self.training)

        # GCNå±¤3
        x = self.conv3(x, edge_index)
        x = F.relu(x)

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã‚’åˆ†å­ãƒ¬ãƒ™ãƒ«ã«é›†ç´„ï¼‰
        x = global_mean_pool(x, batch)

        # å…¨çµåˆå±¤
        x = self.lin1(x)
        x = F.relu(x)
        x = F.dropout(x, p=0.3, training=self.training)

        x = self.lin2(x)
        return x

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
model = GCN_QM9(
    num_node_features=dataset.num_node_features,
    num_classes=1,  # HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—ã®ã¿ã‚’äºˆæ¸¬
    hidden_channels=64
)

print(&quot;===== GCNãƒ¢ãƒ‡ãƒ« =====&quot;)
print(model)
print(f&quot;\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}&quot;)
</code></pre>

<h3>3.3.4 ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´</h3>
<pre class="codehilite"><code class="language-python">from torch_geometric.loader import DataLoader
from sklearn.model_selection import train_test_split
import time

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å°ã•ãã™ã‚‹ï¼ˆé«˜é€ŸåŒ–ã®ãŸã‚ã€å®Ÿéš›ã«ã¯å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
dataset = dataset[:10000]

# HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—ï¼ˆindex=4ï¼‰ã®ã¿ã‚’ç›®çš„å¤‰æ•°ã«è¨­å®š
for data in dataset:
    data.y = data.y[:, 4:5]  # shape: (1, 1)

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆ80% train, 10% val, 10% testï¼‰
train_dataset = dataset[:8000]
val_dataset = dataset[8000:9000]
test_dataset = dataset[9000:]

# DataLoaderã‚’ä½œæˆ
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®šï¼ˆGPUåˆ©ç”¨å¯èƒ½ãªã‚‰GPUã€ãã†ã§ãªã‘ã‚Œã°CPUï¼‰
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

# æå¤±é–¢æ•°ã¨æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)

# è¨“ç·´é–¢æ•°
def train(model, loader, optimizer, criterion, device):
    model.train()
    total_loss = 0

    for data in loader:
        data = data.to(device)
        optimizer.zero_grad()

        # é †ä¼æ’­
        out = model(data.x, data.edge_index, data.batch)
        loss = criterion(out, data.y)

        # é€†ä¼æ’­
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * data.num_graphs

    return total_loss / len(loader.dataset)

# æ¤œè¨¼é–¢æ•°
def evaluate(model, loader, criterion, device):
    model.eval()
    total_loss = 0

    with torch.no_grad():
        for data in loader:
            data = data.to(device)
            out = model(data.x, data.edge_index, data.batch)
            loss = criterion(out, data.y)
            total_loss += loss.item() * data.num_graphs

    return total_loss / len(loader.dataset)

# è¨“ç·´ãƒ«ãƒ¼ãƒ—
epochs = 50
train_losses = []
val_losses = []
best_val_loss = float('inf')

print(&quot;===== è¨“ç·´é–‹å§‹ =====&quot;)
start_time = time.time()

for epoch in range(1, epochs + 1):
    train_loss = train(model, train_loader, optimizer, criterion, device)
    val_loss = evaluate(model, val_loader, criterion, device)

    train_losses.append(train_loss)
    val_losses.append(val_loss)

    # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
    if val_loss &lt; best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), 'best_model_qm9.pt')

    if epoch % 10 == 0:
        print(f&quot;Epoch {epoch:03d}, &quot;
              f&quot;Train Loss: {train_loss:.4f}, &quot;
              f&quot;Val Loss: {val_loss:.4f}&quot;)

training_time = time.time() - start_time
print(f&quot;\nè¨“ç·´å®Œäº†! æ‰€è¦æ™‚é–“: {training_time:.2f}ç§’&quot;)

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
model.load_state_dict(torch.load('best_model_qm9.pt'))

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
test_loss = evaluate(model, test_loader, criterion, device)
test_mae = test_loss ** 0.5  # RMSEã‚’MAEã®è¿‘ä¼¼ã¨ã—ã¦ä½¿ç”¨

print(f&quot;\n===== ãƒ†ã‚¹ãƒˆæ€§èƒ½ =====&quot;)
print(f&quot;Test Loss (MSE): {test_loss:.4f}&quot;)
print(f&quot;Test MAE (approx): {test_mae:.4f} eV&quot;)
</code></pre>

<h3>3.3.5 å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–</h3>
<pre class="codehilite"><code class="language-python">import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(10, 6))
ax.plot(train_losses, label='Train Loss', linewidth=2)
ax.plot(val_losses, label='Validation Loss', linewidth=2)
ax.set_xlabel('Epoch', fontsize=12)
ax.set_ylabel('Loss (MSE)', fontsize=12)
ax.set_title('GCNå­¦ç¿’æ›²ç·šï¼ˆQM9 HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ï¼‰', fontsize=14)
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# äºˆæ¸¬ vs å®Ÿæ¸¬ã®ãƒ—ãƒ­ãƒƒãƒˆ
model.eval()
all_preds = []
all_targets = []

with torch.no_grad():
    for data in test_loader:
        data = data.to(device)
        out = model(data.x, data.edge_index, data.batch)
        all_preds.append(out.cpu().numpy())
        all_targets.append(data.y.cpu().numpy())

all_preds = np.concatenate(all_preds)
all_targets = np.concatenate(all_targets)

fig, ax = plt.subplots(figsize=(8, 8))
ax.scatter(all_targets, all_preds, alpha=0.6, s=10)
ax.plot([all_targets.min(), all_targets.max()],
        [all_targets.min(), all_targets.max()],
        'r--', lw=2, label='å®Œå…¨ãªäºˆæ¸¬')
ax.set_xlabel('å®Ÿæ¸¬å€¤ (eV)', fontsize=12)
ax.set_ylabel('äºˆæ¸¬å€¤ (eV)', fontsize=12)
ax.set_title('HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬çµæœ', fontsize=14)
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3)

# RÂ²ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
from sklearn.metrics import r2_score
r2 = r2_score(all_targets, all_preds)
mae = np.mean(np.abs(all_targets - all_preds))

ax.text(0.05, 0.95, f'RÂ² = {r2:.3f}\nMAE = {mae:.3f} eV',
        transform=ax.transAxes, fontsize=12, verticalalignment='top',
        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.show()

print(f&quot;===== æœ€çµ‚æ€§èƒ½ =====&quot;)
print(f&quot;RÂ² score: {r2:.4f}&quot;)
print(f&quot;MAE: {mae:.4f} eV&quot;)
</code></pre>

<hr />
<h2>3.4 Materials Projectãƒ‡ãƒ¼ã‚¿ã§çµæ™¶ç‰¹æ€§äºˆæ¸¬</h2>
<h3>3.4.1 çµæ™¶æ§‹é€ ã®ã‚°ãƒ©ãƒ•è¡¨ç¾</h3>
<p>çµæ™¶ã¯å‘¨æœŸçš„ãªæ§‹é€ ã‚’æŒã¤ãŸã‚ã€åˆ†å­ã¨ã¯ç•°ãªã‚‹æ‰±ã„ãŒå¿…è¦ã§ã™ã€‚</p>
<pre class="codehilite"><code class="language-python">from pymatgen.core import Structure
from pymatgen.ext.matproj import MPRester
import torch
from torch_geometric.data import Data

def structure_to_graph(structure, cutoff=5.0):
    &quot;&quot;&quot;
    pymatgen Structureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚°ãƒ©ãƒ•ã«å¤‰æ›

    Parameters:
    -----------
    structure : pymatgen.core.Structure
        çµæ™¶æ§‹é€ 
    cutoff : float
        ã‚¨ãƒƒã‚¸ã‚’ä½œæˆã™ã‚‹è·é›¢ã®ã‚«ãƒƒãƒˆã‚ªãƒ•ï¼ˆÃ…ï¼‰

    Returns:
    --------
    data : torch_geometric.data.Data
        ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿
    &quot;&quot;&quot;
    # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆåŸå­ç•ªå·ï¼‰
    atomic_numbers = [site.specie.Z for site in structure]
    x = torch.tensor(atomic_numbers, dtype=torch.float).view(-1, 1)

    # ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆåŸå­é–“è·é›¢ï¼‰
    edge_indices = []
    edge_attrs = []

    for i, site_i in enumerate(structure):
        for j, site_j in enumerate(structure):
            if i != j:
                distance = structure.get_distance(i, j)
                if distance &lt; cutoff:
                    edge_indices.append([i, j])
                    edge_attrs.append([distance])

    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()
    edge_attr = torch.tensor(edge_attrs, dtype=torch.float)

    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)
    return data

# Materials Projectã‹ã‚‰LiåŒ–åˆç‰©ã‚’å–å¾—ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
# æ³¨æ„: å®Ÿéš›ã«ã¯APIã‚­ãƒ¼ãŒå¿…è¦
# API_KEY = &quot;your_api_key_here&quot;
# with MPRester(API_KEY) as mpr:
#     entries = mpr.query(
#         criteria={&quot;elements&quot;: {&quot;$all&quot;: [&quot;Li&quot;]}, &quot;nelements&quot;: 2},
#         properties=[&quot;structure&quot;, &quot;band_gap&quot;]
#     )

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆLiClçµæ™¶ï¼‰
from pymatgen.core import Lattice, Structure

# LiCl å²©å¡©å‹æ§‹é€ 
lattice = Lattice.cubic(5.14)  # æ ¼å­å®šæ•°
species = [&quot;Li&quot;, &quot;Li&quot;, &quot;Li&quot;, &quot;Li&quot;, &quot;Cl&quot;, &quot;Cl&quot;, &quot;Cl&quot;, &quot;Cl&quot;]
coords = [
    [0, 0, 0], [0.5, 0.5, 0], [0.5, 0, 0.5], [0, 0.5, 0.5],
    [0.5, 0, 0], [0, 0.5, 0], [0, 0, 0.5], [0.5, 0.5, 0.5]
]
structure = Structure(lattice, species, coords)

# ã‚°ãƒ©ãƒ•ã«å¤‰æ›
data = structure_to_graph(structure, cutoff=4.0)

print(&quot;===== LiClçµæ™¶ã®ã‚°ãƒ©ãƒ•è¡¨ç¾ =====&quot;)
print(f&quot;ãƒãƒ¼ãƒ‰æ•°ï¼ˆåŸå­æ•°ï¼‰: {data.num_nodes}&quot;)
print(f&quot;ã‚¨ãƒƒã‚¸æ•°ï¼ˆè·é›¢ &lt; 4.0Ã…ã®åŸå­ãƒšã‚¢ï¼‰: {data.num_edges}&quot;)
print(f&quot;ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡: {data.x}&quot;)
print(f&quot;\nã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆè·é›¢ï¼‰ã®çµ±è¨ˆ:&quot;)
print(f&quot;  æœ€å°è·é›¢: {data.edge_attr.min().item():.2f} Ã…&quot;)
print(f&quot;  æœ€å¤§è·é›¢: {data.edge_attr.max().item():.2f} Ã…&quot;)
print(f&quot;  å¹³å‡è·é›¢: {data.edge_attr.mean().item():.2f} Ã…&quot;)
</code></pre>

<h3>3.4.2 çµæ™¶ç‰¹æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ï¼ˆCrystal Graph Convolutional Networkï¼‰</h3>
<pre class="codehilite"><code class="language-python">import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, global_add_pool

class CGCN(torch.nn.Module):
    &quot;&quot;&quot;
    Crystal Graph Convolutional Network
    çµæ™¶ã®ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã‚’äºˆæ¸¬
    &quot;&quot;&quot;
    def __init__(self, num_node_features=1, hidden_channels=64):
        super(CGCN, self).__init__()

        # ãƒãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿å±¤
        self.embedding = torch.nn.Linear(num_node_features, hidden_channels)

        # GCNå±¤ï¼ˆã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã‚’è€ƒæ…®ã™ã‚‹å ´åˆã¯SchNetãªã©ã‚’ä½¿ç”¨ï¼‰
        self.conv1 = GCNConv(hidden_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.conv3 = GCNConv(hidden_channels, hidden_channels)

        # å…¨çµåˆå±¤
        self.lin1 = torch.nn.Linear(hidden_channels, hidden_channels // 2)
        self.lin2 = torch.nn.Linear(hidden_channels // 2, 1)

    def forward(self, x, edge_index, edge_attr, batch):
        # ãƒãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿
        x = self.embedding(x)
        x = F.relu(x)

        # GCNå±¤
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.2, training=self.training)

        x = self.conv2(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.2, training=self.training)

        x = self.conv3(x, edge_index)
        x = F.relu(x)

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆçµæ™¶ãƒ¬ãƒ™ãƒ«ã«é›†ç´„ï¼‰
        x = global_add_pool(x, batch)

        # å…¨çµåˆå±¤
        x = self.lin1(x)
        x = F.relu(x)
        x = self.lin2(x)

        return x

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
model_crystal = CGCN(num_node_features=1, hidden_channels=128)

print(&quot;===== Crystal Graph Convolutional Network =====&quot;)
print(model_crystal)
print(f&quot;\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model_crystal.parameters()):,}&quot;)
</code></pre>

<h3>3.4.3 æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ã§ã®è¨“ç·´ãƒ‡ãƒ¢</h3>
<pre class="codehilite"><code class="language-python"># æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆå®Ÿéš›ã¯Materials Projectãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
crystal_dataset = []

for i in range(200):
    num_atoms = torch.randint(4, 12, (1,)).item()
    x = torch.randint(1, 20, (num_atoms, 1)).float()  # åŸå­ç•ªå·

    # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚¨ãƒƒã‚¸ï¼ˆè·é›¢ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸã¨ä»®å®šï¼‰
    edge_index = torch.randint(0, num_atoms, (2, num_atoms * 4))
    edge_attr = torch.rand(num_atoms * 4, 1) * 5.0  # è·é›¢ (0-5Ã…)

    # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆåŸå­ç•ªå·ã®é–¢æ•°ã¨ã—ã¦æ¨¡æ“¬ï¼‰
    y = (x.mean() / 10.0 + torch.randn(1) * 0.5).clamp(0, 10)

    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)
    crystal_dataset.append(data)

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
train_crystals = crystal_dataset[:160]
test_crystals = crystal_dataset[160:]

train_loader_crystal = DataLoader(train_crystals, batch_size=16, shuffle=True)
test_loader_crystal = DataLoader(test_crystals, batch_size=16, shuffle=False)

# è¨“ç·´ï¼ˆç°¡ç•¥ç‰ˆï¼‰
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model_crystal = model_crystal.to(device)
optimizer = torch.optim.Adam(model_crystal.parameters(), lr=0.001)
criterion = torch.nn.MSELoss()

print(&quot;===== çµæ™¶ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬è¨“ç·´ =====&quot;)
for epoch in range(1, 51):
    model_crystal.train()
    total_loss = 0

    for data in train_loader_crystal:
        data = data.to(device)
        optimizer.zero_grad()
        out = model_crystal(data.x, data.edge_index, data.edge_attr, data.batch)
        loss = criterion(out, data.y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * data.num_graphs

    if epoch % 10 == 0:
        train_loss = total_loss / len(train_crystals)
        print(f&quot;Epoch {epoch:03d}, Train Loss: {train_loss:.4f}&quot;)

# ãƒ†ã‚¹ãƒˆè©•ä¾¡
model_crystal.eval()
test_preds = []
test_targets = []

with torch.no_grad():
    for data in test_loader_crystal:
        data = data.to(device)
        out = model_crystal(data.x, data.edge_index, data.edge_attr, data.batch)
        test_preds.append(out.cpu().numpy())
        test_targets.append(data.y.cpu().numpy())

test_preds = np.concatenate(test_preds)
test_targets = np.concatenate(test_targets)

test_mae = np.mean(np.abs(test_targets - test_preds))
test_r2 = r2_score(test_targets, test_preds)

print(f&quot;\n===== ãƒ†ã‚¹ãƒˆæ€§èƒ½ =====&quot;)
print(f&quot;MAE: {test_mae:.4f} eV&quot;)
print(f&quot;RÂ²: {test_r2:.4f}&quot;)
</code></pre>

<hr />
<h2>3.5 ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h2>
<h3>3.5.1 å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°</h3>
<pre class="codehilite"><code class="language-python">from torch.optim.lr_scheduler import ReduceLROnPlateau

# å­¦ç¿’ç‡ã‚’å‹•çš„ã«èª¿æ•´
scheduler = ReduceLROnPlateau(
    optimizer,
    mode='min',
    factor=0.5,     # å­¦ç¿’ç‡ã‚’åŠåˆ†ã«
    patience=10,    # 10ã‚¨ãƒãƒƒã‚¯æ”¹å–„ãªã—ã§èª¿æ•´
    verbose=True
)

# è¨“ç·´ãƒ«ãƒ¼ãƒ—å†…ã§ä½¿ç”¨
for epoch in range(epochs):
    train_loss = train(model, train_loader, optimizer, criterion, device)
    val_loss = evaluate(model, val_loader, criterion, device)

    # æ¤œè¨¼æå¤±ã«åŸºã¥ã„ã¦å­¦ç¿’ç‡ã‚’èª¿æ•´
    scheduler.step(val_loss)
</code></pre>

<h3>3.5.2 Early Stopping</h3>
<pre class="codehilite"><code class="language-python">class EarlyStopping:
    &quot;&quot;&quot;
    Early Stoppingã‚¯ãƒ©ã‚¹
    æ¤œè¨¼æå¤±ãŒæ”¹å–„ã—ãªããªã£ãŸã‚‰è¨“ç·´ã‚’åœæ­¢
    &quot;&quot;&quot;
    def __init__(self, patience=20, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = None
        self.early_stop = False

    def __call__(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss &gt; self.best_loss - self.min_delta:
            self.counter += 1
            if self.counter &gt;= self.patience:
                self.early_stop = True
        else:
            self.best_loss = val_loss
            self.counter = 0

# ä½¿ç”¨ä¾‹
early_stopping = EarlyStopping(patience=20)

for epoch in range(epochs):
    train_loss = train(model, train_loader, optimizer, criterion, device)
    val_loss = evaluate(model, val_loader, criterion, device)

    early_stopping(val_loss)
    if early_stopping.early_stop:
        print(f&quot;Early stopping at epoch {epoch}&quot;)
        break
</code></pre>

<h3>3.5.3 ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆã‚°ãƒ©ãƒ•ã®æ‘‚å‹•ï¼‰</h3>
<pre class="codehilite"><code class="language-python">import torch
from torch_geometric.utils import dropout_edge

def augment_graph(data, drop_edge_prob=0.1, noise_scale=0.01):
    &quot;&quot;&quot;
    ã‚°ãƒ©ãƒ•ã®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ

    Parameters:
    -----------
    data : Data
        å…ƒã®ã‚°ãƒ©ãƒ•
    drop_edge_prob : float
        ã‚¨ãƒƒã‚¸ã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã™ã‚‹ç¢ºç‡
    noise_scale : float
        ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã«åŠ ãˆã‚‹ãƒã‚¤ã‚ºã®ã‚¹ã‚±ãƒ¼ãƒ«

    Returns:
    --------
    augmented_data : Data
        æ‹¡å¼µã•ã‚ŒãŸã‚°ãƒ©ãƒ•
    &quot;&quot;&quot;
    # ã‚¨ãƒƒã‚¸ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ
    edge_index, edge_mask = dropout_edge(data.edge_index, p=drop_edge_prob)

    # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã«ãƒã‚¤ã‚ºã‚’è¿½åŠ 
    noise = torch.randn_like(data.x) * noise_scale
    x = data.x + noise

    augmented_data = Data(x=x, edge_index=edge_index, y=data.y)
    return augmented_data

# ä½¿ç”¨ä¾‹
original = dataset[0]
augmented = augment_graph(original, drop_edge_prob=0.15)

print(f&quot;å…ƒã®ã‚¨ãƒƒã‚¸æ•°: {original.num_edges}&quot;)
print(f&quot;æ‹¡å¼µå¾Œã®ã‚¨ãƒƒã‚¸æ•°: {augmented.num_edges}&quot;)
</code></pre>

<hr />
<h2>3.6 ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®è©•ä¾¡ã¨å¯è¦–åŒ–</h2>
<h3>3.6.1 è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—</h3>
<pre class="codehilite"><code class="language-python">from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

def evaluate_regression(y_true, y_pred):
    &quot;&quot;&quot;
    å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
    &quot;&quot;&quot;
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)

    # Mean Absolute Percentage Error
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

    return {
        'MAE': mae,
        'MSE': mse,
        'RMSE': rmse,
        'RÂ²': r2,
        'MAPE': mape
    }

# ä½¿ç”¨ä¾‹
metrics = evaluate_regression(test_targets, test_preds)

print(&quot;===== è©•ä¾¡æŒ‡æ¨™ =====&quot;)
for name, value in metrics.items():
    print(f&quot;{name}: {value:.4f}&quot;)
</code></pre>

<h3>3.6.2 æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ</h3>
<pre class="codehilite"><code class="language-python">import matplotlib.pyplot as plt

def plot_residuals(y_true, y_pred):
    &quot;&quot;&quot;
    æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
    &quot;&quot;&quot;
    residuals = y_true - y_pred

    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # æ®‹å·® vs äºˆæ¸¬å€¤
    axes[0].scatter(y_pred, residuals, alpha=0.6, s=20)
    axes[0].axhline(y=0, color='r', linestyle='--', lw=2)
    axes[0].set_xlabel('äºˆæ¸¬å€¤', fontsize=12)
    axes[0].set_ylabel('æ®‹å·®ï¼ˆå®Ÿæ¸¬ - äºˆæ¸¬ï¼‰', fontsize=12)
    axes[0].set_title('æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ', fontsize=14)
    axes[0].grid(True, alpha=0.3)

    # æ®‹å·®ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    axes[1].hist(residuals, bins=30, alpha=0.7, edgecolor='black')
    axes[1].set_xlabel('æ®‹å·®', fontsize=12)
    axes[1].set_ylabel('é »åº¦', fontsize=12)
    axes[1].set_title('æ®‹å·®åˆ†å¸ƒ', fontsize=14)
    axes[1].axvline(x=0, color='r', linestyle='--', lw=2)
    axes[1].grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    plt.show()

# ä½¿ç”¨ä¾‹
plot_residuals(test_targets, test_preds)
</code></pre>

<h3>3.6.3 ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ</h3>
<pre class="codehilite"><code class="language-python">import pandas as pd
import matplotlib.pyplot as plt

# è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ¯”è¼ƒ
models_performance = {
    'GCN (3å±¤)': {'MAE': 0.32, 'RÂ²': 0.88, 'Time': 45.2},
    'GAT (2å±¤)': {'MAE': 0.28, 'RÂ²': 0.91, 'Time': 62.8},
    'SchNet': {'MAE': 0.25, 'RÂ²': 0.93, 'Time': 89.5},
    'MPNN': {'MAE': 0.30, 'RÂ²': 0.90, 'Time': 55.1},
}

df = pd.DataFrame(models_performance).T

# ãƒ—ãƒ­ãƒƒãƒˆ
fig, axes = plt.subplots(1, 3, figsize=(16, 4))

# MAEæ¯”è¼ƒ
df['MAE'].plot(kind='bar', ax=axes[0], color='steelblue')
axes[0].set_ylabel('MAE (eV)', fontsize=12)
axes[0].set_title('å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆä½ã„ã»ã©è‰¯ã„ï¼‰', fontsize=13)
axes[0].tick_params(axis='x', rotation=45)
axes[0].grid(True, alpha=0.3, axis='y')

# RÂ²æ¯”è¼ƒ
df['RÂ²'].plot(kind='bar', ax=axes[1], color='forestgreen')
axes[1].set_ylabel('RÂ² Score', fontsize=12)
axes[1].set_title('æ±ºå®šä¿‚æ•°ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰', fontsize=13)
axes[1].tick_params(axis='x', rotation=45)
axes[1].grid(True, alpha=0.3, axis='y')
axes[1].set_ylim(0.8, 1.0)

# è¨“ç·´æ™‚é–“æ¯”è¼ƒ
df['Time'].plot(kind='bar', ax=axes[2], color='coral')
axes[2].set_ylabel('è¨“ç·´æ™‚é–“ (ç§’)', fontsize=12)
axes[2].set_title('è¨ˆç®—ã‚³ã‚¹ãƒˆ', fontsize=13)
axes[2].tick_params(axis='x', rotation=45)
axes[2].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()
</code></pre>

<hr />
<h2>3.7 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°</h2>
<h3>3.7.1 ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨è§£æ±ºç­–</h3>
<table>
<thead>
<tr>
<th>ã‚¨ãƒ©ãƒ¼</th>
<th>åŸå› </th>
<th>è§£æ±ºæ–¹æ³•</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>RuntimeError: CUDA out of memory</code></td>
<td>GPU ãƒ¡ãƒ¢ãƒªä¸è¶³</td>
<td>ãƒãƒƒãƒã‚µã‚¤ã‚ºå‰Šæ¸›ã€ãƒ¢ãƒ‡ãƒ«ã®å°å‹åŒ–ã€CPUä½¿ç”¨</td>
</tr>
<tr>
<td><code>AssertionError: edge_index not contiguous</code></td>
<td>ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ¡ãƒ¢ãƒªé…ç½®</td>
<td><code>edge_index = edge_index.t().contiguous()</code></td>
</tr>
<tr>
<td><code>ValueError: too many values to unpack</code></td>
<td>Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å±æ€§ä¸è¶³</td>
<td><code>x</code>, <code>edge_index</code>, <code>batch</code>ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª</td>
</tr>
<tr>
<td><code>RuntimeError: Expected all tensors on same device</code></td>
<td>ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒ‡ãƒã‚¤ã‚¹ä¸ä¸€è‡´</td>
<td><code>data = data.to(device)</code>ã‚’ç¢ºèª</td>
</tr>
</tbody>
</table>
<h3>3.7.2 ãƒ‡ãƒãƒƒã‚°ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ</h3>
<pre class="codehilite"><code class="language-python"># ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
print(f&quot;ãƒãƒ¼ãƒ‰æ•°: {data.num_nodes}&quot;)
print(f&quot;ã‚¨ãƒƒã‚¸æ•°: {data.num_edges}&quot;)
print(f&quot;å­¤ç«‹ãƒãƒ¼ãƒ‰: {data.contains_isolated_nodes()}&quot;)
print(f&quot;è‡ªå·±ãƒ«ãƒ¼ãƒ—: {data.contains_self_loops()}&quot;)

# ãƒ†ãƒ³ã‚½ãƒ«ã®å½¢çŠ¶ç¢ºèª
print(f&quot;x.shape: {data.x.shape}&quot;)
print(f&quot;edge_index.shape: {data.edge_index.shape}&quot;)
print(f&quot;y.shape: {data.y.shape}&quot;)

# ãƒ‡ãƒã‚¤ã‚¹ã®ç¢ºèª
print(f&quot;x device: {data.x.device}&quot;)
print(f&quot;edge_index device: {data.edge_index.device}&quot;)

# ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç¯„å›²ç¢ºèª
print(f&quot;max edge index: {data.edge_index.max().item()}&quot;)
print(f&quot;num_nodes: {data.num_nodes}&quot;)
assert data.edge_index.max().item() &lt; data.num_nodes, &quot;ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒãƒãƒ¼ãƒ‰æ•°ã‚’è¶…ãˆã¦ã„ã¾ã™&quot;
</code></pre>

<hr />
<h2>3.8 æœ¬ç« ã®ã¾ã¨ã‚</h2>
<h3>å­¦ã‚“ã ã“ã¨</h3>
<ol>
<li><strong>PyTorch Geometricç’°å¢ƒæ§‹ç¯‰</strong></li>
<li>Condaã€pipã€Google Colabã®3ã¤ã®æ–¹æ³•</li>
<li>
<p>ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§ã®ç¢ºèªã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°</p>
</li>
<li>
<p><strong>ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç†è§£</strong></p>
</li>
<li>Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹é€ ï¼ˆx, edge_index, batchï¼‰</li>
<li>RDKitã‹ã‚‰ã®ã‚°ãƒ©ãƒ•å¤‰æ›</li>
<li>
<p>DataLoaderã«ã‚ˆã‚‹ãƒãƒƒãƒå‡¦ç†</p>
</li>
<li>
<p><strong>QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å®Ÿè·µ</strong></p>
</li>
<li>134,000åˆ†å­ã®é‡å­åŒ–å­¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</li>
<li>GCNãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…ã¨è¨“ç·´</li>
<li>
<p>HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ï¼ˆMAE &lt; 0.5 eVç›®æ¨™ï¼‰</p>
</li>
<li>
<p><strong>çµæ™¶ç‰¹æ€§äºˆæ¸¬</strong></p>
</li>
<li>Materials Projectçµæ™¶ãƒ‡ãƒ¼ã‚¿ã®ã‚°ãƒ©ãƒ•è¡¨ç¾</li>
<li>Crystal Graph Convolutional Network</li>
<li>
<p>ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬</p>
</li>
<li>
<p><strong>è¨“ç·´ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</strong></p>
</li>
<li>å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°</li>
<li>Early Stopping</li>
<li>
<p>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆã‚°ãƒ©ãƒ•ã®æ‘‚å‹•ï¼‰</p>
</li>
<li>
<p><strong>è©•ä¾¡ã¨å¯è¦–åŒ–</strong></p>
</li>
<li>MAEã€MSEã€RÂ²ãªã©ã®æŒ‡æ¨™</li>
<li>æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ</li>
<li>ãƒ¢ãƒ‡ãƒ«é–“ã®æ€§èƒ½æ¯”è¼ƒ</li>
</ol>
<h3>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</h3>
<ul>
<li>âœ… PyTorch Geometricã¯ææ–™ãƒ»åˆ†å­ã®GNNå®Ÿè£…ã«æœ€é©</li>
<li>âœ… QM9ã¯åˆå­¦è€…ã«æœ€é©ãªåˆ†å­ç‰¹æ€§äºˆæ¸¬ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</li>
<li>âœ… ã‚°ãƒ©ãƒ•ã®å‰å‡¦ç†ï¼ˆå­¤ç«‹ãƒãƒ¼ãƒ‰ã€è‡ªå·±ãƒ«ãƒ¼ãƒ—ã®ç¢ºèªï¼‰ãŒé‡è¦</li>
<li>âœ… ãƒãƒƒãƒå‡¦ç†ã§ã¯<code>batch</code>ãƒ†ãƒ³ã‚½ãƒ«ãŒå„ãƒãƒ¼ãƒ‰ã®æ‰€å±ã‚’ç¤ºã™</li>
<li>âœ… å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã¨Early Stoppingã§éå­¦ç¿’ã‚’é˜²æ­¢</li>
</ul>
<h3>æ¬¡ã®ç« ã¸</h3>
<p>ç¬¬4ç« ã§ã¯ã€é«˜åº¦ãªGNNæŠ€è¡“ã‚’å­¦ã³ã¾ã™ï¼š
- ã‚°ãƒ©ãƒ•ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆéšå±¤çš„è¡¨ç¾ï¼‰
- ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã®æ´»ç”¨
- 3Då¹¾ä½•æƒ…å ±ã®çµ„è¾¼ã¿ï¼ˆSchNetã€DimeNetï¼‰
- ç­‰å¤‰GNNï¼ˆE(3)-equivariantï¼‰
- GNNExplainerã«ã‚ˆã‚‹è§£é‡ˆå¯èƒ½æ€§</p>
<p><strong><a href="./chapter-4.md">ç¬¬4ç« ï¼šé«˜åº¦ãªGNNæŠ€è¡“ â†’</a></strong></p>
<hr />
<h2>æ¼”ç¿’å•é¡Œ</h2>
<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>
<p>PyTorch Geometricã®Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å«ã¾ã‚Œã‚‹ä¸»è¦ãªå±æ€§ã‚’3ã¤æŒ™ã’ã€ãã‚Œãã‚Œã®å½¹å‰²ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

ãƒãƒ¼ãƒ‰ã€ã‚¨ãƒƒã‚¸ã€ãƒãƒƒãƒã«é–¢ã™ã‚‹æƒ…å ±ã‚’æ ¼ç´ã™ã‚‹å±æ€§ã‚’è€ƒãˆã¾ã—ã‚‡ã†ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

**ä¸»è¦ãª3ã¤ã®å±æ€§**:

1. **`x` (ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡)**
   - å½¢çŠ¶: `(num_nodes, num_node_features)`
   - å½¹å‰²: å„ãƒãƒ¼ãƒ‰ï¼ˆåŸå­ï¼‰ã®ç‰¹å¾´é‡ã‚’æ ¼ç´
   - ä¾‹: åŸå­ç•ªå·ã€é›»æ°—é™°æ€§åº¦ã€å½¢å¼é›»è·ãªã©

2. **`edge_index` (ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)**
   - å½¢çŠ¶: `(2, num_edges)`
   - å½¹å‰²: ã‚°ãƒ©ãƒ•ã®æ¥ç¶šé–¢ä¿‚ï¼ˆéš£æ¥ãƒªã‚¹ãƒˆå½¢å¼ï¼‰
   - ä¾‹: `[[0, 1], [1, 2]]` â†’ ãƒãƒ¼ãƒ‰0ã¨ãƒãƒ¼ãƒ‰1ãŒæ¥ç¶š

3. **`batch` (ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)**
   - å½¢çŠ¶: `(num_nodes,)`
   - å½¹å‰²: å„ãƒãƒ¼ãƒ‰ãŒã©ã®ã‚°ãƒ©ãƒ•ã«å±ã™ã‚‹ã‹ã‚’ç¤ºã™
   - ä¾‹: `[0, 0, 1, 1, 2]` â†’ ãƒãƒ¼ãƒ‰0,1ã¯ã‚°ãƒ©ãƒ•0ã€ãƒãƒ¼ãƒ‰2,3ã¯ã‚°ãƒ©ãƒ•1

**è¿½åŠ ã®é‡è¦ãªå±æ€§**:
- `edge_attr`: ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆçµåˆã‚¿ã‚¤ãƒ—ã€è·é›¢ãªã©ï¼‰
- `y`: ç›®çš„å¤‰æ•°ï¼ˆåˆ†å­ç‰¹æ€§ã€çµæ™¶ç‰¹æ€§ï¼‰

</details>

<hr />
<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã—ãŸGCNãƒ¢ãƒ‡ãƒ«ã®MAEãŒ0.8 eVã§ã—ãŸã€‚æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®3ã¤ã®å…·ä½“çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®3ã¤ã®è¦³ç‚¹ã‹ã‚‰è€ƒãˆã¾ã—ã‚‡ã†ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1: ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ”¹å–„**


<pre class="codehilite"><code class="language-python"># GATãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½¿ç”¨ï¼ˆæ³¨æ„æ©Ÿæ§‹ã§é‡è¦ãªçµåˆã‚’å­¦ç¿’ï¼‰
from torch_geometric.nn import GATConv

class ImprovedGNN(torch.nn.Module):
    def __init__(self, num_node_features, hidden_channels=128):
        super().__init__()
        # GATãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼ˆãƒ˜ãƒƒãƒ‰æ•°=8ï¼‰
        self.conv1 = GATConv(num_node_features, hidden_channels, heads=8)
        self.conv2 = GATConv(hidden_channels * 8, hidden_channels, heads=8)
        self.conv3 = GATConv(hidden_channels * 8, hidden_channels, heads=1)
        # å±¤ã‚’å¢—ã‚„ã™ï¼ˆ3å±¤ â†’ 4å±¤ï¼‰
        self.conv4 = GCNConv(hidden_channels, hidden_channels)
</code></pre>



**æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„**: MAE 0.8 eV â†’ 0.5-0.6 eV

---

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ2: ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã®æ´»ç”¨**


<pre class="codehilite"><code class="language-python"># ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆçµåˆã‚¿ã‚¤ãƒ—ï¼‰ã‚’çµ„ã¿è¾¼ã‚€
from torch_geometric.nn import NNConv

class EdgeFeaturesGNN(torch.nn.Module):
    def __init__(self, num_node_features, num_edge_features, hidden_channels=64):
        super().__init__()
        # NNConv: ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã‚’è€ƒæ…®
        nn = torch.nn.Sequential(
            torch.nn.Linear(num_edge_features, hidden_channels * hidden_channels),
            torch.nn.ReLU()
        )
        self.conv1 = NNConv(num_node_features, hidden_channels, nn, aggr='mean')
</code></pre>



**æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„**: MAE 0.8 eV â†’ 0.6-0.7 eV

---

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ3: ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ã¨æ‹¡å¼µ**


<pre class="codehilite"><code class="language-python"># ç›®çš„å¤‰æ•°ã‚’æ¨™æº–åŒ–
y_mean = train_dataset.data.y.mean(dim=0)
y_std = train_dataset.data.y.std(dim=0)

for data in train_dataset:
    data.y = (data.y - y_mean) / y_std

# ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆã‚°ãƒ©ãƒ•ã®æ‘‚å‹•ï¼‰
def augment_graph(data):
    # ã‚¨ãƒƒã‚¸ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ
    edge_index, _ = dropout_edge(data.edge_index, p=0.1)
    # ãƒã‚¤ã‚ºè¿½åŠ 
    x = data.x + torch.randn_like(data.x) * 0.01
    return Data(x=x, edge_index=edge_index, y=data.y)

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’2å€ã«
augmented_train = [augment_graph(data) for data in train_dataset]
train_dataset = train_dataset + augmented_train
</code></pre>



**æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„**: MAE 0.8 eV â†’ 0.7 eV

---

**æœ€é©ãªæˆ¦ç•¥**: ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1ï¼ˆãƒ¢ãƒ‡ãƒ«æ”¹å–„ï¼‰ã¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ2ï¼ˆã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼‰ã‚’çµ„ã¿åˆã‚ã›ã€MAE 0.4-0.5 eVã‚’ç›®æŒ‡ã™ã€‚

</details>

<hr />
<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚åŸå› ã‚’ç‰¹å®šã—ã€ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚</p>
<pre class="codehilite"><code class="language-python"># ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã‚³ãƒ¼ãƒ‰
model = GCN_QM9(num_node_features=11, num_classes=1)
device = torch.device('cuda')
model = model.to(device)

for data in train_loader:
    optimizer.zero_grad()
    out = model(data.x, data.edge_index, data.batch)
    loss = criterion(out, data.y)
    loss.backward()
    optimizer.step()
</code></pre>

<p><strong>ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸</strong>:</p>
<pre class="codehilite"><code>RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
</code></pre>

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒã‚¤ã‚¹ãŒä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

**åŸå› **:
ãƒ¢ãƒ‡ãƒ«ã¯`cuda`ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•ã•ã‚Œã¦ã„ã¾ã™ãŒã€`data`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯`cpu`ã®ã¾ã¾ã§ã™ã€‚PyTorchã§ã¯ã€ã™ã¹ã¦ã®ãƒ†ãƒ³ã‚½ãƒ«ãŒåŒã˜ãƒ‡ãƒã‚¤ã‚¹ä¸Šã«ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

**ä¿®æ­£ã‚³ãƒ¼ãƒ‰**:


<pre class="codehilite"><code class="language-python">model = GCN_QM9(num_node_features=11, num_classes=1)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

for data in train_loader:
    # ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«ç§»å‹•ï¼ˆé‡è¦ï¼ï¼‰
    data = data.to(device)

    optimizer.zero_grad()
    out = model(data.x, data.edge_index, data.batch)
    loss = criterion(out, data.y)
    loss.backward()
    optimizer.step()
</code></pre>



**é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ**:
1. `data = data.to(device)`ã§ã€`data`å†…ã®ã™ã¹ã¦ã®ãƒ†ãƒ³ã‚½ãƒ«ï¼ˆ`x`, `edge_index`, `batch`, `y`ï¼‰ã‚’ä¸€åº¦ã«GPUã«ç§»å‹•
2. `torch.cuda.is_available()`ã§GPUãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèªï¼ˆCPUã®ã¿ã®ç’°å¢ƒã§ã‚‚ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ï¼‰
3. è¨“ç·´ãƒ«ãƒ¼ãƒ—ã®**æœ€åˆ**ã§ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•

**ãƒ‡ãƒãƒƒã‚°ã®ãƒã‚§ãƒƒã‚¯**:

<pre class="codehilite"><code class="language-python"># ãƒ‡ãƒã‚¤ã‚¹ã®ç¢ºèª
print(f&quot;Model device: {next(model.parameters()).device}&quot;)
print(f&quot;Data x device: {data.x.device}&quot;)
print(f&quot;Data edge_index device: {data.edge_index.device}&quot;)
</code></pre>



</details>

<hr />
<h2>å‚è€ƒæ–‡çŒ®</h2>
<ol>
<li>
<p>Fey, M., &amp; Lenssen, J. E. (2019). "Fast Graph Representation Learning with PyTorch Geometric." <em>ICLR Workshop on Representation Learning on Graphs and Manifolds</em>.
   GitHub: https://github.com/pyg-team/pytorch_geometric
   <em>PyTorch Geometricå…¬å¼è«–æ–‡ã€‚ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è¨­è¨ˆæ€æƒ³ã¨å®Ÿè£…ã®è©³ç´°ã€‚</em></p>
</li>
<li>
<p>Ramakrishnan, R., et al. (2014). "Quantum chemistry structures and properties of 134 kilo molecules." <em>Scientific Data</em>, 1, 140022.
   DOI: <a href="https://doi.org/10.1038/sdata.2014.22">10.1038/sdata.2014.22</a>
   <em>QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¬å¼è«–æ–‡ã€‚134,000åˆ†å­ã®é‡å­åŒ–å­¦è¨ˆç®—ãƒ‡ãƒ¼ã‚¿ã€‚</em></p>
</li>
<li>
<p>Xie, T., &amp; Grossman, J. C. (2018). "Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties." <em>Physical Review Letters</em>, 120(14), 145301.
   DOI: <a href="https://doi.org/10.1103/PhysRevLett.120.145301">10.1103/PhysRevLett.120.145301</a>
   <em>Crystal Graph Convolutional Networksï¼ˆCGCNï¼‰ã®åŸè«–æ–‡ã€‚çµæ™¶ç‰¹æ€§äºˆæ¸¬ã¸ã®å¿œç”¨ã€‚</em></p>
</li>
<li>
<p>Gilmer, J., et al. (2017). "Neural Message Passing for Quantum Chemistry." <em>ICML 2017</em>.
   URL: https://arxiv.org/abs/1704.01212
   <em>Message Passing Neural Networksï¼ˆMPNNï¼‰ã®ç†è«–ã€‚QM9ã§ã®é«˜ç²¾åº¦äºˆæ¸¬ã‚’é”æˆã€‚</em></p>
</li>
<li>
<p>PyTorch Geometric Documentation. (2024). "Introduction by Example."
   URL: https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html
   <em>PyTorch Geometricå…¬å¼ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã€‚åŸºæœ¬çš„ãªä½¿ã„æ–¹ã‚’ä¾‹ç¤ºã€‚</em></p>
</li>
<li>
<p>RDKit Documentation. (2024). "Getting Started with the RDKit in Python."
   URL: https://www.rdkit.org/docs/GettingStartedInPython.html
   <em>RDKitã®å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€‚SMILESã‹ã‚‰åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã™ã‚‹æ–¹æ³•ã€‚</em></p>
</li>
</ol>
<hr />
<p><strong>ä½œæˆæ—¥</strong>: 2025-10-17
<strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0
<strong>ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ</strong>: chapter-template-v2.0
<strong>è‘—è€…</strong>: GNNå…¥é–€ã‚·ãƒªãƒ¼ã‚ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</p>

        <div class="navigation">
            <a href="chapter-2.html" class="nav-button">â† å‰ç« : GNNã®åŸºç¤ç†è«–</a>
            <a href="chapter-4.html" class="nav-button">æ¬¡ç« : é«˜åº¦ãªGNNæŠ€è¡“ â†’</a>
            <a href="index.html" class="nav-button">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
        </div>
    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-17</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default'
                });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</body>
</html>