<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬3ç« ï¼šPyTorch Geometricå®Ÿè·µ - åˆ†å­ãƒ»ææ–™ç‰¹æ€§äºˆæ¸¬ã®å®Ÿè£… - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬3ç« ï¼šPyTorch Geometricå®Ÿè·µ - åˆ†å­ãƒ»ææ–™ç‰¹æ€§äºˆæ¸¬ã®å®Ÿè£…</h1>
            <p class="subtitle">å®Ÿãƒ‡ãƒ¼ã‚¿ã§å­¦ã¶ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ§‹ç¯‰ã¨è©•ä¾¡</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 20-25åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 0å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 0å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h1>ç¬¬3ç« ï¼šPyTorch Geometricå®Ÿè·µ - åˆ†å­ãƒ»ææ–™ç‰¹æ€§äºˆæ¸¬ã®å®Ÿè£…</h1>

<h2>å­¦ç¿’ç›®æ¨™</h2>

ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š
- PyTorch Geometricç’°å¢ƒã‚’æ§‹ç¯‰ã—ã€GNNãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã„ã“ãªã›ã‚‹
- QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§åˆ†å­ç‰¹æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã§ãã‚‹
- Materials Projectãƒ‡ãƒ¼ã‚¿ã§çµæ™¶ç‰¹æ€§äºˆæ¸¬ã‚’å®Ÿè¡Œã§ãã‚‹
- ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’é©ç”¨ã§ãã‚‹
- äºˆæ¸¬çµæœã‚’å¯è¦–åŒ–ã—ã€æ€§èƒ½ã‚’è©•ä¾¡ã§ãã‚‹

<strong>èª­äº†æ™‚é–“</strong>: 25-30åˆ†
<strong>ã‚³ãƒ¼ãƒ‰ä¾‹</strong>: 10å€‹
<strong>æ¼”ç¿’å•é¡Œ</strong>: 3å•

---

<h2>3.1 ç’°å¢ƒæ§‹ç¯‰ï¼šPyTorch Geometricã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</h2>

<h3>3.1.1 PyTorch Geometricã¨ã¯</h3>

<strong>PyTorch Geometric (PyG)</strong>ã¯ã€PyTorchä¸Šã§å‹•ä½œã™ã‚‹ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å°‚ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚

<strong>ä¸»ãªç‰¹å¾´</strong>:
- ğŸš€ <strong>é«˜é€Ÿ</strong>: GPUã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªã‚°ãƒ©ãƒ•å‡¦ç†
- ğŸ“¦ <strong>è±Šå¯Œãªãƒ¢ãƒ‡ãƒ«</strong>: GCNã€GATã€GraphSAGEã€SchNetãªã©30ç¨®é¡ä»¥ä¸Š
- ğŸ§ª <strong>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</strong>: QM9ã€ZINCã€OGBï¼ˆOpen Graph Benchmarkï¼‰ãŒçµ„ã¿è¾¼ã¿æ¸ˆã¿
- ğŸ› ï¸ <strong>æŸ”è»Ÿæ€§</strong>: ã‚«ã‚¹ã‚¿ãƒ ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚„ãƒ¢ãƒ‡ãƒ«ã‚’ç°¡å˜ã«å®Ÿè£…å¯èƒ½

<h3>3.1.2 ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †</h3>

<strong>Option 1: Condaç’°å¢ƒï¼ˆæ¨å¥¨ï¼‰</strong>

<pre><code class="language-bash"><h1>1. Python 3.9ä»¥ä¸Šã®ç’°å¢ƒã‚’ä½œæˆ</h1>
conda create -n gnn-env python=3.10
conda activate gnn-env

<h1>2. PyTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆCUDAç‰ˆæ¨å¥¨ï¼‰</h1>
<h1>CPUç‰ˆã®å ´åˆ:</h1>
conda install pytorch torchvision torchaudio cpuonly -c pytorch

<h1>GPUç‰ˆã®å ´åˆï¼ˆCUDA 11.8ï¼‰:</h1>
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

<h1>3. PyTorch Geometricã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</h1>
conda install pyg -c pyg

<h1>4. è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª</h1>
pip install rdkit matplotlib seaborn pandas scikit-learn</code></pre>

<strong>Option 2: pipã§ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</strong>

<pre><code class="language-bash"><h1>1. ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆ</h1>
python -m venv gnn-env
source gnn-env/bin/activate  # macOS/Linux
<h1>gnn-env\Scripts\activate  # Windows</h1>

<h1>2. PyTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</h1>
pip install torch torchvision torchaudio

<h1>3. PyTorch Geometricã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</h1>
pip install torch-geometric

<h1>4. ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª</h1>
pip install torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-2.0.0+cpu.html

<h1>5. è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª</h1>
pip install rdkit matplotlib seaborn pandas scikit-learn</code></pre>

<strong>Option 3: Google Colabï¼ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸è¦ï¼‰</strong>

<pre><code class="language-python"><h1>Google Colabã§ã¯ä»¥ä¸‹ã‚’å®Ÿè¡Œ</h1>
!pip install torch-geometric
!pip install rdkit</code></pre>

<h3>3.1.3 ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª</h3>

<pre><code class="language-python">import torch
import torch_geometric
from torch_geometric.data import Data
from rdkit import Chem
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

print("===== ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª =====")
print(f"PyTorch version: {torch.__version__}")
print(f"PyTorch Geometric version: {torch_geometric.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA version: {torch.version.cuda}")
    print(f"GPU: {torch.cuda.get_device_name(0)}")

<h1>ç°¡å˜ãªã‚°ãƒ©ãƒ•ã‚’ä½œæˆã—ã¦ãƒ†ã‚¹ãƒˆ</h1>
edge_index = torch.tensor([[0, 1, 1, 2],
                           [1, 0, 2, 1]], dtype=torch.long)
x = torch.tensor([[-1], [0], [1]], dtype=torch.float)
data = Data(x=x, edge_index=edge_index)

print(f"\nãƒ†ã‚¹ãƒˆã‚°ãƒ©ãƒ•ä½œæˆæˆåŠŸ!")
print(f"ãƒãƒ¼ãƒ‰æ•°: {data.num_nodes}")
print(f"ã‚¨ãƒƒã‚¸æ•°: {data.num_edges}")
print("âœ… PyTorch Geometricç’°å¢ƒã®æ§‹ç¯‰å®Œäº†!")</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›</strong>:
<pre><code>===== ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª =====
PyTorch version: 2.0.0
PyTorch Geometric version: 2.3.0
CUDA available: True
CUDA version: 11.8
GPU: NVIDIA GeForce RTX 3090

ãƒ†ã‚¹ãƒˆã‚°ãƒ©ãƒ•ä½œæˆæˆåŠŸ!
ãƒãƒ¼ãƒ‰æ•°: 3
ã‚¨ãƒƒã‚¸æ•°: 4
âœ… PyTorch Geometricç’°å¢ƒã®æ§‹ç¯‰å®Œäº†!</code></pre>

<h3>3.1.4 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°</h3>

| ã‚¨ãƒ©ãƒ¼ | åŸå›  | è§£æ±ºæ–¹æ³• |
|--------|------|----------|
| <code>ImportError: No module named 'torch_geometric'</code> | PyGæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« | <code>pip install torch-geometric</code> |
| <code>OSError: [WinError 126] DLLèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼</code> (Windows) | C++å†é ’å¸ƒå¯èƒ½ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¸è¶³ | Microsoft Visual C++ Redistributableã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« |
| <code>RuntimeError: CUDA out of memory</code> | GPU ãƒ¡ãƒ¢ãƒªä¸è¶³ | ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å‰Šæ¸›ã€CPUç‰ˆPyTorchä½¿ç”¨ |
| <code>ImportError: cannot import name 'Data'</code> | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸ä¸€è‡´ | PyTorchã¨PyGã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèª |

---

<h2>3.2 PyTorch Geometricã®åŸºæœ¬ï¼šãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¨DataLoader</h2>

<h3>3.2.1 Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹é€ </h3>

PyTorch Geometricã§ã¯ã€ã‚°ãƒ©ãƒ•ã‚’<code>Data</code>ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§è¡¨ç¾ã—ã¾ã™ã€‚

<pre><code class="language-python">from torch_geometric.data import Data
import torch

<h1>ã‚¨ã‚¿ãƒãƒ¼ãƒ«åˆ†å­ (C2H5OH) ã‚’ã‚°ãƒ©ãƒ•ã§è¡¨ç¾</h1>
<h1>C: ç‚­ç´ ï¼ˆãƒãƒ¼ãƒ‰0, 1ï¼‰</h1>
<h1>O: é…¸ç´ ï¼ˆãƒãƒ¼ãƒ‰2ï¼‰</h1>
<h1>H: æ°´ç´ ï¼ˆãƒãƒ¼ãƒ‰3-7ï¼‰</h1>

<h1>ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆåŸå­ç•ªå·ã‚’ä½¿ç”¨ï¼‰</h1>
x = torch.tensor([
    [6],   # C (ç‚­ç´ )
    [6],   # C (ç‚­ç´ )
    [8],   # O (é…¸ç´ )
    [1],   # H (æ°´ç´ )
    [1],   # H (æ°´ç´ )
    [1],   # H (æ°´ç´ )
    [1],   # H (æ°´ç´ )
    [1],   # H (æ°´ç´ )
], dtype=torch.float)

<h1>ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆçµåˆé–¢ä¿‚ï¼‰</h1>
<h1>å„çµåˆã¯åŒæ–¹å‘ï¼ˆç„¡å‘ã‚°ãƒ©ãƒ•ï¼‰</h1>
edge_index = torch.tensor([
    [0, 1, 1, 0, 0, 2, 2, 0, 0, 3, 3, 0, 1, 4, 4, 1, 1, 5, 5, 1, 2, 6, 6, 2],
    [1, 0, 2, 2, 3, 0, 0, 3, 4, 1, 1, 4, 5, 1, 1, 5, 6, 2, 2, 6, 7, 2, 2, 7]
], dtype=torch.long)

<h1>ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆçµåˆã‚¿ã‚¤ãƒ—: 1=å˜çµåˆï¼‰</h1>
edge_attr = torch.ones(edge_index.size(1), 1)

<h1>åˆ†å­ãƒ¬ãƒ™ãƒ«ã®ç‰¹å¾´ï¼ˆç›®çš„å¤‰æ•°ï¼‰</h1>
y = torch.tensor([[156.0]], dtype=torch.float)  # æ²¸ç‚¹ (Â°C)

<h1>Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ</h1>
ethanol = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)

print("===== ã‚¨ã‚¿ãƒãƒ¼ãƒ«åˆ†å­ã®ã‚°ãƒ©ãƒ•è¡¨ç¾ =====")
print(f"ãƒãƒ¼ãƒ‰æ•°ï¼ˆåŸå­æ•°ï¼‰: {ethanol.num_nodes}")
print(f"ã‚¨ãƒƒã‚¸æ•°ï¼ˆçµåˆæ•°Ã—2ï¼‰: {ethanol.num_edges}")
print(f"ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®å½¢çŠ¶: {ethanol.x.shape}")
print(f"ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å½¢çŠ¶: {ethanol.edge_index.shape}")
print(f"ç›®çš„å¤‰æ•°ï¼ˆæ²¸ç‚¹ï¼‰: {ethanol.y.item()} Â°C")

<h1>ã‚°ãƒ©ãƒ•ã®åŸºæœ¬çµ±è¨ˆ</h1>
print(f"\n===== ã‚°ãƒ©ãƒ•ã®çµ±è¨ˆæƒ…å ± =====")
print(f"å¹³å‡æ¬¡æ•°ï¼ˆçµåˆæ•°ï¼‰: {ethanol.num_edges / ethanol.num_nodes:.2f}")
print(f"å­¤ç«‹ãƒãƒ¼ãƒ‰: {ethanol.contains_isolated_nodes()}")
print(f"è‡ªå·±ãƒ«ãƒ¼ãƒ—: {ethanol.contains_self_loops()}")</code></pre>

<strong>å‡ºåŠ›</strong>:
<pre><code>===== ã‚¨ã‚¿ãƒãƒ¼ãƒ«åˆ†å­ã®ã‚°ãƒ©ãƒ•è¡¨ç¾ =====
ãƒãƒ¼ãƒ‰æ•°ï¼ˆåŸå­æ•°ï¼‰: 8
ã‚¨ãƒƒã‚¸æ•°ï¼ˆçµåˆæ•°Ã—2ï¼‰: 24
ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®å½¢çŠ¶: torch.Size([8, 1])
ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å½¢çŠ¶: torch.Size([2, 24])
ç›®çš„å¤‰æ•°ï¼ˆæ²¸ç‚¹ï¼‰: 156.0 Â°C

===== ã‚°ãƒ©ãƒ•ã®çµ±è¨ˆæƒ…å ± =====
å¹³å‡æ¬¡æ•°ï¼ˆçµåˆæ•°ï¼‰: 3.00
å­¤ç«‹ãƒãƒ¼ãƒ‰: False
è‡ªå·±ãƒ«ãƒ¼ãƒ—: False</code></pre>

<h3>3.2.2 RDKitã‹ã‚‰ã‚°ãƒ©ãƒ•ã¸ã®å¤‰æ›</h3>

RDKitã¯SMILESï¼ˆåˆ†å­ã®æ–‡å­—åˆ—è¡¨ç¾ï¼‰ã‹ã‚‰åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã§ãã¾ã™ã€‚

<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import Draw
from torch_geometric.data import Data
import torch

def mol_to_graph(smiles):
    """
    SMILESæ–‡å­—åˆ—ã‹ã‚‰PyTorch Geometricã®Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ

    Parameters:
    -----------
    smiles : str
        åˆ†å­ã®SMILESè¡¨ç¾

    Returns:
    --------
    data : torch_geometric.data.Data
        ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿
    """
    # SMILESã‹ã‚‰åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None

    # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆåŸå­ã®ç‰¹æ€§ï¼‰
    atom_features = []
    for atom in mol.GetAtoms():
        # åŸå­ç•ªå·ã‚’ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆC, N, O, F, ãã®ä»–ï¼‰
        atom_type = [0] * 5
        if atom.GetAtomicNum() == 6:    # C
            atom_type[0] = 1
        elif atom.GetAtomicNum() == 7:  # N
            atom_type[1] = 1
        elif atom.GetAtomicNum() == 8:  # O
            atom_type[2] = 1
        elif atom.GetAtomicNum() == 9:  # F
            atom_type[3] = 1
        else:
            atom_type[4] = 1

        # å½¢å¼é›»è·ã¨èŠ³é¦™æ—æ€§ã‚’è¿½åŠ 
        formal_charge = atom.GetFormalCharge()
        is_aromatic = int(atom.GetIsAromatic())

        atom_features.append(atom_type + [formal_charge, is_aromatic])

    x = torch.tensor(atom_features, dtype=torch.float)

    # ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆçµåˆé–¢ä¿‚ï¼‰
    edge_indices = []
    for bond in mol.GetBonds():
        i = bond.GetBeginAtomIdx()
        j = bond.GetEndAtomIdx()
        edge_indices += [[i, j], [j, i]]  # ç„¡å‘ã‚°ãƒ©ãƒ•ãªã®ã§åŒæ–¹å‘

    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()

    data = Data(x=x, edge_index=edge_index)
    return data, mol

<h1>ãƒ†ã‚¹ãƒˆ: ã„ãã¤ã‹ã®åˆ†å­ã‚’ã‚°ãƒ©ãƒ•ã«å¤‰æ›</h1>
smiles_list = [
    ("C", "ãƒ¡ã‚¿ãƒ³"),
    ("CCO", "ã‚¨ã‚¿ãƒãƒ¼ãƒ«"),
    ("c1ccccc1", "ãƒ™ãƒ³ã‚¼ãƒ³"),
    ("CC(=O)O", "é…¢é…¸"),
]

print("===== SMILESã‹ã‚‰ã‚°ãƒ©ãƒ•ã¸ã®å¤‰æ› =====")
for smiles, name in smiles_list:
    data, mol = mol_to_graph(smiles)
    print(f"\n{name} ({smiles}):")
    print(f"  ãƒãƒ¼ãƒ‰æ•°: {data.num_nodes}")
    print(f"  ã‚¨ãƒƒã‚¸æ•°: {data.num_edges}")
    print(f"  ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡æ¬¡å…ƒ: {data.x.shape[1]}")

<h1>åˆ†å­æ§‹é€ ã®å¯è¦–åŒ–</h1>
import matplotlib.pyplot as plt
from rdkit.Chem import Draw

fig, axes = plt.subplots(1, 4, figsize=(16, 4))
for i, (smiles, name) in enumerate(smiles_list):
    _, mol = mol_to_graph(smiles)
    img = Draw.MolToImage(mol, size=(300, 300))
    axes[i].imshow(img)
    axes[i].set_title(f"{name}\n{smiles}", fontsize=12)
    axes[i].axis('off')

plt.tight_layout()
plt.show()</code></pre>

<h3>3.2.3 DataLoaderã®ä½¿ç”¨</h3>

è¤‡æ•°ã®ã‚°ãƒ©ãƒ•ã‚’ãƒãƒƒãƒå‡¦ç†ã™ã‚‹ã«ã¯<code>DataLoader</code>ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

<pre><code class="language-python">from torch_geometric.data import Data, DataLoader
import torch

<h1>ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆï¼ˆ10å€‹ã®åˆ†å­ï¼‰</h1>
dataset = []
for i in range(10):
    num_nodes = torch.randint(5, 15, (1,)).item()  # 5-14åŸå­
    x = torch.randn(num_nodes, 7)  # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆ7æ¬¡å…ƒï¼‰

    # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚¨ãƒƒã‚¸ã‚’ç”Ÿæˆ
    edge_index = torch.randint(0, num_nodes, (2, num_nodes * 2))

    # ç›®çš„å¤‰æ•°ï¼ˆä¾‹: HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—ï¼‰
    y = torch.randn(1)

    data = Data(x=x, edge_index=edge_index, y=y)
    dataset.append(data)

<h1>DataLoaderã‚’ä½œæˆï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚º=4ï¼‰</h1>
loader = DataLoader(dataset, batch_size=4, shuffle=True)

print("===== DataLoaderã®ä½¿ç”¨ =====")
print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: {len(dataset)}")
print(f"ãƒãƒƒãƒæ•°: {len(loader)}")

<h1>æœ€åˆã®ãƒãƒƒãƒã‚’ç¢ºèª</h1>
for batch in loader:
    print(f"\næœ€åˆã®ãƒãƒƒãƒ:")
    print(f"  ãƒãƒƒãƒå†…ã®åˆ†å­æ•°: {batch.num_graphs}")
    print(f"  ç·ãƒãƒ¼ãƒ‰æ•°: {batch.num_nodes}")
    print(f"  ç·ã‚¨ãƒƒã‚¸æ•°: {batch.num_edges}")
    print(f"  ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®å½¢çŠ¶: {batch.x.shape}")
    print(f"  ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {batch.batch}")
    print(f"  ç›®çš„å¤‰æ•°ã®å½¢çŠ¶: {batch.y.shape}")
    break</code></pre>

<strong>å‡ºåŠ›ä¾‹</strong>:
<pre><code>===== DataLoaderã®ä½¿ç”¨ =====
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: 10
ãƒãƒƒãƒæ•°: 3

æœ€åˆã®ãƒãƒƒãƒ:
  ãƒãƒƒãƒå†…ã®åˆ†å­æ•°: 4
  ç·ãƒãƒ¼ãƒ‰æ•°: 38
  ç·ã‚¨ãƒƒã‚¸æ•°: 76
  ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®å½¢çŠ¶: torch.Size([38, 7])
  ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: tensor([0, 0, 0, ..., 3, 3, 3])
  ç›®çš„å¤‰æ•°ã®å½¢çŠ¶: torch.Size([4, 1])</code></pre>

<strong>é‡è¦</strong>: <code>batch</code>ãƒ†ãƒ³ã‚½ãƒ«ã¯å„ãƒãƒ¼ãƒ‰ãŒã©ã®åˆ†å­ã«å±ã™ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ï¼ˆ0, 0, 0, 1, 1, 2, 2, 2, 3, ...ï¼‰ã€‚

---

<h2>3.3 QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§åˆ†å­ç‰¹æ€§äºˆæ¸¬</h2>

<h3>3.3.1 QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¦‚è¦</h3>

<strong>QM9</strong>ã¯134,000å€‹ã®æœ‰æ©Ÿå°åˆ†å­ã®é‡å­åŒ–å­¦è¨ˆç®—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚

<strong>å«ã¾ã‚Œã‚‹ç‰¹æ€§</strong>:
- HOMOï¼ˆæœ€é«˜è¢«å è»Œé“ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰
- LUMOï¼ˆæœ€ä½éå è»Œé“ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰
- ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆHOMO-LUMOã‚®ãƒ£ãƒƒãƒ—ï¼‰
- åŒæ¥µå­ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ
- å†…éƒ¨ã‚¨ãƒãƒ«ã‚®ãƒ¼
- ã‚¨ãƒ³ã‚¿ãƒ«ãƒ”ãƒ¼ã€è‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼ã€ç†±å®¹é‡ãªã©

<h3>3.3.2 QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿</h3>

<pre><code class="language-python">from torch_geometric.datasets import QM9
import torch

<h1>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå›ã®ã¿ã€ç´„1GBï¼‰</h1>
dataset = QM9(root='./data/QM9')

print("===== QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ =====")
print(f"åˆ†å­æ•°: {len(dataset)}")
print(f"ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡æ¬¡å…ƒ: {dataset.num_node_features}")
print(f"ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡æ¬¡å…ƒ: {dataset.num_edge_features}")
print(f"ç›®çš„å¤‰æ•°æ•°: {dataset.num_classes}")

<h1>æœ€åˆã®åˆ†å­ã‚’ç¢ºèª</h1>
data = dataset[0]
print(f"\næœ€åˆã®åˆ†å­:")
print(f"  åŸå­æ•°: {data.num_nodes}")
print(f"  çµåˆæ•°: {data.num_edges // 2}")
print(f"  ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡: {data.x.shape}")
print(f"  ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡: {data.edge_attr.shape}")
print(f"  ç›®çš„å¤‰æ•°ï¼ˆ19ç¨®é¡ï¼‰: {data.y.shape}")

<h1>ç›®çš„å¤‰æ•°ã®ä¸€éƒ¨ã‚’è¡¨ç¤º</h1>
target_names = ['mu', 'alpha', 'homo', 'lumo', 'gap', 'r2', 'zpve',
                'U0', 'U', 'H', 'G', 'Cv']
print(f"\nä¸»è¦ãªç‰¹æ€§å€¤:")
for i, name in enumerate(target_names):
    print(f"  {name}: {data.y[0, i].item():.4f}")</code></pre>

<h3>3.3.3 Graph Convolutional Networkï¼ˆGCNï¼‰ã®å®Ÿè£…</h3>

<pre><code class="language-python">import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, global_mean_pool

class GCN_QM9(torch.nn.Module):
    """
    QM9åˆ†å­ç‰¹æ€§äºˆæ¸¬ç”¨ã®Graph Convolutional Network

    Architecture:
    - 3å±¤ã®GCNConv
    - Global mean pooling
    - 2å±¤ã®å…¨çµåˆå±¤
    """
    def __init__(self, num_node_features, num_classes, hidden_channels=64):
        super(GCN_QM9, self).__init__()

        # GCNå±¤
        self.conv1 = GCNConv(num_node_features, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.conv3 = GCNConv(hidden_channels, hidden_channels)

        # å…¨çµåˆå±¤
        self.lin1 = torch.nn.Linear(hidden_channels, hidden_channels // 2)
        self.lin2 = torch.nn.Linear(hidden_channels // 2, num_classes)

    def forward(self, x, edge_index, batch):
        """
        Parameters:
        -----------
        x : torch.Tensor (num_nodes, num_node_features)
            ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡
        edge_index : torch.Tensor (2, num_edges)
            ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        batch : torch.Tensor (num_nodes,)
            ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

        Returns:
        --------
        out : torch.Tensor (batch_size, num_classes)
            äºˆæ¸¬å€¤
        """
        # GCNå±¤1ï¼ˆç•³ã¿è¾¼ã¿ + æ´»æ€§åŒ– + ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆï¼‰
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.2, training=self.training)

        # GCNå±¤2
        x = self.conv2(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.2, training=self.training)

        # GCNå±¤3
        x = self.conv3(x, edge_index)
        x = F.relu(x)

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã‚’åˆ†å­ãƒ¬ãƒ™ãƒ«ã«é›†ç´„ï¼‰
        x = global_mean_pool(x, batch)

        # å…¨çµåˆå±¤
        x = self.lin1(x)
        x = F.relu(x)
        x = F.dropout(x, p=0.3, training=self.training)

        x = self.lin2(x)
        return x

<h1>ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–</h1>
model = GCN_QM9(
    num_node_features=dataset.num_node_features,
    num_classes=1,  # HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—ã®ã¿ã‚’äºˆæ¸¬
    hidden_channels=64
)

print("===== GCNãƒ¢ãƒ‡ãƒ« =====")
print(model)
print(f"\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")</code></pre>

<h3>3.3.4 ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´</h3>

<pre><code class="language-python">from torch_geometric.loader import DataLoader
from sklearn.model_selection import train_test_split
import time

<h1>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å°ã•ãã™ã‚‹ï¼ˆé«˜é€ŸåŒ–ã®ãŸã‚ã€å®Ÿéš›ã«ã¯å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰</h1>
dataset = dataset[:10000]

<h1>HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—ï¼ˆindex=4ï¼‰ã®ã¿ã‚’ç›®çš„å¤‰æ•°ã«è¨­å®š</h1>
for data in dataset:
    data.y = data.y[:, 4:5]  # shape: (1, 1)

<h1>ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆ80% train, 10% val, 10% testï¼‰</h1>
train_dataset = dataset[:8000]
val_dataset = dataset[8000:9000]
test_dataset = dataset[9000:]

<h1>DataLoaderã‚’ä½œæˆ</h1>
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

<h1>ãƒ‡ãƒã‚¤ã‚¹è¨­å®šï¼ˆGPUåˆ©ç”¨å¯èƒ½ãªã‚‰GPUã€ãã†ã§ãªã‘ã‚Œã°CPUï¼‰</h1>
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

<h1>æå¤±é–¢æ•°ã¨æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </h1>
criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)

<h1>è¨“ç·´é–¢æ•°</h1>
def train(model, loader, optimizer, criterion, device):
    model.train()
    total_loss = 0

    for data in loader:
        data = data.to(device)
        optimizer.zero_grad()

        # é †ä¼æ’­
        out = model(data.x, data.edge_index, data.batch)
        loss = criterion(out, data.y)

        # é€†ä¼æ’­
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * data.num_graphs

    return total_loss / len(loader.dataset)

<h1>æ¤œè¨¼é–¢æ•°</h1>
def evaluate(model, loader, criterion, device):
    model.eval()
    total_loss = 0

    with torch.no_grad():
        for data in loader:
            data = data.to(device)
            out = model(data.x, data.edge_index, data.batch)
            loss = criterion(out, data.y)
            total_loss += loss.item() * data.num_graphs

    return total_loss / len(loader.dataset)

<h1>è¨“ç·´ãƒ«ãƒ¼ãƒ—</h1>
epochs = 50
train_losses = []
val_losses = []
best_val_loss = float('inf')

print("===== è¨“ç·´é–‹å§‹ =====")
start_time = time.time()

for epoch in range(1, epochs + 1):
    train_loss = train(model, train_loader, optimizer, criterion, device)
    val_loss = evaluate(model, val_loader, criterion, device)

    train_losses.append(train_loss)
    val_losses.append(val_loss)

    # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), 'best_model_qm9.pt')

    if epoch % 10 == 0:
        print(f"Epoch {epoch:03d}, "
              f"Train Loss: {train_loss:.4f}, "
              f"Val Loss: {val_loss:.4f}")

training_time = time.time() - start_time
print(f"\nè¨“ç·´å®Œäº†! æ‰€è¦æ™‚é–“: {training_time:.2f}ç§’")

<h1>æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰</h1>
model.load_state_dict(torch.load('best_model_qm9.pt'))

<h1>ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡</h1>
test_loss = evaluate(model, test_loader, criterion, device)
test_mae = test_loss ** 0.5  # RMSEã‚’MAEã®è¿‘ä¼¼ã¨ã—ã¦ä½¿ç”¨

print(f"\n===== ãƒ†ã‚¹ãƒˆæ€§èƒ½ =====")
print(f"Test Loss (MSE): {test_loss:.4f}")
print(f"Test MAE (approx): {test_mae:.4f} eV")</code></pre>

<h3>3.3.5 å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–</h3>

<pre><code class="language-python">import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(10, 6))
ax.plot(train_losses, label='Train Loss', linewidth=2)
ax.plot(val_losses, label='Validation Loss', linewidth=2)
ax.set_xlabel('Epoch', fontsize=12)
ax.set_ylabel('Loss (MSE)', fontsize=12)
ax.set_title('GCNå­¦ç¿’æ›²ç·šï¼ˆQM9 HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ï¼‰', fontsize=14)
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

<h1>äºˆæ¸¬ vs å®Ÿæ¸¬ã®ãƒ—ãƒ­ãƒƒãƒˆ</h1>
model.eval()
all_preds = []
all_targets = []

with torch.no_grad():
    for data in test_loader:
        data = data.to(device)
        out = model(data.x, data.edge_index, data.batch)
        all_preds.append(out.cpu().numpy())
        all_targets.append(data.y.cpu().numpy())

all_preds = np.concatenate(all_preds)
all_targets = np.concatenate(all_targets)

fig, ax = plt.subplots(figsize=(8, 8))
ax.scatter(all_targets, all_preds, alpha=0.6, s=10)
ax.plot([all_targets.min(), all_targets.max()],
        [all_targets.min(), all_targets.max()],
        'r--', lw=2, label='å®Œå…¨ãªäºˆæ¸¬')
ax.set_xlabel('å®Ÿæ¸¬å€¤ (eV)', fontsize=12)
ax.set_ylabel('äºˆæ¸¬å€¤ (eV)', fontsize=12)
ax.set_title('HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬çµæœ', fontsize=14)
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3)

<h1>RÂ²ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—</h1>
from sklearn.metrics import r2_score
r2 = r2_score(all_targets, all_preds)
mae = np.mean(np.abs(all_targets - all_preds))

ax.text(0.05, 0.95, f'RÂ² = {r2:.3f}\nMAE = {mae:.3f} eV',
        transform=ax.transAxes, fontsize=12, verticalalignment='top',
        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.show()

print(f"===== æœ€çµ‚æ€§èƒ½ =====")
print(f"RÂ² score: {r2:.4f}")
print(f"MAE: {mae:.4f} eV")</code></pre>

---

<h2>3.4 Materials Projectãƒ‡ãƒ¼ã‚¿ã§çµæ™¶ç‰¹æ€§äºˆæ¸¬</h2>

<h3>3.4.1 çµæ™¶æ§‹é€ ã®ã‚°ãƒ©ãƒ•è¡¨ç¾</h3>

çµæ™¶ã¯å‘¨æœŸçš„ãªæ§‹é€ ã‚’æŒã¤ãŸã‚ã€åˆ†å­ã¨ã¯ç•°ãªã‚‹æ‰±ã„ãŒå¿…è¦ã§ã™ã€‚

<pre><code class="language-python">from pymatgen.core import Structure
from pymatgen.ext.matproj import MPRester
import torch
from torch_geometric.data import Data

def structure_to_graph(structure, cutoff=5.0):
    """
    pymatgen Structureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚°ãƒ©ãƒ•ã«å¤‰æ›

    Parameters:
    -----------
    structure : pymatgen.core.Structure
        çµæ™¶æ§‹é€ 
    cutoff : float
        ã‚¨ãƒƒã‚¸ã‚’ä½œæˆã™ã‚‹è·é›¢ã®ã‚«ãƒƒãƒˆã‚ªãƒ•ï¼ˆÃ…ï¼‰

    Returns:
    --------
    data : torch_geometric.data.Data
        ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿
    """
    # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆåŸå­ç•ªå·ï¼‰
    atomic_numbers = [site.specie.Z for site in structure]
    x = torch.tensor(atomic_numbers, dtype=torch.float).view(-1, 1)

    # ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆåŸå­é–“è·é›¢ï¼‰
    edge_indices = []
    edge_attrs = []

    for i, site_i in enumerate(structure):
        for j, site_j in enumerate(structure):
            if i != j:
                distance = structure.get_distance(i, j)
                if distance < cutoff:
                    edge_indices.append([i, j])
                    edge_attrs.append([distance])

    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()
    edge_attr = torch.tensor(edge_attrs, dtype=torch.float)

    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)
    return data

<h1>Materials Projectã‹ã‚‰LiåŒ–åˆç‰©ã‚’å–å¾—ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰</h1>
<h1>æ³¨æ„: å®Ÿéš›ã«ã¯APIã‚­ãƒ¼ãŒå¿…è¦</h1>
<h1>API_KEY = "your_api_key_here"</h1>
<h1>with MPRester(API_KEY) as mpr:</h1>
<h1>    entries = mpr.query(</h1>
<h1>        criteria={"elements": {"$all": ["Li"]}, "nelements": 2},</h1>
<h1>        properties=["structure", "band_gap"]</h1>
<h1>    )</h1>

<h1>ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆLiClçµæ™¶ï¼‰</h1>
from pymatgen.core import Lattice, Structure

<h1>LiCl å²©å¡©å‹æ§‹é€ </h1>
lattice = Lattice.cubic(5.14)  # æ ¼å­å®šæ•°
species = ["Li", "Li", "Li", "Li", "Cl", "Cl", "Cl", "Cl"]
coords = [
    [0, 0, 0], [0.5, 0.5, 0], [0.5, 0, 0.5], [0, 0.5, 0.5],
    [0.5, 0, 0], [0, 0.5, 0], [0, 0, 0.5], [0.5, 0.5, 0.5]
]
structure = Structure(lattice, species, coords)

<h1>ã‚°ãƒ©ãƒ•ã«å¤‰æ›</h1>
data = structure_to_graph(structure, cutoff=4.0)

print("===== LiClçµæ™¶ã®ã‚°ãƒ©ãƒ•è¡¨ç¾ =====")
print(f"ãƒãƒ¼ãƒ‰æ•°ï¼ˆåŸå­æ•°ï¼‰: {data.num_nodes}")
print(f"ã‚¨ãƒƒã‚¸æ•°ï¼ˆè·é›¢ < 4.0Ã…ã®åŸå­ãƒšã‚¢ï¼‰: {data.num_edges}")
print(f"ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡: {data.x}")
print(f"\nã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆè·é›¢ï¼‰ã®çµ±è¨ˆ:")
print(f"  æœ€å°è·é›¢: {data.edge_attr.min().item():.2f} Ã…")
print(f"  æœ€å¤§è·é›¢: {data.edge_attr.max().item():.2f} Ã…")
print(f"  å¹³å‡è·é›¢: {data.edge_attr.mean().item():.2f} Ã…")</code></pre>

<h3>3.4.2 çµæ™¶ç‰¹æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ï¼ˆCrystal Graph Convolutional Networkï¼‰</h3>

<pre><code class="language-python">import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, global_add_pool

class CGCN(torch.nn.Module):
    """
    Crystal Graph Convolutional Network
    çµæ™¶ã®ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã‚’äºˆæ¸¬
    """
    def __init__(self, num_node_features=1, hidden_channels=64):
        super(CGCN, self).__init__()

        # ãƒãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿å±¤
        self.embedding = torch.nn.Linear(num_node_features, hidden_channels)

        # GCNå±¤ï¼ˆã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã‚’è€ƒæ…®ã™ã‚‹å ´åˆã¯SchNetãªã©ã‚’ä½¿ç”¨ï¼‰
        self.conv1 = GCNConv(hidden_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.conv3 = GCNConv(hidden_channels, hidden_channels)

        # å…¨çµåˆå±¤
        self.lin1 = torch.nn.Linear(hidden_channels, hidden_channels // 2)
        self.lin2 = torch.nn.Linear(hidden_channels // 2, 1)

    def forward(self, x, edge_index, edge_attr, batch):
        # ãƒãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿
        x = self.embedding(x)
        x = F.relu(x)

        # GCNå±¤
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.2, training=self.training)

        x = self.conv2(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.2, training=self.training)

        x = self.conv3(x, edge_index)
        x = F.relu(x)

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆçµæ™¶ãƒ¬ãƒ™ãƒ«ã«é›†ç´„ï¼‰
        x = global_add_pool(x, batch)

        # å…¨çµåˆå±¤
        x = self.lin1(x)
        x = F.relu(x)
        x = self.lin2(x)

        return x

<h1>ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–</h1>
model_crystal = CGCN(num_node_features=1, hidden_channels=128)

print("===== Crystal Graph Convolutional Network =====")
print(model_crystal)
print(f"\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model_crystal.parameters()):,}")</code></pre>

<h3>3.4.3 æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ã§ã®è¨“ç·´ãƒ‡ãƒ¢</h3>

<pre><code class="language-python"><h1>æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆå®Ÿéš›ã¯Materials Projectãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰</h1>
crystal_dataset = []

for i in range(200):
    num_atoms = torch.randint(4, 12, (1,)).item()
    x = torch.randint(1, 20, (num_atoms, 1)).float()  # åŸå­ç•ªå·

    # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚¨ãƒƒã‚¸ï¼ˆè·é›¢ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸã¨ä»®å®šï¼‰
    edge_index = torch.randint(0, num_atoms, (2, num_atoms * 4))
    edge_attr = torch.rand(num_atoms * 4, 1) * 5.0  # è·é›¢ (0-5Ã…)

    # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆåŸå­ç•ªå·ã®é–¢æ•°ã¨ã—ã¦æ¨¡æ“¬ï¼‰
    y = (x.mean() / 10.0 + torch.randn(1) * 0.5).clamp(0, 10)

    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)
    crystal_dataset.append(data)

<h1>ãƒ‡ãƒ¼ã‚¿åˆ†å‰²</h1>
train_crystals = crystal_dataset[:160]
test_crystals = crystal_dataset[160:]

train_loader_crystal = DataLoader(train_crystals, batch_size=16, shuffle=True)
test_loader_crystal = DataLoader(test_crystals, batch_size=16, shuffle=False)

<h1>è¨“ç·´ï¼ˆç°¡ç•¥ç‰ˆï¼‰</h1>
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model_crystal = model_crystal.to(device)
optimizer = torch.optim.Adam(model_crystal.parameters(), lr=0.001)
criterion = torch.nn.MSELoss()

print("===== çµæ™¶ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬è¨“ç·´ =====")
for epoch in range(1, 51):
    model_crystal.train()
    total_loss = 0

    for data in train_loader_crystal:
        data = data.to(device)
        optimizer.zero_grad()
        out = model_crystal(data.x, data.edge_index, data.edge_attr, data.batch)
        loss = criterion(out, data.y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * data.num_graphs

    if epoch % 10 == 0:
        train_loss = total_loss / len(train_crystals)
        print(f"Epoch {epoch:03d}, Train Loss: {train_loss:.4f}")

<h1>ãƒ†ã‚¹ãƒˆè©•ä¾¡</h1>
model_crystal.eval()
test_preds = []
test_targets = []

with torch.no_grad():
    for data in test_loader_crystal:
        data = data.to(device)
        out = model_crystal(data.x, data.edge_index, data.edge_attr, data.batch)
        test_preds.append(out.cpu().numpy())
        test_targets.append(data.y.cpu().numpy())

test_preds = np.concatenate(test_preds)
test_targets = np.concatenate(test_targets)

test_mae = np.mean(np.abs(test_targets - test_preds))
test_r2 = r2_score(test_targets, test_preds)

print(f"\n===== ãƒ†ã‚¹ãƒˆæ€§èƒ½ =====")
print(f"MAE: {test_mae:.4f} eV")
print(f"RÂ²: {test_r2:.4f}")</code></pre>

---

<h2>3.5 ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</h2>

<h3>3.5.1 å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°</h3>

<pre><code class="language-python">from torch.optim.lr_scheduler import ReduceLROnPlateau

<h1>å­¦ç¿’ç‡ã‚’å‹•çš„ã«èª¿æ•´</h1>
scheduler = ReduceLROnPlateau(
    optimizer,
    mode='min',
    factor=0.5,     # å­¦ç¿’ç‡ã‚’åŠåˆ†ã«
    patience=10,    # 10ã‚¨ãƒãƒƒã‚¯æ”¹å–„ãªã—ã§èª¿æ•´
    verbose=True
)

<h1>è¨“ç·´ãƒ«ãƒ¼ãƒ—å†…ã§ä½¿ç”¨</h1>
for epoch in range(epochs):
    train_loss = train(model, train_loader, optimizer, criterion, device)
    val_loss = evaluate(model, val_loader, criterion, device)

    # æ¤œè¨¼æå¤±ã«åŸºã¥ã„ã¦å­¦ç¿’ç‡ã‚’èª¿æ•´
    scheduler.step(val_loss)</code></pre>

<h3>3.5.2 Early Stopping</h3>

<pre><code class="language-python">class EarlyStopping:
    """
    Early Stoppingã‚¯ãƒ©ã‚¹
    æ¤œè¨¼æå¤±ãŒæ”¹å–„ã—ãªããªã£ãŸã‚‰è¨“ç·´ã‚’åœæ­¢
    """
    def __init__(self, patience=20, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = None
        self.early_stop = False

    def __call__(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss > self.best_loss - self.min_delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_loss = val_loss
            self.counter = 0

<h1>ä½¿ç”¨ä¾‹</h1>
early_stopping = EarlyStopping(patience=20)

for epoch in range(epochs):
    train_loss = train(model, train_loader, optimizer, criterion, device)
    val_loss = evaluate(model, val_loader, criterion, device)

    early_stopping(val_loss)
    if early_stopping.early_stop:
        print(f"Early stopping at epoch {epoch}")
        break</code></pre>

<h3>3.5.3 ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆã‚°ãƒ©ãƒ•ã®æ‘‚å‹•ï¼‰</h3>

<pre><code class="language-python">import torch
from torch_geometric.utils import dropout_edge

def augment_graph(data, drop_edge_prob=0.1, noise_scale=0.01):
    """
    ã‚°ãƒ©ãƒ•ã®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ

    Parameters:
    -----------
    data : Data
        å…ƒã®ã‚°ãƒ©ãƒ•
    drop_edge_prob : float
        ã‚¨ãƒƒã‚¸ã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã™ã‚‹ç¢ºç‡
    noise_scale : float
        ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã«åŠ ãˆã‚‹ãƒã‚¤ã‚ºã®ã‚¹ã‚±ãƒ¼ãƒ«

    Returns:
    --------
    augmented_data : Data
        æ‹¡å¼µã•ã‚ŒãŸã‚°ãƒ©ãƒ•
    """
    # ã‚¨ãƒƒã‚¸ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ
    edge_index, edge_mask = dropout_edge(data.edge_index, p=drop_edge_prob)

    # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã«ãƒã‚¤ã‚ºã‚’è¿½åŠ 
    noise = torch.randn_like(data.x) * noise_scale
    x = data.x + noise

    augmented_data = Data(x=x, edge_index=edge_index, y=data.y)
    return augmented_data

<h1>ä½¿ç”¨ä¾‹</h1>
original = dataset[0]
augmented = augment_graph(original, drop_edge_prob=0.15)

print(f"å…ƒã®ã‚¨ãƒƒã‚¸æ•°: {original.num_edges}")
print(f"æ‹¡å¼µå¾Œã®ã‚¨ãƒƒã‚¸æ•°: {augmented.num_edges}")</code></pre>

---

<h2>3.6 ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®è©•ä¾¡ã¨å¯è¦–åŒ–</h2>

<h3>3.6.1 è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—</h3>

<pre><code class="language-python">from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

def evaluate_regression(y_true, y_pred):
    """
    å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
    """
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)

    # Mean Absolute Percentage Error
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

    return {
        'MAE': mae,
        'MSE': mse,
        'RMSE': rmse,
        'RÂ²': r2,
        'MAPE': mape
    }

<h1>ä½¿ç”¨ä¾‹</h1>
metrics = evaluate_regression(test_targets, test_preds)

print("===== è©•ä¾¡æŒ‡æ¨™ =====")
for name, value in metrics.items():
    print(f"{name}: {value:.4f}")</code></pre>

<h3>3.6.2 æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ</h3>

<pre><code class="language-python">import matplotlib.pyplot as plt

def plot_residuals(y_true, y_pred):
    """
    æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
    """
    residuals = y_true - y_pred

    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # æ®‹å·® vs äºˆæ¸¬å€¤
    axes[0].scatter(y_pred, residuals, alpha=0.6, s=20)
    axes[0].axhline(y=0, color='r', linestyle='--', lw=2)
    axes[0].set_xlabel('äºˆæ¸¬å€¤', fontsize=12)
    axes[0].set_ylabel('æ®‹å·®ï¼ˆå®Ÿæ¸¬ - äºˆæ¸¬ï¼‰', fontsize=12)
    axes[0].set_title('æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ', fontsize=14)
    axes[0].grid(True, alpha=0.3)

    # æ®‹å·®ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    axes[1].hist(residuals, bins=30, alpha=0.7, edgecolor='black')
    axes[1].set_xlabel('æ®‹å·®', fontsize=12)
    axes[1].set_ylabel('é »åº¦', fontsize=12)
    axes[1].set_title('æ®‹å·®åˆ†å¸ƒ', fontsize=14)
    axes[1].axvline(x=0, color='r', linestyle='--', lw=2)
    axes[1].grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    plt.show()

<h1>ä½¿ç”¨ä¾‹</h1>
plot_residuals(test_targets, test_preds)</code></pre>

<h3>3.6.3 ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ</h3>

<pre><code class="language-python">import pandas as pd
import matplotlib.pyplot as plt

<h1>è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ¯”è¼ƒ</h1>
models_performance = {
    'GCN (3å±¤)': {'MAE': 0.32, 'RÂ²': 0.88, 'Time': 45.2},
    'GAT (2å±¤)': {'MAE': 0.28, 'RÂ²': 0.91, 'Time': 62.8},
    'SchNet': {'MAE': 0.25, 'RÂ²': 0.93, 'Time': 89.5},
    'MPNN': {'MAE': 0.30, 'RÂ²': 0.90, 'Time': 55.1},
}

df = pd.DataFrame(models_performance).T

<h1>ãƒ—ãƒ­ãƒƒãƒˆ</h1>
fig, axes = plt.subplots(1, 3, figsize=(16, 4))

<h1>MAEæ¯”è¼ƒ</h1>
df['MAE'].plot(kind='bar', ax=axes[0], color='steelblue')
axes[0].set_ylabel('MAE (eV)', fontsize=12)
axes[0].set_title('å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆä½ã„ã»ã©è‰¯ã„ï¼‰', fontsize=13)
axes[0].tick_params(axis='x', rotation=45)
axes[0].grid(True, alpha=0.3, axis='y')

<h1>RÂ²æ¯”è¼ƒ</h1>
df['RÂ²'].plot(kind='bar', ax=axes[1], color='forestgreen')
axes[1].set_ylabel('RÂ² Score', fontsize=12)
axes[1].set_title('æ±ºå®šä¿‚æ•°ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰', fontsize=13)
axes[1].tick_params(axis='x', rotation=45)
axes[1].grid(True, alpha=0.3, axis='y')
axes[1].set_ylim(0.8, 1.0)

<h1>è¨“ç·´æ™‚é–“æ¯”è¼ƒ</h1>
df['Time'].plot(kind='bar', ax=axes[2], color='coral')
axes[2].set_ylabel('è¨“ç·´æ™‚é–“ (ç§’)', fontsize=12)
axes[2].set_title('è¨ˆç®—ã‚³ã‚¹ãƒˆ', fontsize=13)
axes[2].tick_params(axis='x', rotation=45)
axes[2].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()</code></pre>

---

<h2>3.7 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°</h2>

<h3>3.7.1 ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨è§£æ±ºç­–</h3>

| ã‚¨ãƒ©ãƒ¼ | åŸå›  | è§£æ±ºæ–¹æ³• |
|--------|------|----------|
| <code>RuntimeError: CUDA out of memory</code> | GPU ãƒ¡ãƒ¢ãƒªä¸è¶³ | ãƒãƒƒãƒã‚µã‚¤ã‚ºå‰Šæ¸›ã€ãƒ¢ãƒ‡ãƒ«ã®å°å‹åŒ–ã€CPUä½¿ç”¨ |
| <code>AssertionError: edge_index not contiguous</code> | ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ¡ãƒ¢ãƒªé…ç½® | <code>edge_index = edge_index.t().contiguous()</code> |
| <code>ValueError: too many values to unpack</code> | Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å±æ€§ä¸è¶³ | <code>x</code>, <code>edge_index</code>, <code>batch</code>ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª |
| <code>RuntimeError: Expected all tensors on same device</code> | ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒ‡ãƒã‚¤ã‚¹ä¸ä¸€è‡´ | <code>data = data.to(device)</code>ã‚’ç¢ºèª |

<h3>3.7.2 ãƒ‡ãƒãƒƒã‚°ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ</h3>

<pre><code class="language-python"><h1>ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª</h1>
print(f"ãƒãƒ¼ãƒ‰æ•°: {data.num_nodes}")
print(f"ã‚¨ãƒƒã‚¸æ•°: {data.num_edges}")
print(f"å­¤ç«‹ãƒãƒ¼ãƒ‰: {data.contains_isolated_nodes()}")
print(f"è‡ªå·±ãƒ«ãƒ¼ãƒ—: {data.contains_self_loops()}")

<h1>ãƒ†ãƒ³ã‚½ãƒ«ã®å½¢çŠ¶ç¢ºèª</h1>
print(f"x.shape: {data.x.shape}")
print(f"edge_index.shape: {data.edge_index.shape}")
print(f"y.shape: {data.y.shape}")

<h1>ãƒ‡ãƒã‚¤ã‚¹ã®ç¢ºèª</h1>
print(f"x device: {data.x.device}")
print(f"edge_index device: {data.edge_index.device}")

<h1>ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç¯„å›²ç¢ºèª</h1>
print(f"max edge index: {data.edge_index.max().item()}")
print(f"num_nodes: {data.num_nodes}")
assert data.edge_index.max().item() < data.num_nodes, "ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒãƒãƒ¼ãƒ‰æ•°ã‚’è¶…ãˆã¦ã„ã¾ã™"</code></pre>

---

<h2>3.8 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

1. <strong>PyTorch Geometricç’°å¢ƒæ§‹ç¯‰</strong>
   - Condaã€pipã€Google Colabã®3ã¤ã®æ–¹æ³•
   - ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§ã®ç¢ºèªã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

2. <strong>ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç†è§£</strong>
   - Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹é€ ï¼ˆx, edge_index, batchï¼‰
   - RDKitã‹ã‚‰ã®ã‚°ãƒ©ãƒ•å¤‰æ›
   - DataLoaderã«ã‚ˆã‚‹ãƒãƒƒãƒå‡¦ç†

3. <strong>QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å®Ÿè·µ</strong>
   - 134,000åˆ†å­ã®é‡å­åŒ–å­¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
   - GCNãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…ã¨è¨“ç·´
   - HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ï¼ˆMAE < 0.5 eVç›®æ¨™ï¼‰

4. <strong>çµæ™¶ç‰¹æ€§äºˆæ¸¬</strong>
   - Materials Projectçµæ™¶ãƒ‡ãƒ¼ã‚¿ã®ã‚°ãƒ©ãƒ•è¡¨ç¾
   - Crystal Graph Convolutional Network
   - ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬

5. <strong>è¨“ç·´ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹</strong>
   - å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°
   - Early Stopping
   - ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆã‚°ãƒ©ãƒ•ã®æ‘‚å‹•ï¼‰

6. <strong>è©•ä¾¡ã¨å¯è¦–åŒ–</strong>
   - MAEã€MSEã€RÂ²ãªã©ã®æŒ‡æ¨™
   - æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
   - ãƒ¢ãƒ‡ãƒ«é–“ã®æ€§èƒ½æ¯”è¼ƒ

<h3>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</h3>

- âœ… PyTorch Geometricã¯ææ–™ãƒ»åˆ†å­ã®GNNå®Ÿè£…ã«æœ€é©
- âœ… QM9ã¯åˆå­¦è€…ã«æœ€é©ãªåˆ†å­ç‰¹æ€§äºˆæ¸¬ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- âœ… ã‚°ãƒ©ãƒ•ã®å‰å‡¦ç†ï¼ˆå­¤ç«‹ãƒãƒ¼ãƒ‰ã€è‡ªå·±ãƒ«ãƒ¼ãƒ—ã®ç¢ºèªï¼‰ãŒé‡è¦
- âœ… ãƒãƒƒãƒå‡¦ç†ã§ã¯<code>batch</code>ãƒ†ãƒ³ã‚½ãƒ«ãŒå„ãƒãƒ¼ãƒ‰ã®æ‰€å±ã‚’ç¤ºã™
- âœ… å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã¨Early Stoppingã§éå­¦ç¿’ã‚’é˜²æ­¢

<h3>æ¬¡ã®ç« ã¸</h3>

ç¬¬4ç« ã§ã¯ã€é«˜åº¦ãªGNNæŠ€è¡“ã‚’å­¦ã³ã¾ã™ï¼š
- ã‚°ãƒ©ãƒ•ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆéšå±¤çš„è¡¨ç¾ï¼‰
- ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã®æ´»ç”¨
- 3Då¹¾ä½•æƒ…å ±ã®çµ„è¾¼ã¿ï¼ˆSchNetã€DimeNetï¼‰
- ç­‰å¤‰GNNï¼ˆE(3)-equivariantï¼‰
- GNNExplainerã«ã‚ˆã‚‹è§£é‡ˆå¯èƒ½æ€§

<strong>[ç¬¬4ç« ï¼šé«˜åº¦ãªGNNæŠ€è¡“ â†’](./chapter-4.md)</strong>

---

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>

PyTorch Geometricã®Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å«ã¾ã‚Œã‚‹ä¸»è¦ãªå±æ€§ã‚’3ã¤æŒ™ã’ã€ãã‚Œãã‚Œã®å½¹å‰²ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

ãƒãƒ¼ãƒ‰ã€ã‚¨ãƒƒã‚¸ã€ãƒãƒƒãƒã«é–¢ã™ã‚‹æƒ…å ±ã‚’æ ¼ç´ã™ã‚‹å±æ€§ã‚’è€ƒãˆã¾ã—ã‚‡ã†ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

<strong>ä¸»è¦ãª3ã¤ã®å±æ€§</strong>:

1. <strong><code>x</code> (ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡)</strong>
   - å½¢çŠ¶: <code>(num_nodes, num_node_features)</code>
   - å½¹å‰²: å„ãƒãƒ¼ãƒ‰ï¼ˆåŸå­ï¼‰ã®ç‰¹å¾´é‡ã‚’æ ¼ç´
   - ä¾‹: åŸå­ç•ªå·ã€é›»æ°—é™°æ€§åº¦ã€å½¢å¼é›»è·ãªã©

2. <strong><code>edge_index</code> (ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)</strong>
   - å½¢çŠ¶: <code>(2, num_edges)</code>
   - å½¹å‰²: ã‚°ãƒ©ãƒ•ã®æ¥ç¶šé–¢ä¿‚ï¼ˆéš£æ¥ãƒªã‚¹ãƒˆå½¢å¼ï¼‰
   - ä¾‹: <code>[[0, 1], [1, 2]]</code> â†’ ãƒãƒ¼ãƒ‰0ã¨ãƒãƒ¼ãƒ‰1ãŒæ¥ç¶š

3. <strong><code>batch</code> (ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)</strong>
   - å½¢çŠ¶: <code>(num_nodes,)</code>
   - å½¹å‰²: å„ãƒãƒ¼ãƒ‰ãŒã©ã®ã‚°ãƒ©ãƒ•ã«å±ã™ã‚‹ã‹ã‚’ç¤ºã™
   - ä¾‹: <code>[0, 0, 1, 1, 2]</code> â†’ ãƒãƒ¼ãƒ‰0,1ã¯ã‚°ãƒ©ãƒ•0ã€ãƒãƒ¼ãƒ‰2,3ã¯ã‚°ãƒ©ãƒ•1

<strong>è¿½åŠ ã®é‡è¦ãªå±æ€§</strong>:
- <code>edge_attr</code>: ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆçµåˆã‚¿ã‚¤ãƒ—ã€è·é›¢ãªã©ï¼‰
- <code>y</code>: ç›®çš„å¤‰æ•°ï¼ˆåˆ†å­ç‰¹æ€§ã€çµæ™¶ç‰¹æ€§ï¼‰

</details>

---

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>

QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã—ãŸGCNãƒ¢ãƒ‡ãƒ«ã®MAEãŒ0.8 eVã§ã—ãŸã€‚æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®3ã¤ã®å…·ä½“çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®3ã¤ã®è¦³ç‚¹ã‹ã‚‰è€ƒãˆã¾ã—ã‚‡ã†ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

<strong>ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1: ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ”¹å–„</strong>

<pre><code class="language-python"><h1>GATãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½¿ç”¨ï¼ˆæ³¨æ„æ©Ÿæ§‹ã§é‡è¦ãªçµåˆã‚’å­¦ç¿’ï¼‰</h1>
from torch_geometric.nn import GATConv

class ImprovedGNN(torch.nn.Module):
    def __init__(self, num_node_features, hidden_channels=128):
        super().__init__()
        # GATãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼ˆãƒ˜ãƒƒãƒ‰æ•°=8ï¼‰
        self.conv1 = GATConv(num_node_features, hidden_channels, heads=8)
        self.conv2 = GATConv(hidden_channels * 8, hidden_channels, heads=8)
        self.conv3 = GATConv(hidden_channels * 8, hidden_channels, heads=1)
        # å±¤ã‚’å¢—ã‚„ã™ï¼ˆ3å±¤ â†’ 4å±¤ï¼‰
        self.conv4 = GCNConv(hidden_channels, hidden_channels)</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„</strong>: MAE 0.8 eV â†’ 0.5-0.6 eV

---

<strong>ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ2: ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã®æ´»ç”¨</strong>

<pre><code class="language-python"><h1>ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆçµåˆã‚¿ã‚¤ãƒ—ï¼‰ã‚’çµ„ã¿è¾¼ã‚€</h1>
from torch_geometric.nn import NNConv

class EdgeFeaturesGNN(torch.nn.Module):
    def __init__(self, num_node_features, num_edge_features, hidden_channels=64):
        super().__init__()
        # NNConv: ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã‚’è€ƒæ…®
        nn = torch.nn.Sequential(
            torch.nn.Linear(num_edge_features, hidden_channels * hidden_channels),
            torch.nn.ReLU()
        )
        self.conv1 = NNConv(num_node_features, hidden_channels, nn, aggr='mean')</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„</strong>: MAE 0.8 eV â†’ 0.6-0.7 eV

---

<strong>ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ3: ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ã¨æ‹¡å¼µ</strong>

<pre><code class="language-python"><h1>ç›®çš„å¤‰æ•°ã‚’æ¨™æº–åŒ–</h1>
y_mean = train_dataset.data.y.mean(dim=0)
y_std = train_dataset.data.y.std(dim=0)

for data in train_dataset:
    data.y = (data.y - y_mean) / y_std

<h1>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆã‚°ãƒ©ãƒ•ã®æ‘‚å‹•ï¼‰</h1>
def augment_graph(data):
    # ã‚¨ãƒƒã‚¸ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ
    edge_index, _ = dropout_edge(data.edge_index, p=0.1)
    # ãƒã‚¤ã‚ºè¿½åŠ 
    x = data.x + torch.randn_like(data.x) * 0.01
    return Data(x=x, edge_index=edge_index, y=data.y)

<h1>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’2å€ã«</h1>
augmented_train = [augment_graph(data) for data in train_dataset]
train_dataset = train_dataset + augmented_train</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„</strong>: MAE 0.8 eV â†’ 0.7 eV

---

<strong>æœ€é©ãªæˆ¦ç•¥</strong>: ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1ï¼ˆãƒ¢ãƒ‡ãƒ«æ”¹å–„ï¼‰ã¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ2ï¼ˆã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼‰ã‚’çµ„ã¿åˆã‚ã›ã€MAE 0.4-0.5 eVã‚’ç›®æŒ‡ã™ã€‚

</details>

---

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚åŸå› ã‚’ç‰¹å®šã—ã€ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

<pre><code class="language-python"><h1>ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã‚³ãƒ¼ãƒ‰</h1>
model = GCN_QM9(num_node_features=11, num_classes=1)
device = torch.device('cuda')
model = model.to(device)

for data in train_loader:
    optimizer.zero_grad()
    out = model(data.x, data.edge_index, data.batch)
    loss = criterion(out, data.y)
    loss.backward()
    optimizer.step()</code></pre>

<strong>ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸</strong>:
<pre><code>RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!</code></pre>

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒã‚¤ã‚¹ãŒä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

<strong>åŸå› </strong>:
ãƒ¢ãƒ‡ãƒ«ã¯<code>cuda</code>ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•ã•ã‚Œã¦ã„ã¾ã™ãŒã€<code>data</code>ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯<code>cpu</code>ã®ã¾ã¾ã§ã™ã€‚PyTorchã§ã¯ã€ã™ã¹ã¦ã®ãƒ†ãƒ³ã‚½ãƒ«ãŒåŒã˜ãƒ‡ãƒã‚¤ã‚¹ä¸Šã«ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

<strong>ä¿®æ­£ã‚³ãƒ¼ãƒ‰</strong>:

<pre><code class="language-python">model = GCN_QM9(num_node_features=11, num_classes=1)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

for data in train_loader:
    # ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«ç§»å‹•ï¼ˆé‡è¦ï¼ï¼‰
    data = data.to(device)

    optimizer.zero_grad()
    out = model(data.x, data.edge_index, data.batch)
    loss = criterion(out, data.y)
    loss.backward()
    optimizer.step()</code></pre>

<strong>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</strong>:
1. <code>data = data.to(device)</code>ã§ã€<code>data</code>å†…ã®ã™ã¹ã¦ã®ãƒ†ãƒ³ã‚½ãƒ«ï¼ˆ<code>x</code>, <code>edge_index</code>, <code>batch</code>, <code>y</code>ï¼‰ã‚’ä¸€åº¦ã«GPUã«ç§»å‹•
2. <code>torch.cuda.is_available()</code>ã§GPUãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèªï¼ˆCPUã®ã¿ã®ç’°å¢ƒã§ã‚‚ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ï¼‰
3. è¨“ç·´ãƒ«ãƒ¼ãƒ—ã®<strong>æœ€åˆ</strong>ã§ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•

<strong>ãƒ‡ãƒãƒƒã‚°ã®ãƒã‚§ãƒƒã‚¯</strong>:
<pre><code class="language-python"><h1>ãƒ‡ãƒã‚¤ã‚¹ã®ç¢ºèª</h1>
print(f"Model device: {next(model.parameters()).device}")
print(f"Data x device: {data.x.device}")
print(f"Data edge_index device: {data.edge_index.device}")</code></pre>

</details>

---

<h2>å‚è€ƒæ–‡çŒ®</h2>

1. Fey, M., & Lenssen, J. E. (2019). "Fast Graph Representation Learning with PyTorch Geometric." *ICLR Workshop on Representation Learning on Graphs and Manifolds*.
   GitHub: https://github.com/pyg-team/pytorch_geometric
   *PyTorch Geometricå…¬å¼è«–æ–‡ã€‚ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è¨­è¨ˆæ€æƒ³ã¨å®Ÿè£…ã®è©³ç´°ã€‚*

2. Ramakrishnan, R., et al. (2014). "Quantum chemistry structures and properties of 134 kilo molecules." *Scientific Data*, 1, 140022.
   DOI: [10.1038/sdata.2014.22](https://doi.org/10.1038/sdata.2014.22)
   *QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¬å¼è«–æ–‡ã€‚134,000åˆ†å­ã®é‡å­åŒ–å­¦è¨ˆç®—ãƒ‡ãƒ¼ã‚¿ã€‚*

3. Xie, T., & Grossman, J. C. (2018). "Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties." *Physical Review Letters*, 120(14), 145301.
   DOI: [10.1103/PhysRevLett.120.145301](https://doi.org/10.1103/PhysRevLett.120.145301)
   *Crystal Graph Convolutional Networksï¼ˆCGCNï¼‰ã®åŸè«–æ–‡ã€‚çµæ™¶ç‰¹æ€§äºˆæ¸¬ã¸ã®å¿œç”¨ã€‚*

4. Gilmer, J., et al. (2017). "Neural Message Passing for Quantum Chemistry." *ICML 2017*.
   URL: https://arxiv.org/abs/1704.01212
   *Message Passing Neural Networksï¼ˆMPNNï¼‰ã®ç†è«–ã€‚QM9ã§ã®é«˜ç²¾åº¦äºˆæ¸¬ã‚’é”æˆã€‚*

5. PyTorch Geometric Documentation. (2024). "Introduction by Example."
   URL: https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html
   *PyTorch Geometricå…¬å¼ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã€‚åŸºæœ¬çš„ãªä½¿ã„æ–¹ã‚’ä¾‹ç¤ºã€‚*

6. RDKit Documentation. (2024). "Getting Started with the RDKit in Python."
   URL: https://www.rdkit.org/docs/GettingStartedInPython.html
   *RDKitã®å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€‚SMILESã‹ã‚‰åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã™ã‚‹æ–¹æ³•ã€‚*

---

<strong>ä½œæˆæ—¥</strong>: 2025-10-17
<strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0
<strong>ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ</strong>: chapter-template-v2.0
<strong>è‘—è€…</strong>: GNNå…¥é–€ã‚·ãƒªãƒ¼ã‚ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
<div class="navigation">
    <a href="chapter-2.html" class="nav-button">â† ç¬¬2ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
    <a href="chapter-4.html" class="nav-button">ç¬¬4ç«  â†’</a>
</div>
    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-17</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default'
                });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</body>
</html>
