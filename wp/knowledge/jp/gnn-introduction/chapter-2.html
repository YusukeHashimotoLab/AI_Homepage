<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Á¨¨2Á´†ÔºöGNN„ÅÆÂü∫Á§éÁêÜË´ñ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Á¨¨2Á´†ÔºöGNN„ÅÆÂü∫Á§éÁêÜË´ñ</h1>
            <p class="subtitle">„É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„Åã„ÇâÊùêÊñôÁßëÂ≠¶ÁâπÂåñGNN„Åæ„Åß</p>
            <div class="meta">
                <span class="meta-item">üìñ Ë™≠‰∫ÜÊôÇÈñì: 25-30ÂàÜ</span>
                <span class="meta-item">üìä Èõ£ÊòìÂ∫¶: ‰∏≠Á¥ö</span>
                <span class="meta-item">üíª „Ç≥„Éº„Éâ‰æã: 10ÂÄã</span>
                <span class="meta-item">üìù ÊºîÁøíÂïèÈ°å: 3Âïè</span>
            </div>
        </div>
    </header>

    <main class="container">

<h1>Á¨¨2Á´†ÔºöGNN„ÅÆÂü∫Á§éÁêÜË´ñ</h1>

<strong>„É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„Åã„ÇâÊùêÊñôÁßëÂ≠¶ÁâπÂåñGNN„Åæ„Åß</strong>

<h2>Â≠¶ÁøíÁõÆÊ®ô</h2>

„Åì„ÅÆÁ´†„ÇíË™≠„ÇÄ„Åì„Å®„Åß„ÄÅ‰ª•‰∏ã„ÇíÁøíÂæó„Åß„Åç„Åæ„ÅôÔºö

- ‚úÖ „Ç∞„É©„Éï„ÅÆÊï∞Â≠¶ÁöÑÂÆöÁæ©„Å®Ë°®ÁèæÊñπÊ≥ï„ÇíÁêÜËß£„Åô„Çã
- ‚úÖ „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅÆ3„Çπ„ÉÜ„ÉÉ„ÉóÔºàÈõÜÁ¥Ñ‚ÜíÊõ¥Êñ∞‚ÜíÂá∫ÂäõÔºâ„ÇíË™¨Êòé„Åß„Åç„Çã
- ‚úÖ GCN„ÄÅGAT„ÄÅGraphSAGE„ÅÆÂéüÁêÜ„Å®ÈÅï„ÅÑ„ÇíÁêÜËß£„Åô„Çã
- ‚úÖ ÊùêÊñôÁßëÂ≠¶ÁâπÂåñGNNÔºàSchNet„ÄÅDimeNetÔºâ„ÅÆÁâπÂæ¥„ÇíÁü•„Çã
- ‚úÖ „Ç∑„É≥„Éó„É´„Å™GNN„ÇíPyTorch„ÅßÂÆüË£Ö„Åß„Åç„Çã
- ‚úÖ Á≠âÂ§âGNN„ÅÆÈáçË¶ÅÊÄß„ÇíÁêÜËß£„Åô„Çã

<strong>Ë™≠‰∫ÜÊôÇÈñì</strong>: 25-30ÂàÜ
<strong>„Ç≥„Éº„Éâ‰æã</strong>: 10ÂÄã
<strong>ÊºîÁøíÂïèÈ°å</strong>: 3Âïè

---

<h2>2.1 „Ç∞„É©„Éï„ÅÆÊï∞Â≠¶ÁöÑÂÆöÁæ©</h2>

<h3>„Ç∞„É©„Éï„ÅÆÂü∫Êú¨Ë¶ÅÁ¥†</h3>

<strong>ÂÆöÁæ©</strong>:
> „Ç∞„É©„Éï $G = (V, E)$ „ÅØ„ÄÅÈ†ÇÁÇπÈõÜÂêà $V$ „Å®Ëæ∫ÈõÜÂêà $E \subseteq V \times V$ „Åã„Çâ„Å™„Çã„ÄÇ

<strong>Ë®òÊ≥ï</strong>:
- $n = |V|$: È†ÇÁÇπÊï∞
- $m = |E|$: Ëæ∫Êï∞
- $\mathcal{N}(v)$: È†ÇÁÇπ $v$ „ÅÆÈö£Êé•È†ÇÁÇπÈõÜÂêà

---

<h3>Èö£Êé•Ë°åÂàóÔºàAdjacency MatrixÔºâ</h3>

<strong>ÂÆöÁæ©</strong>:
$$
A \in \{0, 1\}^{n \times n}, \quad A_{ij} = \begin{cases}
1 & \text{if } (v_i, v_j) \in E \\
0 & \text{otherwise}
\end{cases}
$$

<strong>Python„Åß„ÅÆÂÆüË£Ö</strong>:
<pre><code class="language-python">import numpy as np

<h1>‰æãÔºö‰∏âËßíÂΩ¢„Ç∞„É©„ÉïÔºà3È†ÇÁÇπ„ÄÅ3Ëæ∫Ôºâ</h1>
n = 3
A = np.array([
    [0, 1, 1],  # È†ÇÁÇπ0: 1, 2„Å´Êé•Á∂ö
    [1, 0, 1],  # È†ÇÁÇπ1: 0, 2„Å´Êé•Á∂ö
    [1, 1, 0]   # È†ÇÁÇπ2: 0, 1„Å´Êé•Á∂ö
])

print("Èö£Êé•Ë°åÂàó:")
print(A)
print(f"\nÈ†ÇÁÇπÊï∞: {n}")
print(f"Ëæ∫Êï∞: {A.sum() // 2}")  # ÁÑ°Âêë„Ç∞„É©„Éï„ÅØ2„ÅßÂâ≤„Çã</code></pre>

<strong>Âá∫Âäõ</strong>:
<pre><code>Èö£Êé•Ë°åÂàó:
[[0 1 1]
 [1 0 1]
 [1 1 0]]

È†ÇÁÇπÊï∞: 3
Ëæ∫Êï∞: 3</code></pre>

---

<h3>Ê¨°Êï∞Ë°åÂàóÔºàDegree MatrixÔºâ</h3>

<strong>ÂÆöÁæ©</strong>:
$$
D \in \mathbb{R}^{n \times n}, \quad D_{ii} = \sum_{j=1}^{n} A_{ij}
$$

<strong>Áâ©ÁêÜÁöÑÊÑèÂë≥</strong>: ÂêÑÈ†ÇÁÇπ„ÅÆÊé•Á∂öÊï∞ÔºàÂåñÂ≠¶„Åß„ÅØÁµêÂêàÊï∞Ôºâ

<pre><code class="language-python"><h1>Ê¨°Êï∞Ë°åÂàó</h1>
D = np.diag(A.sum(axis=1))
print("Ê¨°Êï∞Ë°åÂàó:")
print(D)
print(f"\nÂêÑÈ†ÇÁÇπ„ÅÆÊ¨°Êï∞: {np.diag(D)}")</code></pre>

<strong>Âá∫Âäõ</strong>:
<pre><code>Ê¨°Êï∞Ë°åÂàó:
[[2 0 0]
 [0 2 0]
 [0 0 2]]

ÂêÑÈ†ÇÁÇπ„ÅÆÊ¨°Êï∞: [2 2 2]</code></pre>

---

<h3>„É©„Éó„É©„Ç∑„Ç¢„É≥Ë°åÂàóÔºàLaplacian MatrixÔºâ</h3>

<strong>ÂÆöÁæ©</strong>:
$$
L = D - A
$$

<strong>Ê≠£Ë¶èÂåñ„É©„Éó„É©„Ç∑„Ç¢„É≥</strong>ÔºàGNN„Åß„Çà„Åè‰ΩøÁî®Ôºâ:
$$
\tilde{L} = D^{-1/2} L D^{-1/2} = I - D^{-1/2} A D^{-1/2}
$$

<pre><code class="language-python"><h1>„É©„Éó„É©„Ç∑„Ç¢„É≥Ë°åÂàó</h1>
L = D - A
print("„É©„Éó„É©„Ç∑„Ç¢„É≥Ë°åÂàó:")
print(L)

<h1>Ê≠£Ë¶èÂåñ„É©„Éó„É©„Ç∑„Ç¢„É≥</h1>
D_inv_sqrt = np.diag(1 / np.sqrt(np.diag(D)))
L_norm = np.eye(n) - D_inv_sqrt @ A @ D_inv_sqrt
print("\nÊ≠£Ë¶èÂåñ„É©„Éó„É©„Ç∑„Ç¢„É≥:")
print(L_norm)</code></pre>

<strong>Âá∫Âäõ</strong>:
<pre><code>„É©„Éó„É©„Ç∑„Ç¢„É≥Ë°åÂàó:
[[ 2 -1 -1]
 [-1  2 -1]
 [-1 -1  2]]

Ê≠£Ë¶èÂåñ„É©„Éó„É©„Ç∑„Ç¢„É≥:
[[ 1.  -0.5 -0.5]
 [-0.5  1.  -0.5]
 [-0.5 -0.5  1. ]]</code></pre>

<strong>Áî®ÈÄî</strong>:
- „Çπ„Éö„ÇØ„Éà„É´„Ç∞„É©„ÉïÁêÜË´ñ
- „Ç∞„É©„Éï„Éï„Éº„É™„Ç®Â§âÊèõ
- „Ç∞„É©„Éï‰ø°Âè∑Âá¶ÁêÜ

---

<h3>È†ÇÁÇπÁâπÂæ¥Èáè„Å®Ëæ∫ÁâπÂæ¥Èáè</h3>

<strong>È†ÇÁÇπÁâπÂæ¥Ë°åÂàó</strong> $X \in \mathbb{R}^{n \times d}$:
- ÂêÑË°å $x_i \in \mathbb{R}^d$: È†ÇÁÇπ $i$ „ÅÆÁâπÂæ¥„Éô„ÇØ„Éà„É´
- ÊùêÊñôÁßëÂ≠¶: ÂéüÂ≠êÁï™Âè∑„ÄÅÈõªÊ∞óÈô∞ÊÄßÂ∫¶„ÄÅ‰æ°ÈõªÂ≠êÊï∞„Å™„Å©

<strong>Ëæ∫ÁâπÂæ¥Ë°åÂàó</strong> $E \in \mathbb{R}^{m \times d_e}$:
- ÂêÑË°å $e_{ij} \in \mathbb{R}^{d_e}$: Ëæ∫ $(i, j)$ „ÅÆÁâπÂæ¥
- ÊùêÊñôÁßëÂ≠¶: ÁµêÂêàÈï∑„ÄÅÁµêÂêàÊ¨°Êï∞„ÄÅÁµêÂêàËßí„Å™„Å©

<pre><code class="language-python"><h1>‰æãÔºöÊ∞¥ÂàÜÂ≠êÔºàH‚ÇÇOÔºâ„ÅÆÁâπÂæ¥Èáè</h1>
X = np.array([
    [8, 2.55, 6],   # O: ÂéüÂ≠êÁï™Âè∑8, ÈõªÊ∞óÈô∞ÊÄßÂ∫¶2.55, ‰æ°ÈõªÂ≠ê6
    [1, 2.20, 1],   # H1
    [1, 2.20, 1]    # H2
])

print("È†ÇÁÇπÁâπÂæ¥Ë°åÂàó (3√ó3):")
print(X)
print(f"ÂΩ¢Áä∂: {X.shape}")</code></pre>

---

<h2>2.2 „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅÆ‰ªïÁµÑ„Åø</h2>

<h3>Message Passing Neural Network (MPNN)</h3>

GNN„ÅÆ<strong>Áµ±‰∏Ä„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ</strong>„Åß„ÅôÔºàGilmer et al., 2017Ôºâ„ÄÇ

<strong>„Ç¢„É´„Ç¥„É™„Ç∫„É†</strong>:

<div class="mermaid">graph LR
    A[ÂÖ•Âäõ: È†ÇÁÇπÁâπÂæ¥ X] --> B[„Çπ„ÉÜ„ÉÉ„Éó1: „É°„ÉÉ„Çª„Éº„Ç∏ÁîüÊàê]
    B --> C[„Çπ„ÉÜ„ÉÉ„Éó2: ÈõÜÁ¥Ñ Aggregation]
    C --> D[„Çπ„ÉÜ„ÉÉ„Éó3: Êõ¥Êñ∞ Update]
    D --> E{Áπ∞„ÇäËøî„Åó?}
    E -->|Yes| B
    E -->|No| F[Âá∫Âäõ: Êñ∞„Åó„ÅÑÁâπÂæ¥]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style F fill:#ffebee</div>

---

<h3>„Çπ„ÉÜ„ÉÉ„Éó1: „É°„ÉÉ„Çª„Éº„Ç∏ÁîüÊàêÔºàMessageÔºâ</h3>

<strong>ÂÆöÁæ©</strong>:
$$
m_{ij}^{(t)} = \text{Message}(h_i^{(t)}, h_j^{(t)}, e_{ij})
$$

- $h_i^{(t)}$: „É¨„Ç§„É§„Éº $t$ „Åß„ÅÆÈ†ÇÁÇπ $i$ „ÅÆÈö†„ÇåÁä∂ÊÖã
- $h_j^{(t)}$: Èö£Êé•È†ÇÁÇπ $j$ „ÅÆÈö†„ÇåÁä∂ÊÖã
- $e_{ij}$: Ëæ∫ $(i, j)$ „ÅÆÁâπÂæ¥Èáè

<strong>ÊúÄ„ÇÇ„Ç∑„É≥„Éó„É´„Å™ÂΩ¢</strong>:
$$
m_{ij}^{(t)} = W \cdot h_j^{(t)}
$$

<pre><code class="language-python">import torch
import torch.nn as nn

class MessageFunction(nn.Module):
    def __init__(self, in_dim, out_dim):
        super().__init__()
        self.W = nn.Linear(in_dim, out_dim)

    def forward(self, h_j):
        """
        Èö£Êé•È†ÇÁÇπ„Åã„Çâ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÁîüÊàê

        Parameters:
        -----------
        h_j : Tensor (num_neighbors, in_dim)
            Èö£Êé•È†ÇÁÇπ„ÅÆÁâπÂæ¥Èáè

        Returns:
        --------
        messages : Tensor (num_neighbors, out_dim)
            ÁîüÊàê„Åï„Çå„Åü„É°„ÉÉ„Çª„Éº„Ç∏
        """
        return self.W(h_j)

<h1>‰æã</h1>
in_dim, out_dim = 16, 32
msg_fn = MessageFunction(in_dim, out_dim)

<h1>Èö£Êé•È†ÇÁÇπ„ÅÆÁâπÂæ¥Ôºà3ÂÄã„ÅÆÈö£Êé•È†ÇÁÇπÔºâ</h1>
h_neighbors = torch.randn(3, in_dim)
messages = msg_fn(h_neighbors)
print(f"„É°„ÉÉ„Çª„Éº„Ç∏ÂΩ¢Áä∂: {messages.shape}")
<h1>Âá∫Âäõ: torch.Size([3, 32])</h1></code></pre>

---

<h3>„Çπ„ÉÜ„ÉÉ„Éó2: ÈõÜÁ¥ÑÔºàAggregationÔºâ</h3>

<strong>ÂÆöÁæ©</strong>:
$$
m_i^{(t)} = \text{Aggregate}\left( \{m_{ij}^{(t)} : j \in \mathcal{N}(i)\} \right)
$$

<strong>‰ª£Ë°®ÁöÑ„Å™ÈõÜÁ¥ÑÈñ¢Êï∞</strong>:

| ÈõÜÁ¥ÑÊñπÊ≥ï | Êï∞Âºè | ÁâπÂæ¥ |
|---------|------|------|
| <strong>Sum</strong> | $\sum_{j \in \mathcal{N}(i)} m_{ij}^{(t)}$ | È†ÜÂ∫è‰∏çÂ§â„ÄÅÊ¨°Êï∞„Å´ÊïèÊÑü |
| <strong>Mean</strong> | $\frac{1}{|\mathcal{N}(i)|} \sum_{j \in \mathcal{N}(i)} m_{ij}^{(t)}$ | Ê¨°Êï∞Ê≠£Ë¶èÂåñ |
| <strong>Max</strong> | $\max_{j \in \mathcal{N}(i)} m_{ij}^{(t)}$ | ÊúÄ„ÇÇÂº∑„ÅÑÁâπÂæ¥„Çí‰øùÊåÅ |
| <strong>Attention</strong> | $\sum_{j \in \mathcal{N}(i)} \alpha_{ij} m_{ij}^{(t)}$ | ÈáçË¶ÅÂ∫¶„ÅßÈáç„Åø‰ªò„Åë |

<pre><code class="language-python">class AggregationFunction:
    @staticmethod
    def sum_agg(messages):
        """Sum aggregation"""
        return torch.sum(messages, dim=0)

    @staticmethod
    def mean_agg(messages):
        """Mean aggregation"""
        return torch.mean(messages, dim=0)

    @staticmethod
    def max_agg(messages):
        """Max aggregation"""
        return torch.max(messages, dim=0)[0]

<h1>‰æã</h1>
messages = torch.tensor([
    [1.0, 2.0, 3.0],
    [4.0, 5.0, 6.0],
    [7.0, 8.0, 9.0]
])

print("Sum:", AggregationFunction.sum_agg(messages))
<h1>Âá∫Âäõ: tensor([12., 15., 18.])</h1>

print("Mean:", AggregationFunction.mean_agg(messages))
<h1>Âá∫Âäõ: tensor([4., 5., 6.])</h1>

print("Max:", AggregationFunction.max_agg(messages))
<h1>Âá∫Âäõ: tensor([7., 8., 9.])</h1></code></pre>

---

<h3>„Çπ„ÉÜ„ÉÉ„Éó3: Êõ¥Êñ∞ÔºàUpdateÔºâ</h3>

<strong>ÂÆöÁæ©</strong>:
$$
h_i^{(t+1)} = \text{Update}\left( h_i^{(t)}, m_i^{(t)} \right)
$$

<strong>ÂÖ∏ÂûãÁöÑ„Å™Êõ¥Êñ∞Âºè</strong>:
$$
h_i^{(t+1)} = \sigma\left( W_1 h_i^{(t)} + W_2 m_i^{(t)} \right)
$$

<pre><code class="language-python">class UpdateFunction(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        self.W1 = nn.Linear(hidden_dim, hidden_dim)
        self.W2 = nn.Linear(hidden_dim, hidden_dim)
        self.activation = nn.ReLU()

    def forward(self, h_i, m_i):
        """
        È†ÇÁÇπÁâπÂæ¥„ÇíÊõ¥Êñ∞

        Parameters:
        -----------
        h_i : Tensor (hidden_dim,)
            ÁèæÂú®„ÅÆÈ†ÇÁÇπÁâπÂæ¥
        m_i : Tensor (hidden_dim,)
            ÈõÜÁ¥Ñ„Åï„Çå„Åü„É°„ÉÉ„Çª„Éº„Ç∏

        Returns:
        --------
        h_new : Tensor (hidden_dim,)
            Êõ¥Êñ∞„Åï„Çå„ÅüÈ†ÇÁÇπÁâπÂæ¥
        """
        return self.activation(self.W1(h_i) + self.W2(m_i))

<h1>‰æã</h1>
hidden_dim = 32
update_fn = UpdateFunction(hidden_dim)

h_current = torch.randn(hidden_dim)
m_aggregated = torch.randn(hidden_dim)
h_new = update_fn(h_current, m_aggregated)

print(f"Êõ¥Êñ∞Ââç: {h_current[:5]}")
print(f"Êõ¥Êñ∞Âæå: {h_new[:5]}")</code></pre>

---

<h3>„É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅÆÂÖ®‰ΩìÂÉè</h3>

<pre><code class="language-python">class SimpleGNN(nn.Module):
    def __init__(self, in_dim, hidden_dim, num_layers):
        super().__init__()
        self.num_layers = num_layers

        # ÂêÑ„É¨„Ç§„É§„Éº„ÅÆ„Éë„É©„É°„Éº„Çø
        self.message_fns = nn.ModuleList([
            MessageFunction(hidden_dim, hidden_dim)
            for _ in range(num_layers)
        ])
        self.update_fns = nn.ModuleList([
            UpdateFunction(hidden_dim)
            for _ in range(num_layers)
        ])

        # ÂÖ•ÂäõÂ§âÊèõ
        self.input_proj = nn.Linear(in_dim, hidden_dim)

    def forward(self, x, edge_index):
        """
        Parameters:
        -----------
        x : Tensor (num_nodes, in_dim)
            È†ÇÁÇπÁâπÂæ¥Ë°åÂàó
        edge_index : Tensor (2, num_edges)
            Ëæ∫„ÅÆ„É™„Çπ„Éà [[src], [dst]]

        Returns:
        --------
        h : Tensor (num_nodes, hidden_dim)
            Êõ¥Êñ∞„Åï„Çå„ÅüÈ†ÇÁÇπÁâπÂæ¥
        """
        # ÂÖ•ÂäõÂ§âÊèõ
        h = self.input_proj(x)

        # „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅÆ„É¨„Ç§„É§„Éº
        for layer in range(self.num_layers):
            h_new = []

            # ÂêÑÈ†ÇÁÇπ„ÇíÊõ¥Êñ∞
            for i in range(x.size(0)):
                # Èö£Êé•È†ÇÁÇπ„ÇíÂèñÂæó
                neighbors = edge_index[1][edge_index[0] == i]

                if len(neighbors) > 0:
                    # „Çπ„ÉÜ„ÉÉ„Éó1: „É°„ÉÉ„Çª„Éº„Ç∏ÁîüÊàê
                    messages = self.message_fns[layer](h[neighbors])

                    # „Çπ„ÉÜ„ÉÉ„Éó2: ÈõÜÁ¥Ñ
                    m_i = torch.mean(messages, dim=0)

                    # „Çπ„ÉÜ„ÉÉ„Éó3: Êõ¥Êñ∞
                    h_i_new = self.update_fns[layer](h[i], m_i)
                else:
                    # Èö£Êé•È†ÇÁÇπ„Åå„Å™„ÅÑÂ†¥Âêà
                    h_i_new = h[i]

                h_new.append(h_i_new)

            h = torch.stack(h_new)

        return h

<h1>‰ΩøÁî®‰æã</h1>
model = SimpleGNN(in_dim=16, hidden_dim=32, num_layers=3)

<h1>„Ç∞„É©„Éï„Éá„Éº„ÇøÔºà‰∏âËßíÂΩ¢Ôºâ</h1>
x = torch.randn(3, 16)  # 3È†ÇÁÇπ„ÄÅ16Ê¨°ÂÖÉÁâπÂæ¥
edge_index = torch.tensor([
    [0, 0, 1, 1, 2, 2],  # ÂßãÁÇπ
    [1, 2, 0, 2, 0, 1]   # ÁµÇÁÇπ
])

<h1>È†Ü‰ºùÊí≠</h1>
h_out = model(x, edge_index)
print(f"Âá∫ÂäõÂΩ¢Áä∂: {h_out.shape}")
<h1>Âá∫Âäõ: torch.Size([3, 32])</h1></code></pre>

---

<h2>2.3 ‰ª£Ë°®ÁöÑ„Å™GNN„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£</h2>

<h3>Graph Convolutional Network (GCN)</h3>

<strong>Ë´ñÊñá</strong>: Kipf & Welling (2017), *ICLR*

<strong>Ê†∏ÂøÉ„Ç¢„Ç§„Éá„Ç¢</strong>: „Ç∞„É©„Éï„ÅÆ„Çπ„Éö„ÇØ„Éà„É´Áï≥„ÅøËæº„Åø

<strong>Êõ¥Êñ∞Âºè</strong>:
$$
H^{(l+1)} = \sigma\left( \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2} H^{(l)} W^{(l)} \right)
$$

- $\tilde{A} = A + I$: Ëá™Â∑±„É´„Éº„Éó‰ªò„ÅçÈö£Êé•Ë°åÂàó
- $\tilde{D}_{ii} = \sum_j \tilde{A}_{ij}$: Ê¨°Êï∞Ë°åÂàó
- $H^{(l)} \in \mathbb{R}^{n \times d}$: „É¨„Ç§„É§„Éº $l$ „ÅÆÁâπÂæ¥Èáè
- $W^{(l)} \in \mathbb{R}^{d \times d'}$: Â≠¶ÁøíÂèØËÉΩ„Å™Èáç„Åø

<strong>Python„Åß„ÅÆÂÆüË£Ö</strong>:
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class GCNLayer(nn.Module):
    def __init__(self, in_features, out_features):
        super().__init__()
        self.linear = nn.Linear(in_features, out_features)

    def forward(self, X, A):
        """
        Parameters:
        -----------
        X : Tensor (num_nodes, in_features)
            È†ÇÁÇπÁâπÂæ¥Ë°åÂàó
        A : Tensor (num_nodes, num_nodes)
            Èö£Êé•Ë°åÂàó

        Returns:
        --------
        H : Tensor (num_nodes, out_features)
            Êõ¥Êñ∞„Åï„Çå„ÅüÁâπÂæ¥Èáè
        """
        # Ëá™Â∑±„É´„Éº„Éó„ÅÆËøΩÂä†
        A_tilde = A + torch.eye(A.size(0), device=A.device)

        # Ê¨°Êï∞Ë°åÂàó
        D_tilde = torch.diag(A_tilde.sum(dim=1))

        # Ê≠£Ë¶èÂåñ: D^(-1/2) * A * D^(-1/2)
        D_inv_sqrt = torch.diag(1.0 / torch.sqrt(D_tilde.diagonal()))
        A_norm = D_inv_sqrt @ A_tilde @ D_inv_sqrt

        # „Ç∞„É©„ÉïÁï≥„ÅøËæº„Åø
        H = A_norm @ X
        H = self.linear(H)
        return F.relu(H)

<h1>‰ΩøÁî®‰æã</h1>
gcn = GCNLayer(in_features=16, out_features=32)

<h1>„Ç∞„É©„Éï„Éá„Éº„Çø</h1>
X = torch.randn(5, 16)  # 5È†ÇÁÇπ„ÄÅ16Ê¨°ÂÖÉ
A = torch.tensor([
    [0, 1, 1, 0, 0],
    [1, 0, 1, 1, 0],
    [1, 1, 0, 1, 1],
    [0, 1, 1, 0, 1],
    [0, 0, 1, 1, 0]
], dtype=torch.float32)

H = gcn(X, A)
print(f"GCNÂá∫ÂäõÂΩ¢Áä∂: {H.shape}")
<h1>Âá∫Âäõ: torch.Size([5, 32])</h1></code></pre>

<strong>ÁâπÂæ¥</strong>:
- ‚úÖ „Ç∑„É≥„Éó„É´„ÅßÈ´òÈÄü
- ‚úÖ ÈÅéÂâ∞Âπ≥ÊªëÂåñÔºàover-smoothingÔºâ„Å´Ê≥®ÊÑè
- ‚úÖ Âõ∫ÂÆöÁöÑ„Å™Èáç„ÅøÔºàÂÖ®Èö£Êé•È†ÇÁÇπ„ÅåÂêå„ÅòÊâ±„ÅÑÔºâ

---

<h3>Graph Attention Network (GAT)</h3>

<strong>Ë´ñÊñá</strong>: Veliƒçkoviƒá et al. (2018), *ICLR*

<strong>Ê†∏ÂøÉ„Ç¢„Ç§„Éá„Ç¢</strong>: Attention„ÅßÈáçË¶Å„Å™Èö£Êé•È†ÇÁÇπ„ÇíÈáçË¶ñ

<strong>Attention‰øÇÊï∞</strong>:
$$
\alpha_{ij} = \frac{\exp\left( \text{LeakyReLU}(a^T [W h_i \| W h_j]) \right)}
{\sum_{k \in \mathcal{N}(i)} \exp\left( \text{LeakyReLU}(a^T [W h_i \| W h_k]) \right)}
$$

<strong>Êõ¥Êñ∞Âºè</strong>:
$$
h_i^{(l+1)} = \sigma\left( \sum_{j \in \mathcal{N}(i)} \alpha_{ij} W^{(l)} h_j^{(l)} \right)
$$

<pre><code class="language-python">class GATLayer(nn.Module):
    def __init__(self, in_features, out_features, dropout=0.6,
                 alpha=0.2):
        super().__init__()
        self.W = nn.Linear(in_features, out_features, bias=False)
        self.a = nn.Parameter(torch.zeros(2 * out_features, 1))
        self.leakyrelu = nn.LeakyReLU(alpha)
        self.dropout = nn.Dropout(dropout)

        nn.init.xavier_uniform_(self.a.data, gain=1.414)

    def forward(self, X, A):
        """
        Parameters:
        -----------
        X : Tensor (num_nodes, in_features)
        A : Tensor (num_nodes, num_nodes)

        Returns:
        --------
        H : Tensor (num_nodes, out_features)
        """
        # Á∑öÂΩ¢Â§âÊèõ
        Wh = self.W(X)  # (N, out_features)
        N = Wh.size(0)

        # AttentionË®àÁÆó
        # [Wh_i || Wh_j] for all edges
        Wh_repeat_interleave = Wh.repeat_interleave(N, dim=0)
        Wh_repeat = Wh.repeat(N, 1)
        concat = torch.cat([Wh_repeat_interleave, Wh_repeat], dim=1)
        concat = concat.view(N, N, -1)

        # Attention score
        e = self.leakyrelu(concat @ self.a).squeeze(2)

        # „Éû„Çπ„ÇØÔºàËæ∫„Åå„Å™„ÅÑÂ†¥Âêà„ÅØ-infÔºâ
        zero_vec = -9e15 * torch.ones_like(e)
        attention = torch.where(A > 0, e, zero_vec)

        # Softmax
        attention = F.softmax(attention, dim=1)
        attention = self.dropout(attention)

        # Weighted sum
        H = torch.matmul(attention, Wh)
        return F.elu(H)

<h1>‰ΩøÁî®‰æã</h1>
gat = GATLayer(in_features=16, out_features=32)
H_gat = gat(X, A)
print(f"GATÂá∫ÂäõÂΩ¢Áä∂: {H_gat.shape}")
<h1>Âá∫Âäõ: torch.Size([5, 32])</h1></code></pre>

<strong>ÁâπÂæ¥</strong>:
- ‚úÖ ÂãïÁöÑ„Å™Èáç„ÅøÔºàÈáçË¶Å„Å™Èö£Êé•È†ÇÁÇπ„ÇíËá™ÂãïÂ≠¶ÁøíÔºâ
- ‚úÖ Ëß£ÈáàÂèØËÉΩÊÄßÔºàAttention‰øÇÊï∞„ÅÆÂèØË¶ñÂåñÔºâ
- ‚ùå Ë®àÁÆó„Ç≥„Çπ„Éà„ÅåÈ´ò„ÅÑÔºàGCN„ÅÆÁ¥Ñ2ÂÄçÔºâ

---

<h3>GraphSAGEÔºàSAmple and aggreGatEÔºâ</h3>

<strong>Ë´ñÊñá</strong>: Hamilton et al. (2017), *NeurIPS*

<strong>Ê†∏ÂøÉ„Ç¢„Ç§„Éá„Ç¢</strong>: „Éü„Éã„Éê„ÉÉ„ÉÅÂ≠¶Áøí„ÅÆ„Åü„ÇÅ„ÅÆ„Çµ„É≥„Éó„É™„É≥„Ç∞

<strong>Êõ¥Êñ∞Âºè</strong>:
$$
h_i^{(l+1)} = \sigma\left( W \cdot \text{Concat}\left( h_i^{(l)}, \text{Aggregate}(\{h_j^{(l)} : j \in \mathcal{S}(i)\}) \right) \right)
$$

- $\mathcal{S}(i)$: „Çµ„É≥„Éó„É™„É≥„Ç∞„Åï„Çå„ÅüÈö£Êé•È†ÇÁÇπÔºàÂÖ®„Å¶„Åß„ÅØ„Å™„ÅÑÔºâ

<pre><code class="language-python">class GraphSAGELayer(nn.Module):
    def __init__(self, in_features, out_features, num_samples=10):
        super().__init__()
        self.num_samples = num_samples
        # ConcatÁâà: ÂÖ•Âäõ„ÅØ in_features * 2
        self.linear = nn.Linear(in_features * 2, out_features)

    def forward(self, X, A):
        """
        Parameters:
        -----------
        X : Tensor (num_nodes, in_features)
        A : Tensor (num_nodes, num_nodes)

        Returns:
        --------
        H : Tensor (num_nodes, out_features)
        """
        N = X.size(0)
        H_new = []

        for i in range(N):
            # Èö£Êé•È†ÇÁÇπ„ÅÆ„Çµ„É≥„Éó„É™„É≥„Ç∞
            neighbors = torch.nonzero(A[i]).squeeze()
            if neighbors.numel() > self.num_samples:
                # „É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞
                perm = torch.randperm(neighbors.numel())
                sampled = neighbors[perm[:self.num_samples]]
            else:
                sampled = neighbors

            # ÈõÜÁ¥ÑÔºàMeanÔºâ
            if sampled.numel() > 0:
                h_neighbors = X[sampled]
                h_agg = torch.mean(h_neighbors, dim=0)
            else:
                h_agg = torch.zeros_like(X[i])

            # Concat
            h_concat = torch.cat([X[i], h_agg], dim=0)

            # Á∑öÂΩ¢Â§âÊèõ
            h_new = self.linear(h_concat)
            H_new.append(h_new)

        H = torch.stack(H_new)
        return F.relu(H)

<h1>‰ΩøÁî®‰æã</h1>
sage = GraphSAGELayer(in_features=16, out_features=32,
                      num_samples=3)
H_sage = sage(X, A)
print(f"GraphSAGEÂá∫ÂäõÂΩ¢Áä∂: {H_sage.shape}")
<h1>Âá∫Âäõ: torch.Size([5, 32])</h1></code></pre>

<strong>ÁâπÂæ¥</strong>:
- ‚úÖ „Çπ„Ç±„Éº„É©„Éñ„É´ÔºàÂ§ßË¶èÊ®°„Ç∞„É©„Éï„Å´ÂØæÂøúÔºâ
- ‚úÖ „Éü„Éã„Éê„ÉÉ„ÉÅË®ìÁ∑¥„ÅåÂèØËÉΩ
- ‚úÖ Â∏∞Á¥çÁöÑÂ≠¶ÁøíÔºàÊñ∞„Åó„ÅÑÈ†ÇÁÇπ„Å∏„ÅÆÊ±éÂåñÔºâ

---

<h3>3„Å§„ÅÆGNN„ÅÆÊØîËºÉ</h3>

<div class="mermaid">flowchart TD
    A[GNNÈÅ∏Êäû] --> B{„Éá„Éº„Çø„Çµ„Ç§„Ç∫}
    B -->|Â∞èË¶èÊ®°<br/>10kÈ†ÇÁÇπ| C[GCN]
    B -->|‰∏≠Ë¶èÊ®°<br/>10k-100k| D[GAT]
    B -->|Â§ßË¶èÊ®°<br/>100k+| E[GraphSAGE]

    C --> F[„Ç∑„É≥„Éó„É´„ÄÅÈ´òÈÄü]
    D --> G[È´òÁ≤æÂ∫¶„ÄÅËß£ÈáàÊÄß]
    E --> H[„Çπ„Ç±„Éº„É©„Éñ„É´]

    style A fill:#e3f2fd
    style C fill:#fff3e0
    style D fill:#f3e5f5
    style E fill:#e8f5e9</div>

| ÊâãÊ≥ï | Ë®àÁÆóÈáè | Á≤æÂ∫¶ | „Çπ„Ç±„Éº„É©„Éì„É™„ÉÜ„Ç£ | Ëß£ÈáàÊÄß | Êé®Â•®Áî®ÈÄî |
|------|-------|------|---------------|-------|---------|
| <strong>GCN</strong> | $O(m \cdot d^2)$ | ‰∏≠ | ‰Ωé | ‰∏≠ | Â∞èË¶èÊ®°„ÄÅ„Éó„É≠„Éà„Çø„Ç§„Éî„É≥„Ç∞ |
| <strong>GAT</strong> | $O(m \cdot d^2 + n \cdot d)$ | È´ò | ‰∏≠ | È´ò | ‰∏≠Ë¶èÊ®°„ÄÅÈ´òÁ≤æÂ∫¶Ë¶ÅÊ±Ç |
| <strong>GraphSAGE</strong> | $O(k \cdot s \cdot d^2)$ | ‰∏≠„ÄúÈ´ò | È´ò | ‰∏≠ | Â§ßË¶èÊ®°„ÄÅÂÆüÊôÇÈñì‰∫àÊ∏¨ |

- $m$: Ëæ∫Êï∞
- $n$: È†ÇÁÇπÊï∞
- $d$: ÁâπÂæ¥Ê¨°ÂÖÉ
- $k$: „É¨„Ç§„É§„ÉºÊï∞
- $s$: „Çµ„É≥„Éó„É´Êï∞

---

<h2>2.4 ÊùêÊñôÁßëÂ≠¶ÁâπÂåñGNN</h2>

<h3>SchNetÔºàContinuous-filter Convolutional NNÔºâ</h3>

<strong>Ë´ñÊñá</strong>: Sch√ºtt et al. (2017), *NeurIPS*

<strong>ÂØæË±°</strong>: ÂàÜÂ≠ê„ÉªÊùêÊñô„ÅÆ<strong>ÈáèÂ≠êÂåñÂ≠¶ÁâπÊÄß</strong>‰∫àÊ∏¨

<strong>Ê†∏ÂøÉ„Ç¢„Ç§„Éá„Ç¢</strong>:
1. <strong>ÈÄ£Á∂ö„Éï„Ç£„É´„Çø</strong>: Èõ¢Êï£„Ç∞„É©„Éï„Åß„ÅØ„Å™„Åè3DÁ©∫Èñì„Åß„ÅÆÁï≥„ÅøËæº„Åø
2. <strong>Ë∑ùÈõ¢‰æùÂ≠ò</strong>: ÂéüÂ≠êÈñìË∑ùÈõ¢„ÇíÊòéÁ§∫ÁöÑ„Å´„É¢„Éá„É´Âåñ

<strong>„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£</strong>:

<div class="mermaid">graph LR
    A[ÂéüÂ≠êÁâπÂæ¥] --> B[Âüã„ÇÅËæº„ÅøÂ±§]
    B --> C[Áõ∏‰∫í‰ΩúÁî®„Éñ„É≠„ÉÉ„ÇØ 1]
    C --> D[Áõ∏‰∫í‰ΩúÁî®„Éñ„É≠„ÉÉ„ÇØ 2]
    D --> E[Áõ∏‰∫í‰ΩúÁî®„Éñ„É≠„ÉÉ„ÇØ 3]
    E --> F[Âá∫ÂäõÂ±§]

    G[ÂéüÂ≠êÈñìË∑ùÈõ¢] --> C
    G --> D
    G --> E

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#ffebee
    style F fill:#fff9c4
    style G fill:#e1bee7</div>

<strong>Êï∞Âºè</strong>:
$$
h_i^{(l+1)} = h_i^{(l)} + \sum_{j \in \mathcal{N}(i)} h_j^{(l)} \odot \phi\left( \|r_i - r_j\| \right)
$$

- $\phi(d)$: <strong>ÈÄ£Á∂ö„Éï„Ç£„É´„ÇøÈñ¢Êï∞</strong>ÔºàË∑ùÈõ¢ $d$ „Å´‰æùÂ≠òÔºâ
- $r_i, r_j$: ÂéüÂ≠ê„ÅÆ3DÂ∫ßÊ®ô

<strong>„Éï„Ç£„É´„ÇøÈñ¢Êï∞</strong>:
$$
\phi(d) = \sum_{k=1}^{K} w_k \exp\left( -\gamma (d - \mu_k)^2 \right)
$$

- „Ç¨„Ç¶„ÇπÂü∫Â∫ïÂ±ïÈñãÔºàRBF: Radial Basis FunctionÔºâ

<pre><code class="language-python">import torch
import torch.nn as nn

class GaussianBasis(nn.Module):
    def __init__(self, start=0.0, stop=5.0, num_gaussians=50):
        super().__init__()
        self.mu = nn.Parameter(
            torch.linspace(start, stop, num_gaussians),
            requires_grad=False
        )
        self.gamma = nn.Parameter(
            torch.tensor(10.0),
            requires_grad=True
        )

    def forward(self, distances):
        """
        Parameters:
        -----------
        distances : Tensor (num_edges,)
            ÂéüÂ≠êÈñìË∑ùÈõ¢

        Returns:
        --------
        rbf : Tensor (num_edges, num_gaussians)
            „Ç¨„Ç¶„ÇπÂü∫Â∫ïÂ±ïÈñã
        """
        # (num_edges, 1) - (1, num_gaussians)
        diff = distances.unsqueeze(-1) - self.mu.unsqueeze(0)
        rbf = torch.exp(-self.gamma * diff ** 2)
        return rbf

class SchNetInteraction(nn.Module):
    def __init__(self, hidden_dim, num_gaussians):
        super().__init__()
        self.rbf_layer = GaussianBasis(num_gaussians=num_gaussians)
        self.filter_net = nn.Sequential(
            nn.Linear(num_gaussians, hidden_dim),
            nn.Softplus(),
            nn.Linear(hidden_dim, hidden_dim)
        )
        self.linear = nn.Linear(hidden_dim, hidden_dim)

    def forward(self, h, edge_index, distances):
        """
        Parameters:
        -----------
        h : Tensor (num_atoms, hidden_dim)
            ÂéüÂ≠êÁâπÂæ¥
        edge_index : Tensor (2, num_edges)
            Ëæ∫„ÅÆ„É™„Çπ„Éà
        distances : Tensor (num_edges,)
            ÂéüÂ≠êÈñìË∑ùÈõ¢

        Returns:
        --------
        h_new : Tensor (num_atoms, hidden_dim)
            Êõ¥Êñ∞„Åï„Çå„ÅüÁâπÂæ¥
        """
        # RBFÂ±ïÈñã
        rbf = self.rbf_layer(distances)

        # „Éï„Ç£„É´„ÇøÁîüÊàê
        W = self.filter_net(rbf)

        # „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞
        src, dst = edge_index
        messages = h[dst] * W  # Ë¶ÅÁ¥†Á©ç

        # ÈõÜÁ¥Ñ
        h_agg = torch.zeros_like(h)
        h_agg.index_add_(0, src, messages)

        # Êõ¥Êñ∞
        h_new = h + self.linear(h_agg)
        return h_new

<h1>‰ΩøÁî®‰æã</h1>
schnet_layer = SchNetInteraction(hidden_dim=128,
                                 num_gaussians=50)

<h1>„Éá„Éº„Çø</h1>
num_atoms = 5
h = torch.randn(num_atoms, 128)
edge_index = torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]])
distances = torch.tensor([1.5, 1.8, 2.0, 1.6])

h_new = schnet_layer(h, edge_index, distances)
print(f"SchNetÂá∫ÂäõÂΩ¢Áä∂: {h_new.shape}")
<h1>Âá∫Âäõ: torch.Size([5, 128])</h1></code></pre>

<strong>ÈÅ©Áî®‰æã</strong>:
- QM9„Éá„Éº„Çø„Çª„ÉÉ„ÉàÔºàÂàÜÂ≠êÁâπÊÄß‰∫àÊ∏¨Ôºâ
- MD17ÔºàÂàÜÂ≠êÂãïÂäõÂ≠¶Ôºâ
- OC20ÔºàËß¶Â™íÂê∏ÁùÄ„Ç®„Éç„É´„ÇÆ„ÉºÔºâ

<strong>ÊÄßËÉΩ</strong>:
<pre><code>QM9 HOMO-LUMO gap:
- DFTË®àÁÆó: 24ÊôÇÈñì/ÂàÜÂ≠ê
- SchNet: 0.01Áßí/ÂàÜÂ≠êÔºàMAE=0.04 eVÔºâ</code></pre>

---

<h3>DimeNetÔºàDirectional Message Passing NNÔºâ</h3>

<strong>Ë´ñÊñá</strong>: Klicpera et al. (2020), *ICLR*

<strong>Êã°Âºµ</strong>: <strong>ÁµêÂêàËßí</strong>„ÇÇËÄÉÊÖÆ

<strong>Ê†∏ÂøÉ„Ç¢„Ç§„Éá„Ç¢</strong>:
- Ë∑ùÈõ¢„Å†„Åë„Åß„Å™„Åè<strong>ËßíÂ∫¶ÊÉÖÂ†±</strong>„ÇÇÂà©Áî®
- 3‰ΩìÁõ∏‰∫í‰ΩúÁî®Ôºàtriplet interactionÔºâ

<strong>Êõ¥Êñ∞Âºè</strong>:
$$
m_{ij} = \sum_{k \in \mathcal{N}(j) \setminus \{i\}} W\left( d_{ij}, d_{jk}, \theta_{ijk} \right) h_k
$$

- $\theta_{ijk}$: ËßíÂ∫¶ $\angle i-j-k$

<div class="mermaid">graph TD
    A[ÂéüÂ≠ê i] ---|d_ij| B[ÂéüÂ≠ê j]
    B ---|d_jk| C[ÂéüÂ≠ê k]
    A -.ËßíÂ∫¶Œ∏_ijk.-> C

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5</div>

<strong>ËßíÂ∫¶„ÅÆË®àÁÆó</strong>:
<pre><code class="language-python">import torch

def compute_angle(pos_i, pos_j, pos_k):
    """
    3ÂéüÂ≠êÈñì„ÅÆËßíÂ∫¶„ÇíË®àÁÆó

    Parameters:
    -----------
    pos_i, pos_j, pos_k : Tensor (3,)
        ÂéüÂ≠ê„ÅÆ3DÂ∫ßÊ®ô

    Returns:
    --------
    angle : Tensor (1,)
        ËßíÂ∫¶Ôºà„É©„Ç∏„Ç¢„É≥Ôºâ
    """
    # „Éô„ÇØ„Éà„É´
    v_ij = pos_j - pos_i
    v_jk = pos_k - pos_j

    # ÂÜÖÁ©ç
    cos_angle = torch.dot(v_ij, v_jk) / (
        torch.norm(v_ij) * torch.norm(v_jk) + 1e-8
    )

    # ËßíÂ∫¶
    angle = torch.acos(torch.clamp(cos_angle, -1.0, 1.0))
    return angle

<h1>‰æãÔºöÊ∞¥ÂàÜÂ≠ê„ÅÆÁµêÂêàËßíÔºàH-O-HÔºâ</h1>
pos_O = torch.tensor([0.0, 0.0, 0.0])
pos_H1 = torch.tensor([0.96, 0.0, 0.0])
pos_H2 = torch.tensor([0.24, 0.93, 0.0])

angle = compute_angle(pos_H1, pos_O, pos_H2)
print(f"H-O-HËßíÂ∫¶: {torch.rad2deg(angle):.1f}¬∞")
<h1>Âá∫Âäõ: 104.5¬∞ÔºàÂÆüÊ∏¨ÂÄ§„Å®„Åª„Åº‰∏ÄËá¥Ôºâ</h1></code></pre>

<strong>ÊÄßËÉΩ</strong>:
<pre><code>QM9„Éá„Éº„Çø„Çª„ÉÉ„Éà:
- SchNet: MAE=0.041 eV
- DimeNet: MAE=0.033 eVÔºà20%ÊîπÂñÑÔºâ

Ë®àÁÆóÊôÇÈñì:
- SchNet: 0.01Áßí/ÂàÜÂ≠ê
- DimeNet: 0.05Áßí/ÂàÜÂ≠êÔºà5ÂÄçÈÅÖ„ÅÑÔºâ</code></pre>

---

<h3>GemNetÔºàGeometric Message Passing NNÔºâ</h3>

<strong>Ë´ñÊñá</strong>: Gasteiger et al. (2021), *NeurIPS*

<strong>„Åï„Çâ„Å™„ÇãÊã°Âºµ</strong>: <strong>4‰ΩìÁõ∏‰∫í‰ΩúÁî®</strong>Ôºà‰∫åÈù¢ËßíÔºâ

<strong>ÂØæË±°</strong>: ÁµêÊô∂ÊßãÈÄ†„ÄÅË§áÈõë„Å™ÂàÜÂ≠ê

<strong>Ê†∏ÂøÉ„Ç¢„Ç§„Éá„Ç¢</strong>:
- ‰∫åÈù¢ËßíÔºàtorsion angleÔºâ„ÅÆËÄÉÊÖÆ
- „Çà„ÇäÈ´òÊ¨°„ÅÆÂπæ‰ΩïÂ≠¶ÁöÑÊÉÖÂ†±

<div class="mermaid">graph LR
    A[ÂéüÂ≠ê i] --- B[ÂéüÂ≠ê j]
    B --- C[ÂéüÂ≠ê k]
    C --- D[ÂéüÂ≠ê l]

    A -.‰∫åÈù¢ËßíœÜ.-> D

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9</div>

<strong>ÊÄßËÉΩ</strong>:
<pre><code>OC20„Éá„Éº„Çø„Çª„ÉÉ„ÉàÔºàËß¶Â™íÔºâ:
- SchNet: MAE=0.61 eV
- DimeNet++: MAE=0.49 eV
- GemNet: MAE=0.43 eVÔºàÊúÄÈ´òÁ≤æÂ∫¶Ôºâ</code></pre>

---

<h3>ÊùêÊñôÁßëÂ≠¶GNN„ÅÆÊØîËºÉ</h3>

| ÊâãÊ≥ï | ËÄÉÊÖÆ„Åô„ÇãÊÉÖÂ†± | Á≤æÂ∫¶ | ÈÄüÂ∫¶ | Êé®Â•®Áî®ÈÄî |
|------|------------|------|------|---------|
| <strong>SchNet</strong> | Ë∑ùÈõ¢ | ‰∏≠ | ÈÄü„ÅÑ | ÂàÜÂ≠êÁâπÊÄß‰∫àÊ∏¨ |
| <strong>DimeNet</strong> | Ë∑ùÈõ¢ + ËßíÂ∫¶ | È´ò | ‰∏≠ | Ëß¶Â™í„ÄÅË§áÈõë„Å™ÂàÜÂ≠ê |
| <strong>GemNet</strong> | Ë∑ùÈõ¢ + ËßíÂ∫¶ + ‰∫åÈù¢Ëßí | ÊúÄÈ´ò | ÈÅÖ„ÅÑ | ÁµêÊô∂„ÄÅÈ´òÁ≤æÂ∫¶Ë¶ÅÊ±Ç |

---

<h2>2.5 Á≠âÂ§âÊÄßÔºàEquivarianceÔºâ„ÅÆÈáçË¶ÅÊÄß</h2>

<h3>Á≠âÂ§âÊÄß„Å®„ÅØ</h3>

<strong>ÂÆöÁæ©</strong>:
> Èñ¢Êï∞ $f$ „ÅåÂ§âÊèõ $T$ „Å´ÂØæ„Åó„Å¶<strong>Á≠âÂ§â</strong>ÔºàequivariantÔºâ„Åß„ÅÇ„Çã„Å®„ÅØ„ÄÅ
> $$f(T(x)) = T(f(x))$$
> „ÅåÊàê„ÇäÁ´ã„Å§„Åì„Å®„ÄÇ

<strong>ÊùêÊñôÁßëÂ≠¶„Åß„ÅÆÊÑèÂë≥</strong>:
- ÂàÜÂ≠ê„ÇíÂõûËª¢„Éª‰∏¶ÈÄ≤„Åó„Å¶„ÇÇ„ÄÅ‰∫àÊ∏¨„ÅØÂêå„ÅòÔºà„Åæ„Åü„ÅØÂØæÂøú„Åô„ÇãÂ§âÊèõÔºâ

---

<h3>E(3)Á≠âÂ§âÊÄß</h3>

<strong>E(3)Áæ§</strong>: 3Ê¨°ÂÖÉ„É¶„Éº„ÇØ„É™„ÉÉ„ÉâÁ©∫Èñì„ÅÆÁ≠âÈï∑Â§âÊèõ
- ÂõûËª¢ÔºàRotationÔºâ
- ‰∏¶ÈÄ≤ÔºàTranslationÔºâ
- ÂèçËª¢ÔºàInversionÔºâ

<strong>ÈáçË¶ÅÊÄß</strong>:
- Áâ©ÁêÜÊ≥ïÂâá„ÅØÂ∫ßÊ®ôÁ≥ª„Å´‰æùÂ≠ò„Åó„Å™„ÅÑ
- GNN„ÇÇÂêåÊßò„Åß„ÅÇ„Çã„Åπ„Åç

---

<h3>Á≠âÂ§âGNN„ÅÆ‰æãÔºöNequIP„ÄÅMACE</h3>

<strong>NequIP</strong> (Batzner et al., 2022):
- <strong>E(3)Á≠âÂ§â„É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞</strong>
- ÁêÉÈù¢Ë™øÂíåÈñ¢Êï∞ÔºàSpherical HarmonicsÔºâ„ÅÆÂà©Áî®

<strong>Êõ¥Êñ∞Âºè</strong>:
$$
m_{ij} = \phi\left( \|r_i - r_j\| \right) \otimes Y_l(r_{ij})
$$

- $Y_l$: ÁêÉÈù¢Ë™øÂíåÈñ¢Êï∞ÔºàËßíÂ∫¶ÊÉÖÂ†±„Çí‰øùÊåÅÔºâ
- $\otimes$: „ÉÜ„É≥„ÇΩ„É´Á©ç

<strong>MACE</strong> (Batatia et al., 2022):
- <strong>È´òÊ¨°„ÅÆÁ≠âÂ§âÊÄß</strong>
- „Çà„ÇäÊ≠£Á¢∫„Å™ÂäõÂ†¥Ôºàforce fieldÔºâ‰∫àÊ∏¨

<strong>ÊÄßËÉΩ</strong>:
<pre><code>MD17„Éá„Éº„Çø„Çª„ÉÉ„ÉàÔºàÂàÜÂ≠êÂãïÂäõÂ≠¶Ôºâ:
- SchNet: MAE(Âäõ) = 0.21 kcal/mol/√Ö
- NequIP: MAE(Âäõ) = 0.05 kcal/mol/√ÖÔºà76%ÊîπÂñÑÔºâ</code></pre>

---

<h3>Á≠âÂ§âÊÄß„ÅÆ„ÉÜ„Çπ„Éà</h3>

<pre><code class="language-python">import torch
import torch.nn as nn

def test_equivariance(model, pos, edge_index):
    """
    „É¢„Éá„É´„ÅÆÁ≠âÂ§âÊÄß„Çí„ÉÜ„Çπ„Éà
    """
    # „Ç™„É™„Ç∏„Éä„É´„ÅÆ‰∫àÊ∏¨
    pred_original = model(pos, edge_index)

    # ÂõûËª¢Ë°åÂàóÔºà90Â∫¶ÂõûËª¢Ôºâ
    angle = torch.tensor(torch.pi / 2)
    rotation = torch.tensor([
        [torch.cos(angle), -torch.sin(angle), 0],
        [torch.sin(angle), torch.cos(angle), 0],
        [0, 0, 1]
    ])

    # Â∫ßÊ®ô„ÇíÂõûËª¢
    pos_rotated = pos @ rotation.T

    # ÂõûËª¢Âæå„ÅÆ‰∫àÊ∏¨
    pred_rotated = model(pos_rotated, edge_index)

    # ‰∫àÊ∏¨„ÇíÂõûËª¢
    pred_original_rotated = pred_original @ rotation.T

    # Ë™§Â∑Æ„ÇíË®àÁÆó
    error = torch.abs(pred_rotated - pred_original_rotated).mean()
    print(f"Á≠âÂ§âÊÄßË™§Â∑Æ: {error.item():.6f}")

    if error < 1e-5:
        print("‚úÖ „É¢„Éá„É´„ÅØÁ≠âÂ§â„Åß„Åô")
    else:
        print("‚ùå „É¢„Éá„É´„ÅØÁ≠âÂ§â„Åß„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì")

<h1>‰ΩøÁî®‰æãÔºàÁ∞°Áï•ÁâàÔºâ</h1>
class SimpleEquivariantModel(nn.Module):
    def forward(self, pos, edge_index):
        # Á∞°Áï•Âåñ: Â∫ßÊ®ô„ÅÆÂ∑ÆÂàÜ„ÇíË®àÁÆóÔºàÁ≠âÂ§âÔºâ
        src, dst = edge_index
        diff = pos[dst] - pos[src]
        return diff

model = SimpleEquivariantModel()
pos = torch.randn(5, 3)
edge_index = torch.tensor([[0, 1, 2], [1, 2, 3]])

test_equivariance(model, pos, edge_index)</code></pre>

---

<h2>2.6 „Ç≥„É©„É†Ôºö„Å™„ÅúÊ∑±„ÅÑGNN„ÅØÈõ£„Åó„ÅÑ„Åã</h2>

<h3>ÈÅéÂâ∞Âπ≥ÊªëÂåñÔºàOver-smoothingÔºâ</h3>

<strong>ÂïèÈ°å</strong>: „É¨„Ç§„É§„Éº„ÇíÊ∑±„Åè„Åô„Çã„Å®„ÄÅ<strong>ÂÖ®„Å¶„ÅÆÈ†ÇÁÇπ„ÅåÂêå„ÅòÁâπÂæ¥</strong>„Å´„Å™„Çã

<strong>ÂéüÂõ†</strong>: „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅÆÁπ∞„ÇäËøî„Åó„ÅßÊÉÖÂ†±„ÅåÊã°Êï£

<pre><code class="language-python"><h1>ÈÅéÂâ∞Âπ≥ÊªëÂåñ„ÅÆ„Éá„É¢</h1>
import torch
import torch.nn.functional as F

def demonstrate_oversmoothing(X, A, num_layers=10):
    """
    ÈÅéÂâ∞Âπ≥ÊªëÂåñ„ÅÆÂèØË¶ñÂåñ
    """
    H = X
    smoothness = []

    for layer in range(num_layers):
        # Á∞°Âçò„Å™GCNÂ±§
        D = torch.diag(A.sum(dim=1))
        D_inv_sqrt = torch.diag(1.0 / torch.sqrt(D.diagonal()))
        A_norm = D_inv_sqrt @ A @ D_inv_sqrt

        H = A_norm @ H
        H = F.relu(H)

        # Âπ≥ÊªëÂ∫¶ÔºàÈ†ÇÁÇπÈñì„ÅÆÈ°û‰ººÂ∫¶Ôºâ
        similarity = F.cosine_similarity(
            H.unsqueeze(1), H.unsqueeze(0), dim=2
        )
        avg_similarity = similarity[torch.triu_indices(
            H.size(0), H.size(0), offset=1
        )[0], torch.triu_indices(
            H.size(0), H.size(0), offset=1
        )[1]].mean()

        smoothness.append(avg_similarity.item())
        print(f"Layer {layer+1}: Âπ≥ÂùáÈ°û‰ººÂ∫¶ = {avg_similarity:.4f}")

    return smoothness

<h1>ÂÆüË°å</h1>
X = torch.randn(5, 16)
A = torch.eye(5) + torch.rand(5, 5) > 0.7
smoothness = demonstrate_oversmoothing(X, A.float(), num_layers=10)</code></pre>

<strong>Âá∫Âäõ‰æã</strong>:
<pre><code>Layer 1: Âπ≥ÂùáÈ°û‰ººÂ∫¶ = 0.2341
Layer 2: Âπ≥ÂùáÈ°û‰ººÂ∫¶ = 0.4523
Layer 3: Âπ≥ÂùáÈ°û‰ººÂ∫¶ = 0.6789
...
Layer 10: Âπ≥ÂùáÈ°û‰ººÂ∫¶ = 0.9876</code></pre>

‚Üí „É¨„Ç§„É§„Éº„ÅåÊ∑±„Åè„Å™„Çã„Å´„Å§„Çå„ÄÅÂÖ®È†ÇÁÇπ„Åå‰ºº„Å¶„Åè„Çã

---

<h3>ÂØæÁ≠ñ</h3>

1. <strong>Residual ConnectionÔºàÊÆãÂ∑ÆÊé•Á∂öÔºâ</strong>:
   $$h_i^{(l+1)} = h_i^{(l)} + \text{GNN}(h_i^{(l)})$$

2. <strong>Jumping Knowledge Network</strong>:
   - ÂÖ®„É¨„Ç§„É§„Éº„ÅÆÂá∫Âäõ„ÇíÁµêÂêà

3. <strong>PairNorm</strong>:
   - ÁâπÂæ¥Èáè„ÅÆÊ≠£Ë¶èÂåñ

<pre><code class="language-python">class GNNWithResidual(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        self.conv = GCNLayer(hidden_dim, hidden_dim)

    def forward(self, X, A):
        # Residual connection
        H = self.conv(X, A)
        return X + H  # „Ç∑„Éß„Éº„Éà„Ç´„ÉÉ„Éà</code></pre>

---

<h2>2.7 Êú¨Á´†„ÅÆ„Åæ„Å®„ÇÅ</h2>

<h3>Â≠¶„Çì„Å†„Åì„Å®</h3>

1. <strong>„Ç∞„É©„Éï„ÅÆÊï∞Â≠¶ÁöÑÂÆöÁæ©</strong>
   - Èö£Êé•Ë°åÂàó„ÄÅÊ¨°Êï∞Ë°åÂàó„ÄÅ„É©„Éó„É©„Ç∑„Ç¢„É≥Ë°åÂàó
   - È†ÇÁÇπÁâπÂæ¥Èáè„Å®Ëæ∫ÁâπÂæ¥Èáè

2. <strong>„É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞</strong>
   - 3„Çπ„ÉÜ„ÉÉ„Éó: „É°„ÉÉ„Çª„Éº„Ç∏ÁîüÊàê ‚Üí ÈõÜÁ¥Ñ ‚Üí Êõ¥Êñ∞
   - ÈõÜÁ¥ÑÈñ¢Êï∞: Sum„ÄÅMean„ÄÅMax„ÄÅAttention

3. <strong>‰ª£Ë°®ÁöÑGNN„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£</strong>
   - GCN: „Ç∑„É≥„Éó„É´„ÄÅÈ´òÈÄü
   - GAT: Attention„ÄÅÈ´òÁ≤æÂ∫¶
   - GraphSAGE: „Çπ„Ç±„Éº„É©„Éñ„É´„ÄÅ„Éü„Éã„Éê„ÉÉ„ÉÅ

4. <strong>ÊùêÊñôÁßëÂ≠¶ÁâπÂåñGNN</strong>
   - SchNet: Ë∑ùÈõ¢‰æùÂ≠ò„ÄÅÈÄ£Á∂ö„Éï„Ç£„É´„Çø
   - DimeNet: ËßíÂ∫¶ÊÉÖÂ†±„ÇÇËÄÉÊÖÆ
   - GemNet: ‰∫åÈù¢Ëßí„Åæ„ÅßËÄÉÊÖÆ

5. <strong>Á≠âÂ§âÊÄß</strong>
   - E(3)Á≠âÂ§âÊÄß„ÅÆÈáçË¶ÅÊÄß
   - NequIP„ÄÅMACE„Å™„Å©ÊúÄÊñ∞ÊâãÊ≥ï

<h3>ÈáçË¶Å„Å™„Éù„Ç§„É≥„Éà</h3>

- ‚úÖ „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅØGNN„ÅÆ<strong>Áµ±‰∏Ä„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ</strong>
- ‚úÖ ÈõÜÁ¥ÑÈñ¢Êï∞„ÅÆÈÅ∏Êäû„ÅåÊÄßËÉΩ„Å´Â§ß„Åç„ÅèÂΩ±Èüø
- ‚úÖ ÊùêÊñôÁßëÂ≠¶„Åß„ÅØ<strong>Âπæ‰ΩïÂ≠¶ÁöÑÊÉÖÂ†±</strong>ÔºàË∑ùÈõ¢„ÄÅËßíÂ∫¶Ôºâ„ÅåÈáçË¶Å
- ‚úÖ Á≠âÂ§âÊÄß„Å´„Çà„Çä<strong>Áâ©ÁêÜÊ≥ïÂâá„Çí‰øùË®º</strong>
- ‚úÖ ÈÅéÂâ∞Âπ≥ÊªëÂåñ„Å´Ê≥®ÊÑèÔºàResidual Connection„ÅßÂØæÁ≠ñÔºâ

<h3>Ê¨°„ÅÆÁ´†„Å∏</h3>

Á¨¨3Á´†„Åß„ÅØ„ÄÅ<strong>PyTorch GeometricÂÆüË∑µ</strong>„ÇíÂ≠¶„Å≥„Åæ„ÅôÔºö
- Áí∞Â¢ÉÊßãÁØâÔºàPyG„ÄÅRDKit„ÄÅASEÔºâ
- QM9„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅßÂàÜÂ≠êÁâπÊÄß‰∫àÊ∏¨
- Materials Project„Éá„Éº„Çø„ÅßÁµêÊô∂ÁâπÊÄß‰∫àÊ∏¨
- „É¢„Éá„É´Ë©ï‰æ°„Å®„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞
- ÂÆüË∑µ„Éó„É≠„Ç∏„Çß„ÇØ„Éà

<strong>[Á¨¨3Á´†ÔºöPyTorch GeometricÂÆüË∑µ ‚Üí](./chapter-3.md)</strong>

---

<h2>ÊºîÁøíÂïèÈ°å</h2>

<h3>ÂïèÈ°å1ÔºàÈõ£ÊòìÂ∫¶ÔºöeasyÔºâ</h3>

Ê¨°„ÅÆÊñáÁ´†„ÅÆÊ≠£Ë™§„ÇíÂà§ÂÆö„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

1. „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅØ„ÄÅÈõÜÁ¥ÑÔºàAggregationÔºâ‚Üí Êõ¥Êñ∞ÔºàUpdateÔºâ‚Üí „É°„ÉÉ„Çª„Éº„Ç∏ÁîüÊàê„ÅÆÈ†Ü„ÅßË°å„Çè„Çå„Çã
2. GAT„ÅØAttention„Çí‰Ωø„ÅÜ„Åü„ÇÅ„ÄÅÂÖ®„Å¶„ÅÆÈö£Êé•È†ÇÁÇπ„ÇíÂêå„ÅòÈáç„Åø„ÅßÊâ±„ÅÜ
3. SchNet„ÅØÂéüÂ≠êÈñìË∑ùÈõ¢„ÇíÊòéÁ§∫ÁöÑ„Å´ËÄÉÊÖÆ„Åô„Çã

<details>
<summary>„Éí„É≥„Éà</summary>

- „É°„ÉÉ„Çª„Éº„Ç∏„Éë„ÉÉ„Ç∑„É≥„Ç∞„ÅÆ3„Çπ„ÉÜ„ÉÉ„Éó„ÇíÊÄù„ÅÑÂá∫„Åó„Åæ„Åó„Çá„ÅÜ
- GAT„ÅÆÊ†∏ÂøÉ„Ç¢„Ç§„Éá„Ç¢„ÅØ„ÄåÈáçË¶Å„Å™Èö£Êé•È†ÇÁÇπ„ÇíÈáçË¶ñ„Äç„Åß„Åô
- SchNet„ÅÆÁâπÂæ¥„ÅØ„ÄåÈÄ£Á∂ö„Éï„Ç£„É´„Çø„Äç„Åß„Åô

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<strong>Ëß£Á≠î</strong>:
1. <strong>Ë™§</strong> - Ê≠£„Åó„ÅÑÈ†ÜÁï™„ÅØÔºö„É°„ÉÉ„Çª„Éº„Ç∏ÁîüÊàê ‚Üí ÈõÜÁ¥Ñ ‚Üí Êõ¥Êñ∞
2. <strong>Ë™§</strong> - GAT„ÅØ Attention„Åß<strong>Áï∞„Å™„ÇãÈáç„Åø</strong>„ÇíÂâ≤„ÇäÂΩì„Å¶„Çã
3. <strong>Ê≠£</strong> - SchNet„ÅØRBFÔºà„Ç¨„Ç¶„ÇπÂü∫Â∫ïÔºâ„ÅßË∑ùÈõ¢„Çí„Ç®„É≥„Ç≥„Éº„Éâ

<strong>Ëß£Ë™¨</strong>:

1„Å´„Å§„ÅÑ„Å¶Ôºö
<pre><code class="language-python"><h1>Ê≠£„Åó„ÅÑÈ†ÜÂ∫è</h1>
for layer in range(num_layers):
    # Step 1: „É°„ÉÉ„Çª„Éº„Ç∏ÁîüÊàê
    messages = message_function(h_neighbors)

    # Step 2: ÈõÜÁ¥Ñ
    m_i = aggregate(messages)

    # Step 3: Êõ¥Êñ∞
    h_i = update_function(h_i, m_i)</code></pre>

2„Å´„Å§„ÅÑ„Å¶Ôºö
- GAT „ÅÆ Attention ‰øÇÊï∞ $\alpha_{ij}$ „ÅØÈö£Êé•È†ÇÁÇπ„Åî„Å®„Å´Áï∞„Å™„Çã
- ÈáçË¶Å„Å™Èö£Êé•È†ÇÁÇπ„Å´„ÅØÂ§ß„Åç„Å™Èáç„Åø„ÄÅ„Åù„ÅÜ„Åß„Å™„ÅÑ„ÇÇ„ÅÆ„Å´„ÅØÂ∞è„Åï„Å™Èáç„Åø

3„Å´„Å§„ÅÑ„Å¶Ôºö
- SchNet „ÅÆ „Éï„Ç£„É´„ÇøÈñ¢Êï∞: $\phi(d) = \sum_k w_k \exp(-\gamma (d - \mu_k)^2)$
- Ë∑ùÈõ¢ $d$ „ÅåÁï∞„Å™„Çå„Å∞„ÄÅ„Éï„Ç£„É´„Çø„ÅÆÂÄ§„ÇÇÁï∞„Å™„Çã

</details>

---

<h3>ÂïèÈ°å2ÔºàÈõ£ÊòìÂ∫¶ÔºömediumÔºâ</h3>

‰ª•‰∏ã„ÅÆ„Ç∞„É©„Éï„Å´ÂØæ„Åó„Å¶„ÄÅGCN„ÅÆ1Â±§„ÅÆÈ†Ü‰ºùÊí≠„ÇíÊâãË®àÁÆó„ÅßÊ±Ç„ÇÅ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

<strong>„Ç∞„É©„Éï</strong>:
<pre><code>È†ÇÁÇπ: 3ÂÄãÔºàv0, v1, v2Ôºâ
Ëæ∫: v0-v1, v1-v2ÔºàÁ∑öÂΩ¢„Ç∞„É©„ÉïÔºâ

È†ÇÁÇπÁâπÂæ¥:
X = [[1, 0],
     [0, 1],
     [1, 1]]

Èö£Êé•Ë°åÂàó:
A = [[0, 1, 0],
     [1, 0, 1],
     [0, 1, 0]]

Èáç„ÅøË°åÂàóÔºàÁ∞°Áï•ÂåñÔºâ:
W = [[1, 0],
     [0, 1]]  ÔºàÊÅíÁ≠âË°åÂàóÔºâ</code></pre>

<strong>Ë¶ÅÊ±Ç‰∫ãÈ†Ö</strong>:
1. $\tilde{A} = A + I$ „ÇíË®àÁÆó
2. Ê≠£Ë¶èÂåñÈö£Êé•Ë°åÂàó $\hat{A} = \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2}$ „ÇíË®àÁÆó
3. GCNÂá∫Âäõ $H = \hat{A} X W$ „ÇíË®àÁÆóÔºàÊ¥ªÊÄßÂåñÈñ¢Êï∞„Å™„ÅóÔºâ

<details>
<summary>„Éí„É≥„Éà</summary>

<strong>ÊâãÈ†Ü</strong>:
1. Ëá™Â∑±„É´„Éº„Éó„ÇíËøΩÂä†: $\tilde{A}_{ii} = 1$
2. Ê¨°Êï∞Ë°åÂàó: $\tilde{D}_{ii} = \sum_j \tilde{A}_{ij}$
3. $\tilde{D}^{-1/2}$ „ÇíË®àÁÆóÔºàÂØæËßíË¶ÅÁ¥†„ÅÆÈÄÜÊï∞„ÅÆÂπ≥ÊñπÊ†πÔºâ
4. Ë°åÂàóÁ©ç„ÇíË®àÁÆó

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<strong>Step 1: Ëá™Â∑±„É´„Éº„Éó‰ªò„ÅçÈö£Êé•Ë°åÂàó</strong>
$$
\tilde{A} = A + I = \begin{bmatrix}
0 & 1 & 0 \\
1 & 0 & 1 \\
0 & 1 & 0
\end{bmatrix} + \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix} = \begin{bmatrix}
1 & 1 & 0 \\
1 & 1 & 1 \\
0 & 1 & 1
\end{bmatrix}
$$

<strong>Step 2: Ê¨°Êï∞Ë°åÂàó</strong>
$$
\tilde{D} = \begin{bmatrix}
2 & 0 & 0 \\
0 & 3 & 0 \\
0 & 0 & 2
\end{bmatrix}
$$

ÔºàÂêÑË°å„ÅÆÂíåÔºâ

<strong>Step 3: $\tilde{D}^{-1/2}$</strong>
$$
\tilde{D}^{-1/2} = \begin{bmatrix}
1/\sqrt{2} & 0 & 0 \\
0 & 1/\sqrt{3} & 0 \\
0 & 0 & 1/\sqrt{2}
\end{bmatrix} \approx \begin{bmatrix}
0.707 & 0 & 0 \\
0 & 0.577 & 0 \\
0 & 0 & 0.707
\end{bmatrix}
$$

<strong>Step 4: Ê≠£Ë¶èÂåñÈö£Êé•Ë°åÂàó</strong>
$$
\hat{A} = \tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2}
$$

Ë®àÁÆóÈÅéÁ®ã:
<pre><code class="language-python">import numpy as np

A_tilde = np.array([
    [1, 1, 0],
    [1, 1, 1],
    [0, 1, 1]
], dtype=float)

D_tilde = np.diag([2, 3, 2])
D_inv_sqrt = np.diag([1/np.sqrt(2), 1/np.sqrt(3), 1/np.sqrt(2)])

A_hat = D_inv_sqrt @ A_tilde @ D_inv_sqrt
print("Ê≠£Ë¶èÂåñÈö£Êé•Ë°åÂàó:")
print(A_hat)</code></pre>

$$
\hat{A} \approx \begin{bmatrix}
0.500 & 0.408 & 0 \\
0.408 & 0.333 & 0.408 \\
0 & 0.408 & 0.500
\end{bmatrix}
$$

<strong>Step 5: GCNÂá∫Âäõ</strong>
$$
H = \hat{A} X W
$$

Ôºà$W = I$ „Å™„ÅÆ„Åß $H = \hat{A} X$Ôºâ

<pre><code class="language-python">X = np.array([
    [1, 0],
    [0, 1],
    [1, 1]
], dtype=float)

H = A_hat @ X
print("GCNÂá∫Âäõ:")
print(H)</code></pre>

$$
H \approx \begin{bmatrix}
0.500 & 0.408 \\
0.816 & 0.741 \\
0.408 & 0.908
\end{bmatrix}
$$

<strong>Ëß£Èáà</strong>:
- È†ÇÁÇπ1Ôºà‰∏≠ÂøÉÔºâ: ‰∏°ÂÅ¥„ÅÆÈö£Êé•È†ÇÁÇπ„ÅÆÊÉÖÂ†±„ÇíÈõÜÁ¥Ñ
- È†ÇÁÇπ0,2ÔºàÁ´ØÁÇπÔºâ: Èö£Êé•È†ÇÁÇπ1„ÅÆÊÉÖÂ†±„Çí‰∏ª„Å´Âèñ„ÇäËæº„ÇÄ

<strong>Python„Åß„ÅÆÊ§úË®º</strong>:
<pre><code class="language-python"><h1>ÂÆåÂÖ®„Å™„Ç≥„Éº„Éâ</h1>
A = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]], dtype=float)
X = np.array([[1, 0], [0, 1], [1, 1]], dtype=float)

<h1>GCN</h1>
A_tilde = A + np.eye(3)
D_tilde = np.diag(A_tilde.sum(axis=1))
D_inv_sqrt = np.diag(1.0 / np.sqrt(D_tilde.diagonal()))
A_hat = D_inv_sqrt @ A_tilde @ D_inv_sqrt

H = A_hat @ X
print("ÊúÄÁµÇÂá∫Âäõ:")
print(H)</code></pre>

</details>

---

<h3>ÂïèÈ°å3ÔºàÈõ£ÊòìÂ∫¶ÔºöhardÔºâ</h3>

SchNet„ÅÆÈÄ£Á∂ö„Éï„Ç£„É´„ÇøÈñ¢Êï∞„ÇíÂÆüË£Ö„Åó„ÄÅÁï∞„Å™„ÇãÂéüÂ≠êÈñìË∑ùÈõ¢„Å´ÂØæ„Åô„Çã„Éï„Ç£„É´„Çø„ÅÆÂøúÁ≠î„ÇíÂèØË¶ñÂåñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

<strong>Ë¶ÅÊ±Ç‰∫ãÈ†Ö</strong>:
1. „Ç¨„Ç¶„ÇπÂü∫Â∫ïÔºàRBFÔºâÈñ¢Êï∞„ÇíÂÆüË£Ö
2. Ë∑ùÈõ¢0.5√Ö„Äú5.0√Ö„Å´ÂØæ„Åô„ÇãRBFÂøúÁ≠î„ÇíË®àÁÆó
3. „Éí„Éº„Éà„Éû„ÉÉ„Éó„ÅßÂèØË¶ñÂåñ
4. „Éï„Ç£„É´„Çø„ÅÆÁâ©ÁêÜÁöÑÊÑèÂë≥„ÇíËÄÉÂØü

<details>
<summary>„Éí„É≥„Éà</summary>

<strong>RBF „ÅÆÂºè</strong>:
$$\phi_k(d) = \exp\left( -\gamma (d - \mu_k)^2 \right)$$

- $\mu_k$: „Ç¨„Ç¶„ÇπÈñ¢Êï∞„ÅÆ‰∏≠ÂøÉÔºà0„Äú5√Ö„Å´ÂùáÁ≠âÈÖçÁΩÆÔºâ
- $\gamma$: Â∫É„Åå„Çä„Éë„É©„É°„Éº„ÇøÔºà10Á®ãÂ∫¶Ôºâ

<strong>ÂèØË¶ñÂåñ„ÅÆ„Éù„Ç§„É≥„Éà</strong>:
- XËª∏: Ë∑ùÈõ¢ (0.5„Äú5.0√Ö)
- YËª∏: RBF „Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ (0„Äú49)
- Ëâ≤: RBF ÂøúÁ≠îÂÄ§ (0„Äú1)

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<pre><code class="language-python">import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

<h1>===== ÂÆüË£Ö =====</h1>
class GaussianBasisFunction:
    def __init__(self, start=0.0, stop=5.0, num_gaussians=50,
                 gamma=10.0):
        """
        „Ç¨„Ç¶„ÇπÂü∫Â∫ïÈñ¢Êï∞ÔºàRBFÔºâ

        Parameters:
        -----------
        start, stop : float
            Ë∑ùÈõ¢„ÅÆÁØÑÂõ≤
        num_gaussians : int
            „Ç¨„Ç¶„ÇπÈñ¢Êï∞„ÅÆÊï∞
        gamma : float
            Â∫É„Åå„Çä„Éë„É©„É°„Éº„Çø
        """
        self.mu = torch.linspace(start, stop, num_gaussians)
        self.gamma = gamma

    def __call__(self, distances):
        """
        RBF ÂøúÁ≠î„ÇíË®àÁÆó

        Parameters:
        -----------
        distances : Tensor (num_distances,)

        Returns:
        --------
        rbf : Tensor (num_distances, num_gaussians)
        """
        # (num_distances, 1) - (1, num_gaussians)
        diff = distances.unsqueeze(-1) - self.mu.unsqueeze(0)
        rbf = torch.exp(-self.gamma * diff ** 2)
        return rbf

<h1>===== ÂèØË¶ñÂåñ =====</h1>
<h1>RBFÁîüÊàê</h1>
rbf_layer = GaussianBasisFunction(
    start=0.0, stop=5.0,
    num_gaussians=50, gamma=10.0
)

<h1>Ë∑ùÈõ¢„Çµ„É≥„Éó„É´Ôºà0.5„Äú5.0√ÖÔºâ</h1>
distances = torch.linspace(0.5, 5.0, 100)

<h1>RBF ÂøúÁ≠î</h1>
rbf_response = rbf_layer(distances)  # (100, 50)

<h1>„Éí„Éº„Éà„Éû„ÉÉ„Éó</h1>
plt.figure(figsize=(12, 6))
sns.heatmap(
    rbf_response.T.numpy(),  # Ëª¢ÁΩÆÔºàRBF x Ë∑ùÈõ¢Ôºâ
    cmap='viridis',
    xticklabels=10,
    yticklabels=10,
    cbar_kws={'label': 'RBF Response'}
)
plt.xlabel('Distance (√Ö)')
plt.ylabel('RBF Index')
plt.title('SchNet Continuous Filter: RBF Response')

<h1>XËª∏„É©„Éô„É´„ÇíÂÆüÈöõ„ÅÆË∑ùÈõ¢„Å´</h1>
xticks = np.linspace(0, len(distances)-1, 10).astype(int)
xticklabels = [f'{distances[i]:.1f}' for i in xticks]
plt.xticks(xticks, xticklabels)

plt.tight_layout()
plt.savefig('schnet_rbf_heatmap.png', dpi=150)
plt.show()

<h1>===== ÁâπÂÆöË∑ùÈõ¢„ÅÆRBFÂøúÁ≠î =====</h1>
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
example_distances = [1.0, 1.5, 2.0, 3.0]  # √Ö

for ax, d in zip(axes.flatten(), example_distances):
    d_tensor = torch.tensor([d])
    rbf = rbf_layer(d_tensor).squeeze()

    ax.plot(rbf_layer.mu.numpy(), rbf.numpy(),
            marker='o', linewidth=2)
    ax.axvline(d, color='red', linestyle='--',
               label=f'Distance = {d}√Ö')
    ax.set_xlabel('RBF Center Œº (√Ö)')
    ax.set_ylabel('RBF Response')
    ax.set_title(f'RBF Response at d = {d}√Ö')
    ax.legend()
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('schnet_rbf_profiles.png', dpi=150)
plt.show()

<h1>===== Áâ©ÁêÜÁöÑÊÑèÂë≥„ÅÆËÄÉÂØü =====</h1>
print("\n===== Áâ©ÁêÜÁöÑÊÑèÂë≥ =====")
print("1. Áü≠Ë∑ùÈõ¢Ôºà0.5-2.0√ÖÔºâ: ÂÖ±ÊúâÁµêÂêàÈ†òÂüü")
print("   - C-C: 1.54√Ö, C=C: 1.34√Ö, C-H: 1.09√Ö")
print("   - RBF„ÅØÊÄ•Â≥ª„Å´ÂèçÂøúÔºàÁµêÂêà„ÅÆÊúâÁÑ°„ÇíË≠òÂà•Ôºâ")

print("\n2. ‰∏≠Ë∑ùÈõ¢Ôºà2.0-3.5√ÖÔºâ: ÈùûÂÖ±ÊúâÁµêÂêàÁõ∏‰∫í‰ΩúÁî®")
print("   - Ê∞¥Á¥†ÁµêÂêà: 2.8√Ö, „Éï„Ç°„É≥„Éá„É´„ÉØ„Éº„É´„ÇπÂäõ")
print("   - RBF„ÅØ„Å™„Å†„Çâ„Åã„Å´ÂèçÂøú")

print("\n3. Èï∑Ë∑ùÈõ¢Ôºà3.5-5.0√ÖÔºâ: Âº±„ÅÑÁõ∏‰∫í‰ΩúÁî®")
print("   - ÈùôÈõªÁõ∏‰∫í‰ΩúÁî®„ÄÅÂàÜÊï£Âäõ")
print("   - RBF„ÅÆÂøúÁ≠î„ÅØÂ∞è„Åï„ÅÑ")

print("\n4. „Ç¨„Ç¶„ÇπÂü∫Â∫ï„ÅÆÂΩπÂâ≤:")
print("   - ÈÄ£Á∂öÁöÑ„Å™Ë∑ùÈõ¢Ë°®ÁèæÔºàÈõ¢Êï£Âåñ„Å™„ÅóÔºâ")
print("   - ‰ªªÊÑè„ÅÆË∑ùÈõ¢„Å´ÂØæ„Åó„Å¶ÂæÆÂàÜÂèØËÉΩ")
print("   - Ê©üÊ¢∞Â≠¶Áøí„ÅßÊúÄÈÅ©ÂåñÂèØËÉΩÔºàŒ≥„Éë„É©„É°„Éº„ÇøÔºâ")</code></pre>

<strong>Âá∫Âäõ„ÅÆËß£Èáà</strong>:

1. <strong>„Éí„Éº„Éà„Éû„ÉÉ„Éó</strong>:
   - ÂØæËßíÁ∑öÁä∂„ÅÆ„Éë„Çø„Éº„É≥ÔºàÂêÑRBF„ÅåÁâπÂÆöË∑ùÈõ¢„ÅßÊúÄÂ§ßÂøúÁ≠îÔºâ
   - Êªë„Çâ„Åã„Å™ÈÅ∑ÁßªÔºà„Ç¨„Ç¶„ÇπÈñ¢Êï∞„ÅÆÈáç„Å™„ÇäÔºâ

2. <strong>RBF„Éó„É≠„Éï„Ç°„Ç§„É´</strong>:
   - Ë∑ùÈõ¢1.0√Ö: RBF #10‰ªòËøë„ÅåÂº∑„ÅèÂèçÂøú
   - Ë∑ùÈõ¢2.0√Ö: RBF #20‰ªòËøë„ÅåÂº∑„ÅèÂèçÂøú
   - „Ç¨„Ç¶„ÇπÂΩ¢Áä∂„Å´„Çà„Çä„ÄÅÈö£Êé•RBF„ÇÇÂº±„ÅèÂèçÂøú

3. <strong>Áâ©ÁêÜÁöÑÊÑèÂë≥</strong>:
   - <strong>SchNet„ÅØË∑ùÈõ¢„Çí„ÄåÂàÜÂ∏É„Äç„Å®„Åó„Å¶Ë°®Áèæ</strong>
   - Èõ¢Êï£ÁöÑ„Å™„Éì„É≥ÂàÜ„Åë„Åß„ÅØ„Å™„Åè„ÄÅÈÄ£Á∂öÁöÑ„Å™Èáç„Å™„Çä
   - „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅåË∑ùÈõ¢‰æùÂ≠òÊÄß„ÇíÂ≠¶Áøí

<strong>Êã°ÂºµË™≤È°å</strong>:
1. $\gamma$ „Éë„É©„É°„Éº„Çø„ÇíÂ§â„Åà„Å¶„ÄÅRBF„ÅÆÂ∫É„Åå„Çä„ÇíË™øÊï¥
2. ÈùûÂØæÁß∞„Å™„Ç¨„Ç¶„ÇπÂü∫Â∫ïÔºàÁü≠Ë∑ùÈõ¢„ÇíÂØÜ„Å´„ÄÅÈï∑Ë∑ùÈõ¢„ÇíÁñé„Å´Ôºâ
3. ÂÆüÈöõ„ÅÆÂàÜÂ≠ê„ÅßRBF„Éï„Ç£„É´„Çø„ÇíÂèØË¶ñÂåñ

</details>

---

<h2>ÂèÇËÄÉÊñáÁåÆ</h2>

1. Kipf, T. N. & Welling, M. (2017). "Semi-Supervised Classification with Graph Convolutional Networks." *ICLR*.
   DOI: [https://arxiv.org/abs/1609.02907](https://arxiv.org/abs/1609.02907)

2. Veliƒçkoviƒá, P. et al. (2018). "Graph Attention Networks." *ICLR*.
   DOI: [https://arxiv.org/abs/1710.10903](https://arxiv.org/abs/1710.10903)

3. Hamilton, W. L. et al. (2017). "Inductive Representation Learning on Large Graphs." *NeurIPS*.
   DOI: [https://arxiv.org/abs/1706.02216](https://arxiv.org/abs/1706.02216)

4. Sch√ºtt, K. T. et al. (2017). "SchNet: A continuous-filter convolutional neural network for modeling quantum interactions." *NeurIPS*.
   DOI: [https://arxiv.org/abs/1706.08566](https://arxiv.org/abs/1706.08566)

5. Klicpera, J. et al. (2020). "Directional Message Passing for Molecular Graphs." *ICLR*.
   DOI: [https://arxiv.org/abs/2003.03123](https://arxiv.org/abs/2003.03123)

6. Gasteiger, J. et al. (2021). "GemNet: Universal Directional Graph Neural Networks for Molecules." *NeurIPS*.
   DOI: [https://arxiv.org/abs/2106.08903](https://arxiv.org/abs/2106.08903)

7. Batzner, S. et al. (2022). "E(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials." *Nature Communications*, 13, 2453.
   DOI: [https://doi.org/10.1038/s41467-022-29939-5](https://doi.org/10.1038/s41467-022-29939-5)

---

<h2>„Éä„Éì„Ç≤„Éº„Ç∑„Éß„É≥</h2>

<h3>Ââç„ÅÆÁ´†</h3>
<strong>[Á¨¨1Á´†Ôºö„Å™„ÅúÊùêÊñôÁßëÂ≠¶„Å´GNN„ÅåÂøÖË¶Å„Åã ‚Üê](./chapter-1.md)</strong>

<h3>Ê¨°„ÅÆÁ´†</h3>
<strong>[Á¨¨3Á´†ÔºöPyTorch GeometricÂÆüË∑µ ‚Üí](./chapter-3.md)</strong>

<h3>„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°</h3>
<strong>[‚Üê „Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã](./index.md)</strong>

---

<h2>ËëóËÄÖÊÉÖÂ†±</h2>

<strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team
<strong>Áõ£‰øÆ</strong>: Dr. Yusuke HashimotoÔºàÊù±ÂåóÂ§ßÂ≠¶Ôºâ
<strong>‰ΩúÊàêÊó•</strong>: 2025-10-17
<strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0

<strong>Êõ¥Êñ∞Â±•Ê≠¥</strong>:
- 2025-10-17: v1.0 ÂàùÁâàÂÖ¨Èñã

<strong>„Éï„Ç£„Éº„Éâ„Éê„ÉÉ„ÇØ</strong>:
- GitHub Issues: [„É™„Éù„Ç∏„Éà„É™URL]/issues
- Email: yusuke.hashimoto.b8@tohoku.ac.jp

<strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0

---

<strong>Á¨¨3Á´†„Åß„ÄÅÂÆüÈöõ„Å´GNN„ÇíÂãï„Åã„Åó„Å¶„Åø„Åæ„Åó„Çá„ÅÜÔºÅ</strong>
<div class="navigation">
    <a href="chapter-1.html" class="nav-button">‚Üê Á¨¨1Á´†</a>
    <a href="index.html" class="nav-button">„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã</a>
    <a href="chapter-3.html" class="nav-button">Á¨¨3Á´† ‚Üí</a>
</div>
    </main>

    <footer>
        <p><strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team</p>
        <p><strong>Áõ£‰øÆ</strong>: Dr. Yusuke HashimotoÔºàÊù±ÂåóÂ§ßÂ≠¶Ôºâ</p>
        <p><strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0 | <strong>‰ΩúÊàêÊó•</strong>: 2025-10-17</p>
        <p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0</p>
        <p>¬© 2025 AI Terakoya. All rights reserved.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default'
                });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</body>
</html>
