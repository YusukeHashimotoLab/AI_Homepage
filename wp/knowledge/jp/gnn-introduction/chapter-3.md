---
title: "ç¬¬3ç« ï¼šPyTorch Geometricå®Ÿè·µ - åˆ†å­ãƒ»ææ–™ç‰¹æ€§äºˆæ¸¬ã®å®Ÿè£…"
subtitle: "å®Ÿãƒ‡ãƒ¼ã‚¿ã§å­¦ã¶ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ§‹ç¯‰ã¨è©•ä¾¡"
level: "intermediate"
difficulty: "ä¸­ç´š"
target_audience: "undergraduate-graduate"
estimated_time: "25-30åˆ†"
learning_objectives:
  - PyTorch Geometricç’°å¢ƒã‚’æ§‹ç¯‰ã—ã€GNNãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã„ã“ãªã›ã‚‹
  - QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§åˆ†å­ç‰¹æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã§ãã‚‹
  - Materials Projectãƒ‡ãƒ¼ã‚¿ã§çµæ™¶ç‰¹æ€§äºˆæ¸¬ã‚’å®Ÿè¡Œã§ãã‚‹
  - ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’é©ç”¨ã§ãã‚‹
  - äºˆæ¸¬çµæœã‚’å¯è¦–åŒ–ã—ã€æ€§èƒ½ã‚’è©•ä¾¡ã§ãã‚‹
topics: ["pytorch-geometric", "graph-neural-networks", "molecular-property-prediction", "materials-prediction", "qm9"]
prerequisites: ["ç¬¬1ç« ï¼šGNNå…¥é–€", "ç¬¬2ç« ï¼šGNNåŸºç¤ç†è«–", "PythonåŸºç¤", "PyTorchåŸºç¤"]
series: "GNNå…¥é–€ã‚·ãƒªãƒ¼ã‚º v1.0"
series_order: 3
version: "1.0"
created_at: "2025-10-17"
template_version: "2.0"
---

# ç¬¬3ç« ï¼šPyTorch Geometricå®Ÿè·µ - åˆ†å­ãƒ»ææ–™ç‰¹æ€§äºˆæ¸¬ã®å®Ÿè£…

## å­¦ç¿’ç›®æ¨™

ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š
- PyTorch Geometricç’°å¢ƒã‚’æ§‹ç¯‰ã—ã€GNNãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã„ã“ãªã›ã‚‹
- QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§åˆ†å­ç‰¹æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã§ãã‚‹
- Materials Projectãƒ‡ãƒ¼ã‚¿ã§çµæ™¶ç‰¹æ€§äºˆæ¸¬ã‚’å®Ÿè¡Œã§ãã‚‹
- ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’é©ç”¨ã§ãã‚‹
- äºˆæ¸¬çµæœã‚’å¯è¦–åŒ–ã—ã€æ€§èƒ½ã‚’è©•ä¾¡ã§ãã‚‹

**èª­äº†æ™‚é–“**: 25-30åˆ†
**ã‚³ãƒ¼ãƒ‰ä¾‹**: 10å€‹
**æ¼”ç¿’å•é¡Œ**: 3å•

---

## 3.1 ç’°å¢ƒæ§‹ç¯‰ï¼šPyTorch Geometricã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

### 3.1.1 PyTorch Geometricã¨ã¯

**PyTorch Geometric (PyG)**ã¯ã€PyTorchä¸Šã§å‹•ä½œã™ã‚‹ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å°‚ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚

**ä¸»ãªç‰¹å¾´**:
- ğŸš€ **é«˜é€Ÿ**: GPUã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªã‚°ãƒ©ãƒ•å‡¦ç†
- ğŸ“¦ **è±Šå¯Œãªãƒ¢ãƒ‡ãƒ«**: GCNã€GATã€GraphSAGEã€SchNetãªã©30ç¨®é¡ä»¥ä¸Š
- ğŸ§ª **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: QM9ã€ZINCã€OGBï¼ˆOpen Graph Benchmarkï¼‰ãŒçµ„ã¿è¾¼ã¿æ¸ˆã¿
- ğŸ› ï¸ **æŸ”è»Ÿæ€§**: ã‚«ã‚¹ã‚¿ãƒ ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚„ãƒ¢ãƒ‡ãƒ«ã‚’ç°¡å˜ã«å®Ÿè£…å¯èƒ½

### 3.1.2 ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †

**Option 1: Condaç’°å¢ƒï¼ˆæ¨å¥¨ï¼‰**

```bash
# 1. Python 3.9ä»¥ä¸Šã®ç’°å¢ƒã‚’ä½œæˆ
conda create -n gnn-env python=3.10
conda activate gnn-env

# 2. PyTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆCUDAç‰ˆæ¨å¥¨ï¼‰
# CPUç‰ˆã®å ´åˆ:
conda install pytorch torchvision torchaudio cpuonly -c pytorch

# GPUç‰ˆã®å ´åˆï¼ˆCUDA 11.8ï¼‰:
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

# 3. PyTorch Geometricã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
conda install pyg -c pyg

# 4. è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install rdkit matplotlib seaborn pandas scikit-learn
```

**Option 2: pipã§ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**

```bash
# 1. ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆ
python -m venv gnn-env
source gnn-env/bin/activate  # macOS/Linux
# gnn-env\Scripts\activate  # Windows

# 2. PyTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install torch torchvision torchaudio

# 3. PyTorch Geometricã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install torch-geometric

# 4. ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-2.0.0+cpu.html

# 5. è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install rdkit matplotlib seaborn pandas scikit-learn
```

**Option 3: Google Colabï¼ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸è¦ï¼‰**

```python
# Google Colabã§ã¯ä»¥ä¸‹ã‚’å®Ÿè¡Œ
!pip install torch-geometric
!pip install rdkit
```

### 3.1.3 ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª

```python
import torch
import torch_geometric
from torch_geometric.data import Data
from rdkit import Chem
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

print("===== ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª =====")
print(f"PyTorch version: {torch.__version__}")
print(f"PyTorch Geometric version: {torch_geometric.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA version: {torch.version.cuda}")
    print(f"GPU: {torch.cuda.get_device_name(0)}")

# ç°¡å˜ãªã‚°ãƒ©ãƒ•ã‚’ä½œæˆã—ã¦ãƒ†ã‚¹ãƒˆ
edge_index = torch.tensor([[0, 1, 1, 2],
                           [1, 0, 2, 1]], dtype=torch.long)
x = torch.tensor([[-1], [0], [1]], dtype=torch.float)
data = Data(x=x, edge_index=edge_index)

print(f"\nãƒ†ã‚¹ãƒˆã‚°ãƒ©ãƒ•ä½œæˆæˆåŠŸ!")
print(f"ãƒãƒ¼ãƒ‰æ•°: {data.num_nodes}")
print(f"ã‚¨ãƒƒã‚¸æ•°: {data.num_edges}")
print("âœ… PyTorch Geometricç’°å¢ƒã®æ§‹ç¯‰å®Œäº†!")
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:
```
===== ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª =====
PyTorch version: 2.0.0
PyTorch Geometric version: 2.3.0
CUDA available: True
CUDA version: 11.8
GPU: NVIDIA GeForce RTX 3090

ãƒ†ã‚¹ãƒˆã‚°ãƒ©ãƒ•ä½œæˆæˆåŠŸ!
ãƒãƒ¼ãƒ‰æ•°: 3
ã‚¨ãƒƒã‚¸æ•°: 4
âœ… PyTorch Geometricç’°å¢ƒã®æ§‹ç¯‰å®Œäº†!
```

### 3.1.4 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

| ã‚¨ãƒ©ãƒ¼ | åŸå›  | è§£æ±ºæ–¹æ³• |
|--------|------|----------|
| `ImportError: No module named 'torch_geometric'` | PyGæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« | `pip install torch-geometric` |
| `OSError: [WinError 126] DLLèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼` (Windows) | C++å†é ’å¸ƒå¯èƒ½ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¸è¶³ | Microsoft Visual C++ Redistributableã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« |
| `RuntimeError: CUDA out of memory` | GPU ãƒ¡ãƒ¢ãƒªä¸è¶³ | ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å‰Šæ¸›ã€CPUç‰ˆPyTorchä½¿ç”¨ |
| `ImportError: cannot import name 'Data'` | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸ä¸€è‡´ | PyTorchã¨PyGã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèª |

---

## 3.2 PyTorch Geometricã®åŸºæœ¬ï¼šãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¨DataLoader

### 3.2.1 Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹é€ 

PyTorch Geometricã§ã¯ã€ã‚°ãƒ©ãƒ•ã‚’`Data`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§è¡¨ç¾ã—ã¾ã™ã€‚

```python
from torch_geometric.data import Data
import torch

# ã‚¨ã‚¿ãƒãƒ¼ãƒ«åˆ†å­ (C2H5OH) ã‚’ã‚°ãƒ©ãƒ•ã§è¡¨ç¾
# C: ç‚­ç´ ï¼ˆãƒãƒ¼ãƒ‰0, 1ï¼‰
# O: é…¸ç´ ï¼ˆãƒãƒ¼ãƒ‰2ï¼‰
# H: æ°´ç´ ï¼ˆãƒãƒ¼ãƒ‰3-7ï¼‰

# ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆåŸå­ç•ªå·ã‚’ä½¿ç”¨ï¼‰
x = torch.tensor([
    [6],   # C (ç‚­ç´ )
    [6],   # C (ç‚­ç´ )
    [8],   # O (é…¸ç´ )
    [1],   # H (æ°´ç´ )
    [1],   # H (æ°´ç´ )
    [1],   # H (æ°´ç´ )
    [1],   # H (æ°´ç´ )
    [1],   # H (æ°´ç´ )
], dtype=torch.float)

# ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆçµåˆé–¢ä¿‚ï¼‰
# å„çµåˆã¯åŒæ–¹å‘ï¼ˆç„¡å‘ã‚°ãƒ©ãƒ•ï¼‰
edge_index = torch.tensor([
    [0, 1, 1, 0, 0, 2, 2, 0, 0, 3, 3, 0, 1, 4, 4, 1, 1, 5, 5, 1, 2, 6, 6, 2],
    [1, 0, 2, 2, 3, 0, 0, 3, 4, 1, 1, 4, 5, 1, 1, 5, 6, 2, 2, 6, 7, 2, 2, 7]
], dtype=torch.long)

# ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆçµåˆã‚¿ã‚¤ãƒ—: 1=å˜çµåˆï¼‰
edge_attr = torch.ones(edge_index.size(1), 1)

# åˆ†å­ãƒ¬ãƒ™ãƒ«ã®ç‰¹å¾´ï¼ˆç›®çš„å¤‰æ•°ï¼‰
y = torch.tensor([[156.0]], dtype=torch.float)  # æ²¸ç‚¹ (Â°C)

# Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
ethanol = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)

print("===== ã‚¨ã‚¿ãƒãƒ¼ãƒ«åˆ†å­ã®ã‚°ãƒ©ãƒ•è¡¨ç¾ =====")
print(f"ãƒãƒ¼ãƒ‰æ•°ï¼ˆåŸå­æ•°ï¼‰: {ethanol.num_nodes}")
print(f"ã‚¨ãƒƒã‚¸æ•°ï¼ˆçµåˆæ•°Ã—2ï¼‰: {ethanol.num_edges}")
print(f"ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®å½¢çŠ¶: {ethanol.x.shape}")
print(f"ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å½¢çŠ¶: {ethanol.edge_index.shape}")
print(f"ç›®çš„å¤‰æ•°ï¼ˆæ²¸ç‚¹ï¼‰: {ethanol.y.item()} Â°C")

# ã‚°ãƒ©ãƒ•ã®åŸºæœ¬çµ±è¨ˆ
print(f"\n===== ã‚°ãƒ©ãƒ•ã®çµ±è¨ˆæƒ…å ± =====")
print(f"å¹³å‡æ¬¡æ•°ï¼ˆçµåˆæ•°ï¼‰: {ethanol.num_edges / ethanol.num_nodes:.2f}")
print(f"å­¤ç«‹ãƒãƒ¼ãƒ‰: {ethanol.contains_isolated_nodes()}")
print(f"è‡ªå·±ãƒ«ãƒ¼ãƒ—: {ethanol.contains_self_loops()}")
```

**å‡ºåŠ›**:
```
===== ã‚¨ã‚¿ãƒãƒ¼ãƒ«åˆ†å­ã®ã‚°ãƒ©ãƒ•è¡¨ç¾ =====
ãƒãƒ¼ãƒ‰æ•°ï¼ˆåŸå­æ•°ï¼‰: 8
ã‚¨ãƒƒã‚¸æ•°ï¼ˆçµåˆæ•°Ã—2ï¼‰: 24
ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®å½¢çŠ¶: torch.Size([8, 1])
ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å½¢çŠ¶: torch.Size([2, 24])
ç›®çš„å¤‰æ•°ï¼ˆæ²¸ç‚¹ï¼‰: 156.0 Â°C

===== ã‚°ãƒ©ãƒ•ã®çµ±è¨ˆæƒ…å ± =====
å¹³å‡æ¬¡æ•°ï¼ˆçµåˆæ•°ï¼‰: 3.00
å­¤ç«‹ãƒãƒ¼ãƒ‰: False
è‡ªå·±ãƒ«ãƒ¼ãƒ—: False
```

### 3.2.2 RDKitã‹ã‚‰ã‚°ãƒ©ãƒ•ã¸ã®å¤‰æ›

RDKitã¯SMILESï¼ˆåˆ†å­ã®æ–‡å­—åˆ—è¡¨ç¾ï¼‰ã‹ã‚‰åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã§ãã¾ã™ã€‚

```python
from rdkit import Chem
from rdkit.Chem import Draw
from torch_geometric.data import Data
import torch

def mol_to_graph(smiles):
    """
    SMILESæ–‡å­—åˆ—ã‹ã‚‰PyTorch Geometricã®Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ

    Parameters:
    -----------
    smiles : str
        åˆ†å­ã®SMILESè¡¨ç¾

    Returns:
    --------
    data : torch_geometric.data.Data
        ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿
    """
    # SMILESã‹ã‚‰åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None

    # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆåŸå­ã®ç‰¹æ€§ï¼‰
    atom_features = []
    for atom in mol.GetAtoms():
        # åŸå­ç•ªå·ã‚’ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆC, N, O, F, ãã®ä»–ï¼‰
        atom_type = [0] * 5
        if atom.GetAtomicNum() == 6:    # C
            atom_type[0] = 1
        elif atom.GetAtomicNum() == 7:  # N
            atom_type[1] = 1
        elif atom.GetAtomicNum() == 8:  # O
            atom_type[2] = 1
        elif atom.GetAtomicNum() == 9:  # F
            atom_type[3] = 1
        else:
            atom_type[4] = 1

        # å½¢å¼é›»è·ã¨èŠ³é¦™æ—æ€§ã‚’è¿½åŠ 
        formal_charge = atom.GetFormalCharge()
        is_aromatic = int(atom.GetIsAromatic())

        atom_features.append(atom_type + [formal_charge, is_aromatic])

    x = torch.tensor(atom_features, dtype=torch.float)

    # ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆçµåˆé–¢ä¿‚ï¼‰
    edge_indices = []
    for bond in mol.GetBonds():
        i = bond.GetBeginAtomIdx()
        j = bond.GetEndAtomIdx()
        edge_indices += [[i, j], [j, i]]  # ç„¡å‘ã‚°ãƒ©ãƒ•ãªã®ã§åŒæ–¹å‘

    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()

    data = Data(x=x, edge_index=edge_index)
    return data, mol

# ãƒ†ã‚¹ãƒˆ: ã„ãã¤ã‹ã®åˆ†å­ã‚’ã‚°ãƒ©ãƒ•ã«å¤‰æ›
smiles_list = [
    ("C", "ãƒ¡ã‚¿ãƒ³"),
    ("CCO", "ã‚¨ã‚¿ãƒãƒ¼ãƒ«"),
    ("c1ccccc1", "ãƒ™ãƒ³ã‚¼ãƒ³"),
    ("CC(=O)O", "é…¢é…¸"),
]

print("===== SMILESã‹ã‚‰ã‚°ãƒ©ãƒ•ã¸ã®å¤‰æ› =====")
for smiles, name in smiles_list:
    data, mol = mol_to_graph(smiles)
    print(f"\n{name} ({smiles}):")
    print(f"  ãƒãƒ¼ãƒ‰æ•°: {data.num_nodes}")
    print(f"  ã‚¨ãƒƒã‚¸æ•°: {data.num_edges}")
    print(f"  ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡æ¬¡å…ƒ: {data.x.shape[1]}")

# åˆ†å­æ§‹é€ ã®å¯è¦–åŒ–
import matplotlib.pyplot as plt
from rdkit.Chem import Draw

fig, axes = plt.subplots(1, 4, figsize=(16, 4))
for i, (smiles, name) in enumerate(smiles_list):
    _, mol = mol_to_graph(smiles)
    img = Draw.MolToImage(mol, size=(300, 300))
    axes[i].imshow(img)
    axes[i].set_title(f"{name}\n{smiles}", fontsize=12)
    axes[i].axis('off')

plt.tight_layout()
plt.show()
```

### 3.2.3 DataLoaderã®ä½¿ç”¨

è¤‡æ•°ã®ã‚°ãƒ©ãƒ•ã‚’ãƒãƒƒãƒå‡¦ç†ã™ã‚‹ã«ã¯`DataLoader`ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

```python
from torch_geometric.data import Data, DataLoader
import torch

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆï¼ˆ10å€‹ã®åˆ†å­ï¼‰
dataset = []
for i in range(10):
    num_nodes = torch.randint(5, 15, (1,)).item()  # 5-14åŸå­
    x = torch.randn(num_nodes, 7)  # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆ7æ¬¡å…ƒï¼‰

    # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚¨ãƒƒã‚¸ã‚’ç”Ÿæˆ
    edge_index = torch.randint(0, num_nodes, (2, num_nodes * 2))

    # ç›®çš„å¤‰æ•°ï¼ˆä¾‹: HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—ï¼‰
    y = torch.randn(1)

    data = Data(x=x, edge_index=edge_index, y=y)
    dataset.append(data)

# DataLoaderã‚’ä½œæˆï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚º=4ï¼‰
loader = DataLoader(dataset, batch_size=4, shuffle=True)

print("===== DataLoaderã®ä½¿ç”¨ =====")
print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: {len(dataset)}")
print(f"ãƒãƒƒãƒæ•°: {len(loader)}")

# æœ€åˆã®ãƒãƒƒãƒã‚’ç¢ºèª
for batch in loader:
    print(f"\næœ€åˆã®ãƒãƒƒãƒ:")
    print(f"  ãƒãƒƒãƒå†…ã®åˆ†å­æ•°: {batch.num_graphs}")
    print(f"  ç·ãƒãƒ¼ãƒ‰æ•°: {batch.num_nodes}")
    print(f"  ç·ã‚¨ãƒƒã‚¸æ•°: {batch.num_edges}")
    print(f"  ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®å½¢çŠ¶: {batch.x.shape}")
    print(f"  ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {batch.batch}")
    print(f"  ç›®çš„å¤‰æ•°ã®å½¢çŠ¶: {batch.y.shape}")
    break
```

**å‡ºåŠ›ä¾‹**:
```
===== DataLoaderã®ä½¿ç”¨ =====
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: 10
ãƒãƒƒãƒæ•°: 3

æœ€åˆã®ãƒãƒƒãƒ:
  ãƒãƒƒãƒå†…ã®åˆ†å­æ•°: 4
  ç·ãƒãƒ¼ãƒ‰æ•°: 38
  ç·ã‚¨ãƒƒã‚¸æ•°: 76
  ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®å½¢çŠ¶: torch.Size([38, 7])
  ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: tensor([0, 0, 0, ..., 3, 3, 3])
  ç›®çš„å¤‰æ•°ã®å½¢çŠ¶: torch.Size([4, 1])
```

**é‡è¦**: `batch`ãƒ†ãƒ³ã‚½ãƒ«ã¯å„ãƒãƒ¼ãƒ‰ãŒã©ã®åˆ†å­ã«å±ã™ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ï¼ˆ0, 0, 0, 1, 1, 2, 2, 2, 3, ...ï¼‰ã€‚

---

## 3.3 QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§åˆ†å­ç‰¹æ€§äºˆæ¸¬

### 3.3.1 QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¦‚è¦

**QM9**ã¯134,000å€‹ã®æœ‰æ©Ÿå°åˆ†å­ã®é‡å­åŒ–å­¦è¨ˆç®—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚

**å«ã¾ã‚Œã‚‹ç‰¹æ€§**:
- HOMOï¼ˆæœ€é«˜è¢«å è»Œé“ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰
- LUMOï¼ˆæœ€ä½éå è»Œé“ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰
- ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆHOMO-LUMOã‚®ãƒ£ãƒƒãƒ—ï¼‰
- åŒæ¥µå­ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ
- å†…éƒ¨ã‚¨ãƒãƒ«ã‚®ãƒ¼
- ã‚¨ãƒ³ã‚¿ãƒ«ãƒ”ãƒ¼ã€è‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼ã€ç†±å®¹é‡ãªã©

### 3.3.2 QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿

```python
from torch_geometric.datasets import QM9
import torch

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå›ã®ã¿ã€ç´„1GBï¼‰
dataset = QM9(root='./data/QM9')

print("===== QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ =====")
print(f"åˆ†å­æ•°: {len(dataset)}")
print(f"ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡æ¬¡å…ƒ: {dataset.num_node_features}")
print(f"ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡æ¬¡å…ƒ: {dataset.num_edge_features}")
print(f"ç›®çš„å¤‰æ•°æ•°: {dataset.num_classes}")

# æœ€åˆã®åˆ†å­ã‚’ç¢ºèª
data = dataset[0]
print(f"\næœ€åˆã®åˆ†å­:")
print(f"  åŸå­æ•°: {data.num_nodes}")
print(f"  çµåˆæ•°: {data.num_edges // 2}")
print(f"  ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡: {data.x.shape}")
print(f"  ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡: {data.edge_attr.shape}")
print(f"  ç›®çš„å¤‰æ•°ï¼ˆ19ç¨®é¡ï¼‰: {data.y.shape}")

# ç›®çš„å¤‰æ•°ã®ä¸€éƒ¨ã‚’è¡¨ç¤º
target_names = ['mu', 'alpha', 'homo', 'lumo', 'gap', 'r2', 'zpve',
                'U0', 'U', 'H', 'G', 'Cv']
print(f"\nä¸»è¦ãªç‰¹æ€§å€¤:")
for i, name in enumerate(target_names):
    print(f"  {name}: {data.y[0, i].item():.4f}")
```

### 3.3.3 Graph Convolutional Networkï¼ˆGCNï¼‰ã®å®Ÿè£…

```python
import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, global_mean_pool

class GCN_QM9(torch.nn.Module):
    """
    QM9åˆ†å­ç‰¹æ€§äºˆæ¸¬ç”¨ã®Graph Convolutional Network

    Architecture:
    - 3å±¤ã®GCNConv
    - Global mean pooling
    - 2å±¤ã®å…¨çµåˆå±¤
    """
    def __init__(self, num_node_features, num_classes, hidden_channels=64):
        super(GCN_QM9, self).__init__()

        # GCNå±¤
        self.conv1 = GCNConv(num_node_features, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.conv3 = GCNConv(hidden_channels, hidden_channels)

        # å…¨çµåˆå±¤
        self.lin1 = torch.nn.Linear(hidden_channels, hidden_channels // 2)
        self.lin2 = torch.nn.Linear(hidden_channels // 2, num_classes)

    def forward(self, x, edge_index, batch):
        """
        Parameters:
        -----------
        x : torch.Tensor (num_nodes, num_node_features)
            ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡
        edge_index : torch.Tensor (2, num_edges)
            ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        batch : torch.Tensor (num_nodes,)
            ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

        Returns:
        --------
        out : torch.Tensor (batch_size, num_classes)
            äºˆæ¸¬å€¤
        """
        # GCNå±¤1ï¼ˆç•³ã¿è¾¼ã¿ + æ´»æ€§åŒ– + ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆï¼‰
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.2, training=self.training)

        # GCNå±¤2
        x = self.conv2(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.2, training=self.training)

        # GCNå±¤3
        x = self.conv3(x, edge_index)
        x = F.relu(x)

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã‚’åˆ†å­ãƒ¬ãƒ™ãƒ«ã«é›†ç´„ï¼‰
        x = global_mean_pool(x, batch)

        # å…¨çµåˆå±¤
        x = self.lin1(x)
        x = F.relu(x)
        x = F.dropout(x, p=0.3, training=self.training)

        x = self.lin2(x)
        return x

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
model = GCN_QM9(
    num_node_features=dataset.num_node_features,
    num_classes=1,  # HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—ã®ã¿ã‚’äºˆæ¸¬
    hidden_channels=64
)

print("===== GCNãƒ¢ãƒ‡ãƒ« =====")
print(model)
print(f"\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")
```

### 3.3.4 ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´

```python
from torch_geometric.loader import DataLoader
from sklearn.model_selection import train_test_split
import time

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å°ã•ãã™ã‚‹ï¼ˆé«˜é€ŸåŒ–ã®ãŸã‚ã€å®Ÿéš›ã«ã¯å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
dataset = dataset[:10000]

# HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—ï¼ˆindex=4ï¼‰ã®ã¿ã‚’ç›®çš„å¤‰æ•°ã«è¨­å®š
for data in dataset:
    data.y = data.y[:, 4:5]  # shape: (1, 1)

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆ80% train, 10% val, 10% testï¼‰
train_dataset = dataset[:8000]
val_dataset = dataset[8000:9000]
test_dataset = dataset[9000:]

# DataLoaderã‚’ä½œæˆ
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®šï¼ˆGPUåˆ©ç”¨å¯èƒ½ãªã‚‰GPUã€ãã†ã§ãªã‘ã‚Œã°CPUï¼‰
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

# æå¤±é–¢æ•°ã¨æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)

# è¨“ç·´é–¢æ•°
def train(model, loader, optimizer, criterion, device):
    model.train()
    total_loss = 0

    for data in loader:
        data = data.to(device)
        optimizer.zero_grad()

        # é †ä¼æ’­
        out = model(data.x, data.edge_index, data.batch)
        loss = criterion(out, data.y)

        # é€†ä¼æ’­
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * data.num_graphs

    return total_loss / len(loader.dataset)

# æ¤œè¨¼é–¢æ•°
def evaluate(model, loader, criterion, device):
    model.eval()
    total_loss = 0

    with torch.no_grad():
        for data in loader:
            data = data.to(device)
            out = model(data.x, data.edge_index, data.batch)
            loss = criterion(out, data.y)
            total_loss += loss.item() * data.num_graphs

    return total_loss / len(loader.dataset)

# è¨“ç·´ãƒ«ãƒ¼ãƒ—
epochs = 50
train_losses = []
val_losses = []
best_val_loss = float('inf')

print("===== è¨“ç·´é–‹å§‹ =====")
start_time = time.time()

for epoch in range(1, epochs + 1):
    train_loss = train(model, train_loader, optimizer, criterion, device)
    val_loss = evaluate(model, val_loader, criterion, device)

    train_losses.append(train_loss)
    val_losses.append(val_loss)

    # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), 'best_model_qm9.pt')

    if epoch % 10 == 0:
        print(f"Epoch {epoch:03d}, "
              f"Train Loss: {train_loss:.4f}, "
              f"Val Loss: {val_loss:.4f}")

training_time = time.time() - start_time
print(f"\nè¨“ç·´å®Œäº†! æ‰€è¦æ™‚é–“: {training_time:.2f}ç§’")

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
model.load_state_dict(torch.load('best_model_qm9.pt'))

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
test_loss = evaluate(model, test_loader, criterion, device)
test_mae = test_loss ** 0.5  # RMSEã‚’MAEã®è¿‘ä¼¼ã¨ã—ã¦ä½¿ç”¨

print(f"\n===== ãƒ†ã‚¹ãƒˆæ€§èƒ½ =====")
print(f"Test Loss (MSE): {test_loss:.4f}")
print(f"Test MAE (approx): {test_mae:.4f} eV")
```

### 3.3.5 å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–

```python
import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(10, 6))
ax.plot(train_losses, label='Train Loss', linewidth=2)
ax.plot(val_losses, label='Validation Loss', linewidth=2)
ax.set_xlabel('Epoch', fontsize=12)
ax.set_ylabel('Loss (MSE)', fontsize=12)
ax.set_title('GCNå­¦ç¿’æ›²ç·šï¼ˆQM9 HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ï¼‰', fontsize=14)
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# äºˆæ¸¬ vs å®Ÿæ¸¬ã®ãƒ—ãƒ­ãƒƒãƒˆ
model.eval()
all_preds = []
all_targets = []

with torch.no_grad():
    for data in test_loader:
        data = data.to(device)
        out = model(data.x, data.edge_index, data.batch)
        all_preds.append(out.cpu().numpy())
        all_targets.append(data.y.cpu().numpy())

all_preds = np.concatenate(all_preds)
all_targets = np.concatenate(all_targets)

fig, ax = plt.subplots(figsize=(8, 8))
ax.scatter(all_targets, all_preds, alpha=0.6, s=10)
ax.plot([all_targets.min(), all_targets.max()],
        [all_targets.min(), all_targets.max()],
        'r--', lw=2, label='å®Œå…¨ãªäºˆæ¸¬')
ax.set_xlabel('å®Ÿæ¸¬å€¤ (eV)', fontsize=12)
ax.set_ylabel('äºˆæ¸¬å€¤ (eV)', fontsize=12)
ax.set_title('HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬çµæœ', fontsize=14)
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3)

# RÂ²ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
from sklearn.metrics import r2_score
r2 = r2_score(all_targets, all_preds)
mae = np.mean(np.abs(all_targets - all_preds))

ax.text(0.05, 0.95, f'RÂ² = {r2:.3f}\nMAE = {mae:.3f} eV',
        transform=ax.transAxes, fontsize=12, verticalalignment='top',
        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.show()

print(f"===== æœ€çµ‚æ€§èƒ½ =====")
print(f"RÂ² score: {r2:.4f}")
print(f"MAE: {mae:.4f} eV")
```

---

## 3.4 Materials Projectãƒ‡ãƒ¼ã‚¿ã§çµæ™¶ç‰¹æ€§äºˆæ¸¬

### 3.4.1 çµæ™¶æ§‹é€ ã®ã‚°ãƒ©ãƒ•è¡¨ç¾

çµæ™¶ã¯å‘¨æœŸçš„ãªæ§‹é€ ã‚’æŒã¤ãŸã‚ã€åˆ†å­ã¨ã¯ç•°ãªã‚‹æ‰±ã„ãŒå¿…è¦ã§ã™ã€‚

```python
from pymatgen.core import Structure
from pymatgen.ext.matproj import MPRester
import torch
from torch_geometric.data import Data

def structure_to_graph(structure, cutoff=5.0):
    """
    pymatgen Structureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚°ãƒ©ãƒ•ã«å¤‰æ›

    Parameters:
    -----------
    structure : pymatgen.core.Structure
        çµæ™¶æ§‹é€ 
    cutoff : float
        ã‚¨ãƒƒã‚¸ã‚’ä½œæˆã™ã‚‹è·é›¢ã®ã‚«ãƒƒãƒˆã‚ªãƒ•ï¼ˆÃ…ï¼‰

    Returns:
    --------
    data : torch_geometric.data.Data
        ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿
    """
    # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆåŸå­ç•ªå·ï¼‰
    atomic_numbers = [site.specie.Z for site in structure]
    x = torch.tensor(atomic_numbers, dtype=torch.float).view(-1, 1)

    # ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆåŸå­é–“è·é›¢ï¼‰
    edge_indices = []
    edge_attrs = []

    for i, site_i in enumerate(structure):
        for j, site_j in enumerate(structure):
            if i != j:
                distance = structure.get_distance(i, j)
                if distance < cutoff:
                    edge_indices.append([i, j])
                    edge_attrs.append([distance])

    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()
    edge_attr = torch.tensor(edge_attrs, dtype=torch.float)

    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)
    return data

# Materials Projectã‹ã‚‰LiåŒ–åˆç‰©ã‚’å–å¾—ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
# æ³¨æ„: å®Ÿéš›ã«ã¯APIã‚­ãƒ¼ãŒå¿…è¦
# API_KEY = "your_api_key_here"
# with MPRester(API_KEY) as mpr:
#     entries = mpr.query(
#         criteria={"elements": {"$all": ["Li"]}, "nelements": 2},
#         properties=["structure", "band_gap"]
#     )

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆLiClçµæ™¶ï¼‰
from pymatgen.core import Lattice, Structure

# LiCl å²©å¡©å‹æ§‹é€ 
lattice = Lattice.cubic(5.14)  # æ ¼å­å®šæ•°
species = ["Li", "Li", "Li", "Li", "Cl", "Cl", "Cl", "Cl"]
coords = [
    [0, 0, 0], [0.5, 0.5, 0], [0.5, 0, 0.5], [0, 0.5, 0.5],
    [0.5, 0, 0], [0, 0.5, 0], [0, 0, 0.5], [0.5, 0.5, 0.5]
]
structure = Structure(lattice, species, coords)

# ã‚°ãƒ©ãƒ•ã«å¤‰æ›
data = structure_to_graph(structure, cutoff=4.0)

print("===== LiClçµæ™¶ã®ã‚°ãƒ©ãƒ•è¡¨ç¾ =====")
print(f"ãƒãƒ¼ãƒ‰æ•°ï¼ˆåŸå­æ•°ï¼‰: {data.num_nodes}")
print(f"ã‚¨ãƒƒã‚¸æ•°ï¼ˆè·é›¢ < 4.0Ã…ã®åŸå­ãƒšã‚¢ï¼‰: {data.num_edges}")
print(f"ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡: {data.x}")
print(f"\nã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆè·é›¢ï¼‰ã®çµ±è¨ˆ:")
print(f"  æœ€å°è·é›¢: {data.edge_attr.min().item():.2f} Ã…")
print(f"  æœ€å¤§è·é›¢: {data.edge_attr.max().item():.2f} Ã…")
print(f"  å¹³å‡è·é›¢: {data.edge_attr.mean().item():.2f} Ã…")
```

### 3.4.2 çµæ™¶ç‰¹æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ï¼ˆCrystal Graph Convolutional Networkï¼‰

```python
import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, global_add_pool

class CGCN(torch.nn.Module):
    """
    Crystal Graph Convolutional Network
    çµæ™¶ã®ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã‚’äºˆæ¸¬
    """
    def __init__(self, num_node_features=1, hidden_channels=64):
        super(CGCN, self).__init__()

        # ãƒãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿å±¤
        self.embedding = torch.nn.Linear(num_node_features, hidden_channels)

        # GCNå±¤ï¼ˆã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã‚’è€ƒæ…®ã™ã‚‹å ´åˆã¯SchNetãªã©ã‚’ä½¿ç”¨ï¼‰
        self.conv1 = GCNConv(hidden_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.conv3 = GCNConv(hidden_channels, hidden_channels)

        # å…¨çµåˆå±¤
        self.lin1 = torch.nn.Linear(hidden_channels, hidden_channels // 2)
        self.lin2 = torch.nn.Linear(hidden_channels // 2, 1)

    def forward(self, x, edge_index, edge_attr, batch):
        # ãƒãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿
        x = self.embedding(x)
        x = F.relu(x)

        # GCNå±¤
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.2, training=self.training)

        x = self.conv2(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.2, training=self.training)

        x = self.conv3(x, edge_index)
        x = F.relu(x)

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆçµæ™¶ãƒ¬ãƒ™ãƒ«ã«é›†ç´„ï¼‰
        x = global_add_pool(x, batch)

        # å…¨çµåˆå±¤
        x = self.lin1(x)
        x = F.relu(x)
        x = self.lin2(x)

        return x

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
model_crystal = CGCN(num_node_features=1, hidden_channels=128)

print("===== Crystal Graph Convolutional Network =====")
print(model_crystal)
print(f"\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model_crystal.parameters()):,}")
```

### 3.4.3 æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ã§ã®è¨“ç·´ãƒ‡ãƒ¢

```python
# æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆå®Ÿéš›ã¯Materials Projectãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
crystal_dataset = []

for i in range(200):
    num_atoms = torch.randint(4, 12, (1,)).item()
    x = torch.randint(1, 20, (num_atoms, 1)).float()  # åŸå­ç•ªå·

    # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚¨ãƒƒã‚¸ï¼ˆè·é›¢ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸã¨ä»®å®šï¼‰
    edge_index = torch.randint(0, num_atoms, (2, num_atoms * 4))
    edge_attr = torch.rand(num_atoms * 4, 1) * 5.0  # è·é›¢ (0-5Ã…)

    # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆåŸå­ç•ªå·ã®é–¢æ•°ã¨ã—ã¦æ¨¡æ“¬ï¼‰
    y = (x.mean() / 10.0 + torch.randn(1) * 0.5).clamp(0, 10)

    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)
    crystal_dataset.append(data)

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
train_crystals = crystal_dataset[:160]
test_crystals = crystal_dataset[160:]

train_loader_crystal = DataLoader(train_crystals, batch_size=16, shuffle=True)
test_loader_crystal = DataLoader(test_crystals, batch_size=16, shuffle=False)

# è¨“ç·´ï¼ˆç°¡ç•¥ç‰ˆï¼‰
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model_crystal = model_crystal.to(device)
optimizer = torch.optim.Adam(model_crystal.parameters(), lr=0.001)
criterion = torch.nn.MSELoss()

print("===== çµæ™¶ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬è¨“ç·´ =====")
for epoch in range(1, 51):
    model_crystal.train()
    total_loss = 0

    for data in train_loader_crystal:
        data = data.to(device)
        optimizer.zero_grad()
        out = model_crystal(data.x, data.edge_index, data.edge_attr, data.batch)
        loss = criterion(out, data.y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * data.num_graphs

    if epoch % 10 == 0:
        train_loss = total_loss / len(train_crystals)
        print(f"Epoch {epoch:03d}, Train Loss: {train_loss:.4f}")

# ãƒ†ã‚¹ãƒˆè©•ä¾¡
model_crystal.eval()
test_preds = []
test_targets = []

with torch.no_grad():
    for data in test_loader_crystal:
        data = data.to(device)
        out = model_crystal(data.x, data.edge_index, data.edge_attr, data.batch)
        test_preds.append(out.cpu().numpy())
        test_targets.append(data.y.cpu().numpy())

test_preds = np.concatenate(test_preds)
test_targets = np.concatenate(test_targets)

test_mae = np.mean(np.abs(test_targets - test_preds))
test_r2 = r2_score(test_targets, test_preds)

print(f"\n===== ãƒ†ã‚¹ãƒˆæ€§èƒ½ =====")
print(f"MAE: {test_mae:.4f} eV")
print(f"RÂ²: {test_r2:.4f}")
```

---

## 3.5 ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 3.5.1 å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°

```python
from torch.optim.lr_scheduler import ReduceLROnPlateau

# å­¦ç¿’ç‡ã‚’å‹•çš„ã«èª¿æ•´
scheduler = ReduceLROnPlateau(
    optimizer,
    mode='min',
    factor=0.5,     # å­¦ç¿’ç‡ã‚’åŠåˆ†ã«
    patience=10,    # 10ã‚¨ãƒãƒƒã‚¯æ”¹å–„ãªã—ã§èª¿æ•´
    verbose=True
)

# è¨“ç·´ãƒ«ãƒ¼ãƒ—å†…ã§ä½¿ç”¨
for epoch in range(epochs):
    train_loss = train(model, train_loader, optimizer, criterion, device)
    val_loss = evaluate(model, val_loader, criterion, device)

    # æ¤œè¨¼æå¤±ã«åŸºã¥ã„ã¦å­¦ç¿’ç‡ã‚’èª¿æ•´
    scheduler.step(val_loss)
```

### 3.5.2 Early Stopping

```python
class EarlyStopping:
    """
    Early Stoppingã‚¯ãƒ©ã‚¹
    æ¤œè¨¼æå¤±ãŒæ”¹å–„ã—ãªããªã£ãŸã‚‰è¨“ç·´ã‚’åœæ­¢
    """
    def __init__(self, patience=20, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = None
        self.early_stop = False

    def __call__(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss > self.best_loss - self.min_delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_loss = val_loss
            self.counter = 0

# ä½¿ç”¨ä¾‹
early_stopping = EarlyStopping(patience=20)

for epoch in range(epochs):
    train_loss = train(model, train_loader, optimizer, criterion, device)
    val_loss = evaluate(model, val_loader, criterion, device)

    early_stopping(val_loss)
    if early_stopping.early_stop:
        print(f"Early stopping at epoch {epoch}")
        break
```

### 3.5.3 ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆã‚°ãƒ©ãƒ•ã®æ‘‚å‹•ï¼‰

```python
import torch
from torch_geometric.utils import dropout_edge

def augment_graph(data, drop_edge_prob=0.1, noise_scale=0.01):
    """
    ã‚°ãƒ©ãƒ•ã®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ

    Parameters:
    -----------
    data : Data
        å…ƒã®ã‚°ãƒ©ãƒ•
    drop_edge_prob : float
        ã‚¨ãƒƒã‚¸ã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã™ã‚‹ç¢ºç‡
    noise_scale : float
        ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã«åŠ ãˆã‚‹ãƒã‚¤ã‚ºã®ã‚¹ã‚±ãƒ¼ãƒ«

    Returns:
    --------
    augmented_data : Data
        æ‹¡å¼µã•ã‚ŒãŸã‚°ãƒ©ãƒ•
    """
    # ã‚¨ãƒƒã‚¸ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ
    edge_index, edge_mask = dropout_edge(data.edge_index, p=drop_edge_prob)

    # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã«ãƒã‚¤ã‚ºã‚’è¿½åŠ 
    noise = torch.randn_like(data.x) * noise_scale
    x = data.x + noise

    augmented_data = Data(x=x, edge_index=edge_index, y=data.y)
    return augmented_data

# ä½¿ç”¨ä¾‹
original = dataset[0]
augmented = augment_graph(original, drop_edge_prob=0.15)

print(f"å…ƒã®ã‚¨ãƒƒã‚¸æ•°: {original.num_edges}")
print(f"æ‹¡å¼µå¾Œã®ã‚¨ãƒƒã‚¸æ•°: {augmented.num_edges}")
```

---

## 3.6 ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®è©•ä¾¡ã¨å¯è¦–åŒ–

### 3.6.1 è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—

```python
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

def evaluate_regression(y_true, y_pred):
    """
    å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
    """
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)

    # Mean Absolute Percentage Error
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

    return {
        'MAE': mae,
        'MSE': mse,
        'RMSE': rmse,
        'RÂ²': r2,
        'MAPE': mape
    }

# ä½¿ç”¨ä¾‹
metrics = evaluate_regression(test_targets, test_preds)

print("===== è©•ä¾¡æŒ‡æ¨™ =====")
for name, value in metrics.items():
    print(f"{name}: {value:.4f}")
```

### 3.6.2 æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ

```python
import matplotlib.pyplot as plt

def plot_residuals(y_true, y_pred):
    """
    æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
    """
    residuals = y_true - y_pred

    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # æ®‹å·® vs äºˆæ¸¬å€¤
    axes[0].scatter(y_pred, residuals, alpha=0.6, s=20)
    axes[0].axhline(y=0, color='r', linestyle='--', lw=2)
    axes[0].set_xlabel('äºˆæ¸¬å€¤', fontsize=12)
    axes[0].set_ylabel('æ®‹å·®ï¼ˆå®Ÿæ¸¬ - äºˆæ¸¬ï¼‰', fontsize=12)
    axes[0].set_title('æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ', fontsize=14)
    axes[0].grid(True, alpha=0.3)

    # æ®‹å·®ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    axes[1].hist(residuals, bins=30, alpha=0.7, edgecolor='black')
    axes[1].set_xlabel('æ®‹å·®', fontsize=12)
    axes[1].set_ylabel('é »åº¦', fontsize=12)
    axes[1].set_title('æ®‹å·®åˆ†å¸ƒ', fontsize=14)
    axes[1].axvline(x=0, color='r', linestyle='--', lw=2)
    axes[1].grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    plt.show()

# ä½¿ç”¨ä¾‹
plot_residuals(test_targets, test_preds)
```

### 3.6.3 ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ

```python
import pandas as pd
import matplotlib.pyplot as plt

# è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ¯”è¼ƒ
models_performance = {
    'GCN (3å±¤)': {'MAE': 0.32, 'RÂ²': 0.88, 'Time': 45.2},
    'GAT (2å±¤)': {'MAE': 0.28, 'RÂ²': 0.91, 'Time': 62.8},
    'SchNet': {'MAE': 0.25, 'RÂ²': 0.93, 'Time': 89.5},
    'MPNN': {'MAE': 0.30, 'RÂ²': 0.90, 'Time': 55.1},
}

df = pd.DataFrame(models_performance).T

# ãƒ—ãƒ­ãƒƒãƒˆ
fig, axes = plt.subplots(1, 3, figsize=(16, 4))

# MAEæ¯”è¼ƒ
df['MAE'].plot(kind='bar', ax=axes[0], color='steelblue')
axes[0].set_ylabel('MAE (eV)', fontsize=12)
axes[0].set_title('å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆä½ã„ã»ã©è‰¯ã„ï¼‰', fontsize=13)
axes[0].tick_params(axis='x', rotation=45)
axes[0].grid(True, alpha=0.3, axis='y')

# RÂ²æ¯”è¼ƒ
df['RÂ²'].plot(kind='bar', ax=axes[1], color='forestgreen')
axes[1].set_ylabel('RÂ² Score', fontsize=12)
axes[1].set_title('æ±ºå®šä¿‚æ•°ï¼ˆé«˜ã„ã»ã©è‰¯ã„ï¼‰', fontsize=13)
axes[1].tick_params(axis='x', rotation=45)
axes[1].grid(True, alpha=0.3, axis='y')
axes[1].set_ylim(0.8, 1.0)

# è¨“ç·´æ™‚é–“æ¯”è¼ƒ
df['Time'].plot(kind='bar', ax=axes[2], color='coral')
axes[2].set_ylabel('è¨“ç·´æ™‚é–“ (ç§’)', fontsize=12)
axes[2].set_title('è¨ˆç®—ã‚³ã‚¹ãƒˆ', fontsize=13)
axes[2].tick_params(axis='x', rotation=45)
axes[2].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()
```

---

## 3.7 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 3.7.1 ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨è§£æ±ºç­–

| ã‚¨ãƒ©ãƒ¼ | åŸå›  | è§£æ±ºæ–¹æ³• |
|--------|------|----------|
| `RuntimeError: CUDA out of memory` | GPU ãƒ¡ãƒ¢ãƒªä¸è¶³ | ãƒãƒƒãƒã‚µã‚¤ã‚ºå‰Šæ¸›ã€ãƒ¢ãƒ‡ãƒ«ã®å°å‹åŒ–ã€CPUä½¿ç”¨ |
| `AssertionError: edge_index not contiguous` | ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ¡ãƒ¢ãƒªé…ç½® | `edge_index = edge_index.t().contiguous()` |
| `ValueError: too many values to unpack` | Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å±æ€§ä¸è¶³ | `x`, `edge_index`, `batch`ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª |
| `RuntimeError: Expected all tensors on same device` | ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒ‡ãƒã‚¤ã‚¹ä¸ä¸€è‡´ | `data = data.to(device)`ã‚’ç¢ºèª |

### 3.7.2 ãƒ‡ãƒãƒƒã‚°ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

```python
# ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
print(f"ãƒãƒ¼ãƒ‰æ•°: {data.num_nodes}")
print(f"ã‚¨ãƒƒã‚¸æ•°: {data.num_edges}")
print(f"å­¤ç«‹ãƒãƒ¼ãƒ‰: {data.contains_isolated_nodes()}")
print(f"è‡ªå·±ãƒ«ãƒ¼ãƒ—: {data.contains_self_loops()}")

# ãƒ†ãƒ³ã‚½ãƒ«ã®å½¢çŠ¶ç¢ºèª
print(f"x.shape: {data.x.shape}")
print(f"edge_index.shape: {data.edge_index.shape}")
print(f"y.shape: {data.y.shape}")

# ãƒ‡ãƒã‚¤ã‚¹ã®ç¢ºèª
print(f"x device: {data.x.device}")
print(f"edge_index device: {data.edge_index.device}")

# ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç¯„å›²ç¢ºèª
print(f"max edge index: {data.edge_index.max().item()}")
print(f"num_nodes: {data.num_nodes}")
assert data.edge_index.max().item() < data.num_nodes, "ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒãƒãƒ¼ãƒ‰æ•°ã‚’è¶…ãˆã¦ã„ã¾ã™"
```

---

## 3.8 æœ¬ç« ã®ã¾ã¨ã‚

### å­¦ã‚“ã ã“ã¨

1. **PyTorch Geometricç’°å¢ƒæ§‹ç¯‰**
   - Condaã€pipã€Google Colabã®3ã¤ã®æ–¹æ³•
   - ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§ã®ç¢ºèªã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

2. **ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç†è§£**
   - Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹é€ ï¼ˆx, edge_index, batchï¼‰
   - RDKitã‹ã‚‰ã®ã‚°ãƒ©ãƒ•å¤‰æ›
   - DataLoaderã«ã‚ˆã‚‹ãƒãƒƒãƒå‡¦ç†

3. **QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å®Ÿè·µ**
   - 134,000åˆ†å­ã®é‡å­åŒ–å­¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
   - GCNãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…ã¨è¨“ç·´
   - HOMO-LUMOã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬ï¼ˆMAE < 0.5 eVç›®æ¨™ï¼‰

4. **çµæ™¶ç‰¹æ€§äºˆæ¸¬**
   - Materials Projectçµæ™¶ãƒ‡ãƒ¼ã‚¿ã®ã‚°ãƒ©ãƒ•è¡¨ç¾
   - Crystal Graph Convolutional Network
   - ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—äºˆæ¸¬

5. **è¨“ç·´ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹**
   - å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°
   - Early Stopping
   - ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆã‚°ãƒ©ãƒ•ã®æ‘‚å‹•ï¼‰

6. **è©•ä¾¡ã¨å¯è¦–åŒ–**
   - MAEã€MSEã€RÂ²ãªã©ã®æŒ‡æ¨™
   - æ®‹å·®ãƒ—ãƒ­ãƒƒãƒˆ
   - ãƒ¢ãƒ‡ãƒ«é–“ã®æ€§èƒ½æ¯”è¼ƒ

### é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

- âœ… PyTorch Geometricã¯ææ–™ãƒ»åˆ†å­ã®GNNå®Ÿè£…ã«æœ€é©
- âœ… QM9ã¯åˆå­¦è€…ã«æœ€é©ãªåˆ†å­ç‰¹æ€§äºˆæ¸¬ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- âœ… ã‚°ãƒ©ãƒ•ã®å‰å‡¦ç†ï¼ˆå­¤ç«‹ãƒãƒ¼ãƒ‰ã€è‡ªå·±ãƒ«ãƒ¼ãƒ—ã®ç¢ºèªï¼‰ãŒé‡è¦
- âœ… ãƒãƒƒãƒå‡¦ç†ã§ã¯`batch`ãƒ†ãƒ³ã‚½ãƒ«ãŒå„ãƒãƒ¼ãƒ‰ã®æ‰€å±ã‚’ç¤ºã™
- âœ… å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã¨Early Stoppingã§éå­¦ç¿’ã‚’é˜²æ­¢

### æ¬¡ã®ç« ã¸

ç¬¬4ç« ã§ã¯ã€é«˜åº¦ãªGNNæŠ€è¡“ã‚’å­¦ã³ã¾ã™ï¼š
- ã‚°ãƒ©ãƒ•ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆéšå±¤çš„è¡¨ç¾ï¼‰
- ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã®æ´»ç”¨
- 3Då¹¾ä½•æƒ…å ±ã®çµ„è¾¼ã¿ï¼ˆSchNetã€DimeNetï¼‰
- ç­‰å¤‰GNNï¼ˆE(3)-equivariantï¼‰
- GNNExplainerã«ã‚ˆã‚‹è§£é‡ˆå¯èƒ½æ€§

**[ç¬¬4ç« ï¼šé«˜åº¦ãªGNNæŠ€è¡“ â†’](./chapter-4.md)**

---

## æ¼”ç¿’å•é¡Œ

### å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰

PyTorch Geometricã®Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å«ã¾ã‚Œã‚‹ä¸»è¦ãªå±æ€§ã‚’3ã¤æŒ™ã’ã€ãã‚Œãã‚Œã®å½¹å‰²ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

ãƒãƒ¼ãƒ‰ã€ã‚¨ãƒƒã‚¸ã€ãƒãƒƒãƒã«é–¢ã™ã‚‹æƒ…å ±ã‚’æ ¼ç´ã™ã‚‹å±æ€§ã‚’è€ƒãˆã¾ã—ã‚‡ã†ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

**ä¸»è¦ãª3ã¤ã®å±æ€§**:

1. **`x` (ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡)**
   - å½¢çŠ¶: `(num_nodes, num_node_features)`
   - å½¹å‰²: å„ãƒãƒ¼ãƒ‰ï¼ˆåŸå­ï¼‰ã®ç‰¹å¾´é‡ã‚’æ ¼ç´
   - ä¾‹: åŸå­ç•ªå·ã€é›»æ°—é™°æ€§åº¦ã€å½¢å¼é›»è·ãªã©

2. **`edge_index` (ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)**
   - å½¢çŠ¶: `(2, num_edges)`
   - å½¹å‰²: ã‚°ãƒ©ãƒ•ã®æ¥ç¶šé–¢ä¿‚ï¼ˆéš£æ¥ãƒªã‚¹ãƒˆå½¢å¼ï¼‰
   - ä¾‹: `[[0, 1], [1, 2]]` â†’ ãƒãƒ¼ãƒ‰0ã¨ãƒãƒ¼ãƒ‰1ãŒæ¥ç¶š

3. **`batch` (ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)**
   - å½¢çŠ¶: `(num_nodes,)`
   - å½¹å‰²: å„ãƒãƒ¼ãƒ‰ãŒã©ã®ã‚°ãƒ©ãƒ•ã«å±ã™ã‚‹ã‹ã‚’ç¤ºã™
   - ä¾‹: `[0, 0, 1, 1, 2]` â†’ ãƒãƒ¼ãƒ‰0,1ã¯ã‚°ãƒ©ãƒ•0ã€ãƒãƒ¼ãƒ‰2,3ã¯ã‚°ãƒ©ãƒ•1

**è¿½åŠ ã®é‡è¦ãªå±æ€§**:
- `edge_attr`: ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆçµåˆã‚¿ã‚¤ãƒ—ã€è·é›¢ãªã©ï¼‰
- `y`: ç›®çš„å¤‰æ•°ï¼ˆåˆ†å­ç‰¹æ€§ã€çµæ™¶ç‰¹æ€§ï¼‰

</details>

---

### å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰

QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã—ãŸGCNãƒ¢ãƒ‡ãƒ«ã®MAEãŒ0.8 eVã§ã—ãŸã€‚æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®3ã¤ã®å…·ä½“çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®3ã¤ã®è¦³ç‚¹ã‹ã‚‰è€ƒãˆã¾ã—ã‚‡ã†ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1: ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ”¹å–„**

```python
# GATãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½¿ç”¨ï¼ˆæ³¨æ„æ©Ÿæ§‹ã§é‡è¦ãªçµåˆã‚’å­¦ç¿’ï¼‰
from torch_geometric.nn import GATConv

class ImprovedGNN(torch.nn.Module):
    def __init__(self, num_node_features, hidden_channels=128):
        super().__init__()
        # GATãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼ˆãƒ˜ãƒƒãƒ‰æ•°=8ï¼‰
        self.conv1 = GATConv(num_node_features, hidden_channels, heads=8)
        self.conv2 = GATConv(hidden_channels * 8, hidden_channels, heads=8)
        self.conv3 = GATConv(hidden_channels * 8, hidden_channels, heads=1)
        # å±¤ã‚’å¢—ã‚„ã™ï¼ˆ3å±¤ â†’ 4å±¤ï¼‰
        self.conv4 = GCNConv(hidden_channels, hidden_channels)
```

**æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„**: MAE 0.8 eV â†’ 0.5-0.6 eV

---

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ2: ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã®æ´»ç”¨**

```python
# ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆçµåˆã‚¿ã‚¤ãƒ—ï¼‰ã‚’çµ„ã¿è¾¼ã‚€
from torch_geometric.nn import NNConv

class EdgeFeaturesGNN(torch.nn.Module):
    def __init__(self, num_node_features, num_edge_features, hidden_channels=64):
        super().__init__()
        # NNConv: ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã‚’è€ƒæ…®
        nn = torch.nn.Sequential(
            torch.nn.Linear(num_edge_features, hidden_channels * hidden_channels),
            torch.nn.ReLU()
        )
        self.conv1 = NNConv(num_node_features, hidden_channels, nn, aggr='mean')
```

**æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„**: MAE 0.8 eV â†’ 0.6-0.7 eV

---

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ3: ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ã¨æ‹¡å¼µ**

```python
# ç›®çš„å¤‰æ•°ã‚’æ¨™æº–åŒ–
y_mean = train_dataset.data.y.mean(dim=0)
y_std = train_dataset.data.y.std(dim=0)

for data in train_dataset:
    data.y = (data.y - y_mean) / y_std

# ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆã‚°ãƒ©ãƒ•ã®æ‘‚å‹•ï¼‰
def augment_graph(data):
    # ã‚¨ãƒƒã‚¸ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ
    edge_index, _ = dropout_edge(data.edge_index, p=0.1)
    # ãƒã‚¤ã‚ºè¿½åŠ 
    x = data.x + torch.randn_like(data.x) * 0.01
    return Data(x=x, edge_index=edge_index, y=data.y)

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’2å€ã«
augmented_train = [augment_graph(data) for data in train_dataset]
train_dataset = train_dataset + augmented_train
```

**æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„**: MAE 0.8 eV â†’ 0.7 eV

---

**æœ€é©ãªæˆ¦ç•¥**: ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1ï¼ˆãƒ¢ãƒ‡ãƒ«æ”¹å–„ï¼‰ã¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ2ï¼ˆã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼‰ã‚’çµ„ã¿åˆã‚ã›ã€MAE 0.4-0.5 eVã‚’ç›®æŒ‡ã™ã€‚

</details>

---

### å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚åŸå› ã‚’ç‰¹å®šã—ã€ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

```python
# ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã‚³ãƒ¼ãƒ‰
model = GCN_QM9(num_node_features=11, num_classes=1)
device = torch.device('cuda')
model = model.to(device)

for data in train_loader:
    optimizer.zero_grad()
    out = model(data.x, data.edge_index, data.batch)
    loss = criterion(out, data.y)
    loss.backward()
    optimizer.step()
```

**ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**:
```
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
```

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒã‚¤ã‚¹ãŒä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

**åŸå› **:
ãƒ¢ãƒ‡ãƒ«ã¯`cuda`ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•ã•ã‚Œã¦ã„ã¾ã™ãŒã€`data`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯`cpu`ã®ã¾ã¾ã§ã™ã€‚PyTorchã§ã¯ã€ã™ã¹ã¦ã®ãƒ†ãƒ³ã‚½ãƒ«ãŒåŒã˜ãƒ‡ãƒã‚¤ã‚¹ä¸Šã«ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

**ä¿®æ­£ã‚³ãƒ¼ãƒ‰**:

```python
model = GCN_QM9(num_node_features=11, num_classes=1)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

for data in train_loader:
    # ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«ç§»å‹•ï¼ˆé‡è¦ï¼ï¼‰
    data = data.to(device)

    optimizer.zero_grad()
    out = model(data.x, data.edge_index, data.batch)
    loss = criterion(out, data.y)
    loss.backward()
    optimizer.step()
```

**é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ**:
1. `data = data.to(device)`ã§ã€`data`å†…ã®ã™ã¹ã¦ã®ãƒ†ãƒ³ã‚½ãƒ«ï¼ˆ`x`, `edge_index`, `batch`, `y`ï¼‰ã‚’ä¸€åº¦ã«GPUã«ç§»å‹•
2. `torch.cuda.is_available()`ã§GPUãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèªï¼ˆCPUã®ã¿ã®ç’°å¢ƒã§ã‚‚ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ï¼‰
3. è¨“ç·´ãƒ«ãƒ¼ãƒ—ã®**æœ€åˆ**ã§ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•

**ãƒ‡ãƒãƒƒã‚°ã®ãƒã‚§ãƒƒã‚¯**:
```python
# ãƒ‡ãƒã‚¤ã‚¹ã®ç¢ºèª
print(f"Model device: {next(model.parameters()).device}")
print(f"Data x device: {data.x.device}")
print(f"Data edge_index device: {data.edge_index.device}")
```

</details>

---

## å‚è€ƒæ–‡çŒ®

1. Fey, M., & Lenssen, J. E. (2019). "Fast Graph Representation Learning with PyTorch Geometric." *ICLR Workshop on Representation Learning on Graphs and Manifolds*.
   GitHub: https://github.com/pyg-team/pytorch_geometric
   *PyTorch Geometricå…¬å¼è«–æ–‡ã€‚ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è¨­è¨ˆæ€æƒ³ã¨å®Ÿè£…ã®è©³ç´°ã€‚*

2. Ramakrishnan, R., et al. (2014). "Quantum chemistry structures and properties of 134 kilo molecules." *Scientific Data*, 1, 140022.
   DOI: [10.1038/sdata.2014.22](https://doi.org/10.1038/sdata.2014.22)
   *QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¬å¼è«–æ–‡ã€‚134,000åˆ†å­ã®é‡å­åŒ–å­¦è¨ˆç®—ãƒ‡ãƒ¼ã‚¿ã€‚*

3. Xie, T., & Grossman, J. C. (2018). "Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties." *Physical Review Letters*, 120(14), 145301.
   DOI: [10.1103/PhysRevLett.120.145301](https://doi.org/10.1103/PhysRevLett.120.145301)
   *Crystal Graph Convolutional Networksï¼ˆCGCNï¼‰ã®åŸè«–æ–‡ã€‚çµæ™¶ç‰¹æ€§äºˆæ¸¬ã¸ã®å¿œç”¨ã€‚*

4. Gilmer, J., et al. (2017). "Neural Message Passing for Quantum Chemistry." *ICML 2017*.
   URL: https://arxiv.org/abs/1704.01212
   *Message Passing Neural Networksï¼ˆMPNNï¼‰ã®ç†è«–ã€‚QM9ã§ã®é«˜ç²¾åº¦äºˆæ¸¬ã‚’é”æˆã€‚*

5. PyTorch Geometric Documentation. (2024). "Introduction by Example."
   URL: https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html
   *PyTorch Geometricå…¬å¼ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã€‚åŸºæœ¬çš„ãªä½¿ã„æ–¹ã‚’ä¾‹ç¤ºã€‚*

6. RDKit Documentation. (2024). "Getting Started with the RDKit in Python."
   URL: https://www.rdkit.org/docs/GettingStartedInPython.html
   *RDKitã®å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€‚SMILESã‹ã‚‰åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã™ã‚‹æ–¹æ³•ã€‚*

---

**ä½œæˆæ—¥**: 2025-10-17
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0
**ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**: chapter-template-v2.0
**è‘—è€…**: GNNå…¥é–€ã‚·ãƒªãƒ¼ã‚ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
