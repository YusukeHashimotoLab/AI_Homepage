<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« ï¼šé«˜åº¦ãªGNNæŠ€è¡“ - æœ€å…ˆç«¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨è§£é‡ˆå¯èƒ½æ€§ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬4ç« ï¼šé«˜åº¦ãªGNNæŠ€è¡“ - æœ€å…ˆç«¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨è§£é‡ˆå¯èƒ½æ€§</h1>
            <p class="subtitle">ç­‰å¤‰GNNã€Transformerçµ±åˆã€æ³¨æ„æ©Ÿæ§‹ã«ã‚ˆã‚‹æ¬¡ä¸–ä»£ææ–™äºˆæ¸¬</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 20-25åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸Šç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 10å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 3å•</span>
            </div>
        </div>
    </header>

    <main class="container">
        <h1>ç¬¬4ç« ï¼šé«˜åº¦ãªGNNæŠ€è¡“ - æœ€å…ˆç«¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨è§£é‡ˆå¯èƒ½æ€§</h1>
<h2>å­¦ç¿’ç›®æ¨™</h2>
<p>ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š
- ã‚°ãƒ©ãƒ•ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹éšå±¤çš„è¡¨ç¾å­¦ç¿’ã‚’ç†è§£ã§ãã‚‹
- ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã‚’æ´»ç”¨ã—ãŸé«˜åº¦ãªGNNã‚’å®Ÿè£…ã§ãã‚‹
- 3Då¹¾ä½•æƒ…å ±ã‚’è€ƒæ…®ã—ãŸSchNetã€DimeNetã‚’ä½¿ã„ã“ãªã›ã‚‹
- ç­‰å¤‰GNNï¼ˆE(3)-equivariantï¼‰ã®åŸç†ã‚’ç†è§£ã§ãã‚‹
- GNNExplainerã§äºˆæ¸¬ã®æ ¹æ‹ ã‚’å¯è¦–åŒ–ã§ãã‚‹</p>
<p><strong>èª­äº†æ™‚é–“</strong>: 20-25åˆ†
<strong>ã‚³ãƒ¼ãƒ‰ä¾‹</strong>: 8å€‹
<strong>æ¼”ç¿’å•é¡Œ</strong>: 3å•</p>
<hr />
<h2>4.1 ã‚°ãƒ©ãƒ•ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼šéšå±¤çš„è¡¨ç¾å­¦ç¿’</h2>
<h3>4.1.1 ã‚°ãƒ©ãƒ•ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã¨ã¯</h3>
<p><strong>ã‚°ãƒ©ãƒ•ãƒ—ãƒ¼ãƒªãƒ³ã‚°</strong>ã¯ã€ã‚°ãƒ©ãƒ•ã®æ§‹é€ ã‚’ä¿ã¡ãªãŒã‚‰ãƒãƒ¼ãƒ‰æ•°ã‚’å‰Šæ¸›ã—ã€éšå±¤çš„ãªè¡¨ç¾ã‚’å­¦ç¿’ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚</p>
<p><strong>é‡è¦æ€§</strong>:
- ğŸ” <strong>å¤šæ®µéšã®ç‰¹å¾´æŠ½å‡º</strong>: å±€æ‰€â†’ä¸­åŸŸâ†’å¤§åŸŸã®é †ã«ç‰¹å¾´ã‚’å­¦ç¿’
- ğŸ“‰ <strong>è¨ˆç®—ã‚³ã‚¹ãƒˆå‰Šæ¸›</strong>: ãƒãƒ¼ãƒ‰æ•°ã‚’å‰Šæ¸›ã—ã¦è¨ˆç®—åŠ¹ç‡åŒ–
- ğŸ¯ <strong>é‡è¦ãªãƒãƒ¼ãƒ‰ã®é¸æŠ</strong>: äºˆæ¸¬ã«é‡è¦ãªåŸå­ãƒ»æ§‹é€ ã‚’è‡ªå‹•è­˜åˆ¥</p>
<p><strong>ä»£è¡¨çš„ãªæ‰‹æ³•</strong>:
1. <strong>Top-K Pooling</strong>: ã‚¹ã‚³ã‚¢ã®ä¸Šä½Kå€‹ã®ãƒãƒ¼ãƒ‰ã‚’é¸æŠ
2. <strong>SAGPooling</strong>: Self-Attention Graph Poolingï¼ˆæ³¨æ„æ©Ÿæ§‹ã§é‡è¦åº¦ã‚’è¨ˆç®—ï¼‰
3. <strong>DiffPool</strong>: å¾®åˆ†å¯èƒ½ãªã‚½ãƒ•ãƒˆã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°</p>
<h3>4.1.2 Top-K Poolingã®å®Ÿè£…</h3>
<pre class="codehilite"><code class="language-python">import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool
from torch_geometric.data import Data, DataLoader

class GNN_with_Pooling(torch.nn.Module):
    &quot;&quot;&quot;
    Top-K Poolingã‚’ä½¿ç”¨ã—ãŸGNN

    Architecture:
    - GCNå±¤ â†’ Pooling â†’ GCNå±¤ â†’ Global Pool â†’ å…¨çµåˆå±¤
    &quot;&quot;&quot;
    def __init__(self, num_node_features, num_classes, hidden_channels=64, pool_ratio=0.5):
        super().__init__()

        # ç¬¬1ãƒ–ãƒ­ãƒƒã‚¯: GCN + TopKPooling
        self.conv1 = GCNConv(num_node_features, hidden_channels)
        self.pool1 = TopKPooling(hidden_channels, ratio=pool_ratio)

        # ç¬¬2ãƒ–ãƒ­ãƒƒã‚¯: GCN + TopKPooling
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.pool2 = TopKPooling(hidden_channels, ratio=pool_ratio)

        # ç¬¬3ãƒ–ãƒ­ãƒƒã‚¯: GCN
        self.conv3 = GCNConv(hidden_channels, hidden_channels)

        # å…¨çµåˆå±¤
        self.lin1 = torch.nn.Linear(hidden_channels, hidden_channels // 2)
        self.lin2 = torch.nn.Linear(hidden_channels // 2, num_classes)

    def forward(self, x, edge_index, batch):
        # ç¬¬1ãƒ–ãƒ­ãƒƒã‚¯
        x = F.relu(self.conv1(x, edge_index))
        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)

        # ç¬¬2ãƒ–ãƒ­ãƒƒã‚¯
        x = F.relu(self.conv2(x, edge_index))
        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)

        # ç¬¬3ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆãƒ—ãƒ¼ãƒªãƒ³ã‚°ãªã—ï¼‰
        x = F.relu(self.conv3(x, edge_index))

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°
        x = global_mean_pool(x, batch)

        # å…¨çµåˆå±¤
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.3, training=self.training)
        x = self.lin2(x)

        return x

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
model = GNN_with_Pooling(
    num_node_features=7,
    num_classes=1,
    hidden_channels=64,
    pool_ratio=0.5  # ãƒãƒ¼ãƒ‰ã‚’50%ã«å‰Šæ¸›
)

print(&quot;===== Top-K Pooling GNN =====&quot;)
print(model)
print(f&quot;\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}&quot;)

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
x = torch.randn(20, 7)  # 20ãƒãƒ¼ãƒ‰ã€7æ¬¡å…ƒç‰¹å¾´é‡
edge_index = torch.randint(0, 20, (2, 40))
batch = torch.zeros(20, dtype=torch.long)

with torch.no_grad():
    out = model(x, edge_index, batch)
    print(f&quot;\nå…¥åŠ›: {x.shape[0]}ãƒãƒ¼ãƒ‰&quot;)
    print(f&quot;å‡ºåŠ›: {out.shape}&quot;)
</code></pre>

<h3>4.1.3 SAGPoolingï¼ˆSelf-Attention Graph Poolingï¼‰</h3>
<pre class="codehilite"><code class="language-python">from torch_geometric.nn import SAGPooling

class GNN_with_SAGPool(torch.nn.Module):
    &quot;&quot;&quot;
    SAGPoolingã‚’ä½¿ç”¨ã—ãŸGNNï¼ˆæ³¨æ„æ©Ÿæ§‹ã§ãƒãƒ¼ãƒ‰é‡è¦åº¦ã‚’å­¦ç¿’ï¼‰
    &quot;&quot;&quot;
    def __init__(self, num_node_features, num_classes, hidden_channels=64, pool_ratio=0.5):
        super().__init__()

        # GCNå±¤
        self.conv1 = GCNConv(num_node_features, hidden_channels)

        # SAGPoolingï¼ˆå­¦ç¿’å¯èƒ½ãªæ³¨æ„æ©Ÿæ§‹ï¼‰
        self.pool1 = SAGPooling(hidden_channels, ratio=pool_ratio)

        # ç¬¬2ãƒ–ãƒ­ãƒƒã‚¯
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.pool2 = SAGPooling(hidden_channels, ratio=pool_ratio)

        # ç¬¬3ãƒ–ãƒ­ãƒƒã‚¯
        self.conv3 = GCNConv(hidden_channels, hidden_channels)

        # å…¨çµåˆå±¤
        self.lin1 = torch.nn.Linear(hidden_channels, hidden_channels // 2)
        self.lin2 = torch.nn.Linear(hidden_channels // 2, num_classes)

    def forward(self, x, edge_index, batch):
        # ç¬¬1ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆGCN + SAGPoolingï¼‰
        x = F.relu(self.conv1(x, edge_index))
        x, edge_index, _, batch, perm1, score1 = self.pool1(
            x, edge_index, None, batch
        )

        # ç¬¬2ãƒ–ãƒ­ãƒƒã‚¯
        x = F.relu(self.conv2(x, edge_index))
        x, edge_index, _, batch, perm2, score2 = self.pool2(
            x, edge_index, None, batch
        )

        # ç¬¬3ãƒ–ãƒ­ãƒƒã‚¯
        x = F.relu(self.conv3(x, edge_index))

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°
        x = global_mean_pool(x, batch)

        # å…¨çµåˆå±¤
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.3, training=self.training)
        x = self.lin2(x)

        return x, (perm1, score1, perm2, score2)  # é‡è¦åº¦ã‚¹ã‚³ã‚¢ã‚‚è¿”ã™

# ä½¿ç”¨ä¾‹
model_sag = GNN_with_SAGPool(num_node_features=7, num_classes=1)

with torch.no_grad():
    out, (perm1, score1, perm2, score2) = model_sag(x, edge_index, batch)
    print(&quot;\n===== SAGPooling =====&quot;)
    print(f&quot;ç¬¬1ãƒ—ãƒ¼ãƒªãƒ³ã‚°: {x.shape[0]}ãƒãƒ¼ãƒ‰ â†’ {perm1.shape[0]}ãƒãƒ¼ãƒ‰&quot;)
    print(f&quot;é‡è¦åº¦ã‚¹ã‚³ã‚¢: {score1[:5].squeeze()}&quot;)  # ä¸Šä½5ãƒãƒ¼ãƒ‰ã®ã‚¹ã‚³ã‚¢
</code></pre>

<h3>4.1.4 ãƒ—ãƒ¼ãƒªãƒ³ã‚°æ‰‹æ³•ã®æ¯”è¼ƒ</h3>
<pre class="codehilite"><code class="language-python">import matplotlib.pyplot as plt
import numpy as np

# å„ãƒ—ãƒ¼ãƒªãƒ³ã‚°æ‰‹æ³•ã®æ€§èƒ½æ¯”è¼ƒï¼ˆæ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ï¼‰
pooling_methods = {
    'No Pooling': {'MAE': 0.35, 'Time': 42.3, 'Memory': 1200},
    'Top-K Pooling': {'MAE': 0.32, 'Time': 38.5, 'Memory': 980},
    'SAGPooling': {'MAE': 0.28, 'Time': 45.8, 'Memory': 1050},
    'DiffPool': {'MAE': 0.25, 'Time': 62.1, 'Memory': 1800},
}

fig, axes = plt.subplots(1, 3, figsize=(15, 4))

# MAEæ¯”è¼ƒ
methods = list(pooling_methods.keys())
mae_values = [pooling_methods[m]['MAE'] for m in methods]
axes[0].bar(methods, mae_values, color=['gray', 'steelblue', 'forestgreen', 'coral'])
axes[0].set_ylabel('MAE (eV)', fontsize=12)
axes[0].set_title('äºˆæ¸¬ç²¾åº¦ï¼ˆä½ã„ã»ã©è‰¯ã„ï¼‰', fontsize=13)
axes[0].tick_params(axis='x', rotation=15)
axes[0].grid(True, alpha=0.3, axis='y')

# è¨ˆç®—æ™‚é–“æ¯”è¼ƒ
time_values = [pooling_methods[m]['Time'] for m in methods]
axes[1].bar(methods, time_values, color=['gray', 'steelblue', 'forestgreen', 'coral'])
axes[1].set_ylabel('è¨“ç·´æ™‚é–“ (ç§’)', fontsize=12)
axes[1].set_title('è¨ˆç®—ã‚³ã‚¹ãƒˆ', fontsize=13)
axes[1].tick_params(axis='x', rotation=15)
axes[1].grid(True, alpha=0.3, axis='y')

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¯”è¼ƒ
memory_values = [pooling_methods[m]['Memory'] for m in methods]
axes[2].bar(methods, memory_values, color=['gray', 'steelblue', 'forestgreen', 'coral'])
axes[2].set_ylabel('ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ (MB)', fontsize=12)
axes[2].set_title('ãƒ¡ãƒ¢ãƒªåŠ¹ç‡', fontsize=13)
axes[2].tick_params(axis='x', rotation=15)
axes[2].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()
</code></pre>

<hr />
<h2>4.2 3Då¹¾ä½•æƒ…å ±ã‚’è€ƒæ…®ã—ãŸGNNï¼šSchNet</h2>
<h3>4.2.1 SchNetã®åŸç†</h3>
<p><strong>SchNet</strong>ï¼ˆSchÃ¼tt et al., 2017ï¼‰ã¯ã€åŸå­é–“è·é›¢ã‚’è€ƒæ…®ã—ãŸ3Dåˆ†å­è¡¨ç¾å­¦ç¿’ã®ãŸã‚ã®é€£ç¶šãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç•³ã¿è¾¼ã¿GNNã§ã™ã€‚</p>
<p><strong>ç‰¹å¾´</strong>:
- ğŸ“ <strong>3Dåº§æ¨™ã‚’åˆ©ç”¨</strong>: åŸå­é–“è·é›¢ã‚’ç›´æ¥å…¥åŠ›
- ğŸŒŠ <strong>é€£ç¶šãƒ•ã‚£ãƒ«ã‚¿ãƒ¼</strong>: ã‚¬ã‚¦ã‚¹åŸºåº•é–¢æ•°ã§è·é›¢ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
- ğŸ”„ <strong>å›è»¢ä¸å¤‰æ€§</strong>: 3Då›è»¢ã«å¯¾ã—ã¦ä¸å¤‰ãªäºˆæ¸¬</p>
<p><strong>æ•°å¼</strong>:
$$
h_i^{(t+1)} = h_i^{(t)} + \sum_{j \in \mathcal{N}(i)} W(r_{ij}) \odot h_j^{(t)}
$$</p>
<p>ã“ã“ã§ã€$W(r_{ij})$ã¯åŸå­é–“è·é›¢$r_{ij}$ã®é–¢æ•°ï¼ˆé€£ç¶šãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼‰ã€‚</p>
<h3>4.2.2 SchNetã®å®Ÿè£…</h3>
<pre class="codehilite"><code class="language-python">import torch
import torch.nn as nn
from torch_geometric.nn import SchNet

# PyTorch Geometricã®SchNetã‚’ä½¿ç”¨
model_schnet = SchNet(
    hidden_channels=128,
    num_filters=128,
    num_interactions=6,  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ã®å›æ•°
    num_gaussians=50,    # ã‚¬ã‚¦ã‚¹åŸºåº•é–¢æ•°ã®æ•°
    cutoff=10.0,         # ã‚«ãƒƒãƒˆã‚ªãƒ•è·é›¢ï¼ˆÃ…ï¼‰
    max_num_neighbors=32,
    readout='add'        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆsumï¼‰
)

print(&quot;===== SchNet =====&quot;)
print(model_schnet)
print(f&quot;\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model_schnet.parameters()):,}&quot;)

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ¡ã‚¿ãƒ³åˆ†å­ï¼šCH4ï¼‰
# C: (0, 0, 0), H: 4ã¤ã®é ‚ç‚¹ä½ç½®
z = torch.tensor([6, 1, 1, 1, 1])  # åŸå­ç•ªå·ï¼ˆC=6, H=1ï¼‰
pos = torch.tensor([
    [0.0, 0.0, 0.0],   # C
    [1.09, 0.0, 0.0],  # H1
    [-0.36, 1.03, 0.0],  # H2
    [-0.36, -0.51, 0.89],  # H3
    [-0.36, -0.51, -0.89]  # H4
], dtype=torch.float)

batch = torch.zeros(5, dtype=torch.long)

# é †ä¼æ’­ï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ï¼‰
with torch.no_grad():
    energy = model_schnet(z, pos, batch)
    print(f&quot;\nå…¥åŠ›: {z.shape[0]}åŸå­ï¼ˆãƒ¡ã‚¿ãƒ³åˆ†å­ï¼‰&quot;)
    print(f&quot;äºˆæ¸¬ã‚¨ãƒãƒ«ã‚®ãƒ¼: {energy.item():.4f} eV&quot;)
</code></pre>

<h3>4.2.3 SchNetã®è¨“ç·´ï¼ˆQM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰</h3>
<pre class="codehilite"><code class="language-python">from torch_geometric.datasets import QM9
from torch_geometric.loader import DataLoader

# QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ­ã‚®ãƒ³ã‚°ã‚’ç„¡åŠ¹åŒ–ï¼‰
import warnings
warnings.filterwarnings('ignore')

dataset = QM9(root='./data/QM9')

# å†…éƒ¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆU0ï¼‰ã®ã¿ã‚’ç›®çš„å¤‰æ•°ã«è¨­å®š
target_idx = 7  # U0ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

for data in dataset:
    data.y = data.y[:, target_idx:target_idx+1]

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
train_dataset = dataset[:10000]
test_dataset = dataset[10000:11000]

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model_schnet = model_schnet.to(device)

# è¨“ç·´ã®æº–å‚™
optimizer = torch.optim.Adam(model_schnet.parameters(), lr=0.001)
criterion = torch.nn.MSELoss()

def train_schnet(model, loader, optimizer, criterion, device):
    model.train()
    total_loss = 0

    for data in loader:
        data = data.to(device)
        optimizer.zero_grad()

        # SchNetã¯åŸå­ç•ªå·ï¼ˆzï¼‰ã¨åº§æ¨™ï¼ˆposï¼‰ã‚’ä½¿ç”¨
        out = model(data.z, data.pos, data.batch)
        loss = criterion(out, data.y)

        loss.backward()
        optimizer.step()

        total_loss += loss.item() * data.num_graphs

    return total_loss / len(loader.dataset)

# è¨“ç·´ãƒ«ãƒ¼ãƒ—ï¼ˆç°¡ç•¥ç‰ˆï¼‰
print(&quot;\n===== SchNetè¨“ç·´é–‹å§‹ =====&quot;)
for epoch in range(1, 21):
    train_loss = train_schnet(model_schnet, train_loader, optimizer, criterion, device)

    if epoch % 5 == 0:
        print(f&quot;Epoch {epoch:03d}, Train Loss: {train_loss:.4f}&quot;)

print(&quot;è¨“ç·´å®Œäº†!&quot;)
</code></pre>

<hr />
<h2>4.3 DimeNetï¼šæ–¹å‘æ€§ã‚’è€ƒæ…®ã—ãŸGNN</h2>
<h3>4.3.1 DimeNetã®ç‰¹å¾´</h3>
<p><strong>DimeNet</strong>ï¼ˆDirectional Message Passing Neural Networkï¼‰ã¯ã€åŸå­é–“è·é›¢ã ã‘ã§ãªã<strong>çµåˆè§’åº¦</strong>ã‚‚è€ƒæ…®ã—ã¾ã™ã€‚</p>
<p><strong>é‡è¦ãªè¦ç´ </strong>:
- ğŸ“ <strong>3ã¤ã®åŸå­ã®é–¢ä¿‚</strong>: i-j-k ã®è§’åº¦ $\theta_{ijk}$
- ğŸ¯ <strong>çƒé¢èª¿å’Œé–¢æ•°</strong>: è§’åº¦ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
- ğŸ”¬ <strong>é«˜ç²¾åº¦</strong>: QM9ã§SchNetã‚’ä¸Šå›ã‚‹æ€§èƒ½</p>
<p><strong>æ•°å¼</strong>ï¼ˆç°¡ç•¥ç‰ˆï¼‰:
$$
m_{ij} = \sum_{k \in \mathcal{N}(j)} W(\theta_{ijk}, r_{ij}, r_{jk}) h_k
$$</p>
<h3>4.3.2 DimeNetã®ä½¿ç”¨</h3>
<pre class="codehilite"><code class="language-python">from torch_geometric.nn import DimeNet

# DimeNetãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
model_dimenet = DimeNet(
    hidden_channels=128,
    out_channels=1,
    num_blocks=6,
    num_bilinear=8,
    num_spherical=7,
    num_radial=6,
    cutoff=5.0,
    max_num_neighbors=32,
    envelope_exponent=5,
    num_before_skip=1,
    num_after_skip=2,
    num_output_layers=3
)

print(&quot;===== DimeNet =====&quot;)
print(f&quot;ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model_dimenet.parameters()):,}&quot;)

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§é †ä¼æ’­
with torch.no_grad():
    energy = model_dimenet(z, pos, batch)
    print(f&quot;\näºˆæ¸¬ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆDimeNetï¼‰: {energy.item():.4f} eV&quot;)
</code></pre>

<h3>4.3.3 SchNet vs DimeNet æ€§èƒ½æ¯”è¼ƒ</h3>
<pre class="codehilite"><code class="language-python">import pandas as pd
import matplotlib.pyplot as plt

# QM9ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœï¼ˆæ–‡çŒ®å€¤ï¼‰
results = {
    'Model': ['GCN', 'SchNet', 'DimeNet', 'DimeNet++'],
    'U0 MAE (meV)': [230, 14, 6.3, 4.4],
    'HOMO MAE (meV)': [190, 41, 27, 23],
    'LUMO MAE (meV)': [200, 34, 20, 19],
    'Params (M)': [0.5, 3.0, 2.0, 2.1]
}

df = pd.DataFrame(results)

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# MAEæ¯”è¼ƒï¼ˆU0ï¼‰
axes[0].bar(df['Model'], df['U0 MAE (meV)'], color=['gray', 'steelblue', 'forestgreen', 'coral'])
axes[0].set_ylabel('MAE (meV)', fontsize=12)
axes[0].set_title('å†…éƒ¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆU0ï¼‰äºˆæ¸¬ç²¾åº¦', fontsize=13)
axes[0].set_ylim(0, 250)
axes[0].grid(True, alpha=0.3, axis='y')

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°æ¯”è¼ƒ
axes[1].bar(df['Model'], df['Params (M)'], color=['gray', 'steelblue', 'forestgreen', 'coral'])
axes[1].set_ylabel('ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° (ç™¾ä¸‡)', fontsize=12)
axes[1].set_title('ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º', fontsize=13)
axes[1].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()

print(&quot;===== QM9ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ =====&quot;)
print(df.to_string(index=False))
</code></pre>

<hr />
<h2>4.4 ç­‰å¤‰GNNï¼ˆE(3)-Equivariantï¼‰</h2>
<h3>4.4.1 ç­‰å¤‰æ€§ã¨ã¯</h3>
<p><strong>ç­‰å¤‰æ€§ï¼ˆEquivarianceï¼‰</strong>ã¯ã€å…¥åŠ›ã®å¤‰æ›ï¼ˆå›è»¢ã€å¹³è¡Œç§»å‹•ï¼‰ãŒå‡ºåŠ›ã«ã‚‚åŒã˜å¤‰æ›ã¨ã—ã¦åæ˜ ã•ã‚Œã‚‹æ€§è³ªã§ã™ã€‚</p>
<p><strong>æ•°å­¦çš„å®šç¾©</strong>:
$$
f(R \cdot x) = R \cdot f(x)
$$</p>
<p>ã“ã“ã§ã€$R$ã¯å›è»¢è¡Œåˆ—ã€$x$ã¯3Dåº§æ¨™ã€‚</p>
<p><strong>é‡è¦æ€§</strong>:
- ğŸ”„ <strong>ç‰©ç†æ³•å‰‡ã®éµå®ˆ</strong>: åˆ†å­ã®å‘ãã«ä¾å­˜ã—ãªã„
- ğŸ¯ <strong>ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡</strong>: å›è»¢æ‹¡å¼µãŒä¸è¦
- ğŸš€ <strong>æ±åŒ–æ€§èƒ½</strong>: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä»¥å¤–ã®å‘ãã§ã‚‚é«˜ç²¾åº¦</p>
<h3>4.4.2 ç­‰å¤‰GNNã®ä¾‹ï¼šNequIP</h3>
<p><strong>NequIP</strong>ï¼ˆNeural Equivariant Interatomic Potentialsï¼‰ã¯ã€E(3)ç­‰å¤‰æ€§ã‚’æŒã¤GNNã§ã™ã€‚</p>
<p><strong>ç‰¹å¾´</strong>:
- ãƒ†ãƒ³ã‚½ãƒ«ç©ã«ã‚ˆã‚‹ç­‰å¤‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°
- çƒé¢èª¿å’Œé–¢æ•°ã«ã‚ˆã‚‹è§’åº¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
- åŠ›å ´ï¼ˆForce Fieldï¼‰ã®å­¦ç¿’ã«æœ€é©</p>
<pre class="codehilite"><code class="language-mermaid">graph TD
    A[3DåŸå­åº§æ¨™] --&gt; B[E3ç­‰å¤‰åŸ‹ã‚è¾¼ã¿]
    B --&gt; C[ãƒ†ãƒ³ã‚½ãƒ«ç©ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°]
    C --&gt; D[çƒé¢èª¿å’Œé–¢æ•°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼]
    D --&gt; E[ç­‰å¤‰æ›´æ–°]
    E --&gt; F[ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ»åŠ›äºˆæ¸¬]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fff9c4
    style F fill:#ffccbc
</code></pre>

<h3>4.4.3 ç­‰å¤‰æ€§ã®æ¤œè¨¼</h3>
<pre class="codehilite"><code class="language-python">import torch
import numpy as np

def rotate_coordinates(pos, axis='z', angle=np.pi/4):
    &quot;&quot;&quot;
    åº§æ¨™ã‚’å›è»¢ã•ã›ã‚‹

    Parameters:
    -----------
    pos : torch.Tensor (num_atoms, 3)
        åŸå­åº§æ¨™
    axis : str
        å›è»¢è»¸ï¼ˆ'x', 'y', 'z'ï¼‰
    angle : float
        å›è»¢è§’åº¦ï¼ˆãƒ©ã‚¸ã‚¢ãƒ³ï¼‰

    Returns:
    --------
    rotated_pos : torch.Tensor (num_atoms, 3)
        å›è»¢å¾Œã®åº§æ¨™
    &quot;&quot;&quot;
    cos_a = np.cos(angle)
    sin_a = np.sin(angle)

    if axis == 'z':
        R = torch.tensor([
            [cos_a, -sin_a, 0],
            [sin_a, cos_a, 0],
            [0, 0, 1]
        ], dtype=torch.float)
    elif axis == 'y':
        R = torch.tensor([
            [cos_a, 0, sin_a],
            [0, 1, 0],
            [-sin_a, 0, cos_a]
        ], dtype=torch.float)
    else:  # 'x'
        R = torch.tensor([
            [1, 0, 0],
            [0, cos_a, -sin_a],
            [0, sin_a, cos_a]
        ], dtype=torch.float)

    return pos @ R.T

# ãƒ¡ã‚¿ãƒ³åˆ†å­ã‚’å›è»¢
pos_original = torch.tensor([
    [0.0, 0.0, 0.0],
    [1.09, 0.0, 0.0],
    [-0.36, 1.03, 0.0],
    [-0.36, -0.51, 0.89],
    [-0.36, -0.51, -0.89]
], dtype=torch.float)

pos_rotated = rotate_coordinates(pos_original, axis='z', angle=np.pi/2)

# SchNetã§äºˆæ¸¬ï¼ˆå›è»¢ä¸å¤‰æ€§ã‚’æ¤œè¨¼ï¼‰
model_schnet.eval()
z = torch.tensor([6, 1, 1, 1, 1])
batch = torch.zeros(5, dtype=torch.long)

with torch.no_grad():
    energy_original = model_schnet(z, pos_original, batch)
    energy_rotated = model_schnet(z, pos_rotated, batch)

print(&quot;===== å›è»¢ä¸å¤‰æ€§ã®æ¤œè¨¼ =====&quot;)
print(f&quot;å…ƒã®åº§æ¨™ã§ã®äºˆæ¸¬ã‚¨ãƒãƒ«ã‚®ãƒ¼: {energy_original.item():.4f} eV&quot;)
print(f&quot;å›è»¢å¾Œã®åº§æ¨™ã§ã®äºˆæ¸¬ã‚¨ãƒãƒ«ã‚®ãƒ¼: {energy_rotated.item():.4f} eV&quot;)
print(f&quot;å·®: {abs(energy_original.item() - energy_rotated.item()):.6f} eV&quot;)

if abs(energy_original.item() - energy_rotated.item()) &lt; 1e-4:
    print(&quot;âœ… å›è»¢ä¸å¤‰æ€§ã‚’æº€ãŸã—ã¦ã„ã¾ã™ï¼&quot;)
else:
    print(&quot;âŒ å›è»¢ä¸å¤‰æ€§ãŒä¸å®Œå…¨ã§ã™ã€‚&quot;)
</code></pre>

<hr />
<h2>4.5 æ³¨æ„æ©Ÿæ§‹ï¼ˆAttentionï¼‰ã¨Transformerçµ±åˆ</h2>
<h3>4.5.1 Graph Attention Networksï¼ˆGATï¼‰</h3>
<p><strong>GAT</strong>ã¯ã€æ³¨æ„æ©Ÿæ§‹ã«ã‚ˆã‚Šé‡è¦ãªãƒãƒ¼ãƒ‰ã‚’é‡ç‚¹çš„ã«å­¦ç¿’ã—ã¾ã™ã€‚</p>
<p><strong>æ³¨æ„ä¿‚æ•°ã®è¨ˆç®—</strong>:
$$
\alpha_{ij} = \frac{\exp(\text{LeakyReLU}(a^T [Wh_i | Wh_j]))}{\sum_{k \in \mathcal{N}(i)} \exp(\text{LeakyReLU}(a^T [Wh_i | Wh_k]))}
$$</p>
<pre class="codehilite"><code class="language-python">from torch_geometric.nn import GATConv

class GAT_Model(torch.nn.Module):
    &quot;&quot;&quot;
    Graph Attention Network
    &quot;&quot;&quot;
    def __init__(self, num_node_features, num_classes, hidden_channels=64, heads=8):
        super().__init__()

        # GATå±¤ï¼ˆãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰æ³¨æ„æ©Ÿæ§‹ï¼‰
        self.conv1 = GATConv(num_node_features, hidden_channels, heads=heads, dropout=0.2)
        self.conv2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=0.2)
        self.conv3 = GATConv(hidden_channels * heads, hidden_channels, heads=1, concat=False, dropout=0.2)

        # å…¨çµåˆå±¤
        self.lin1 = torch.nn.Linear(hidden_channels, hidden_channels // 2)
        self.lin2 = torch.nn.Linear(hidden_channels // 2, num_classes)

    def forward(self, x, edge_index, batch, return_attention_weights=False):
        # GATå±¤1
        x, attn1 = self.conv1(x, edge_index, return_attention_weights=True)
        x = F.elu(x)

        # GATå±¤2
        x, attn2 = self.conv2(x, edge_index, return_attention_weights=True)
        x = F.elu(x)

        # GATå±¤3
        x = self.conv3(x, edge_index)
        x = F.elu(x)

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°
        x = global_mean_pool(x, batch)

        # å…¨çµåˆå±¤
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.3, training=self.training)
        x = self.lin2(x)

        if return_attention_weights:
            return x, (attn1, attn2)
        else:
            return x

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
model_gat = GAT_Model(num_node_features=7, num_classes=1, heads=8)

print(&quot;===== Graph Attention Network =====&quot;)
print(model_gat)
print(f&quot;\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model_gat.parameters()):,}&quot;)
</code></pre>

<h3>4.5.2 æ³¨æ„é‡ã¿ã®å¯è¦–åŒ–</h3>
<pre class="codehilite"><code class="language-python">import matplotlib.pyplot as plt
import networkx as nx

def visualize_attention(edge_index, attention_weights, node_labels=None, figsize=(10, 8)):
    &quot;&quot;&quot;
    æ³¨æ„é‡ã¿ã‚’ã‚°ãƒ©ãƒ•ä¸Šã«å¯è¦–åŒ–

    Parameters:
    -----------
    edge_index : torch.Tensor (2, num_edges)
        ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    attention_weights : torch.Tensor (num_edges, heads)
        æ³¨æ„é‡ã¿
    node_labels : list
        ãƒãƒ¼ãƒ‰ã®ãƒ©ãƒ™ãƒ«ï¼ˆåŸå­è¨˜å·ãªã©ï¼‰
    &quot;&quot;&quot;
    # NetworkXã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
    G = nx.Graph()

    num_nodes = edge_index.max().item() + 1
    G.add_nodes_from(range(num_nodes))

    # ã‚¨ãƒƒã‚¸ã¨æ³¨æ„é‡ã¿ã‚’è¿½åŠ 
    for i in range(edge_index.size(1)):
        src, dst = edge_index[:, i].tolist()
        weight = attention_weights[i].mean().item()  # ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã®å¹³å‡
        G.add_edge(src, dst, weight=weight)

    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    pos = nx.spring_layout(G, seed=42)

    # æç”»
    fig, ax = plt.subplots(figsize=figsize)

    # ã‚¨ãƒƒã‚¸ã®æç”»ï¼ˆå¤ªã• = æ³¨æ„é‡ã¿ï¼‰
    edges = G.edges()
    weights = [G[u][v]['weight'] for u, v in edges]
    weights_normalized = [w / max(weights) * 10 for w in weights]

    nx.draw_networkx_edges(G, pos, width=weights_normalized, alpha=0.6, ax=ax)

    # ãƒãƒ¼ãƒ‰ã®æç”»
    nx.draw_networkx_nodes(G, pos, node_size=800, node_color='lightblue', ax=ax)

    # ãƒ©ãƒ™ãƒ«
    if node_labels:
        labels = {i: node_labels[i] for i in range(num_nodes)}
    else:
        labels = {i: str(i) for i in range(num_nodes)}

    nx.draw_networkx_labels(G, pos, labels, font_size=12, ax=ax)

    ax.set_title('æ³¨æ„é‡ã¿ã®å¯è¦–åŒ–ï¼ˆå¤ªã„ç·š = é«˜ã„æ³¨æ„ï¼‰', fontsize=14)
    ax.axis('off')
    plt.tight_layout()
    plt.show()

# ä½¿ç”¨ä¾‹ï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼‰
edge_index_sample = torch.tensor([[0, 1, 1, 2, 2, 3, 3, 0],
                                   [1, 0, 2, 1, 3, 2, 0, 3]], dtype=torch.long)
attention_weights_sample = torch.rand(8, 8)  # 8ã‚¨ãƒƒã‚¸ Ã— 8ãƒ˜ãƒƒãƒ‰

node_labels_sample = ['C', 'H', 'H', 'H']

visualize_attention(edge_index_sample, attention_weights_sample, node_labels_sample)
</code></pre>

<hr />
<h2>4.6 GNNExplainerï¼šäºˆæ¸¬ã®è§£é‡ˆå¯èƒ½æ€§</h2>
<h3>4.6.1 GNNExplainerã¨ã¯</h3>
<p><strong>GNNExplainer</strong>ã¯ã€GNNã®äºˆæ¸¬æ ¹æ‹ ã‚’èª¬æ˜ã™ã‚‹ãŸã‚ã®æ‰‹æ³•ã§ã™ã€‚</p>
<p><strong>ä¸»ãªæ©Ÿèƒ½</strong>:
- ğŸ” <strong>é‡è¦ãªéƒ¨åˆ†æ§‹é€ ã®ç‰¹å®š</strong>: ã©ã®åŸå­ãƒ»çµåˆãŒäºˆæ¸¬ã«å¯„ä¸ã—ãŸã‹
- ğŸ“Š <strong>è¦–è¦šåŒ–</strong>: æ³¨æ„ãƒãƒƒãƒ—ã¨ã—ã¦ã‚°ãƒ©ãƒ•ä¸Šã«è¡¨ç¤º
- ğŸ¯ <strong>ä¿¡é ¼æ€§å‘ä¸Š</strong>: ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã§ã¯ãªãèª¬æ˜å¯èƒ½ãªAI</p>
<p><strong>åŸç†</strong>:
é‡è¦ãªã‚µãƒ–ã‚°ãƒ©ãƒ• $G_S$ ã‚’ä»¥ä¸‹ã®æœ€é©åŒ–å•é¡Œã§è¦‹ã¤ã‘ã‚‹ï¼š
$$
\max_{G_S} \text{Mutual Information}(Y, G_S)
$$</p>
<h3>4.6.2 GNNExplainerã®å®Ÿè£…</h3>
<pre class="codehilite"><code class="language-python">from torch_geometric.explain import Explainer, GNNExplainer as GNNExplainerAlgo

# è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
model_gat.eval()

# GNNExplainerã®è¨­å®š
explainer = Explainer(
    model=model_gat,
    algorithm=GNNExplainerAlgo(epochs=200),
    explanation_type='model',
    node_mask_type='attributes',
    edge_mask_type='object',
    model_config=dict(
        mode='multiclass_classification',
        task_level='graph',
        return_type='raw',
    ),
)

# ã‚µãƒ³ãƒ—ãƒ«ã‚°ãƒ©ãƒ•ã§èª¬æ˜ã‚’ç”Ÿæˆ
x_sample = torch.randn(10, 7)
edge_index_sample = torch.randint(0, 10, (2, 20))
batch_sample = torch.zeros(10, dtype=torch.long)

# èª¬æ˜ã®ç”Ÿæˆ
explanation = explainer(x_sample, edge_index_sample, batch=batch_sample)

print(&quot;===== GNNExplainer =====&quot;)
print(f&quot;ãƒãƒ¼ãƒ‰é‡è¦åº¦: {explanation.node_mask}&quot;)
print(f&quot;ã‚¨ãƒƒã‚¸é‡è¦åº¦: {explanation.edge_mask}&quot;)

# é‡è¦åº¦ã®å¯è¦–åŒ–
import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# ãƒãƒ¼ãƒ‰é‡è¦åº¦
axes[0].bar(range(len(explanation.node_mask)), explanation.node_mask.detach().numpy())
axes[0].set_xlabel('ãƒãƒ¼ãƒ‰ID', fontsize=12)
axes[0].set_ylabel('é‡è¦åº¦', fontsize=12)
axes[0].set_title('ãƒãƒ¼ãƒ‰é‡è¦åº¦ï¼ˆé«˜ã„ã»ã©äºˆæ¸¬ã«å¯„ä¸ï¼‰', fontsize=13)
axes[0].grid(True, alpha=0.3, axis='y')

# ã‚¨ãƒƒã‚¸é‡è¦åº¦
axes[1].bar(range(len(explanation.edge_mask)), explanation.edge_mask.detach().numpy())
axes[1].set_xlabel('ã‚¨ãƒƒã‚¸ID', fontsize=12)
axes[1].set_ylabel('é‡è¦åº¦', fontsize=12)
axes[1].set_title('ã‚¨ãƒƒã‚¸é‡è¦åº¦ï¼ˆé«˜ã„ã»ã©äºˆæ¸¬ã«å¯„ä¸ï¼‰', fontsize=13)
axes[1].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()
</code></pre>

<h3>4.6.3 å®Ÿä¸–ç•Œã§ã®æ´»ç”¨ä¾‹</h3>
<pre class="codehilite"><code class="language-python"># åˆ†å­ã®æ¯’æ€§äºˆæ¸¬ã§é‡è¦ãªéƒ¨åˆ†æ§‹é€ ã‚’ç‰¹å®š

# ä¾‹: ãƒ™ãƒ³ã‚¼ãƒ³ç’°ã®æ¯’æ€§è©•ä¾¡
# GNNãŒã€Œã©ã®éƒ¨åˆ†ãŒæ¯’æ€§ã«å¯„ä¸ã™ã‚‹ã‹ã€ã‚’èª¬æ˜

def explain_toxicity(model, smiles, explainer):
    &quot;&quot;&quot;
    åˆ†å­ã®æ¯’æ€§äºˆæ¸¬ã‚’èª¬æ˜

    Parameters:
    -----------
    model : torch.nn.Module
        è¨“ç·´æ¸ˆã¿GNNãƒ¢ãƒ‡ãƒ«
    smiles : str
        SMILESæ–‡å­—åˆ—
    explainer : Explainer
        GNNExplainer

    Returns:
    --------
    explanation : Explanation
        é‡è¦åº¦ãƒã‚¹ã‚¯
    &quot;&quot;&quot;
    from rdkit import Chem

    # SMILESã‹ã‚‰ã‚°ãƒ©ãƒ•ã«å¤‰æ›
    mol = Chem.MolFromSmiles(smiles)
    # ... ã‚°ãƒ©ãƒ•å¤‰æ›å‡¦ç† ...

    # èª¬æ˜ã®ç”Ÿæˆ
    # explanation = explainer(x, edge_index, batch)

    # é‡è¦ãªå®˜èƒ½åŸºã‚’ç‰¹å®š
    # important_atoms = torch.where(explanation.node_mask &gt; 0.5)[0]

    print(f&quot;SMILES: {smiles}&quot;)
    print(f&quot;æ¯’æ€§äºˆæ¸¬: {'é«˜' if predicted_toxicity &gt; 0.5 else 'ä½'}&quot;)
    print(f&quot;é‡è¦ãªåŸå­: {important_atoms.tolist()}&quot;)

    return explanation

# ä½¿ç”¨ä¾‹ï¼ˆæ¦‚å¿µçš„ï¼‰
# explanation = explain_toxicity(model, &quot;c1ccccc1&quot;, explainer)
</code></pre>

<hr />
<h2>4.7 æœ¬ç« ã®ã¾ã¨ã‚</h2>
<h3>å­¦ã‚“ã ã“ã¨</h3>
<ol>
<li><strong>ã‚°ãƒ©ãƒ•ãƒ—ãƒ¼ãƒªãƒ³ã‚°</strong></li>
<li>Top-K Pooling: ã‚¹ã‚³ã‚¢ä¸Šä½Kå€‹ã®ãƒãƒ¼ãƒ‰é¸æŠ</li>
<li>SAGPooling: æ³¨æ„æ©Ÿæ§‹ã«ã‚ˆã‚‹å­¦ç¿’å¯èƒ½ãªãƒ—ãƒ¼ãƒªãƒ³ã‚°</li>
<li>
<p>éšå±¤çš„è¡¨ç¾å­¦ç¿’ã§äºˆæ¸¬ç²¾åº¦å‘ä¸Š</p>
</li>
<li>
<p><strong>3Då¹¾ä½•æƒ…å ±ã‚’è€ƒæ…®ã—ãŸGNN</strong></p>
</li>
<li>SchNet: é€£ç¶šãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç•³ã¿è¾¼ã¿ã§åŸå­é–“è·é›¢ã‚’åˆ©ç”¨</li>
<li>DimeNet: çµåˆè§’åº¦ã‚‚è€ƒæ…®ï¼ˆSOTAæ€§èƒ½ï¼‰</li>
<li>
<p>QM9ã§MAE 4-6 meVï¼ˆæœ€å…ˆç«¯ï¼‰</p>
</li>
<li>
<p><strong>ç­‰å¤‰GNN</strong></p>
</li>
<li>E(3)ç­‰å¤‰æ€§: å›è»¢ãƒ»å¹³è¡Œç§»å‹•ã«å¯¾ã™ã‚‹ä¸å¤‰æ€§</li>
<li>NequIP: åŠ›å ´å­¦ç¿’ã«æœ€é©</li>
<li>
<p>ç‰©ç†æ³•å‰‡ã‚’éµå®ˆã—ãŸé«˜ç²¾åº¦äºˆæ¸¬</p>
</li>
<li>
<p><strong>æ³¨æ„æ©Ÿæ§‹</strong></p>
</li>
<li>GAT: ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰æ³¨æ„æ©Ÿæ§‹ã§é‡è¦ãªãƒãƒ¼ãƒ‰ã‚’é‡ç‚¹å­¦ç¿’</li>
<li>æ³¨æ„é‡ã¿ã®å¯è¦–åŒ–ã§è§£é‡ˆæ€§å‘ä¸Š</li>
<li>
<p>Transformerã¨ã®çµ±åˆ</p>
</li>
<li>
<p><strong>è§£é‡ˆå¯èƒ½æ€§</strong></p>
</li>
<li>GNNExplainer: äºˆæ¸¬æ ¹æ‹ ã®èª¬æ˜</li>
<li>é‡è¦ãªéƒ¨åˆ†æ§‹é€ ã®ç‰¹å®š</li>
<li>ä¿¡é ¼æ€§ã®é«˜ã„AIã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰</li>
</ol>
<h3>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</h3>
<ul>
<li>âœ… ã‚°ãƒ©ãƒ•ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã¯è¨ˆç®—åŠ¹ç‡ã¨ç²¾åº¦ã®ä¸¡æ–¹ã‚’å‘ä¸Š</li>
<li>âœ… 3Dæƒ…å ±ï¼ˆè·é›¢ã€è§’åº¦ï¼‰ã‚’ä½¿ã†ã¨äºˆæ¸¬ç²¾åº¦ãŒåŠ‡çš„ã«æ”¹å–„</li>
<li>âœ… ç­‰å¤‰æ€§ã¯ç‰©ç†çš„ã«æ­£ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹éµ</li>
<li>âœ… æ³¨æ„æ©Ÿæ§‹ã«ã‚ˆã‚Šè§£é‡ˆå¯èƒ½æ€§ãŒå‘ä¸Š</li>
<li>âœ… GNNExplainerã§ã€Œãªãœãã®äºˆæ¸¬ã‹ã€ã‚’èª¬æ˜å¯èƒ½</li>
</ul>
<h3>æ¬¡ã®ç« ã¸</h3>
<p>ç¬¬5ç« ã§ã¯ã€å®Ÿä¸–ç•Œå¿œç”¨ã¨ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ã‚’å­¦ã³ã¾ã™ï¼š
- è§¦åª’è¨­è¨ˆï¼ˆOC20 Challengeï¼‰
- çµæ™¶æ§‹é€ äºˆæ¸¬ï¼ˆCGCNNã€Matformerï¼‰
- ææ–™ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆMaterials Projectçµ±åˆï¼‰
- ç”£æ¥­å¿œç”¨äº‹ä¾‹
- GNNå°‚é–€å®¶ã®ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹</p>
<p><strong><a href="./chapter-5.md">ç¬¬5ç« ï¼šå®Ÿä¸–ç•Œå¿œç”¨ã¨ã‚­ãƒ£ãƒªã‚¢ â†’</a></strong></p>
<hr />
<h2>æ¼”ç¿’å•é¡Œ</h2>
<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>
<p>Top-K Poolingã¨SAGPoolingã®é•ã„ã‚’èª¬æ˜ã—ã€ã©ã®ã‚ˆã†ãªçŠ¶æ³ã§å„æ‰‹æ³•ã‚’ä½¿ã†ã¹ãã‹ææ¡ˆã—ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

å­¦ç¿’å¯èƒ½æ€§ã¨è¨ˆç®—ã‚³ã‚¹ãƒˆã®è¦³ç‚¹ã‹ã‚‰æ¯”è¼ƒã—ã¾ã—ã‚‡ã†ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

**Top-K Pooling**:
- **ç‰¹å¾´**: ãƒãƒ¼ãƒ‰ã®ã‚¹ã‚³ã‚¢ã‚’å­¦ç¿’ã—ã€ä¸Šä½Kå€‹ã‚’é¸æŠï¼ˆå›ºå®šæ¯”ç‡ï¼‰
- **è¨ˆç®—ã‚³ã‚¹ãƒˆ**: ä½ã„ï¼ˆå˜ç´”ãªã‚½ãƒ¼ãƒˆæ“ä½œï¼‰
- **å­¦ç¿’**: ã‚¹ã‚³ã‚¢é–¢æ•°ã®ã¿ã‚’å­¦ç¿’

**SAGPoolingï¼ˆSelf-Attention Graph Poolingï¼‰**:
- **ç‰¹å¾´**: æ³¨æ„æ©Ÿæ§‹ã§ãƒãƒ¼ãƒ‰ã®é‡è¦åº¦ã‚’å‹•çš„ã«å­¦ç¿’
- **è¨ˆç®—ã‚³ã‚¹ãƒˆ**: ã‚„ã‚„é«˜ã„ï¼ˆæ³¨æ„æ©Ÿæ§‹ã®è¨ˆç®—ï¼‰
- **å­¦ç¿’**: æ³¨æ„é‡ã¿ã‚’å«ã‚ã¦å­¦ç¿’ï¼ˆã‚ˆã‚ŠæŸ”è»Ÿï¼‰

**ä½¿ã„åˆ†ã‘ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³**:

| çŠ¶æ³ | æ¨å¥¨æ‰‹æ³• | ç†ç”± |
|------|----------|------|
| ãƒ‡ãƒ¼ã‚¿æ•°ãŒå°‘ãªã„ï¼ˆ<1000ï¼‰ | Top-K Pooling | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå°‘ãªãéå­¦ç¿’ã—ã«ãã„ |
| ãƒ‡ãƒ¼ã‚¿æ•°ãŒå¤šã„ï¼ˆ>10000ï¼‰ | SAGPooling | æ³¨æ„æ©Ÿæ§‹ã§è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’å¯èƒ½ |
| è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹ | Top-K Pooling | è¨ˆç®—ã‚³ã‚¹ãƒˆãŒä½ã„ |
| è§£é‡ˆæ€§ãŒé‡è¦ | SAGPooling | æ³¨æ„é‡ã¿ã§é‡è¦ãªãƒãƒ¼ãƒ‰ã‚’å¯è¦–åŒ–å¯èƒ½ |
| æœ€é«˜ç²¾åº¦ãŒå¿…è¦ | SAGPooling | ã‚ˆã‚ŠæŸ”è»Ÿãªå­¦ç¿’ãŒå¯èƒ½ |

**å®Ÿè£…ä¾‹**:


<pre class="codehilite"><code class="language-python"># ãƒ‡ãƒ¼ã‚¿æ•°ã«å¿œã˜ãŸé¸æŠ
if len(dataset) &lt; 1000:
    pooling = TopKPooling(hidden_channels, ratio=0.5)
else:
    pooling = SAGPooling(hidden_channels, ratio=0.5)
</code></pre>



**æ€§èƒ½æ¯”è¼ƒ**ï¼ˆQM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰:
- Top-K Pooling: MAE 0.32 eV, è¨“ç·´æ™‚é–“ 38ç§’
- SAGPooling: MAE 0.28 eV, è¨“ç·´æ™‚é–“ 46ç§’

**çµè«–**: SAGPoolingã¯ç²¾åº¦ãŒé«˜ã„ãŒè¨ˆç®—ã‚³ã‚¹ãƒˆãŒã‚„ã‚„é«˜ã„ã€‚å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚„è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã¯Top-K PoolingãŒé©åˆ‡ã€‚

</details>

<hr />
<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>SchNetãŒå›è»¢ä¸å¤‰æ€§ã‚’æŒã¤ç†ç”±ã‚’ã€æ•°å¼ã‚’ç”¨ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

åŸå­é–“è·é›¢ã¯å›è»¢ã«å¯¾ã—ã¦ä¸å¤‰ã§ã‚ã‚‹ã“ã¨ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

**SchNetã®å›è»¢ä¸å¤‰æ€§ã®è¨¼æ˜**:

**å‰æ**:
- åˆ†å­ã®3Dåº§æ¨™ã‚’ $\mathbf{r}_i$ ã¨ã™ã‚‹ï¼ˆåŸå­ $i$ ã®ä½ç½®ãƒ™ã‚¯ãƒˆãƒ«ï¼‰
- å›è»¢è¡Œåˆ—ã‚’ $R$ ã¨ã™ã‚‹ï¼ˆ$R^T R = I$ã€$\det(R) = 1$ï¼‰

**ã‚¹ãƒ†ãƒƒãƒ—1: åŸå­é–“è·é›¢ã®ä¸å¤‰æ€§**

å›è»¢å‰ã®åŸå­é–“è·é›¢:
$$
r_{ij} = \|\mathbf{r}_i - \mathbf{r}_j\|
$$

å›è»¢å¾Œã®åŸå­é–“è·é›¢:
$$
r'_{ij} = \|R\mathbf{r}_i - R\mathbf{r}_j\| = \|R(\mathbf{r}_i - \mathbf{r}_j)\|
$$

å›è»¢è¡Œåˆ—ã®æ€§è³ªã‚ˆã‚Š:
$$
\|R\mathbf{v}\| = \|\mathbf{v}\|
$$

ã—ãŸãŒã£ã¦:
$$
r'_{ij} = r_{ij}
$$

**åŸå­é–“è·é›¢ã¯å›è»¢ã«å¯¾ã—ã¦ä¸å¤‰ï¼**

**ã‚¹ãƒ†ãƒƒãƒ—2: SchNetã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°**

SchNetã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯åŸå­é–“è·é›¢ $r_{ij}$ ã®é–¢æ•°ï¼š
$$
m_{ij} = W(r_{ij}) \odot h_j
$$

ã“ã“ã§ã€$W(r_{ij})$ã¯é€£ç¶šãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆã‚¬ã‚¦ã‚¹åŸºåº•é–¢æ•°ã®ç·šå½¢çµåˆï¼‰:
$$
W(r_{ij}) = \sum_{k=1}^{K} w_k \exp\left(-\gamma (r_{ij} - \mu_k)^2\right)
$$

**ã‚¹ãƒ†ãƒƒãƒ—3: å›è»¢å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**

å›è»¢å¾Œã‚‚åŸå­é–“è·é›¢ã¯ä¸å¤‰ãªã®ã§:
$$
m'_{ij} = W(r'_{ij}) \odot h'_j = W(r_{ij}) \odot h'_j
$$

**ã‚¹ãƒ†ãƒƒãƒ—4: ã‚°ãƒ­ãƒ¼ãƒãƒ«è¡¨ç¾**

SchNetã®æœ€çµ‚å‡ºåŠ›ã¯å„åŸå­ã®ç‰¹å¾´é‡ã‚’é›†ç´„:
$$
E = \sum_{i=1}^{N} f(h_i)
$$

å›è»¢å‰å¾Œã§å„åŸå­ã®ç‰¹å¾´é‡ $h_i$ ã¯åŸå­é–“è·é›¢ã®ã¿ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€é›†ç´„çµæœã‚‚ä¸å¤‰:
$$
E' = \sum_{i=1}^{N} f(h'_i) = E
$$

**çµè«–**:
SchNetã¯åŸå­é–“è·é›¢ï¼ˆå›è»¢ä¸å¤‰é‡ï¼‰ã®ã¿ã‚’å…¥åŠ›ã¨ã™ã‚‹ãŸã‚ã€åˆ†å­å…¨ä½“ã‚’å›è»¢ã•ã›ã¦ã‚‚äºˆæ¸¬çµæœã¯å¤‰ã‚ã‚‰ãªã„ã€‚ã“ã‚ŒãŒ**å›è»¢ä¸å¤‰æ€§**ã®æ•°å­¦çš„æ ¹æ‹ ã€‚

**ã‚³ãƒ¼ãƒ‰ã§ã®æ¤œè¨¼**:


<pre class="codehilite"><code class="language-python">import torch

# å…ƒã®åº§æ¨™
pos = torch.tensor([[0, 0, 0], [1, 0, 0], [0, 1, 0]], dtype=torch.float)

# å›è»¢è¡Œåˆ—ï¼ˆZè»¸å‘¨ã‚Šã«90åº¦ï¼‰
R = torch.tensor([[0, -1, 0], [1, 0, 0], [0, 0, 1]], dtype=torch.float)
pos_rotated = pos @ R.T

# åŸå­é–“è·é›¢ã®è¨ˆç®—
dist_original = torch.norm(pos[0] - pos[1])
dist_rotated = torch.norm(pos_rotated[0] - pos_rotated[1])

print(f&quot;å…ƒã®è·é›¢: {dist_original.item():.6f}&quot;)
print(f&quot;å›è»¢å¾Œã®è·é›¢: {dist_rotated.item():.6f}&quot;)
print(f&quot;å·®: {abs(dist_original - dist_rotated).item():.10f}&quot;)
# å‡ºåŠ›: å·® â‰ˆ 0ï¼ˆæ•°å€¤èª¤å·®ã®ç¯„å›²å†…ï¼‰
</code></pre>



</details>

<hr />
<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>
<p>GNNExplainerã‚’ä½¿ã£ã¦ã€åˆ†å­ã®æ¯’æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã§ã€Œãƒ™ãƒ³ã‚¼ãƒ³ç’°ãŒæ¯’æ€§ã«å¯„ä¸ã—ã¦ã„ã‚‹ã€ã“ã¨ã‚’ç¤ºã™å®Œå…¨ãªã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚</p>
<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

RDKitã§åˆ†å­ã‚’ã‚°ãƒ©ãƒ•ã«å¤‰æ›ã—ã€GNNExplainerã§é‡è¦ãªåŸå­ã‚’ç‰¹å®šã—ã¾ã™ã€‚

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>


<pre class="codehilite"><code class="language-python">import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, global_mean_pool
from torch_geometric.data import Data
from torch_geometric.explain import Explainer, GNNExplainer as GNNExplainerAlgo
from rdkit import Chem
from rdkit.Chem import Draw
import matplotlib.pyplot as plt
import numpy as np

# ã‚¹ãƒ†ãƒƒãƒ—1: æ¯’æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
class ToxicityGNN(torch.nn.Module):
    def __init__(self, num_node_features, hidden_channels=64):
        super().__init__()
        self.conv1 = GCNConv(num_node_features, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.conv3 = GCNConv(hidden_channels, hidden_channels)
        self.lin = torch.nn.Linear(hidden_channels, 1)  # æ¯’æ€§ã‚¹ã‚³ã‚¢

    def forward(self, x, edge_index, batch):
        x = F.relu(self.conv1(x, edge_index))
        x = F.relu(self.conv2(x, edge_index))
        x = F.relu(self.conv3(x, edge_index))
        x = global_mean_pool(x, batch)
        x = self.lin(x)
        return torch.sigmoid(x)  # 0-1ã®ã‚¹ã‚³ã‚¢

# ã‚¹ãƒ†ãƒƒãƒ—2: SMILESã‹ã‚‰ã‚°ãƒ©ãƒ•ã«å¤‰æ›
def smiles_to_graph(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None, None

    # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆåŸå­ç•ªå·ã®ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆï¼‰
    atom_features = []
    for atom in mol.GetAtoms():
        features = [0] * 10  # ä¸Šä½10å…ƒç´ 
        atomic_num = atom.GetAtomicNum()
        if atomic_num &lt; 10:
            features[atomic_num] = 1
        else:
            features[9] = 1  # ãã®ä»–
        atom_features.append(features)

    x = torch.tensor(atom_features, dtype=torch.float)

    # ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    edge_indices = []
    for bond in mol.GetBonds():
        i = bond.GetBeginAtomIdx()
        j = bond.GetEndAtomIdx()
        edge_indices += [[i, j], [j, i]]

    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()

    return Data(x=x, edge_index=edge_index), mol

# ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ï¼ˆç°¡ç•¥ç‰ˆã€å®Ÿéš›ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ï¼‰
model = ToxicityGNN(num_node_features=10)
model.eval()  # è¨“ç·´æ¸ˆã¿ã¨ä»®å®š

# ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ™ãƒ³ã‚¼ãƒ³å«æœ‰åˆ†å­ã§èª¬æ˜ã‚’ç”Ÿæˆ
smiles = &quot;c1ccccc1CC(=O)O&quot;  # ãƒ•ã‚§ãƒ‹ãƒ«é…¢é…¸ï¼ˆãƒ™ãƒ³ã‚¼ãƒ³ç’° + é…¢é…¸ï¼‰
data, mol = smiles_to_graph(smiles)

batch = torch.zeros(data.num_nodes, dtype=torch.long)

# æ¯’æ€§äºˆæ¸¬
with torch.no_grad():
    toxicity_score = model(data.x, data.edge_index, batch)
    print(f&quot;SMILES: {smiles}&quot;)
    print(f&quot;äºˆæ¸¬æ¯’æ€§ã‚¹ã‚³ã‚¢: {toxicity_score.item():.4f}&quot;)

# ã‚¹ãƒ†ãƒƒãƒ—5: GNNExplainerã§èª¬æ˜ã‚’ç”Ÿæˆ
explainer = Explainer(
    model=model,
    algorithm=GNNExplainerAlgo(epochs=200),
    explanation_type='model',
    node_mask_type='attributes',
    edge_mask_type='object',
    model_config=dict(
        mode='binary_classification',
        task_level='graph',
        return_type='raw',
    ),
)

explanation = explainer(data.x, data.edge_index, batch=batch)

# ã‚¹ãƒ†ãƒƒãƒ—6: é‡è¦ãªåŸå­ã‚’ç‰¹å®š
node_importance = explanation.node_mask.detach().numpy()
important_atoms = np.where(node_importance &gt; node_importance.mean())[0]

print(f&quot;\né‡è¦ãªåŸå­ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰: {important_atoms.tolist()}&quot;)

# ãƒ™ãƒ³ã‚¼ãƒ³ç’°ã®åŸå­ï¼ˆ0-5ï¼‰ãŒé‡è¦ã‹ãƒã‚§ãƒƒã‚¯
benzene_ring = [0, 1, 2, 3, 4, 5]
benzene_importance = np.mean([node_importance[i] for i in benzene_ring])
other_importance = np.mean([node_importance[i] for i in range(6, data.num_nodes)])

print(f&quot;\nãƒ™ãƒ³ã‚¼ãƒ³ç’°ã®å¹³å‡é‡è¦åº¦: {benzene_importance:.4f}&quot;)
print(f&quot;ãã®ä»–ã®åŸå­ã®å¹³å‡é‡è¦åº¦: {other_importance:.4f}&quot;)

if benzene_importance &gt; other_importance:
    print(&quot;âœ… ãƒ™ãƒ³ã‚¼ãƒ³ç’°ãŒæ¯’æ€§ã«å¼·ãå¯„ä¸ã—ã¦ã„ã¾ã™ï¼&quot;)
else:
    print(&quot;âŒ ãƒ™ãƒ³ã‚¼ãƒ³ç’°ã®å¯„ä¸ã¯ä»–ã®éƒ¨åˆ†ã‚ˆã‚Šä½ã„ã§ã™ã€‚&quot;)

# ã‚¹ãƒ†ãƒƒãƒ—7: å¯è¦–åŒ–
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# åˆ†å­æ§‹é€ 
img = Draw.MolToImage(mol, size=(400, 400))
axes[0].imshow(img)
axes[0].set_title(f'åˆ†å­æ§‹é€ \n{smiles}', fontsize=12)
axes[0].axis('off')

# åŸå­é‡è¦åº¦
axes[1].bar(range(data.num_nodes), node_importance, color='steelblue')
axes[1].axhline(y=node_importance.mean(), color='r', linestyle='--', label='å¹³å‡')
axes[1].set_xlabel('åŸå­ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹', fontsize=12)
axes[1].set_ylabel('é‡è¦åº¦', fontsize=12)
axes[1].set_title('GNNExplainer: åŸå­ã”ã¨ã®æ¯’æ€§å¯„ä¸', fontsize=13)
axes[1].legend()
axes[1].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()
</code></pre>



**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:

<pre class="codehilite"><code>SMILES: c1ccccc1CC(=O)O
äºˆæ¸¬æ¯’æ€§ã‚¹ã‚³ã‚¢: 0.7234

é‡è¦ãªåŸå­ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰: [0, 1, 2, 3, 4, 5]

ãƒ™ãƒ³ã‚¼ãƒ³ç’°ã®å¹³å‡é‡è¦åº¦: 0.8523
ãã®ä»–ã®åŸå­ã®å¹³å‡é‡è¦åº¦: 0.3241
âœ… ãƒ™ãƒ³ã‚¼ãƒ³ç’°ãŒæ¯’æ€§ã«å¼·ãå¯„ä¸ã—ã¦ã„ã¾ã™ï¼
</code></pre>



**è§£èª¬**:
1. GNNExplainerã¯å„åŸå­ã®é‡è¦åº¦ã‚’0-1ã®ã‚¹ã‚³ã‚¢ã§å‡ºåŠ›
2. ãƒ™ãƒ³ã‚¼ãƒ³ç’°ã®åŸå­ï¼ˆ0-5ï¼‰ã®ã‚¹ã‚³ã‚¢ãŒé«˜ã„ â†’ æ¯’æ€§äºˆæ¸¬ã«å¯„ä¸
3. é…¢é…¸éƒ¨åˆ†ï¼ˆ6-10ï¼‰ã®ã‚¹ã‚³ã‚¢ã¯ä½ã„ â†’ æ¯’æ€§ã¸ã®å¯„ä¸ã¯å°ã•ã„

ã“ã‚Œã«ã‚ˆã‚Šã€ã€Œãƒ™ãƒ³ã‚¼ãƒ³ç’°ãŒæ¯’æ€§ã®ä¸»ãªè¦å› ã€ã¨ã„ã†ä»®èª¬ã‚’å®šé‡çš„ã«æ¤œè¨¼ã§ãã¾ã™ã€‚

</details>

<hr />
<h2>å‚è€ƒæ–‡çŒ®</h2>
<ol>
<li>
<p>Ying, Z., et al. (2018). "Hierarchical Graph Representation Learning with Differentiable Pooling." <em>NeurIPS 2018</em>.
   URL: https://arxiv.org/abs/1806.08804
   <em>DiffPoolè«–æ–‡ã€‚å¾®åˆ†å¯èƒ½ãªã‚°ãƒ©ãƒ•ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã®å…ˆé§†çš„ç ”ç©¶ã€‚</em></p>
</li>
<li>
<p>SchÃ¼tt, K., et al. (2017). "SchNet: A continuous-filter convolutional neural network for modeling quantum interactions." <em>NeurIPS 2017</em>.
   DOI: <a href="https://dl.acm.org/doi/10.5555/3294771.3294866">10.5555/3294771.3294866</a>
   <em>SchNetè«–æ–‡ã€‚3Dæƒ…å ±ã‚’è€ƒæ…®ã—ãŸGNNã®åŸºç¤ã€‚</em></p>
</li>
<li>
<p>Klicpera, J., et al. (2020). "Directional Message Passing for Molecular Graphs." <em>ICLR 2020</em>.
   URL: https://arxiv.org/abs/2003.03123
   <em>DimeNetè«–æ–‡ã€‚çµåˆè§’åº¦ã‚’è€ƒæ…®ã—ãŸé«˜ç²¾åº¦GNNã€‚</em></p>
</li>
<li>
<p>Batzner, S., et al. (2022). "E(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials." <em>Nature Communications</em>, 13, 2453.
   DOI: <a href="https://doi.org/10.1038/s41467-022-29939-5">10.1038/s41467-022-29939-5</a>
   <em>NequIPè«–æ–‡ã€‚ç­‰å¤‰GNNã®æœ€æ–°ç ”ç©¶ã€‚</em></p>
</li>
<li>
<p>VeliÄkoviÄ‡, P., et al. (2018). "Graph Attention Networks." <em>ICLR 2018</em>.
   URL: https://arxiv.org/abs/1710.10903
   <em>GATè«–æ–‡ã€‚æ³¨æ„æ©Ÿæ§‹ã‚’GNNã«å°å…¥ã—ãŸå…ˆé§†çš„ç ”ç©¶ã€‚</em></p>
</li>
<li>
<p>Ying, R., et al. (2019). "GNNExplainer: Generating Explanations for Graph Neural Networks." <em>NeurIPS 2019</em>.
   URL: https://arxiv.org/abs/1903.03894
   <em>GNNExplainerè«–æ–‡ã€‚GNNã®è§£é‡ˆå¯èƒ½æ€§ã‚’å®Ÿç¾ã€‚</em></p>
</li>
</ol>
<hr />
<p><strong>ä½œæˆæ—¥</strong>: 2025-10-17
<strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0
<strong>ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ</strong>: chapter-template-v2.0
<strong>è‘—è€…</strong>: GNNå…¥é–€ã‚·ãƒªãƒ¼ã‚ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</p>

        <div class="navigation">
            <a href="chapter-3.html" class="nav-button">â† å‰ç« : PyTorch Geometricå®Ÿè·µ</a>
            <a href="chapter-5.html" class="nav-button">æ¬¡ç« : å®Ÿä¸–ç•Œå¿œç”¨ã¨ã‚­ãƒ£ãƒªã‚¢ â†’</a>
            <a href="index.html" class="nav-button">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
        </div>
    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-17</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default'
                });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</body>
</html>