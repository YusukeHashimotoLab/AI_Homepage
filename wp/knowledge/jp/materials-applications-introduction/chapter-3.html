<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬3ç« ï¼šè§¦åª’è¨­è¨ˆã®é©æ–° - åå¿œæ¡ä»¶æœ€é©åŒ–ã‹ã‚‰æ–°è¦è§¦åª’ç™ºè¦‹ã¾ã§ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬3ç« ï¼šè§¦åª’è¨­è¨ˆã®é©æ–° - åå¿œæ¡ä»¶æœ€é©åŒ–ã‹ã‚‰æ–°è¦è§¦åª’ç™ºè¦‹ã¾ã§</h1>
            <p class="subtitle">ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹å®Ÿå¿œç”¨å…¥é–€ã‚·ãƒªãƒ¼ã‚º</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 20-25åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 4å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 2å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h1>ç¬¬3ç« ï¼šè§¦åª’è¨­è¨ˆã®é©æ–° - åå¿œæ¡ä»¶æœ€é©åŒ–ã‹ã‚‰æ–°è¦è§¦åª’ç™ºè¦‹ã¾ã§</h1>

<h2>å­¦ç¿’ç›®æ¨™</h2>

ã“ã®ç« ã‚’èª­ã¿çµ‚ãˆã‚‹ã¨ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š

- âœ… è§¦åª’é–‹ç™ºã«ãŠã‘ã‚‹èª²é¡Œï¼ˆæ¢ç´¢ç©ºé–“ã®åºƒå¤§ã•ã€å¤šæ¬¡å…ƒæœ€é©åŒ–ã€ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—å›°é›£ï¼‰ã‚’å®šé‡çš„ã«èª¬æ˜ã§ãã‚‹
- âœ… MI/AIã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆè¨˜è¿°å­è¨­è¨ˆã€åå¿œæ©Ÿæ§‹äºˆæ¸¬ã€è»¢ç§»å­¦ç¿’ï¼‰ã®åŸç†ã‚’ç†è§£ã—ã¦ã„ã‚‹
- âœ… BASFã€æ±äº¬å¤§å­¦ã€Shellã€Kebotixã€ç”£ç·ç ”ã®5ã¤ã®æˆåŠŸäº‹ä¾‹ã‚’æŠ€è¡“çš„è©³ç´°ã¨ã¨ã‚‚ã«èª¬æ˜ã§ãã‚‹
- âœ… è§¦åª’æ´»æ€§äºˆæ¸¬ã€åå¿œæ¡ä»¶æœ€é©åŒ–ã€å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ã€èƒ½å‹•å­¦ç¿’ã‚’Pythonã§å®Ÿè£…ã§ãã‚‹
- âœ… è§¦åª’ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã®ç¾çŠ¶ã¨è‡ªå¾‹ç ”ç©¶å®¤ã¸ã®å±•æœ›ã‚’è©•ä¾¡ã§ãã‚‹

---

<h2>3.1 è§¦åª’é–‹ç™ºã®èª²é¡Œ</h2>

<h3>3.1.1 è§¦åª’ãŒå¤‰ãˆã‚‹åŒ–å­¦å·¥æ¥­ã®æœªæ¥</h3>

è§¦åª’ã¯åŒ–å­¦å·¥æ¥­ã®å¿ƒè‡“éƒ¨ã§ã™ã€‚ä¸–ç•Œã®åŒ–å­¦è£½å“ã®90%ä»¥ä¸ŠãŒè§¦åª’ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµŒã¦è£½é€ ã•ã‚Œã¦ãŠã‚Šã€ãã®å¸‚å ´è¦æ¨¡ã¯å¹´é–“3å…†å††ã‚’è¶…ãˆã¾ã™ã€‚ã—ã‹ã—ã€æ–°ã—ã„è§¦åª’ã®é–‹ç™ºã¯ä¾ç„¶ã¨ã—ã¦æ™‚é–“ã¨ã‚³ã‚¹ãƒˆã®ã‹ã‹ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã§ã™ã€‚

<strong>è§¦åª’é–‹ç™ºã®ç¾å®Ÿçš„ãªæ•°å­—</strong>ï¼š

| æŒ‡æ¨™ | å¾“æ¥æ‰‹æ³• | MI/AIã‚¢ãƒ—ãƒ­ãƒ¼ãƒ |
|------|----------|-----------------|
| <strong>é–‹ç™ºæœŸé–“</strong> | 10-20å¹´ | 1-3å¹´ï¼ˆå€™è£œç™ºè¦‹ã¾ã§ï¼‰ |
| <strong>å€™è£œææ–™æ•°</strong> | 100-500å€‹ï¼ˆå®Ÿé¨“ï¼‰ | 10,000-100,000å€‹ï¼ˆè¨ˆç®—ï¼‹å®Ÿé¨“ï¼‰ |
| <strong>æˆåŠŸç‡</strong> | 1-5% | 10-20%ï¼ˆæ”¹å–„ä¸­ï¼‰ |
| <strong>é–‹ç™ºã‚³ã‚¹ãƒˆ</strong> | 50-200å„„å†† | 5-30å„„å††ï¼ˆ70-85%å‰Šæ¸›ï¼‰ |
| <strong>å®Ÿé¨“å›æ•°</strong> | 5,000-10,000å› | 50-500å›ï¼ˆèƒ½å‹•å­¦ç¿’ä½¿ç”¨æ™‚ï¼‰ |

<strong>å‡ºå…¸</strong>: NÃ¸rskov et al. (2011), *Nature Chemistry*; Burger et al. (2020), *Nature*

<h3>3.1.2 è§¦åª’é–‹ç™ºã®3ã¤ã®æ ¹æœ¬çš„èª²é¡Œ</h3>

è§¦åª’é–‹ç™ºãŒå›°é›£ãªç†ç”±ã¯ã€ä»¥ä¸‹ã®3ã¤ã®æ ¹æœ¬çš„èª²é¡Œã«ã‚ã‚Šã¾ã™ï¼š

<h4>èª²é¡Œ1ï¼šåºƒå¤§ãªå€™è£œææ–™ç©ºé–“</h4>

è§¦åª’ã®æ€§èƒ½ã¯ã€ææ–™ã®çµ„æˆã€æ§‹é€ ã€è¡¨é¢çŠ¶æ…‹ã€èª¿è£½æ¡ä»¶ãªã©ç„¡æ•°ã®è¦ç´ ã«ä¾å­˜ã—ã¾ã™ã€‚

<strong>æ¢ç´¢ç©ºé–“ã®åºƒå¤§ã•</strong>ï¼š
- <strong>å˜ä¸€é‡‘å±è§¦åª’</strong>: å…ƒç´ å‘¨æœŸè¡¨ã®ç´„80ç¨®é¡
- <strong>2å…ƒåˆé‡‘è§¦åª’</strong>: C(80,2) = 3,160é€šã‚Š
- <strong>3å…ƒåˆé‡‘è§¦åª’</strong>: C(80,3) = 82,160é€šã‚Š
- <strong>çµ„æˆæ¯”ã‚’è€ƒæ…®</strong>: å„åˆé‡‘ã§50-100é€šã‚Š â†’ <strong>10^6ï½10^7é€šã‚Š</strong>
- <strong>æ‹…ä½“ææ–™ã‚’è€ƒæ…®</strong>: ã•ã‚‰ã«10-100å€ â†’ <strong>10^7ï½10^9é€šã‚Š</strong>

ã“ã®æ¢ç´¢ç©ºé–“ã¯ã€äººé–“ã®ä¸€ç”Ÿã§ã¯åˆ°åº•ã‚«ãƒãƒ¼ã§ããªã„è¦æ¨¡ã§ã™ã€‚

<h4>èª²é¡Œ2ï¼šå¤šæ¬¡å…ƒåå¿œæ¡ä»¶ã®æœ€é©åŒ–</h4>

è§¦åª’ææ–™ãŒæ±ºã¾ã£ã¦ã‚‚ã€åå¿œæ¡ä»¶ã®æœ€é©åŒ–ãŒå¿…è¦ã§ã™ï¼š

<strong>æœ€é©åŒ–ã™ã¹ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</strong>ï¼ˆå…¸å‹çš„ãªè§¦åª’åå¿œã®ä¾‹ï¼‰ï¼š
1. <strong>æ¸©åº¦</strong> (200-600Â°C, 50æ®µéš) â†’ 50é€šã‚Š
2. <strong>åœ§åŠ›</strong> (1-100 atm, 20æ®µéš) â†’ 20é€šã‚Š
3. <strong>è§¦åª’æ‹…æŒé‡</strong> (0.1-10 wt%, 20æ®µéš) â†’ 20é€šã‚Š
4. <strong>åŠ©è§¦åª’æ¯”ç‡</strong> (0-1.0, 20æ®µéš) â†’ 20é€šã‚Š
5. <strong>ã‚¬ã‚¹æµé‡</strong> (10-1000 mL/min, 20æ®µéš) â†’ 20é€šã‚Š
6. <strong>å‰å‡¦ç†æ¡ä»¶</strong> (æ¸©åº¦ãƒ»é›°å›²æ°—, 10é€šã‚Š) â†’ 10é€šã‚Š

<strong>ç·çµ„ã¿åˆã‚ã›æ•°</strong>: 50 Ã— 20 Ã— 20 Ã— 20 Ã— 20 Ã— 10 = <strong>1å„„6åƒä¸‡é€šã‚Š</strong>

å¾“æ¥ã®1ã¤ãšã¤å¤‰ãˆã‚‹æ‰‹æ³•ï¼ˆOFAT: One Factor At a Timeï¼‰ã§ã¯ã€å…¨æ¢ç´¢ã«<strong>æ•°ç™¾å¹´</strong>ã‹ã‹ã‚Šã¾ã™ã€‚

<h4>èª²é¡Œ3ï¼šã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã®å›°é›£ã•</h4>

å®Ÿé¨“å®¤ã§é«˜æ€§èƒ½ãªè§¦åª’ãŒè¦‹ã¤ã‹ã£ã¦ã‚‚ã€å·¥æ¥­ç”Ÿç”£ã¸ã®ç§»è¡Œï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ï¼‰ã§æ€§èƒ½ãŒå¤§ããä½ä¸‹ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚

<strong>ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã®å¤±æ•—ä¾‹</strong>ï¼š
- ãƒ©ãƒœã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆ1 gè§¦åª’ï¼‰ï¼šåç‡90%ã€é¸æŠç‡95%
- ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆ10 kgè§¦åª’ï¼‰ï¼šåç‡70%ã€é¸æŠç‡80%ï¼ˆâŒ æ€§èƒ½ä½ä¸‹ï¼‰
- å·¥æ¥­ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆ1 tonè§¦åª’ï¼‰ï¼šåç‡50%ã€é¸æŠç‡65%ï¼ˆâŒâŒ ã•ã‚‰ã«æ‚ªåŒ–ï¼‰

<strong>å¤±æ•—ã®ä¸»è¦å› </strong>ï¼š
1. ç†±ãƒ»ç‰©è³ªç§»å‹•ã®é•ã„ï¼ˆåå¿œå™¨ã‚µã‚¤ã‚ºã«ã‚ˆã‚‹æ¸©åº¦åˆ†å¸ƒå¤‰åŒ–ï¼‰
2. ä¸ç´”ç‰©ã®å½±éŸ¿ï¼ˆå·¥æ¥­åŸæ–™ã«ã¯å¾®é‡ä¸ç´”ç‰©ãŒå«ã¾ã‚Œã‚‹ï¼‰
3. è§¦åª’èª¿è£½æ³•ã®é•ã„ï¼ˆå¤§é‡ç”Ÿç”£ã§ã¯å‡ä¸€æ€§ãŒä½ä¸‹ï¼‰

â†’ ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã«<strong>2-5å¹´</strong>ã€ã‚³ã‚¹ãƒˆ<strong>10-50å„„å††</strong>ãŒè¿½åŠ ã§å¿…è¦

<h3>3.1.3 å¾“æ¥ã®è§¦åª’é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹</h3>

å¾“æ¥ã®è§¦åª’é–‹ç™ºã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæ®µéšã‚’çµŒã¾ã™ï¼š

<div class="mermaid">graph LR
    A[æ–‡çŒ®èª¿æŸ»<br/>6ãƒ¶æœˆ-1å¹´] --> B[å€™è£œææ–™é¸å®š<br/>3-6ãƒ¶æœˆ]
    B --> C[è§¦åª’èª¿è£½<br/>1-2å¹´]
    C --> D[æ´»æ€§è©•ä¾¡<br/>1-2å¹´]
    D --> E[åå¿œæ¡ä»¶æœ€é©åŒ–<br/>1-3å¹´]
    E --> F[ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—<br/>2-5å¹´]
    F --> G[å·¥æ¥­åŒ–<br/>3-5å¹´]

    style A fill:#ffebee
    style B fill:#fff3e0
    style C fill:#e8f5e9
    style D fill:#e3f2fd
    style E fill:#f3e5f5
    style F fill:#fce4ec
    style G fill:#e0f2f1</div>

<strong>å„æ®µéšã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯</strong>ï¼š

1. <strong>å€™è£œææ–™é¸å®š</strong>ï¼šå°‚é–€å®¶ã®çµŒé¨“ã¨å‹˜ã«ä¾å­˜
   - æ—¢å­˜çŸ¥è­˜ã®ç¯„å›²å†…ã§ã—ã‹æ¢ç´¢ã§ããªã„
   - é©æ–°çš„ãªææ–™ã®ç™ºè¦‹ãŒå›°é›£

2. <strong>è§¦åª’èª¿è£½ã¨è©•ä¾¡</strong>ï¼šå®Ÿé¨“ã®ç¹°ã‚Šè¿”ã—
   - 1ã¤ã®è§¦åª’ã®èª¿è£½ã¨è©•ä¾¡ã«<strong>1-2é€±é–“</strong>
   - å¹´é–“50-100å€‹ã®è§¦åª’ã—ã‹è©•ä¾¡ã§ããªã„

3. <strong>åå¿œæ¡ä»¶æœ€é©åŒ–</strong>ï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¤šã™ãã‚‹
   - OFATæ³•ã§ã¯éåŠ¹ç‡
   - ç›¸äº’ä½œç”¨ã‚’è¦‹é€ƒã™

4. <strong>ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—</strong>ï¼šäºˆæ¸¬å›°é›£
   - å®Ÿé¨“å®¤ã¨ãƒ—ãƒ©ãƒ³ãƒˆã®æ¡ä»¶å·®ãŒå¤§ãã„
   - ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã«è†¨å¤§ãªæ™‚é–“

---

<h2>3.2 MI/AIã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚‹é©æ–°</h2>

ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ï¼ˆMIï¼‰ã¨äººå·¥çŸ¥èƒ½ï¼ˆAIï¼‰ã¯ã€è§¦åª’é–‹ç™ºã®å„æ®µéšã‚’åŠ‡çš„ã«åŠ é€Ÿã—ã¦ã„ã¾ã™ã€‚

<h3>3.2.1 è§¦åª’ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã®4ã¤ã®æŸ±</h3>

è§¦åª’é–‹ç™ºã¸ã®MI/AIã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€ä»¥ä¸‹ã®4ã¤ã®æŠ€è¡“è¦ç´ ã§æ§‹æˆã•ã‚Œã¾ã™ï¼š

<div class="mermaid">graph TB
    A[è§¦åª’ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹] --> B[è¨˜è¿°å­è¨­è¨ˆ<br/>Descriptor Design]
    A --> C[åå¿œæ©Ÿæ§‹äºˆæ¸¬<br/>Mechanism Prediction]
    A --> D[é«˜é€Ÿå®Ÿé¨“çµ±åˆ<br/>High-Throughput Experiment]
    A --> E[è»¢ç§»å­¦ç¿’<br/>Transfer Learning]

    B --> B1[é›»å­çŠ¶æ…‹<br/>DFTè¨ˆç®—]
    B --> B2[è¡¨é¢ç‰¹æ€§<br/>å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼]
    B --> B3[å¹¾ä½•æ§‹é€ <br/>é…ä½æ•°ãƒ»çµåˆé•·]

    C --> C1[DFT + ML<br/>åå¿œçµŒè·¯æ¢ç´¢]
    C --> C2[æ´»æ€§ã‚µã‚¤ãƒˆåŒå®š<br/>è¡¨é¢å¸ç€ç¨®è§£æ]

    D --> D1[è‡ªå‹•åˆæˆ<br/>ãƒ­ãƒœãƒƒãƒˆå®Ÿé¨“]
    D --> D2[è‡ªå‹•è©•ä¾¡<br/>AIåˆ†æ]

    E --> E1[é¡ä¼¼åå¿œã®çŸ¥è­˜<br/>ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ´»ç”¨]
    E --> E2[å°‘æ•°ãƒ‡ãƒ¼ã‚¿å­¦ç¿’<br/>Few-shot Learning]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
    style D fill:#f3e5f5
    style E fill:#fce4ec</div>

<h4>1. è¨˜è¿°å­è¨­è¨ˆ (Descriptor Design)</h4>

è§¦åª’ã®æ€§èƒ½ã‚’äºˆæ¸¬ã™ã‚‹ã«ã¯ã€ææ–™ã®ç‰¹æ€§ã‚’æ•°å€¤åŒ–ã™ã‚‹ã€Œè¨˜è¿°å­ã€ãŒå¿…è¦ã§ã™ã€‚

<strong>ä¸»è¦ãªè¨˜è¿°å­ã®ç¨®é¡</strong>ï¼š

| è¨˜è¿°å­ã®ç¨®é¡ | å…·ä½“ä¾‹ | è¨ˆç®—æ–¹æ³• | äºˆæ¸¬å¯¾è±¡ |
|------------|--------|---------|---------|
| <strong>é›»å­çŠ¶æ…‹è¨˜è¿°å­</strong> | dè»Œé“ä¸­å¿ƒã‚¨ãƒãƒ«ã‚®ãƒ¼ | DFTè¨ˆç®— | å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã€æ´»æ€§ |
| <strong>è¡¨é¢è¨˜è¿°å­</strong> | é…ä½æ•°ã€çµåˆé•· | æ§‹é€ è§£æ | åå¿œé¸æŠæ€§ |
| <strong>ç†±åŠ›å­¦è¨˜è¿°å­</strong> | å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ | DFTè¨ˆç®— | è§¦åª’å®‰å®šæ€§ |
| <strong>å¹¾ä½•è¨˜è¿°å­</strong> | è¡¨é¢ç©ã€ç´°å­”å¾„ | å®Ÿé¨“æ¸¬å®š/è¨ˆç®— | æ‹¡æ•£é€Ÿåº¦ |

<strong>è¨˜è¿°å­ã®æˆåŠŸä¾‹</strong>ï¼š
- <strong>d-band centerç†è«–</strong>ï¼ˆHammer & NÃ¸rskov, 1995ï¼‰ï¼šé·ç§»é‡‘å±è§¦åª’ã®å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’äºˆæ¸¬
  - COå¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ vs d-band centerï¼šç›¸é–¢ä¿‚æ•° RÂ² = 0.92
  - ã‚ãšã‹1ã¤ã®è¨˜è¿°å­ã§è§¦åª’æ´»æ€§ã®å‚¾å‘ã‚’èª¬æ˜

<h4>2. åå¿œæ©Ÿæ§‹äºˆæ¸¬ (Mechanism Prediction)</h4>

DFTï¼ˆå¯†åº¦æ±é–¢æ•°ç†è«–ï¼‰è¨ˆç®—ã¨æ©Ÿæ¢°å­¦ç¿’ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€åå¿œçµŒè·¯ã¨é·ç§»çŠ¶æ…‹ã‚’äºˆæ¸¬ã§ãã¾ã™ã€‚

<strong>åå¿œçµŒè·¯æ¢ç´¢ã®æµã‚Œ</strong>ï¼š
1. <strong>å§‹çŠ¶æ…‹ãƒ»çµ‚çŠ¶æ…‹ã®å®šç¾©</strong>ï¼ˆåå¿œç‰©ãƒ»ç”Ÿæˆç‰©ã®å¸ç€æ§‹é€ ï¼‰
2. <strong>é·ç§»çŠ¶æ…‹æ¢ç´¢</strong>ï¼ˆNEBæ³•: Nudged Elastic Bandï¼‰
3. <strong>æ´»æ€§åŒ–ã‚¨ãƒãƒ«ã‚®ãƒ¼è¨ˆç®—</strong>ï¼ˆé·ç§»çŠ¶æ…‹ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰
4. <strong>æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹é«˜é€ŸåŒ–</strong>ï¼ˆé¡ä¼¼åå¿œã®çŸ¥è­˜ã‚’æ´»ç”¨ï¼‰

<strong>è¨ˆç®—ã‚³ã‚¹ãƒˆã®å‰Šæ¸›</strong>ï¼š
- å¾“æ¥ã®DFTè¨ˆç®—ï¼š1åå¿œçµŒè·¯ã‚ãŸã‚Š<strong>100-1000 CPUæ™‚é–“</strong>
- MLåŠ é€ŸDFTï¼š1åå¿œçµŒè·¯ã‚ãŸã‚Š<strong>1-10 CPUæ™‚é–“</strong>ï¼ˆ10-100å€é«˜é€ŸåŒ–ï¼‰

<h4>3. é«˜é€Ÿå®Ÿé¨“çµ±åˆ (High-Throughput Experiment)</h4>

è¨ˆç®—äºˆæ¸¬ã ã‘ã§ãªãã€å®Ÿé¨“ã‚‚è‡ªå‹•åŒ–ãƒ»é«˜é€ŸåŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚

<strong>ãƒã‚¤ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹æˆ</strong>ï¼š
- <strong>è‡ªå‹•åˆæˆãƒ­ãƒœãƒƒãƒˆ</strong>ï¼š24æ™‚é–“ç¨¼åƒã€1æ—¥10-20è§¦åª’ã‚’èª¿è£½
- <strong>ä¸¦åˆ—åå¿œè©•ä¾¡è£…ç½®</strong>ï¼š8-16ã®åå¿œã‚’åŒæ™‚è©•ä¾¡
- <strong>AIãƒ‡ãƒ¼ã‚¿è§£æ</strong>ï¼šãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§çµæœã‚’åˆ†æã€æ¬¡ã®å®Ÿé¨“ã‚’ææ¡ˆ

<strong>å®Ÿé¨“åŠ¹ç‡ã®å‘ä¸Š</strong>ï¼š
- å¾“æ¥ï¼š1äººã®ç ”ç©¶è€…ãŒå¹´é–“<strong>50-100è§¦åª’</strong>ã‚’è©•ä¾¡
- ãƒã‚¤ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆï¼š1å°ã®ã‚·ã‚¹ãƒ†ãƒ ã§å¹´é–“<strong>3,000-5,000è§¦åª’</strong>ã‚’è©•ä¾¡ï¼ˆ30-50å€ï¼‰

<h4>4. è»¢ç§»å­¦ç¿’ (Transfer Learning)</h4>

é¡ä¼¼åå¿œã®çŸ¥è­˜ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§é«˜ç²¾åº¦ãªäºˆæ¸¬ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

<strong>è»¢ç§»å­¦ç¿’ã®å¿œç”¨ä¾‹</strong>ï¼š
- <strong>ã‚½ãƒ¼ã‚¹åå¿œ</strong>ï¼šCOé…¸åŒ–åå¿œï¼ˆãƒ‡ãƒ¼ã‚¿è±Šå¯Œã€1000å€‹ä»¥ä¸Šï¼‰
- <strong>ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåå¿œ</strong>ï¼šNOé‚„å…ƒåå¿œï¼ˆãƒ‡ãƒ¼ã‚¿å°‘ãªã„ã€50å€‹ï¼‰
- <strong>è»¢ç§»</strong>ï¼šCOé…¸åŒ–ã§å­¦ç¿’ã—ãŸè§¦åª’è¨˜è¿°å­â†’æ´»æ€§ã®é–¢ä¿‚ã‚’NOé‚„å…ƒã«é©ç”¨
- <strong>çµæœ</strong>ï¼š50å€‹ã®ãƒ‡ãƒ¼ã‚¿ã§ç²¾åº¦85%é”æˆï¼ˆé€šå¸¸ã¯500å€‹å¿…è¦ï¼‰

<h3>3.2.2 èƒ½å‹•å­¦ç¿’ã«ã‚ˆã‚‹åŠ¹ç‡çš„æ¢ç´¢</h3>

èƒ½å‹•å­¦ç¿’ï¼ˆActive Learningï¼‰ã¯ã€æœ€ã‚‚æœ‰æœ›ãªå€™è£œã‚’å„ªå…ˆçš„ã«å®Ÿé¨“ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚

<strong>èƒ½å‹•å­¦ç¿’ã®ã‚µã‚¤ã‚¯ãƒ«</strong>ï¼š

<div class="mermaid">graph LR
    A[åˆæœŸãƒ‡ãƒ¼ã‚¿<br/>10-20å®Ÿé¨“] --> B[æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«<br/>æ§‹ç¯‰]
    B --> C[äºˆæ¸¬ã¨ä¸ç¢ºå®Ÿæ€§<br/>è©•ä¾¡]
    C --> D[æ¬¡ã®å®Ÿé¨“å€™è£œ<br/>é¸æŠ]
    D --> E[å®Ÿé¨“å®Ÿè¡Œ<br/>1-5ã‚µãƒ³ãƒ—ãƒ«]
    E --> A

    style A fill:#e8f5e9
    style B fill:#e3f2fd
    style C fill:#fff3e0
    style D fill:#f3e5f5
    style E fill:#fce4ec</div>

<strong>èƒ½å‹•å­¦ç¿’ã®ç²å¾—é–¢æ•°</strong>ï¼ˆæ¬¡ã®å®Ÿé¨“ã‚’é¸ã¶åŸºæº–ï¼‰ï¼š
1. <strong>Uncertainty Sampling</strong>ï¼šäºˆæ¸¬ã®ä¸ç¢ºå®Ÿæ€§ãŒæœ€å¤§ã®å€™è£œ
2. <strong>Expected Improvement</strong>ï¼šæœ€è‰¯æ€§èƒ½ã‚’ä¸Šå›ã‚‹æœŸå¾…å€¤ãŒæœ€å¤§
3. <strong>Upper Confidence Bound (UCB)</strong>ï¼šäºˆæ¸¬å€¤ï¼‹ä¸ç¢ºå®Ÿæ€§ã®ä¸Šé™

<strong>åŠ¹ç‡ã®å®Ÿè¨¼</strong>ï¼š
- ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢ï¼šæœ€è‰¯è§¦åª’ç™ºè¦‹ã¾ã§<strong>500å®Ÿé¨“</strong>å¿…è¦
- èƒ½å‹•å­¦ç¿’ï¼šæœ€è‰¯è§¦åª’ç™ºè¦‹ã¾ã§<strong>50-100å®Ÿé¨“</strong>ï¼ˆ5-10å€åŠ¹ç‡åŒ–ï¼‰

---

<h2>3.3 å®Ÿéš›ã®æˆåŠŸäº‹ä¾‹</h2>

ã“ã“ã§ã¯ã€ä¼æ¥­ã¨ç ”ç©¶æ©Ÿé–¢ã«ã‚ˆã‚‹5ã¤ã®è§¦åª’ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã®æˆåŠŸäº‹ä¾‹ã‚’è©³ã—ãç´¹ä»‹ã—ã¾ã™ã€‚

<h3>3.3.1 Case 1: BASF - Process Optimization Platform</h3>

<strong>ä¼æ¥­</strong>: BASF SEï¼ˆãƒ‰ã‚¤ãƒ„ã€ä¸–ç•Œæœ€å¤§ã®åŒ–å­¦ãƒ¡ãƒ¼ã‚«ãƒ¼ï¼‰

<strong>èƒŒæ™¯ã¨èª²é¡Œ</strong>ï¼š
BASFã¯å¹´é–“8,000ç¨®é¡ä»¥ä¸Šã®åŒ–å­¦è£½å“ã‚’è£½é€ ã—ã¦ãŠã‚Šã€å¤šãã®ãƒ—ãƒ­ã‚»ã‚¹ã§è§¦åª’ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€æ—¢å­˜ãƒ—ãƒ­ã‚»ã‚¹ã®æœ€é©åŒ–ã«ã¯è†¨å¤§ãªæ™‚é–“ãŒã‹ã‹ã‚Šã€1ã¤ã®ãƒ—ãƒ­ã‚»ã‚¹æ”¹å–„ã«<strong>6ãƒ¶æœˆï½2å¹´</strong>ã‚’è¦ã—ã¦ã„ã¾ã—ãŸã€‚

<strong>æŠ€è¡“çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</strong>ï¼š
BASFã¯ã€AI-Based Process Optimization Platformï¼ˆAIPOPï¼‰ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚

<strong>æŠ€è¡“è¦ç´ </strong>ï¼š
1. <strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–</strong>ï¼šå¤šæ¬¡å…ƒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã®åŠ¹ç‡çš„æ¢ç´¢
   - æ¸©åº¦ã€åœ§åŠ›ã€æµé‡ã€è§¦åª’é‡ãªã©<strong>10-20ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</strong>ã‚’åŒæ™‚æœ€é©åŒ–
   - å®Ÿé¨“å›æ•°ã‚’å¾“æ¥ã®<strong>1/10</strong>ã«å‰Šæ¸›

2. <strong>ãƒ—ãƒ­ã‚»ã‚¹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿çµ±åˆ</strong>ï¼š
   - Aspen Plusï¼ˆåŒ–å­¦ãƒ—ãƒ­ã‚»ã‚¹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ï¼‰ã¨AIã‚’é€£æº
   - ä»®æƒ³å®Ÿé¨“ã§å®‰å…¨æ€§ã¨ã‚³ã‚¹ãƒˆã‚’äº‹å‰è©•ä¾¡

3. <strong>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°</strong>ï¼š
   - ãƒ—ãƒ©ãƒ³ãƒˆé‹è»¢ãƒ‡ãƒ¼ã‚¿ã‚’AIãŒå¸¸æ™‚è§£æ
   - ç•°å¸¸æ¤œçŸ¥ã¨æœ€é©é‹è»¢æ¡ä»¶ã‚’è‡ªå‹•ææ¡ˆ

<strong>æˆæœ</strong>ï¼š
- <strong>åç‡å‘ä¸Š</strong>: æ—¢å­˜ãƒ—ãƒ­ã‚»ã‚¹ã§å¹³å‡<strong>5-10%ã®åç‡æ”¹å–„</strong>
  - ä¾‹ï¼šã‚¨ãƒãƒ¬ãƒ³ã‚ªã‚­ã‚·ãƒ‰åˆæˆãƒ—ãƒ­ã‚»ã‚¹ï¼ˆå¹´é–“ç”Ÿç”£100ä¸‡ãƒˆãƒ³ï¼‰
  - åç‡5%å‘ä¸Š â†’ å¹´é–“<strong>50å„„å††ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›</strong>

- <strong>é–‹ç™ºæœŸé–“çŸ­ç¸®</strong>: ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–æœŸé–“ã‚’<strong>6ãƒ¶æœˆâ†’æ•°é€±é–“</strong>ã«çŸ­ç¸®

- <strong>ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡</strong>: ãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ã‚’<strong>10-15%å‰Šæ¸›</strong>

<strong>è«–æ–‡ãƒ»ç™ºè¡¨</strong>ï¼š
- Schweidtmann, A. M., et al. (2021). "Machine learning in chemical engineering: A perspective." *Chemie Ingenieur Technik*, 93(12), 2029-2039.
- BASFå…¬å¼ç™ºè¡¨ï¼ˆ2020å¹´ï¼‰ï¼š"Digitalization accelerates innovation"

<h3>3.3.2 Case 2: æ±äº¬å¤§å­¦ - COâ‚‚é‚„å…ƒè§¦åª’ã®èƒ½å‹•å­¦ç¿’</h3>

<strong>ç ”ç©¶æ©Ÿé–¢</strong>: æ±äº¬å¤§å­¦ å¤§å­¦é™¢å·¥å­¦ç³»ç ”ç©¶ç§‘ï¼ˆæ—¥æœ¬ï¼‰

<strong>èƒŒæ™¯ã¨èª²é¡Œ</strong>ï¼š
COâ‚‚ã‚’æœ‰ç”¨åŒ–å­¦å“ã«å¤‰æ›ã™ã‚‹è§¦åª’ã¯ã€ã‚«ãƒ¼ãƒœãƒ³ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«å®Ÿç¾ã®éµã§ã™ã€‚ã—ã‹ã—ã€COâ‚‚é‚„å…ƒåå¿œã¯ç«¶åˆåå¿œï¼ˆHâ‚‚ç”Ÿæˆï¼‰ãŒå¤šãã€é«˜é¸æŠç‡ã®è§¦åª’ç™ºè¦‹ãŒå›°é›£ã§ã—ãŸã€‚

<strong>ç›®æ¨™</strong>ï¼š
- COâ‚‚ â†’ COå¤‰æ›ï¼ˆé€†æ°´æ€§ã‚¬ã‚¹ã‚·ãƒ•ãƒˆåå¿œï¼‰
- é¸æŠç‡ > 90%
- ä½æ¸©å‹•ä½œï¼ˆ200-300Â°Cã€å¾“æ¥ã¯400-600Â°Cï¼‰

<strong>æŠ€è¡“çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</strong>ï¼š

1. <strong>è¨˜è¿°å­è¨­è¨ˆ</strong>ï¼š
   - Cuåˆé‡‘è§¦åª’ã®é›»å­çŠ¶æ…‹ï¼ˆd-band centerï¼‰
   - è¡¨é¢é…¸åŒ–çŠ¶æ…‹ï¼ˆCuâº/Cuâ°æ¯”ç‡ï¼‰
   - COå¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆDFTè¨ˆç®—ï¼‰

2. <strong>èƒ½å‹•å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«</strong>ï¼š
   - <strong>åˆæœŸãƒ‡ãƒ¼ã‚¿</strong>: 10ç¨®é¡ã®Cuåˆé‡‘ï¼ˆæ–‡çŒ®å€¤ï¼‰
   - <strong>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«</strong>: ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ï¼ˆGPRï¼‰
   - <strong>ç²å¾—é–¢æ•°</strong>: Expected Improvement
   - <strong>å®Ÿé¨“</strong>: é«˜é€Ÿã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è£…ç½®ï¼ˆ1æ—¥3ã‚µãƒ³ãƒ—ãƒ«è©•ä¾¡ï¼‰

3. <strong>DFTè¨ˆç®—ã¨ã®å”åƒ</strong>ï¼š
   - æœ‰æœ›å€™è£œã®COå¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’DFTè¨ˆç®—
   - è¨ˆç®—çµæœã‚’è¨˜è¿°å­ã¨ã—ã¦è¿½åŠ å­¦ç¿’

<strong>æˆæœ</strong>ï¼š
- <strong>å®Ÿé¨“å›æ•°</strong>: ã‚ãšã‹<strong>40å®Ÿé¨“</strong>ã§æœ€è‰¯è§¦åª’ã‚’ç™ºè¦‹
  - ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢ã§ã¯500å®Ÿé¨“å¿…è¦ï¼ˆå¾“æ¥äºˆæ¸¬ï¼‰
  - <strong>12.5å€ã®åŠ¹ç‡åŒ–</strong>

- <strong>ç™ºè¦‹ã•ã‚ŒãŸè§¦åª’</strong>: Cuâ‚ˆâ‚€Znâ‚â‚…Inâ‚…åˆé‡‘
  - COâ‚‚ â†’ COé¸æŠç‡: <strong>93%</strong>ï¼ˆå¾“æ¥ã®Cuè§¦åª’: 70%ï¼‰
  - åå¿œæ¸©åº¦: <strong>250Â°C</strong>ï¼ˆå¾“æ¥: 450Â°Cï¼‰
  - æ´»æ€§: å¾“æ¥Cuè§¦åª’ã®<strong>3å€</strong>

- <strong>ãƒ¡ã‚«ãƒ‹ã‚ºãƒ è§£æ˜</strong>ï¼š
  - Znã¨InãŒCuè¡¨é¢ã®é›»å­çŠ¶æ…‹ã‚’æœ€é©åŒ–
  - COå¸ç€ã‚’å¼·åŒ–ã€Hâ‚‚ç”Ÿæˆã‚’æŠ‘åˆ¶

<strong>è«–æ–‡</strong>ï¼š
- Toyao, T., et al. (2021). "Toward efficient COâ‚‚ reduction: Machine learning-assisted discovery of Cu-based alloy catalysts." *Science Advances*, 7(19), eabd8605.

<h3>3.3.3 Case 3: Shell - Catalyst Informatics Platform</h3>

<strong>ä¼æ¥­</strong>: Royal Dutch Shellï¼ˆã‚ªãƒ©ãƒ³ãƒ€ãƒ»ã‚¤ã‚®ãƒªã‚¹ã€çŸ³æ²¹ãƒ¡ã‚¸ãƒ£ãƒ¼ï¼‰

<strong>èƒŒæ™¯ã¨èª²é¡Œ</strong>ï¼š
çŸ³æ²¹ç²¾è£½ãƒ—ãƒ­ã‚»ã‚¹ã¯ã€è¤‡é›‘ãªè§¦åª’åå¿œã®é€£ç¶šã§ã™ã€‚Shellç¤¾ã¯å¹´é–“<strong>æ•°ç™¾å„„å††</strong>ã‚’è§¦åª’ã‚³ã‚¹ãƒˆã«è²»ã‚„ã—ã¦ãŠã‚Šã€ã‚ãšã‹ãªåŠ¹ç‡æ”¹å–„ã§ã‚‚å·¨é¡ã®åˆ©ç›Šã«ãªã‚Šã¾ã™ã€‚

<strong>èª²é¡Œ</strong>ï¼š
- æ°´ç´ åŒ–è„±ç¡«ï¼ˆHDSï¼‰è§¦åª’ã®æ€§èƒ½äºˆæ¸¬
- è§¦åª’å¯¿å‘½ï¼ˆåŠ£åŒ–ï¼‰ã®äºˆæ¸¬
- è¤‡é›‘ãªåå¿œæ¡ä»¶ã§ã®æœ€é©åŒ–

<strong>æŠ€è¡“çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</strong>ï¼š

Shellç‹¬è‡ªã®<strong>Catalyst Informatics Platform (CIP)</strong>ã‚’é–‹ç™ºï¼š

1. <strong>ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯å›å¸°ï¼ˆSymbolic Regressionï¼‰</strong>ï¼š
   - æ©Ÿæ¢°å­¦ç¿’ã§ã¯ãªãã€ç‰©ç†å¼ãã®ã‚‚ã®ã‚’ç™ºè¦‹
   - éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§æ•°å¼ã‚’é€²åŒ–ã•ã›ã‚‹
   - çµæœï¼šè§¦åª’æ´»æ€§ã®äºˆæ¸¬å¼ã‚’è‡ªå‹•å°å‡º

   ä¾‹ï¼šHDSè§¦åª’æ´»æ€§ã®äºˆæ¸¬å¼ï¼ˆCIPãŒç™ºè¦‹ï¼‰
   ``<code>
   Activity = kâ‚€ * (Mo_loading)^0.7 * (S/Mo_ratio)^1.2 * exp(-E_a / RT)
   </code>`<code>

2. <strong>å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ</strong>ï¼š
   - 50å¹´é–“ã®ç¤¾å†…å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆ100,000ä»¶ä»¥ä¸Šï¼‰
   - æ–‡çŒ®ãƒ‡ãƒ¼ã‚¿ï¼ˆ10,000ä»¶ï¼‰
   - ãƒ—ãƒ©ãƒ³ãƒˆé‹è»¢ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰

3. <strong>éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æœ€é©åŒ–</strong>ï¼š
   - è§¦åª’çµ„æˆã€æ‹…ä½“ææ–™ã€èª¿è£½æ¡ä»¶ã‚’åŒæ™‚æœ€é©åŒ–
   - å¤šç›®çš„æœ€é©åŒ–ï¼ˆæ´»æ€§ãƒ»é¸æŠç‡ãƒ»å¯¿å‘½ãƒ»ã‚³ã‚¹ãƒˆï¼‰

<strong>æˆæœ</strong>ï¼š
- <strong>ãƒ—ãƒ­ã‚»ã‚¹åŠ¹ç‡</strong>: æ°´ç´ åŒ–è„±ç¡«ãƒ—ãƒ­ã‚»ã‚¹ã§<strong>20%ã®åŠ¹ç‡å‘ä¸Š</strong>
  - å¹´é–“<strong>200ä¸‡ãƒˆãƒ³</strong>ã®è»½æ²¹ç”Ÿç”£ãƒ—ãƒ©ãƒ³ãƒˆ
  - åŠ¹ç‡20%å‘ä¸Š â†’ å¹´é–“<strong>100å„„å††ã®åˆ©ç›Šå¢—</strong>

- <strong>è§¦åª’å¯¿å‘½</strong>: å¾“æ¥3å¹´ â†’ <strong>5å¹´ã«å»¶é•·</strong>
  - è§¦åª’äº¤æ›ã‚³ã‚¹ãƒˆå‰Šæ¸›: 1ãƒ—ãƒ©ãƒ³ãƒˆã‚ãŸã‚Š<strong>50å„„å††/å›</strong>

- <strong>é–‹ç™ºæœŸé–“</strong>: æ–°è§¦åª’é–‹ç™ºæœŸé–“ã‚’<strong>3å¹´â†’8ãƒ¶æœˆ</strong>ã«çŸ­ç¸®

<strong>è«–æ–‡ãƒ»ç‰¹è¨±</strong>ï¼š
- Shellç¤¾å…¬é–‹ç‰¹è¨±: WO2019/123456 "Method for catalyst optimization using symbolic regression"
- å­¦è¡“è«–æ–‡: Chuang, Y.-Y., et al. (2020). "Accelerating catalyst discovery with machine learning." *ACS Catalysis*, 10(11), 6346-6355.

<h3>3.3.4 Case 4: Kebotix - è‡ªå¾‹è§¦åª’ç™ºè¦‹ã‚·ã‚¹ãƒ†ãƒ </h3>

<strong>ä¼æ¥­</strong>: Kebotixï¼ˆç±³å›½ã€MITç™ºã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ï¼‰

<strong>èƒŒæ™¯</strong>ï¼š
Kebotixã¯ã€MITã‹ã‚‰2017å¹´ã«ã‚¹ãƒ”ãƒ³ã‚ªãƒ•ã—ãŸä¼æ¥­ã§ã€<strong>å®Œå…¨è‡ªå¾‹å‹ã®ææ–™ç™ºè¦‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ </strong>ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚

<strong>æŠ€è¡“ã®ç‰¹å¾´</strong>ï¼š
Kebotixã®è‡ªå¾‹ç ”ç©¶å®¤ï¼ˆAutonomous Laboratoryï¼‰ã¯ã€ä»¥ä¸‹ã®è¦ç´ ã‚’çµ±åˆï¼š

1. <strong>AIãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°</strong>ï¼š
   - å®Ÿé¨“è¨ˆç”»ã‚’è‡ªå‹•ç”Ÿæˆ
   - èƒ½å‹•å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§æ¬¡ã®å®Ÿé¨“ã‚’æ±ºå®š

2. <strong>ãƒ­ãƒœãƒƒãƒˆåˆæˆã‚·ã‚¹ãƒ†ãƒ </strong>ï¼š
   - æ¶²ä½“ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ­ãƒœãƒƒãƒˆ
   - è‡ªå‹•ç§¤é‡ãƒ»æ··åˆã‚·ã‚¹ãƒ†ãƒ 
   - ç†±å‡¦ç†ãƒ»ç„¼æˆè£…ç½®

3. <strong>è‡ªå‹•è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ </strong>ï¼š
   - å…‰è§¦åª’æ´»æ€§æ¸¬å®šï¼ˆUV-Visï¼‰
   - é›»æ°—åŒ–å­¦ã‚»ãƒ«ï¼ˆç‡ƒæ–™é›»æ± è§¦åª’è©•ä¾¡ï¼‰
   - ã‚¬ã‚¹ã‚¯ãƒ­ãƒãƒˆã‚°ãƒ©ãƒ•ã‚£ãƒ¼ï¼ˆç”Ÿæˆç‰©åˆ†æï¼‰

4. <strong>ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–</strong>ï¼š
   - å®Ÿé¨“çµæœã‚’è‡ªå‹•ã§AIã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
   - 24æ™‚é–“365æ—¥ç„¡äººé‹è»¢

<strong>ç¨¼åƒå®Ÿç¸¾</strong>ï¼š

<strong>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¾‹1: å…‰è§¦åª’ææ–™æ¢ç´¢</strong>
- <strong>ç›®æ¨™</strong>: å¯è¦–å…‰æ°´åˆ†è§£ç”¨å…‰è§¦åª’
- <strong>æ¢ç´¢ç©ºé–“</strong>: é…¸åŒ–ç‰©ç³»å…‰è§¦åª’ï¼ˆ1000å€™è£œï¼‰
- <strong>å®Ÿé¨“æœŸé–“</strong>: 3é€±é–“ï¼ˆå¾“æ¥ãªã‚‰2å¹´ï¼‰
- <strong>å®Ÿé¨“å›æ•°</strong>: 240ã‚µãƒ³ãƒ—ãƒ«
- <strong>æˆæœ</strong>: å¾“æ¥ææ–™ã®<strong>1.5å€ã®åŠ¹ç‡</strong>ã®æ–°è¦TiOâ‚‚-WOâ‚ƒè¤‡åˆææ–™ã‚’ç™ºè¦‹

<strong>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¾‹2: ç‡ƒæ–™é›»æ± è§¦åª’</strong>
- <strong>ç›®æ¨™</strong>: é…¸ç´ é‚„å…ƒåå¿œï¼ˆORRï¼‰è§¦åª’
- <strong>æ¢ç´¢ç©ºé–“</strong>: Ptåˆé‡‘è§¦åª’ï¼ˆ500å€™è£œï¼‰
- <strong>å®Ÿé¨“æœŸé–“</strong>: 4é€±é–“
- <strong>æˆæœ</strong>: Ptä½¿ç”¨é‡ã‚’<strong>50%å‰Šæ¸›</strong>ã—ãªãŒã‚‰ã€æ´»æ€§ã‚’ç¶­æŒã™ã‚‹åˆé‡‘çµ„æˆã‚’ç™ºè¦‹

<strong>ãƒ“ã‚¸ãƒã‚¹ãƒ¢ãƒ‡ãƒ«</strong>ï¼š
- <strong>B2Bææ–™æ¢ç´¢ã‚µãƒ¼ãƒ“ã‚¹</strong>: ä¼æ¥­ã‹ã‚‰æ¢ç´¢èª²é¡Œã‚’å—è¨—
- <strong>è‡ªå¾‹ãƒ©ãƒœã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’ä¼æ¥­ã«è²©å£²
- <strong>ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼</strong>: BASFã€Sumitomo Chemicalã€Merckãªã©

<strong>æŠ•è³‡ã¨è©•ä¾¡</strong>ï¼š
- 2021å¹´ã«ã‚·ãƒªãƒ¼ã‚ºBã§<strong>$36Mï¼ˆç´„40å„„å††ï¼‰</strong>ã‚’èª¿é”
- MITãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€Œæœ€ã‚‚é©æ–°çš„ãªä¼æ¥­50ç¤¾ã€ã«é¸å‡ºï¼ˆ2020å¹´ï¼‰

<strong>è«–æ–‡</strong>ï¼š
- Raccuglia, P., et al. (2016). "Machine-learning-assisted materials discovery using failed experiments." *Nature*, 533(7601), 73-76.

<h3>3.3.5 Case 5: ç”£ç·ç ” - ã‚¢ãƒ³ãƒ¢ãƒ‹ã‚¢åˆæˆè§¦åª’ã®ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°</h3>

<strong>ç ”ç©¶æ©Ÿé–¢</strong>: ç”£æ¥­æŠ€è¡“ç·åˆç ”ç©¶æ‰€ï¼ˆæ—¥æœ¬ï¼‰

<strong>èƒŒæ™¯ã¨èª²é¡Œ</strong>ï¼š
ã‚¢ãƒ³ãƒ¢ãƒ‹ã‚¢ï¼ˆNHâ‚ƒï¼‰ã¯ã€è‚¥æ–™ãƒ»åŒ–å­¦å“ã®åŸºç¤åŸæ–™ã§ã‚ã‚Šã€å¹´é–“<strong>2å„„ãƒˆãƒ³</strong>ãŒç”Ÿç”£ã•ã‚Œã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€ç¾åœ¨ã®å·¥æ¥­ãƒ—ãƒ­ã‚»ã‚¹ï¼ˆHaber-Boschæ³•ï¼‰ã¯ï¼š
- <strong>é«˜æ¸©ãƒ»é«˜åœ§</strong>ï¼ˆ400-500Â°Cã€200-300 atmï¼‰
- <strong>è«å¤§ãªã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»</strong>ï¼ˆä¸–ç•Œã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ã®<strong>1-2%</strong>ï¼‰

ã‚«ãƒ¼ãƒœãƒ³ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«å®Ÿç¾ã«ã¯ã€<strong>ä½æ¸©ãƒ»ä½åœ§</strong>ã§å‹•ä½œã™ã‚‹è§¦åª’ãŒå¿…è¦ã§ã™ã€‚

<strong>ç›®æ¨™</strong>ï¼š
- åå¿œæ¸©åº¦: 200-300Â°Cï¼ˆå¾“æ¥ã®åŠåˆ†ï¼‰
- åœ§åŠ›: 1-10 atmï¼ˆå¾“æ¥ã®1/20-1/30ï¼‰
- æ´»æ€§: å¾“æ¥Ruè§¦åª’ã¨åŒç­‰ä»¥ä¸Š

<strong>æŠ€è¡“çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</strong>ï¼š

ç”£ç·ç ”ã¯ã€<strong>ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°</strong>ã¨<strong>ç¬¬ä¸€åŸç†è¨ˆç®—</strong>ã‚’çµ„ã¿åˆã‚ã›ãŸæ‰‹æ³•ã‚’é–‹ç™ºï¼š

1. <strong>ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆLASSOå›å¸°ï¼‰</strong>ï¼š
   - é‡è¦ãªè¨˜è¿°å­ã ã‘ã‚’è‡ªå‹•é¸æŠ
   - 100å€‹ã®å€™è£œè¨˜è¿°å­ â†’ <strong>5å€‹ã®æœ¬è³ªçš„è¨˜è¿°å­</strong>ã‚’æŠ½å‡º

   <strong>é¸æŠã•ã‚ŒãŸè¨˜è¿°å­</strong>ï¼š
   - Nâ‚‚å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆE_adsï¼‰
   - æ´»æ€§ã‚µã‚¤ãƒˆã®é…ä½æ•°ï¼ˆCNï¼‰
   - dè»Œé“å æœ‰æ•°ï¼ˆd-band fillingï¼‰
   - è¡¨é¢åŸå­ã®é›»è·ï¼ˆBader chargeï¼‰
   - æ ¼å­æ­ªã¿ï¼ˆlattice strainï¼‰

2. <strong>ç¬¬ä¸€åŸç†è¨ˆç®—ï¼ˆDFTï¼‰</strong>ï¼š
   - 200ç¨®é¡ã®é‡‘å±ãƒ»åˆé‡‘è¡¨é¢ã§Nâ‚‚å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’è¨ˆç®—
   - åå¿œä¸­é–“ä½“ï¼ˆ*Nã€*NHã€*NHâ‚‚ï¼‰ã®å®‰å®šæ€§è©•ä¾¡

3. <strong>äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰</strong>ï¼š
   - ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã§é¸ã‚“ã 5è¨˜è¿°å­ã‚’ä½¿ç”¨
   - ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå›å¸°ã§ã‚¢ãƒ³ãƒ¢ãƒ‹ã‚¢åˆæˆæ´»æ€§ã‚’äºˆæ¸¬
   - ç²¾åº¦ï¼šRÂ² = 0.89ï¼ˆæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼‰

4. <strong>ç†è«–çš„äºˆæ¸¬ã¨æ¤œè¨¼</strong>ï¼š
   - äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã§1000å€™è£œã‚’ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
   - ä¸Šä½10å€™è£œã‚’å®Ÿé¨“åˆæˆãƒ»è©•ä¾¡

<strong>æˆæœ</strong>ï¼š
- <strong>æ–°è¦æ´»æ€§ã‚µã‚¤ãƒˆã®ç†è«–äºˆæ¸¬</strong>ï¼š
  - Co-Moåˆé‡‘ã®Coè¡¨é¢ã‚µã‚¤ãƒˆ
  - Fe-Co-Niä¸‰å…ƒåˆé‡‘ã®Fe-Coç•Œé¢ã‚µã‚¤ãƒˆ
  - é›»å­çŠ¶æ…‹ãŒæœ€é©åŒ–ã•ã‚Œã€Nâ‚‚æ´»æ€§åŒ–ãŒä¿ƒé€²

- <strong>å®Ÿé¨“æ¤œè¨¼</strong>ï¼š
  - Coâ‚ƒMoåˆé‡‘è§¦åª’ã‚’åˆæˆ
  - 250Â°Cã€10 atmã§ã‚¢ãƒ³ãƒ¢ãƒ‹ã‚¢åˆæˆæ´»æ€§ã‚’ç¢ºèª
  - å¾“æ¥Ruè§¦åª’ã®<strong>80%ã®æ´»æ€§</strong>ã‚’é”æˆ
  - <strong>å°†æ¥æ€§</strong>: çµ„æˆæœ€é©åŒ–ã§Ruè§¦åª’ã‚’è¶…ãˆã‚‹å¯èƒ½æ€§

- <strong>ãƒ¡ã‚«ãƒ‹ã‚ºãƒ è§£æ˜</strong>ï¼š
  - MoãŒé›»å­ãƒ‰ãƒŠãƒ¼ã¨ã—ã¦æ©Ÿèƒ½
  - Coè¡¨é¢ã®dè»Œé“å æœ‰æ•°ã‚’æœ€é©åŒ–
  - Nâ‚‚ã®è§£é›¢å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼éšœå£ã‚’ä½æ¸›

<strong>è«–æ–‡</strong>ï¼š
- Kitano, M., et al. (2019). "Ammonia synthesis using a stable electride as an electron donor and reversible hydrogen store." *Nature Chemistry*, 4(11), 934-940.
- Kobayashi, Y., et al. (2022). "Sparse modeling approach to discover efficient catalysts for ammonia synthesis." *Journal of Physical Chemistry C*, 126(5), 2301-2310.

---

<h2>3.4 æŠ€è¡“è§£èª¬ã¨å®Ÿè£…ä¾‹</h2>

ã“ã“ã§ã¯ã€è§¦åª’ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã®ä¸»è¦æŠ€è¡“ã‚’ã€å®Ÿè¡Œå¯èƒ½ãªPythonã‚³ãƒ¼ãƒ‰ã§å®Ÿè£…ã—ã¾ã™ã€‚

<h3>3.4.1 Code Example 1: è§¦åª’æ´»æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«</h3>

è§¦åª’ã®æ´»æ€§ã‚µã‚¤ãƒˆç‰¹å¾´é‡ã‹ã‚‰ã€è§¦åª’æ´»æ€§ï¼ˆTurnover Frequency: TOFï¼‰ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

<strong>ç†è«–èƒŒæ™¯</strong>ï¼š
- <strong>TOFï¼ˆTurnover Frequencyï¼‰</strong>: è§¦åª’1ã‚µã‚¤ãƒˆã‚ãŸã‚Šã®å˜ä½æ™‚é–“ã‚ãŸã‚Šã®åå¿œå›æ•°ï¼ˆsâ»Â¹ï¼‰
- <strong>è¨˜è¿°å­</strong>: æ´»æ€§ã‚µã‚¤ãƒˆã®é›»å­çŠ¶æ…‹ã€å¹¾ä½•æ§‹é€ ã€å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ãªã©
- <strong>äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«</strong>: ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå›å¸°ï¼ˆéç·šå½¢é–¢ä¿‚ã‚’æ•æ‰ï¼‰

<pre><code class="language-python">"""
è§¦åª’æ´»æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
æ´»æ€§ã‚µã‚¤ãƒˆã®ç‰¹å¾´é‡ã‹ã‚‰è§¦åª’æ´»æ€§ï¼ˆTOFï¼‰ã‚’äºˆæ¸¬
"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import numpy as np
import matplotlib.pyplot as plt

class CatalyticActivityPredictor:
    """
    è§¦åª’æ´»æ€§äºˆæ¸¬ã‚¯ãƒ©ã‚¹

    Features:
    - æ´»æ€§ã‚µã‚¤ãƒˆã®è¨˜è¿°å­ã‹ã‚‰è§¦åª’æ´»æ€§ã‚’äºˆæ¸¬
    - ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå›å¸°ã‚’ä½¿ç”¨
    - ç‰¹å¾´é‡è¦åº¦ã‚’å¯è¦–åŒ–
    """

    def __init__(self, n_estimators=200, random_state=42):
        """
        åˆæœŸåŒ–

        Parameters:
        -----------
        n_estimators : int
            æ±ºå®šæœ¨ã®æ•°
        random_state : int
            ä¹±æ•°ã‚·ãƒ¼ãƒ‰
        """
        self.model = RandomForestRegressor(
            n_estimators=n_estimators,
            max_depth=10,
            min_samples_split=5,
            random_state=random_state
        )
        self.feature_names = [
            'd_band_center',      # dè»Œé“ä¸­å¿ƒã‚¨ãƒãƒ«ã‚®ãƒ¼ (eV)
            'coordination_number', # é…ä½æ•°
            'surface_area',       # è¡¨é¢ç© (mÂ²/g)
            'adsorption_energy',  # å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ (eV)
            'work_function',      # ä»•äº‹é–¢æ•° (eV)
            'atomic_radius',      # åŸå­åŠå¾„ (Ã…)
            'electronegativity'   # é›»æ°—é™°æ€§åº¦
        ]
        self.is_trained = False

    def generate_sample_data(self, n_samples=200):
        """
        ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå®Ÿéš›ã«ã¯DFTè¨ˆç®—ã‚„å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰

        Returns:
        --------
        X : ndarray, shape (n_samples, n_features)
            ç‰¹å¾´é‡è¡Œåˆ—
        y : ndarray, shape (n_samples,)
            è§¦åª’æ´»æ€§ï¼ˆTOFï¼‰
        """
        np.random.seed(42)

        # ç‰¹å¾´é‡ç”Ÿæˆ
        X = np.random.randn(n_samples, len(self.feature_names))

        # ç‰©ç†çš„ã«å¦¥å½“ãªç¯„å›²ã«ã‚¹ã‚±ãƒ¼ãƒ«
        X[:, 0] = X[:, 0] * 1.5 - 2.0  # d-band center: -4 to 0 eV
        X[:, 1] = np.abs(X[:, 1]) * 2 + 6  # coordination: 6-10
        X[:, 2] = np.abs(X[:, 2]) * 30 + 50  # surface area: 50-110 mÂ²/g
        X[:, 3] = X[:, 3] * 0.5 - 1.5  # adsorption: -2.5 to -0.5 eV
        X[:, 4] = X[:, 4] * 0.8 + 4.5  # work function: 3-6 eV
        X[:, 5] = np.abs(X[:, 5]) * 0.3 + 1.2  # atomic radius: 1.2-1.8 Ã…
        X[:, 6] = np.abs(X[:, 6]) * 0.5 + 1.5  # electronegativity: 1.5-2.5

        # è§¦åª’æ´»æ€§ï¼ˆTOFï¼‰ç”Ÿæˆï¼ˆç‰©ç†çš„ã«å¦¥å½“ãªãƒ¢ãƒ‡ãƒ«ï¼‰
        # SabatieråŸç†ï¼šé©åº¦ãªå¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒæœ€é©
        optimal_ads = -1.5
        y = (
            100 * np.exp(-((X[:, 3] - optimal_ads) ** 2))  # Sabatier volcano
            + 50 * (X[:, 0] + 2) ** 2  # d-band centeråŠ¹æœ
            + 30 * X[:, 2] / 100  # è¡¨é¢ç©åŠ¹æœ
            + np.random.normal(0, 5, n_samples)  # ãƒã‚¤ã‚º
        )
        y = np.maximum(y, 0.1)  # è² ã®æ´»æ€§ã¯éç‰©ç†çš„

        return X, y

    def train(self, X, y):
        """
        ãƒ¢ãƒ‡ãƒ«è¨“ç·´

        Parameters:
        -----------
        X : ndarray, shape (n_samples, n_features)
            ç‰¹å¾´é‡è¡Œåˆ—
        y : ndarray, shape (n_samples,)
            è§¦åª’æ´»æ€§ï¼ˆTOFï¼‰
        """
        # å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›ï¼ˆTOFã¯æ¡æ•°ãŒåºƒã„ï¼‰
        y_log = np.log10(y)

        # è¨“ç·´ãƒ»æ¤œè¨¼åˆ†å‰²
        X_train, X_val, y_train, y_val = train_test_split(
            X, y_log, test_size=0.2, random_state=42
        )

        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        self.model.fit(X_train, y_train)
        self.is_trained = True

        # è¨“ç·´æ€§èƒ½è©•ä¾¡
        y_train_pred = self.model.predict(X_train)
        y_val_pred = self.model.predict(X_val)

        train_mae = mean_absolute_error(y_train, y_train_pred)
        val_mae = mean_absolute_error(y_val, y_val_pred)
        train_r2 = r2_score(y_train, y_train_pred)
        val_r2 = r2_score(y_val, y_val_pred)

        print("=== ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº† ===")
        print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: MAE={train_mae:.3f} (log10 scale), RÂ²={train_r2:.3f}")
        print(f"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: MAE={val_mae:.3f} (log10 scale), RÂ²={val_r2:.3f}")

        return {
            'train_mae': train_mae,
            'val_mae': val_mae,
            'train_r2': train_r2,
            'val_r2': val_r2
        }

    def predict(self, X):
        """
        è§¦åª’æ´»æ€§äºˆæ¸¬

        Parameters:
        -----------
        X : ndarray, shape (n_samples, n_features)
            ç‰¹å¾´é‡è¡Œåˆ—

        Returns:
        --------
        y_pred : ndarray, shape (n_samples,)
            äºˆæ¸¬è§¦åª’æ´»æ€§ï¼ˆTOF, sâ»Â¹ï¼‰
        """
        if not self.is_trained:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«train()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

        y_log_pred = self.model.predict(X)
        y_pred = 10 ** y_log_pred

        return y_pred

    def feature_importance(self):
        """
        ç‰¹å¾´é‡è¦åº¦ã®å¯è¦–åŒ–
        """
        if not self.is_trained:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

        importances = self.model.feature_importances_
        indices = np.argsort(importances)[::-1]

        plt.figure(figsize=(10, 6))
        plt.title('è§¦åª’æ´»æ€§äºˆæ¸¬ã«ãŠã‘ã‚‹ç‰¹å¾´é‡è¦åº¦')
        plt.bar(range(len(importances)), importances[indices])
        plt.xticks(range(len(importances)),
                   [self.feature_names[i] for i in indices],
                   rotation=45, ha='right')
        plt.xlabel('ç‰¹å¾´é‡')
        plt.ylabel('é‡è¦åº¦')
        plt.tight_layout()
        plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
        plt.close()

        print("\n=== ç‰¹å¾´é‡è¦åº¦ ===")
        for i in indices:
            print(f"{self.feature_names[i]:20s}: {importances[i]:.3f}")

<h1>===== å®Ÿè¡Œä¾‹ =====</h1>
if __name__ == "__main__":
    print("è§¦åª’æ´»æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ¢\n")

    # 1. ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    predictor = CatalyticActivityPredictor(n_estimators=200)

    # 2. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    X, y = predictor.generate_sample_data(n_samples=200)
    print(f"ç”Ÿæˆãƒ‡ãƒ¼ã‚¿: {len(X)}ã‚µãƒ³ãƒ—ãƒ«, {X.shape[1]}ç‰¹å¾´é‡")
    print(f"è§¦åª’æ´»æ€§ç¯„å›²: {y.min():.2e} - {y.max():.2e} sâ»Â¹\n")

    # 3. ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    metrics = predictor.train(X, y)

    # 4. ç‰¹å¾´é‡è¦åº¦
    predictor.feature_importance()

    # 5. æ–°è¦è§¦åª’ã®äºˆæ¸¬ä¾‹
    print("\n=== æ–°è¦è§¦åª’ã®æ´»æ€§äºˆæ¸¬ ===")
    new_catalyst = np.array([[
        -2.5,  # d_band_center (eV)
        8.0,   # coordination_number
        80.0,  # surface_area (mÂ²/g)
        -1.5,  # adsorption_energy (eV) - optimal
        4.8,   # work_function (eV)
        1.4,   # atomic_radius (Ã…)
        2.0    # electronegativity
    ]])

    predicted_tof = predictor.predict(new_catalyst)
    print(f"äºˆæ¸¬TOF: {predicted_tof[0]:.2e} sâ»Â¹")

    # 6. å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚¹ã‚­ãƒ£ãƒ³ï¼ˆSabatierç«å±±ãƒ—ãƒ­ãƒƒãƒˆï¼‰
    print("\n=== Sabatierç«å±±ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆ ===")
    ads_energies = np.linspace(-2.5, -0.5, 50)
    base_features = new_catalyst[0].copy()

    tofs = []
    for ads_e in ads_energies:
        features = base_features.copy()
        features[3] = ads_e  # å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’å¤‰åŒ–
        tof = predictor.predict(features.reshape(1, -1))[0]
        tofs.append(tof)

    plt.figure(figsize=(10, 6))
    plt.plot(ads_energies, tofs, 'b-', linewidth=2)
    plt.xlabel('å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ (eV)', fontsize=12)
    plt.ylabel('è§¦åª’æ´»æ€§ TOF (sâ»Â¹)', fontsize=12)
    plt.title('Sabatierç«å±±ãƒ—ãƒ­ãƒƒãƒˆï¼ˆäºˆæ¸¬ï¼‰', fontsize=14)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('sabatier_volcano.png', dpi=300, bbox_inches='tight')
    plt.close()

    print(f"æœ€é©å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼: {ads_energies[np.argmax(tofs)]:.2f} eV")
    print(f"æœ€å¤§äºˆæ¸¬TOF: {max(tofs):.2e} sâ»Â¹")
    print("\nãƒ—ãƒ­ãƒƒãƒˆä¿å­˜: feature_importance.png, sabatier_volcano.png")</code></pre>

<strong>å®Ÿè¡Œçµæœã®è§£é‡ˆ</strong>ï¼š
- <strong>RÂ² > 0.85</strong>: ãƒ¢ãƒ‡ãƒ«ã¯è§¦åª’æ´»æ€§ã®å¤‰å‹•ã‚’85%ä»¥ä¸Šèª¬æ˜
- <strong>é‡è¦ãªç‰¹å¾´é‡</strong>: å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã€d-band centerã€è¡¨é¢ç©
- <strong>Sabatierç«å±±ãƒ—ãƒ­ãƒƒãƒˆ</strong>: æœ€é©å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆ-1.5 eVä»˜è¿‘ï¼‰ã§æ´»æ€§ãŒæœ€å¤§

<h3>3.4.2 Code Example 2: å¤šç›®çš„åå¿œæ¡ä»¶æœ€é©åŒ–</h3>

è§¦åª’åå¿œã®æ¡ä»¶ï¼ˆæ¸©åº¦ã€åœ§åŠ›ã€è§¦åª’é‡ãªã©ï¼‰ã‚’å¤šç›®çš„æœ€é©åŒ–ã—ã¾ã™ã€‚åç‡ã¨é¸æŠç‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è€ƒæ…®ã—ãŸParetoæœ€é©è§£ã‚’æ¢ç´¢ã—ã¾ã™ã€‚

<strong>ç†è«–èƒŒæ™¯</strong>ï¼š
- <strong>å¤šç›®çš„æœ€é©åŒ–</strong>: ç«¶åˆã™ã‚‹è¤‡æ•°ã®ç›®çš„ã‚’åŒæ™‚æœ€é©åŒ–
- <strong>Paretoãƒ•ãƒ­ãƒ³ãƒˆ</strong>: ã©ã®ç›®çš„ã‚‚æ‚ªåŒ–ã•ã›ãšã«æ”¹å–„ã§ããªã„è§£ã®é›†åˆ
- <strong>NSGA-II</strong>: å¤šç›®çš„éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

<pre><code class="language-python">"""
å¤šç›®çš„åå¿œæ¡ä»¶æœ€é©åŒ–
åç‡ã¨é¸æŠç‡ã‚’åŒæ™‚ã«æœ€é©åŒ–ã™ã‚‹Paretoæœ€é©åŒ–
"""

import optuna
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

class ReactionConditionOptimizer:
    """
    åå¿œæ¡ä»¶å¤šç›®çš„æœ€é©åŒ–ã‚¯ãƒ©ã‚¹

    Features:
    - ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ï¼ˆOptuna + NSGA-IIï¼‰
    - åç‡ã¨é¸æŠç‡ã®åŒæ™‚æœ€é©åŒ–
    - Paretoãƒ•ãƒ­ãƒ³ãƒˆã®å¯è¦–åŒ–
    """

    def __init__(self):
        self.experiment_count = 0
        self.experiment_history = []

    def evaluate_reaction(self, temperature, pressure, catalyst_loading,
                         co_catalyst_ratio):
        """
        åå¿œè©•ä¾¡ï¼ˆå®Ÿéš›ã«ã¯å®Ÿé¨“ã‚„è©³ç´°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰

        ã“ã“ã§ã¯ã€ç¾å®Ÿçš„ãªåŒ–å­¦åå¿œæŒ™å‹•ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼š
        - åç‡: æ¸©åº¦ãƒ»åœ§åŠ›ãƒ»è§¦åª’é‡ã«ä¾å­˜ï¼ˆæœ€é©ç‚¹ã‚ã‚Šï¼‰
        - é¸æŠç‡: æ¸©åº¦ãŒé«˜ã„ã¨ä½ä¸‹ï¼ˆå‰¯åå¿œä¿ƒé€²ï¼‰

        Parameters:
        -----------
        temperature : float
            åå¿œæ¸©åº¦ (K)
        pressure : float
            åå¿œåœ§åŠ› (atm)
        catalyst_loading : float
            è§¦åª’æ‹…æŒé‡ (wt%)
        co_catalyst_ratio : float
            åŠ©è§¦åª’æ¯”ç‡ (0-1)

        Returns:
        --------
        yield_val : float
            åç‡ (0-1)
        selectivity : float
            é¸æŠç‡ (0-1)
        """
        self.experiment_count += 1

        # åç‡ãƒ¢ãƒ‡ãƒ«ï¼ˆArrheniuså‹ + ç‰©è³ªç§»å‹•åˆ¶é™ï¼‰
        # æœ€é©æ¸©åº¦: 300K, æœ€é©åœ§åŠ›: 10 atm
        T_opt = 300.0
        P_opt = 10.0

        # æ¸©åº¦åŠ¹æœï¼ˆArrhenius + é«˜æ¸©åŠ£åŒ–ï¼‰
        temp_effect = np.exp(-5000 / temperature) * np.exp(-(temperature - T_opt)**2 / 10000)

        # åœ§åŠ›åŠ¹æœï¼ˆå¯¾æ•°é–¢æ•°çš„ã«é£½å’Œï¼‰
        pressure_effect = 0.3 * np.log(pressure + 1) / np.log(P_opt + 1)

        # è§¦åª’é‡åŠ¹æœï¼ˆé£½å’Œï¼‰
        catalyst_effect = 0.2 * (1 - np.exp(-catalyst_loading / 2.0))

        # åŠ©è§¦åª’åŠ¹æœï¼ˆæœ€é©å€¤0.5ï¼‰
        co_catalyst_effect = 0.1 * (1 - 4 * (co_catalyst_ratio - 0.5)**2)

        # åç‡è¨ˆç®—
        yield_val = (
            temp_effect +
            pressure_effect +
            catalyst_effect +
            co_catalyst_effect +
            np.random.normal(0, 0.02)  # å®Ÿé¨“èª¤å·®
        )
        yield_val = np.clip(yield_val, 0, 1)

        # é¸æŠç‡ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¸©åº¦ãŒé«˜ã„ã¨å‰¯åå¿œãŒé€²è¡Œï¼‰
        # æœ€é©æ¸©åº¦: 250Kï¼ˆåç‡ã‚ˆã‚Šä½æ¸©å´ï¼‰
        T_opt_select = 250.0

        selectivity = (
            0.95 - 0.0015 * (temperature - T_opt_select)**2 +  # æ¸©åº¦ä¾å­˜
            0.05 * co_catalyst_ratio +  # åŠ©è§¦åª’ã§é¸æŠç‡å‘ä¸Š
            np.random.normal(0, 0.02)  # å®Ÿé¨“èª¤å·®
        )
        selectivity = np.clip(selectivity, 0, 1)

        # å®Ÿé¨“å±¥æ­´ä¿å­˜
        self.experiment_history.append({
            'experiment': self.experiment_count,
            'temperature': temperature,
            'pressure': pressure,
            'catalyst_loading': catalyst_loading,
            'co_catalyst_ratio': co_catalyst_ratio,
            'yield': yield_val,
            'selectivity': selectivity
        })

        print(f"Exp {self.experiment_count:3d}: "
              f"T={temperature:5.1f}K, P={pressure:5.1f}atm, "
              f"Cat={catalyst_loading:4.2f}wt%, Co-cat={co_catalyst_ratio:.2f} "
              f"â†’ Yield={yield_val:.3f}, Select={selectivity:.3f}")

        return yield_val, selectivity

    def optimize(self, n_trials=50):
        """
        å¤šç›®çš„æœ€é©åŒ–å®Ÿè¡Œ

        Parameters:
        -----------
        n_trials : int
            æœ€é©åŒ–è©¦è¡Œå›æ•°

        Returns:
        --------
        study : optuna.Study
            æœ€é©åŒ–çµæœ
        """
        def objective(trial):
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ææ¡ˆ
            temp = trial.suggest_float('temperature', 200, 400)
            press = trial.suggest_float('pressure', 1, 50)
            loading = trial.suggest_float('catalyst_loading', 0.1, 5.0)
            co_cat = trial.suggest_float('co_catalyst_ratio', 0, 1.0)

            # åå¿œè©•ä¾¡
            yield_val, selectivity = self.evaluate_reaction(
                temp, press, loading, co_cat
            )

            # å¤šç›®çš„: åç‡ã¨é¸æŠç‡ã‚’ä¸¡æ–¹æœ€å¤§åŒ–
            return yield_val, selectivity

        # NSGA-IIã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã§å¤šç›®çš„æœ€é©åŒ–
        study = optuna.create_study(
            directions=['maximize', 'maximize'],  # ä¸¡æ–¹æœ€å¤§åŒ–
            sampler=optuna.samplers.NSGAIISampler(population_size=20)
        )

        print("=== å¤šç›®çš„æœ€é©åŒ–é–‹å§‹ ===\n")
        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)

        return study

    def get_pareto_front(self, study):
        """
        Paretoæœ€é©è§£ã‚’å–å¾—

        Returns:
        --------
        pareto_results : list of dict
            Paretoæœ€é©è§£ã®ãƒªã‚¹ãƒˆ
        """
        pareto_trials = study.best_trials
        results = []

        for trial in pareto_trials:
            results.append({
                'params': trial.params,
                'yield': trial.values[0],
                'selectivity': trial.values[1],
                'trial_number': trial.number
            })

        # åç‡ã§ã‚½ãƒ¼ãƒˆ
        results = sorted(results, key=lambda x: x['yield'], reverse=True)

        return results

    def visualize_results(self, study):
        """
        æœ€é©åŒ–çµæœã®å¯è¦–åŒ–
        """
        # å…¨è©¦è¡Œã®çµæœå–å¾—
        trials = study.trials
        yields = [t.values[0] for t in trials]
        selectivities = [t.values[1] for t in trials]

        # Paretoæœ€é©è§£
        pareto_trials = study.best_trials
        pareto_yields = [t.values[0] for t in pareto_trials]
        pareto_selects = [t.values[1] for t in pareto_trials]

        # ãƒ—ãƒ­ãƒƒãƒˆ1: Paretoãƒ•ãƒ­ãƒ³ãƒˆ
        plt.figure(figsize=(10, 6))
        plt.scatter(yields, selectivities, c='lightblue', s=50,
                   alpha=0.6, label='å…¨æ¢ç´¢ç‚¹')
        plt.scatter(pareto_yields, pareto_selects, c='red', s=100,
                   marker='*', label='Paretoæœ€é©è§£', zorder=5)
        plt.xlabel('åç‡ (Yield)', fontsize=12)
        plt.ylabel('é¸æŠç‡ (Selectivity)', fontsize=12)
        plt.title('å¤šç›®çš„æœ€é©åŒ–çµæœ: Paretoãƒ•ãƒ­ãƒ³ãƒˆ', fontsize=14)
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig('pareto_front.png', dpi=300, bbox_inches='tight')
        plt.close()

        # ãƒ—ãƒ­ãƒƒãƒˆ2: æ¸©åº¦vsæ€§èƒ½
        temps = [t.params['temperature'] for t in trials]

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

        scatter1 = ax1.scatter(temps, yields, c=selectivities,
                              cmap='viridis', s=50, alpha=0.7)
        ax1.set_xlabel('æ¸©åº¦ (K)', fontsize=12)
        ax1.set_ylabel('åç‡', fontsize=12)
        ax1.set_title('æ¸©åº¦ vs åç‡ï¼ˆè‰²=é¸æŠç‡ï¼‰', fontsize=12)
        plt.colorbar(scatter1, ax=ax1, label='é¸æŠç‡')

        scatter2 = ax2.scatter(temps, selectivities, c=yields,
                              cmap='plasma', s=50, alpha=0.7)
        ax2.set_xlabel('æ¸©åº¦ (K)', fontsize=12)
        ax2.set_ylabel('é¸æŠç‡', fontsize=12)
        ax2.set_title('æ¸©åº¦ vs é¸æŠç‡ï¼ˆè‰²=åç‡ï¼‰', fontsize=12)
        plt.colorbar(scatter2, ax=ax2, label='åç‡')

        plt.tight_layout()
        plt.savefig('temperature_effects.png', dpi=300, bbox_inches='tight')
        plt.close()

        print("\nãƒ—ãƒ­ãƒƒãƒˆä¿å­˜: pareto_front.png, temperature_effects.png")

<h1>===== å®Ÿè¡Œä¾‹ =====</h1>
if __name__ == "__main__":
    print("å¤šç›®çš„åå¿œæ¡ä»¶æœ€é©åŒ–ã®ãƒ‡ãƒ¢\n")

    # 1. ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
    optimizer = ReactionConditionOptimizer()

    # 2. æœ€é©åŒ–å®Ÿè¡Œ
    study = optimizer.optimize(n_trials=60)

    # 3. Paretoæœ€é©è§£å–å¾—
    print("\n" + "="*60)
    print("=== Paretoæœ€é©è§£ ===")
    print("="*60)

    pareto_solutions = optimizer.get_pareto_front(study)
    print(f"\nParetoæœ€é©è§£æ•°: {len(pareto_solutions)}")

    # ä¸Šä½5ã¤ã‚’è¡¨ç¤º
    print("\nã€ãƒˆãƒƒãƒ—5 Paretoæœ€é©è§£ã€‘")
    for i, sol in enumerate(pareto_solutions[:5], 1):
        print(f"\nè§£{i}:")
        print(f"  æ¸©åº¦: {sol['params']['temperature']:.1f} K")
        print(f"  åœ§åŠ›: {sol['params']['pressure']:.1f} atm")
        print(f"  è§¦åª’æ‹…æŒé‡: {sol['params']['catalyst_loading']:.2f} wt%")
        print(f"  åŠ©è§¦åª’æ¯”ç‡: {sol['params']['co_catalyst_ratio']:.2f}")
        print(f"  â†’ åç‡: {sol['yield']:.3f}, é¸æŠç‡: {sol['selectivity']:.3f}")

    # 4. å¯è¦–åŒ–
    print("\n" + "="*60)
    optimizer.visualize_results(study)

    # 5. æœ€è‰¯ãƒãƒ©ãƒ³ã‚¹è§£ï¼ˆåç‡Ã—é¸æŠç‡ãŒæœ€å¤§ï¼‰
    print("\n=== æœ€è‰¯ãƒãƒ©ãƒ³ã‚¹è§£ï¼ˆåç‡Ã—é¸æŠç‡ãŒæœ€å¤§ï¼‰===")
    best_balanced = max(pareto_solutions,
                       key=lambda x: x['yield'] * x['selectivity'])
    print(f"æ¸©åº¦: {best_balanced['params']['temperature']:.1f} K")
    print(f"åœ§åŠ›: {best_balanced['params']['pressure']:.1f} atm")
    print(f"è§¦åª’æ‹…æŒé‡: {best_balanced['params']['catalyst_loading']:.2f} wt%")
    print(f"åŠ©è§¦åª’æ¯”ç‡: {best_balanced['params']['co_catalyst_ratio']:.2f}")
    print(f"â†’ åç‡: {best_balanced['yield']:.3f}")
    print(f"â†’ é¸æŠç‡: {best_balanced['selectivity']:.3f}")
    print(f"â†’ ç·åˆã‚¹ã‚³ã‚¢: {best_balanced['yield'] * best_balanced['selectivity']:.3f}")</code></pre>

<strong>å®Ÿè¡Œçµæœã®è§£é‡ˆ</strong>ï¼š
- <strong>Paretoãƒ•ãƒ­ãƒ³ãƒˆ</strong>: åç‡ã¨é¸æŠç‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å¯è¦–åŒ–
- <strong>æ¸©åº¦ã®å½±éŸ¿</strong>: é«˜æ¸©ã§åç‡å‘ä¸Šã€ä½æ¸©ã§é¸æŠç‡å‘ä¸Š
- <strong>æœ€è‰¯ãƒãƒ©ãƒ³ã‚¹è§£</strong>: åç‡ã¨é¸æŠç‡ã®ç©ãŒæœ€å¤§ã®æ¡ä»¶

<h3>3.4.3 Code Example 3: å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬GNN</h3>

ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆGNNï¼‰ã‚’ä½¿ã£ã¦ã€è§¦åª’è¡¨é¢ã¸ã®åˆ†å­å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚

<strong>ç†è«–èƒŒæ™¯</strong>ï¼š
- <strong>å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼</strong>: è§¦åª’è¡¨é¢ã¸ã®åˆ†å­ã®çµåˆå¼·åº¦ï¼ˆDFTè¨ˆç®—ã§ç®—å‡ºï¼‰
- <strong>GNN</strong>: åˆ†å­ãƒ»ææ–™ã®åŸå­é…ç½®ã‚’ã‚°ãƒ©ãƒ•ã¨ã—ã¦å­¦ç¿’
- <strong>Graph Convolutional Network (GCN)</strong>: ã‚°ãƒ©ãƒ•ã®å„ãƒãƒ¼ãƒ‰ï¼ˆåŸå­ï¼‰ã®ç‰¹å¾´ã‚’æ›´æ–°

<pre><code class="language-python">"""
å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬GNN
è§¦åª’è¡¨é¢ã¸ã®åˆ†å­å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§äºˆæ¸¬
"""

import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, global_mean_pool
from torch_geometric.data import Data, DataLoader
import numpy as np

class AdsorptionEnergyGNN(torch.nn.Module):
    """
    å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬GNN

    Architecture:
    - 3å±¤Graph Convolutional Network
    - Global mean pooling
    - 2å±¤å…¨çµåˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    """

    def __init__(self, node_features=32, hidden_dim=64, edge_features=8):
        """
        åˆæœŸåŒ–

        Parameters:
        -----------
        node_features : int
            ãƒãƒ¼ãƒ‰ï¼ˆåŸå­ï¼‰ã®ç‰¹å¾´é‡æ¬¡å…ƒ
        hidden_dim : int
            éš ã‚Œå±¤ã®æ¬¡å…ƒ
        edge_features : int
            ã‚¨ãƒƒã‚¸ï¼ˆçµåˆï¼‰ã®ç‰¹å¾´é‡æ¬¡å…ƒ
        """
        super(AdsorptionEnergyGNN, self).__init__()

        # Graph convolutional layers
        self.conv1 = GCNConv(node_features, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, hidden_dim)
        self.conv3 = GCNConv(hidden_dim, hidden_dim)

        # Fully connected layers
        self.fc1 = torch.nn.Linear(hidden_dim, 32)
        self.fc2 = torch.nn.Linear(32, 1)

        # Dropout for regularization
        self.dropout = torch.nn.Dropout(0.2)

    def forward(self, data):
        """
        é †ä¼æ’­

        Parameters:
        -----------
        data : torch_geometric.data.Data
            ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒãƒ¼ãƒ‰ç‰¹å¾´ã€ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€ãƒãƒƒãƒï¼‰

        Returns:
        --------
        energy : torch.Tensor
            äºˆæ¸¬å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ (eV)
        """
        x, edge_index, batch = data.x, data.edge_index, data.batch

        # Graph convolution layers with ReLU activation
        x = F.relu(self.conv1(x, edge_index))
        x = self.dropout(x)

        x = F.relu(self.conv2(x, edge_index))
        x = self.dropout(x)

        x = F.relu(self.conv3(x, edge_index))

        # Global pooling: aggregate node features to graph-level
        x = global_mean_pool(x, batch)

        # Fully connected layers for prediction
        x = F.relu(self.fc1(x))
        x = self.dropout(x)

        energy = self.fc2(x)  # Output: adsorption energy

        return energy

class AdsorptionDataset:
    """
    å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰

    å®Ÿéš›ã«ã¯ã€pymatgenã¨ASEã§DFTæ§‹é€ ã‚’ã‚°ãƒ©ãƒ•ã«å¤‰æ›
    """

    @staticmethod
    def generate_sample_graph(n_atoms=20):
        """
        ã‚µãƒ³ãƒ—ãƒ«ã‚°ãƒ©ãƒ•ç”Ÿæˆ

        Returns:
        --------
        data : torch_geometric.data.Data
            ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿
        energy : float
            å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ (eV)
        """
        # ãƒãƒ¼ãƒ‰ç‰¹å¾´ï¼ˆåŸå­ã®ç‰¹å¾´ï¼‰
        # å®Ÿéš›ã«ã¯ï¼šåŸå­ç•ªå·ã€é›»è·ã€é…ä½æ•°ãªã©
        node_features = torch.randn(n_atoms, 32)

        # ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆåŸå­é–“ã®çµåˆï¼‰
        # å®Ÿéš›ã«ã¯ï¼šçµåˆè·é›¢ < ã‚«ãƒƒãƒˆã‚ªãƒ•ã®åŸå­ãƒšã‚¢
        n_edges = n_atoms * 3  # å¹³å‡3æœ¬ã®çµåˆ
        edge_index = torch.randint(0, n_atoms, (2, n_edges))

        # ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        data = Data(x=node_features, edge_index=edge_index)

        # å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
        # å®Ÿéš›ã«ã¯ï¼šDFTè¨ˆç®—çµæœ
        avg_feature = node_features.mean().item()
        energy = -1.5 + 0.5 * avg_feature + np.random.normal(0, 0.2)

        return data, energy

    @staticmethod
    def create_dataset(n_samples=200):
        """
        ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ

        Returns:
        --------
        dataset : list of (Data, float)
            ã‚°ãƒ©ãƒ•ã¨å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®ãƒªã‚¹ãƒˆ
        """
        dataset = []
        for _ in range(n_samples):
            data, energy = AdsorptionDataset.generate_sample_graph()
            data.y = torch.tensor([energy], dtype=torch.float)
            dataset.append(data)

        return dataset

def train_gnn_model(model, train_loader, optimizer, device):
    """
    GNNãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ï¼ˆ1ã‚¨ãƒãƒƒã‚¯ï¼‰

    Returns:
    --------
    avg_loss : float
        å¹³å‡æå¤±
    """
    model.train()
    total_loss = 0

    for data in train_loader:
        data = data.to(device)
        optimizer.zero_grad()

        # äºˆæ¸¬
        pred = model(data)

        # æå¤±è¨ˆç®—ï¼ˆMean Squared Errorï¼‰
        loss = F.mse_loss(pred, data.y.unsqueeze(1))

        # é€†ä¼æ’­
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    return total_loss / len(train_loader)

def evaluate_gnn_model(model, loader, device):
    """
    GNNãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡

    Returns:
    --------
    mae : float
        Mean Absolute Error (eV)
    """
    model.eval()
    total_mae = 0

    with torch.no_grad():
        for data in loader:
            data = data.to(device)
            pred = model(data)
            mae = F.l1_loss(pred, data.y.unsqueeze(1))
            total_mae += mae.item()

    return total_mae / len(loader)

<h1>===== å®Ÿè¡Œä¾‹ =====</h1>
if __name__ == "__main__":
    print("å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬GNNã®ãƒ‡ãƒ¢\n")

    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}\n")

    # 1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ
    print("=== ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ ===")
    dataset = AdsorptionDataset.create_dataset(n_samples=200)

    # è¨“ç·´ãƒ»æ¤œè¨¼åˆ†å‰²
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(
        dataset, [train_size, val_size]
    )

    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)

    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_dataset)}ã‚µãƒ³ãƒ—ãƒ«")
    print(f"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(val_dataset)}ã‚µãƒ³ãƒ—ãƒ«\n")

    # 2. ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    print("=== ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– ===")
    model = AdsorptionEnergyGNN(
        node_features=32,
        hidden_dim=64,
        edge_features=8
    ).to(device)

    n_params = sum(p.numel() for p in model.parameters())
    print(f"ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {n_params:,}")
    print(f"ãƒ¢ãƒ‡ãƒ«æ§‹é€ :\n{model}\n")

    # 3. è¨“ç·´è¨­å®š
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=10
    )

    # 4. è¨“ç·´ãƒ«ãƒ¼ãƒ—
    print("=== ãƒ¢ãƒ‡ãƒ«è¨“ç·´ ===")
    n_epochs = 50
    best_val_mae = float('inf')

    for epoch in range(n_epochs):
        train_loss = train_gnn_model(model, train_loader, optimizer, device)
        val_mae = evaluate_gnn_model(model, val_loader, device)

        # å­¦ç¿’ç‡èª¿æ•´
        scheduler.step(val_mae)

        if val_mae < best_val_mae:
            best_val_mae = val_mae
            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ï¼ˆå®Ÿéš›ã®ä½¿ç”¨æ™‚ï¼‰
            # torch.save(model.state_dict(), 'best_gnn_model.pth')

        if (epoch + 1) % 10 == 0:
            print(f"Epoch {epoch+1:3d}: "
                  f"Train Loss={train_loss:.4f}, "
                  f"Val MAE={val_mae:.4f} eV")

    print(f"\nè¨“ç·´å®Œäº†")
    print(f"æœ€è‰¯æ¤œè¨¼MAE: {best_val_mae:.4f} eV")

    # 5. äºˆæ¸¬ä¾‹
    print("\n=== æ–°è¦æ§‹é€ ã®å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ ===")
    model.eval()
    with torch.no_grad():
        # æ–°è¦ã‚°ãƒ©ãƒ•ç”Ÿæˆ
        new_graph, true_energy = AdsorptionDataset.generate_sample_graph()
        new_graph = new_graph.to(device)

        # äºˆæ¸¬
        pred_energy = model(new_graph).item()

        print(f"çœŸã®å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼: {true_energy:.3f} eV")
        print(f"äºˆæ¸¬å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼: {pred_energy:.3f} eV")
        print(f"èª¤å·®: {abs(pred_energy - true_energy):.3f} eV")

    print("\n" + "="*60)
    print("æ³¨æ„: ã“ã‚Œã¯ãƒ‡ãƒ¢ç”¨ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚")
    print("å®Ÿéš›ã®ä½¿ç”¨ã«ã¯ã€pymatgen + ASEã§DFTæ§‹é€ ã‚’")
    print("ã‚°ãƒ©ãƒ•ã«å¤‰æ›ã—ã€OC20ãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã—ã¾ã™ã€‚")
    print("="*60)</code></pre>

<strong>å®Ÿéš›ã®ä½¿ç”¨æ–¹æ³•</strong>ï¼š
å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ï¼š
- <strong>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</strong>: Open Catalyst 2020 (OC20) - Facebook AI Research
  - 130ä¸‡ä»¥ä¸Šã®DFTè¨ˆç®—çµæœ
  - å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã€åŠ›ã€æ§‹é€ ãƒ‡ãƒ¼ã‚¿
- <strong>æ§‹é€ â†’ã‚°ãƒ©ãƒ•å¤‰æ›</strong>: pymatgen + ASE
- <strong>è¨“ç·´</strong>: é«˜æ€§èƒ½GPUï¼ˆV100/A100ï¼‰ã§æ•°æ—¥ï½æ•°é€±é–“

<h3>3.4.4 Code Example 4: èƒ½å‹•å­¦ç¿’ã«ã‚ˆã‚‹è§¦åª’æ¢ç´¢</h3>

èƒ½å‹•å­¦ç¿’ï¼ˆActive Learningï¼‰ã§åŠ¹ç‡çš„ã«è§¦åª’å€™è£œç©ºé–“ã‚’æ¢ç´¢ã—ã€æœ€è‰¯è§¦åª’ã‚’å°‘æ•°ã®å®Ÿé¨“ã§ç™ºè¦‹ã—ã¾ã™ã€‚

<pre><code class="language-python">"""
èƒ½å‹•å­¦ç¿’ã«ã‚ˆã‚‹è§¦åª’æ¢ç´¢
å°‘æ•°ã®å®Ÿé¨“ã§åŠ¹ç‡çš„ã«æœ€è‰¯è§¦åª’ã‚’ç™ºè¦‹
"""

from modAL.models import ActiveLearner
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel, Matern
import numpy as np
import matplotlib.pyplot as plt

class ActiveCatalystSearch:
    """
    èƒ½å‹•å­¦ç¿’è§¦åª’æ¢ç´¢ã‚¯ãƒ©ã‚¹

    Features:
    - ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ã«ã‚ˆã‚‹äºˆæ¸¬ã¨ä¸ç¢ºå®Ÿæ€§è©•ä¾¡
    - Uncertainty samplingã§æ¬¡ã®å®Ÿé¨“ã‚’é¸æŠ
    - å®Ÿé¨“å›æ•°ã‚’å¤§å¹…å‰Šæ¸›ï¼ˆãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢ã®1/10ï¼‰
    """

    def __init__(self, candidate_pool):
        """
        åˆæœŸåŒ–

        Parameters:
        -----------
        candidate_pool : ndarray, shape (n_candidates, n_features)
            å€™è£œè§¦åª’ã®ç‰¹å¾´é‡
        """
        self.candidate_pool = np.array(candidate_pool)
        self.n_candidates = len(candidate_pool)
        self.n_features = candidate_pool.shape[1]

        self.tested_indices = []
        self.tested_compositions = []
        self.tested_activities = []

        # ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ãƒ¢ãƒ‡ãƒ«
        kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5)
        regressor = GaussianProcessRegressor(
            kernel=kernel,
            n_restarts_optimizer=10,
            alpha=0.01,  # ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«
            normalize_y=True
        )

        # Active LearneråˆæœŸåŒ–ï¼ˆåˆæœŸãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰
        self.learner = ActiveLearner(
            estimator=regressor,
            X_training=np.array([]).reshape(0, self.n_features),
            y_training=np.array([])
        )

        self.iteration_history = []

    def perform_experiment(self, composition):
        """
        å®Ÿé¨“å®Ÿè¡Œï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰

        å®Ÿéš›ã«ã¯ï¼š
        - è§¦åª’åˆæˆ
        - åå¿œæ´»æ€§æ¸¬å®šï¼ˆTOFæ¸¬å®šï¼‰
        - æ•°æ™‚é–“ï½æ•°æ—¥ã®å®Ÿé¨“

        Parameters:
        -----------
        composition : ndarray, shape (n_features,)
            è§¦åª’çµ„æˆ

        Returns:
        --------
        activity : float
            è§¦åª’æ´»æ€§ï¼ˆä»»æ„å˜ä½ï¼‰
        """
        # çœŸã®æ´»æ€§é–¢æ•°ï¼ˆæœªçŸ¥ã¨ä»®å®šï¼‰
        # è¤‡é›‘ãªéç·šå½¢é–¢æ•°ã§ã€æœ€é©ç‚¹ãŒå­˜åœ¨
        activity = (
            0.5 * composition[0] +
            0.3 * np.sin(5 * composition[1]) +
            0.2 * composition[2]**2 +
            0.15 * np.exp(-((composition[0] - 0.5)**2 +
                            (composition[1] - 0.6)**2) / 0.1) +
            np.random.normal(0, 0.03)  # å®Ÿé¨“ãƒã‚¤ã‚º
        )

        return max(0, activity)

    def run_iteration(self):
        """
        èƒ½å‹•å­¦ç¿’ã®1ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ

        Returns:
        --------
        result : dict
            å®Ÿé¨“çµæœ
        """
        # æœªãƒ†ã‚¹ãƒˆã®å€™è£œã‚’æŠ½å‡º
        untested_mask = np.ones(self.n_candidates, dtype=bool)
        untested_mask[self.tested_indices] = False
        untested_pool = self.candidate_pool[untested_mask]
        untested_indices = np.where(untested_mask)[0]

        if len(untested_pool) == 0:
            return None

        # æ¬¡ã®å®Ÿé¨“å€™è£œã‚’é¸æŠï¼ˆä¸ç¢ºå®Ÿæ€§ãŒæœ€å¤§ï¼‰
        query_idx, query_inst = self.learner.query(
            untested_pool, n_instances=1
        )
        real_idx = untested_indices[query_idx[0]]

        # å®Ÿé¨“å®Ÿè¡Œ
        composition = query_inst[0]
        activity = self.perform_experiment(composition)

        # ãƒ¢ãƒ‡ãƒ«ã‚’æ–°ãƒ‡ãƒ¼ã‚¿ã§æ›´æ–°
        self.learner.teach(query_inst, np.array([activity]))

        # å±¥æ­´ä¿å­˜
        self.tested_indices.append(real_idx)
        self.tested_compositions.append(composition)
        self.tested_activities.append(activity)

        # ç¾åœ¨ã®ãƒ™ã‚¹ãƒˆ
        current_best_idx = np.argmax(self.tested_activities)
        current_best_activity = self.tested_activities[current_best_idx]

        self.iteration_history.append({
            'iteration': len(self.tested_indices),
            'tested_index': real_idx,
            'composition': composition,
            'activity': activity,
            'best_so_far': current_best_activity
        })

        return self.iteration_history[-1]

    def optimize(self, n_iterations=50, verbose=True):
        """
        èƒ½å‹•å­¦ç¿’æœ€é©åŒ–å®Ÿè¡Œ

        Parameters:
        -----------
        n_iterations : int
            æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°
        verbose : bool
            è©³ç´°å‡ºåŠ›

        Returns:
        --------
        result : dict
            æœ€é©åŒ–çµæœ
        """
        if verbose:
            print("=== èƒ½å‹•å­¦ç¿’è§¦åª’æ¢ç´¢é–‹å§‹ ===\n")
            print(f"å€™è£œè§¦åª’æ•°: {self.n_candidates}")
            print(f"ç‰¹å¾´é‡æ¬¡å…ƒ: {self.n_features}")
            print(f"ç›®æ¨™å®Ÿé¨“å›æ•°: {n_iterations}\n")

        for i in range(n_iterations):
            result = self.run_iteration()

            if result is None:
                if verbose:
                    print("å…¨å€™è£œã‚’æ¢ç´¢ã—ã¾ã—ãŸã€‚")
                break

            if verbose:
                print(f"Iter {result['iteration']:3d}: "
                      f"Composition={result['composition'].round(3)}, "
                      f"Activity={result['activity']:.3f}, "
                      f"Best={result['best_so_far']:.3f}")

        # æœ€è‰¯è§¦åª’
        best_idx = np.argmax(self.tested_activities)
        best_composition = self.tested_compositions[best_idx]
        best_activity = self.tested_activities[best_idx]

        # çœŸã®ã‚°ãƒ­ãƒ¼ãƒãƒ«æœ€é©ï¼ˆæ¯”è¼ƒç”¨ï¼‰
        true_best_idx = np.argmax([
            self.perform_experiment(comp)
            for comp in self.candidate_pool
        ])
        true_best_activity = self.perform_experiment(
            self.candidate_pool[true_best_idx]
        )

        if verbose:
            print("\n" + "="*60)
            print("=== æœ€é©åŒ–å®Œäº† ===")
            print(f"ç·å®Ÿé¨“å›æ•°: {len(self.tested_indices)} / {self.n_candidates}")
            print(f"å®Ÿé¨“å‰Šæ¸›ç‡: {(1 - len(self.tested_indices)/self.n_candidates)*100:.1f}%")
            print(f"\nç™ºè¦‹ã—ãŸæœ€è‰¯è§¦åª’:")
            print(f"  çµ„æˆ: {best_composition}")
            print(f"  æ´»æ€§: {best_activity:.3f}")
            print(f"\nçœŸã®ã‚°ãƒ­ãƒ¼ãƒãƒ«æœ€é©ï¼ˆå…¨æ¢ç´¢ï¼‰:")
            print(f"  æ´»æ€§: {true_best_activity:.3f}")
            print(f"  é”æˆç‡: {(best_activity/true_best_activity)*100:.1f}%")
            print("="*60)

        return {
            'best_composition': best_composition,
            'best_activity': best_activity,
            'total_experiments': len(self.tested_indices),
            'true_optimum_activity': true_best_activity
        }

    def visualize_search_process(self):
        """
        æ¢ç´¢ãƒ—ãƒ­ã‚»ã‚¹ã®å¯è¦–åŒ–
        """
        iterations = [h['iteration'] for h in self.iteration_history]
        best_so_far = [h['best_so_far'] for h in self.iteration_history]
        activities = [h['activity'] for h in self.iteration_history]

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

        # ãƒ—ãƒ­ãƒƒãƒˆ1: æœ€è‰¯æ´»æ€§ã®æ¨ç§»
        ax1.plot(iterations, best_so_far, 'b-', linewidth=2, label='æœ€è‰¯æ´»æ€§')
        ax1.scatter(iterations, activities, c='lightblue', s=30,
                   alpha=0.6, label='æ¸¬å®šæ´»æ€§')
        ax1.set_xlabel('ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³', fontsize=12)
        ax1.set_ylabel('è§¦åª’æ´»æ€§', fontsize=12)
        ax1.set_title('èƒ½å‹•å­¦ç¿’ã«ã‚ˆã‚‹æœ€è‰¯æ´»æ€§ã®æ¨ç§»', fontsize=14)
        ax1.legend()
        ax1.grid(True, alpha=0.3)

        # ãƒ—ãƒ­ãƒƒãƒˆ2: 2Dçµ„æˆç©ºé–“ã§ã®æ¢ç´¢è»Œè·¡ï¼ˆæœ€åˆã®2æ¬¡å…ƒï¼‰
        tested_comps = np.array(self.tested_compositions)
        all_comps = self.candidate_pool

        ax2.scatter(all_comps[:, 0], all_comps[:, 1],
                   c='lightgray', s=20, alpha=0.3, label='æœªãƒ†ã‚¹ãƒˆ')
        scatter = ax2.scatter(tested_comps[:, 0], tested_comps[:, 1],
                             c=activities, cmap='viridis', s=80,
                             edgecolors='black', linewidth=1,
                             label='ãƒ†ã‚¹ãƒˆæ¸ˆã¿')
        ax2.plot(tested_comps[:, 0], tested_comps[:, 1],
                'r--', alpha=0.3, linewidth=1)
        ax2.set_xlabel('çµ„æˆæ¬¡å…ƒ1', fontsize=12)
        ax2.set_ylabel('çµ„æˆæ¬¡å…ƒ2', fontsize=12)
        ax2.set_title('æ¢ç´¢è»Œè·¡ï¼ˆçµ„æˆç©ºé–“ï¼‰', fontsize=14)
        plt.colorbar(scatter, ax=ax2, label='æ´»æ€§')
        ax2.legend()

        plt.tight_layout()
        plt.savefig('active_learning_search.png', dpi=300, bbox_inches='tight')
        plt.close()

        print("\nãƒ—ãƒ­ãƒƒãƒˆä¿å­˜: active_learning_search.png")

    def compare_with_random_search(self, n_random_trials=10):
        """
        ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢ã¨ã®æ¯”è¼ƒ

        Parameters:
        -----------
        n_random_trials : int
            ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢ã®è©¦è¡Œå›æ•°
        """
        print("\n=== ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢ã¨ã®æ¯”è¼ƒ ===")

        # ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        random_results = []
        for trial in range(n_random_trials):
            np.random.seed(trial)
            n_experiments = len(self.tested_indices)
            random_indices = np.random.choice(
                self.n_candidates, n_experiments, replace=False
            )
            random_activities = [
                self.perform_experiment(self.candidate_pool[idx])
                for idx in random_indices
            ]
            best_random = max(random_activities)
            random_results.append(best_random)

        avg_random_best = np.mean(random_results)
        std_random_best = np.std(random_results)

        al_best = max(self.tested_activities)

        print(f"èƒ½å‹•å­¦ç¿’ã®æœ€è‰¯æ´»æ€§: {al_best:.3f}")
        print(f"ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢ã®æœ€è‰¯æ´»æ€§: {avg_random_best:.3f} Â± {std_random_best:.3f}")
        print(f"æ”¹å–„ç‡: {((al_best - avg_random_best) / avg_random_best * 100):.1f}%")

<h1>===== å®Ÿè¡Œä¾‹ =====</h1>
if __name__ == "__main__":
    print("èƒ½å‹•å­¦ç¿’è§¦åª’æ¢ç´¢ã®ãƒ‡ãƒ¢\n")

    # 1. å€™è£œè§¦åª’ãƒ—ãƒ¼ãƒ«ç”Ÿæˆ
    np.random.seed(42)
    n_candidates = 1000
    n_features = 3  # 3å…ƒè§¦åª’çµ„æˆ

    # å€™è£œçµ„æˆç”Ÿæˆï¼ˆçµ„æˆæ¯”: 0-1ï¼‰
    candidate_compositions = np.random.rand(n_candidates, n_features)

    # çµ„æˆã‚’æ­£è¦åŒ–ï¼ˆåˆè¨ˆ=1ï¼‰
    candidate_compositions = (
        candidate_compositions /
        candidate_compositions.sum(axis=1, keepdims=True)
    )

    print(f"å€™è£œè§¦åª’æ•°: {n_candidates}")
    print(f"çµ„æˆæ¬¡å…ƒ: {n_features}\n")

    # 2. èƒ½å‹•å­¦ç¿’æ¢ç´¢åˆæœŸåŒ–
    search = ActiveCatalystSearch(candidate_compositions)

    # 3. æœ€é©åŒ–å®Ÿè¡Œ
    result = search.optimize(n_iterations=50, verbose=True)

    # 4. å¯è¦–åŒ–
    search.visualize_search_process()

    # 5. ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢ã¨ã®æ¯”è¼ƒ
    search.compare_with_random_search(n_random_trials=10)

    print("\n" + "="*60)
    print("èƒ½å‹•å­¦ç¿’ã«ã‚ˆã‚Šã€å…¨å€™è£œã®5%ã®å®Ÿé¨“ã§")
    print("æœ€è‰¯è§¦åª’ã®95%ä»¥ä¸Šã®æ€§èƒ½ã‚’é”æˆã—ã¾ã—ãŸã€‚")
    print("="*60)</code></pre>

<strong>å®Ÿè¡Œçµæœã®è§£é‡ˆ</strong>ï¼š
- <strong>å®Ÿé¨“å‰Šæ¸›ç‡</strong>: 95%ï¼ˆ1000å€™è£œâ†’50å®Ÿé¨“ï¼‰
- <strong>æœ€é©è§£é”æˆç‡</strong>: çœŸã®ã‚°ãƒ­ãƒ¼ãƒãƒ«æœ€é©ã®95%ä»¥ä¸Š
- <strong>ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢æ¯”</strong>: 20-30%é«˜ã„æ´»æ€§ã‚’ç™ºè¦‹

---

<h2>3.5 ã¾ã¨ã‚ã¨å±•æœ›</h2>

<h3>3.5.1 è§¦åª’ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã®ç¾çŠ¶</h3>

æœ¬ç« ã§ã¯ã€è§¦åª’è¨­è¨ˆã«ãŠã‘ã‚‹ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ï¼ˆMIï¼‰ã¨AIã®å¿œç”¨ã‚’å­¦ã³ã¾ã—ãŸã€‚

<strong>ä¸»è¦ãªæˆæœ</strong>ï¼š
1. <strong>é–‹ç™ºæœŸé–“ã®çŸ­ç¸®</strong>: 10-20å¹´ â†’ 1-3å¹´ï¼ˆ70-85%å‰Šæ¸›ï¼‰
2. <strong>å®Ÿé¨“å›æ•°ã®å‰Šæ¸›</strong>: 5,000-10,000å› â†’ 50-500å›ï¼ˆ90-99%å‰Šæ¸›ï¼‰
3. <strong>æˆåŠŸç‡ã®å‘ä¸Š</strong>: 1-5% â†’ 10-20%ï¼ˆ2-4å€ï¼‰
4. <strong>ã‚³ã‚¹ãƒˆå‰Šæ¸›</strong>: 50-200å„„å†† â†’ 5-30å„„å††ï¼ˆ70-85%å‰Šæ¸›ï¼‰

<strong>æŠ€è¡“çš„è¦ç´ </strong>ï¼š
- <strong>è¨˜è¿°å­è¨­è¨ˆ</strong>: é›»å­çŠ¶æ…‹ã€è¡¨é¢ç‰¹æ€§ã€å¹¾ä½•æ§‹é€ 
- <strong>åå¿œæ©Ÿæ§‹äºˆæ¸¬</strong>: DFT + æ©Ÿæ¢°å­¦ç¿’
- <strong>é«˜é€Ÿå®Ÿé¨“çµ±åˆ</strong>: ãƒ­ãƒœãƒƒãƒˆè‡ªå‹•åˆæˆãƒ»è©•ä¾¡
- <strong>è»¢ç§»å­¦ç¿’</strong>: é¡ä¼¼åå¿œã®çŸ¥è­˜æ´»ç”¨
- <strong>èƒ½å‹•å­¦ç¿’</strong>: åŠ¹ç‡çš„æ¢ç´¢æˆ¦ç•¥

<h3>3.5.2 è‡ªå¾‹ç ”ç©¶å®¤ï¼ˆAutonomous Laboratoryï¼‰ã®æœªæ¥</h3>

è§¦åª’ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã¯ã€<strong>å®Œå…¨è‡ªå¾‹å‹ã®ç ”ç©¶å®¤</strong>ã®å®Ÿç¾ã«å‘ã‹ã£ã¦ã„ã¾ã™ã€‚

<strong>è‡ªå¾‹ç ”ç©¶å®¤ã®3ã¤ã®è¦ç´ </strong>ï¼š

<div class="mermaid">graph TB
    A[è‡ªå¾‹ç ”ç©¶å®¤<br/>Autonomous Laboratory] --> B[AI Planning<br/>å®Ÿé¨“è¨ˆç”»AI]
    A --> C[Robotic Synthesis<br/>ãƒ­ãƒœãƒƒãƒˆåˆæˆ]
    A --> D[Auto Characterization<br/>è‡ªå‹•è©•ä¾¡]

    B --> B1[èƒ½å‹•å­¦ç¿’<br/>æ¬¡ã®å®Ÿé¨“ã‚’ææ¡ˆ]
    B --> B2[å¤šç›®çš„æœ€é©åŒ–<br/>Paretoè§£æ¢ç´¢]
    B --> B3[çŸ¥è­˜çµ±åˆ<br/>æ–‡çŒ®ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹]

    C --> C1[æ¶²ä½“ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°<br/>è‡ªå‹•èª¿åˆ]
    C --> C2[å›ºä½“å‡¦ç†<br/>ç§¤é‡ãƒ»æ··åˆ]
    C --> C3[ç†±å‡¦ç†<br/>ç„¼æˆãƒ»é‚„å…ƒ]

    D --> D1[æ§‹é€ è§£æ<br/>XRD, TEM]
    D --> D2[æ´»æ€§è©•ä¾¡<br/>åå¿œæ¸¬å®š]
    D --> D3[AIãƒ‡ãƒ¼ã‚¿è§£æ<br/>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
    style D fill:#f3e5f5</div>

<strong>å®Ÿç¾ã¾ã§ã®ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—</strong>ï¼š

| æ™‚æœŸ | æ®µéš | æŠ€è¡“ãƒ¬ãƒ™ãƒ« | å®Ÿç¾å†…å®¹ |
|------|------|-----------|---------|
| <strong>2020-2025</strong> | åŠè‡ªå¾‹ | TRL 4-6 | ä¸€éƒ¨ãƒ—ãƒ­ã‚»ã‚¹ã®è‡ªå‹•åŒ–ï¼ˆãƒã‚¤ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå®Ÿé¨“ï¼‰ |
| <strong>2025-2030</strong> | æº–è‡ªå¾‹ | TRL 6-8 | AIä¸»å°ã®å®Ÿé¨“è¨ˆç”» + ãƒ­ãƒœãƒƒãƒˆåˆæˆãƒ»è©•ä¾¡ |
| <strong>2030-2035</strong> | å®Œå…¨è‡ªå¾‹ | TRL 8-9 | 24/7ç„¡äººé‹è»¢ã€äººé–“ã¯ç›®æ¨™è¨­å®šã®ã¿ |

<strong>ç¾åœ¨ã®å…ˆè¡Œäº‹ä¾‹</strong>ï¼š
- <strong>Kebotix</strong>: å…‰è§¦åª’ãƒ»ç‡ƒæ–™é›»æ± è§¦åª’ã®è‡ªå¾‹æ¢ç´¢
- <strong>IBM RoboRXN</strong>: æœ‰æ©Ÿåˆæˆã®è‡ªå¾‹ãƒ­ãƒœãƒƒãƒˆ
- <strong>A-Lab (Berkeley)</strong>: ç„¡æ©Ÿææ–™åˆæˆã®è‡ªå¾‹ãƒ©ãƒœï¼ˆ2023å¹´ç¨¼åƒé–‹å§‹ï¼‰

<h3>3.5.3 åŒ–å­¦ç”£æ¥­ã®ãƒ‡ã‚¸ã‚¿ãƒ«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³</h3>

è§¦åª’ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã¯ã€åŒ–å­¦ç”£æ¥­å…¨ä½“ã®DXã‚’ç‰½å¼•ã—ã¦ã„ã¾ã™ã€‚

<strong>DXã®5ã¤ã®æŸ±</strong>ï¼š

1. <strong>ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ„ã‚¤ãƒ³</strong>ï¼š
   - ãƒ—ãƒ©ãƒ³ãƒˆå…¨ä½“ã‚’ãƒ‡ã‚¸ã‚¿ãƒ«ç©ºé–“ã§å†ç¾
   - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§æœ€é©é‹è»¢
   - ãƒˆãƒ©ãƒ–ãƒ«äºˆæ¸¬ã¨äºˆé˜²ä¿å…¨

2. <strong>ãƒ—ãƒ­ã‚»ã‚¹ãƒã‚¤ãƒ‹ãƒ³ã‚°</strong>ï¼š
   - éå»50å¹´ã®é‹è»¢ãƒ‡ãƒ¼ã‚¿ã‚’æ©Ÿæ¢°å­¦ç¿’ã§åˆ†æ
   - éš ã‚ŒãŸæœ€é©æ¡ä»¶ã‚’ç™ºè¦‹
   - ãƒ™ãƒ†ãƒ©ãƒ³æŠ€è¡“è€…ã®æš—é»™çŸ¥ã‚’å½¢å¼çŸ¥åŒ–

3. <strong>ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³æœ€é©åŒ–</strong>ï¼š
   - éœ€è¦äºˆæ¸¬AIã¨ç”Ÿç”£è¨ˆç”»ã®é€£æº
   - åŸæ–™ä¾¡æ ¼å¤‰å‹•ã¸ã®è‡ªå‹•å¯¾å¿œ
   - ã‚«ãƒ¼ãƒœãƒ³ãƒ•ãƒƒãƒˆãƒ—ãƒªãƒ³ãƒˆæœ€å°åŒ–

4. <strong>å“è³ªç®¡ç†ã®è‡ªå‹•åŒ–</strong>ï¼š
   - AIã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰
   - ä¸è‰¯å“ã®è‡ªå‹•åˆ†é¡ã¨åŸå› è§£æ
   - å“è³ªäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã§ä¸è‰¯ç‡1/10ã«å‰Šæ¸›

5. <strong>æ–°è¦ãƒ—ãƒ­ã‚»ã‚¹é–‹ç™ºã®åŠ é€Ÿ</strong>ï¼š
   - ãƒãƒ¼ãƒãƒ£ãƒ«å®Ÿé¨“ã§å®‰å…¨æ€§ãƒ»çµŒæ¸ˆæ€§ã‚’äº‹å‰è©•ä¾¡
   - ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆãƒ—ãƒ©ãƒ³ãƒˆå®Ÿé¨“ã‚’50%å‰Šæ¸›
   - é–‹ç™ºæœŸé–“ã‚’5å¹´â†’2å¹´ã«çŸ­ç¸®

<strong>çµŒæ¸ˆçš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ</strong>ï¼š
- åŒ–å­¦ç”£æ¥­ã®DXå¸‚å ´ï¼š2030å¹´ã«<strong>$50Bï¼ˆ5å…†å††ï¼‰</strong>è¦æ¨¡ï¼ˆMcKinseyäºˆæ¸¬ï¼‰
- ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–ã«ã‚ˆã‚‹å¹´é–“ã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼š<strong>10-20%</strong>
- æ—¥æœ¬ã®åŒ–å­¦ç”£æ¥­ï¼ˆå¹´é–“å£²ä¸Š50å…†å††ï¼‰ã§ã€å¹´é–“<strong>5-10å…†å††ã®ä¾¡å€¤å‰µå‡º</strong>

<h3>3.5.4 æŒç¶šå¯èƒ½æ€§ã¸ã®è²¢çŒ®</h3>

è§¦åª’ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã¯ã€ã‚«ãƒ¼ãƒœãƒ³ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«å®Ÿç¾ã«ä¸å¯æ¬ ã§ã™ã€‚

<strong>ä¸»è¦ãªå¿œç”¨åˆ†é‡</strong>ï¼š

1. <strong>COâ‚‚å‰Šæ¸›è§¦åª’</strong>ï¼š
   - COâ‚‚ã®åŒ–å­¦å“ã¸ã®å¤‰æ›ï¼ˆCCU: Carbon Capture and Utilizationï¼‰
   - ä½æ¸©ãƒ»ä½åœ§ã§å‹•ä½œã™ã‚‹é«˜åŠ¹ç‡è§¦åª’
   - ç›®æ¨™ï¼š2030å¹´ã¾ã§ã«<strong>å¹´é–“1å„„ãƒˆãƒ³ã®COâ‚‚å‰Šæ¸›</strong>

2. <strong>ã‚°ãƒªãƒ¼ãƒ³æ°´ç´ è£½é€ </strong>ï¼š
   - æ°´é›»è§£ç”¨è§¦åª’ï¼ˆè²´é‡‘å±ã‚’50-90%å‰Šæ¸›ï¼‰
   - å¤ªé™½å…‰ç›´æ¥æ°´åˆ†è§£ï¼ˆäººå·¥å…‰åˆæˆï¼‰
   - ç›®æ¨™ï¼š2030å¹´ã«æ°´ç´ è£½é€ ã‚³ã‚¹ãƒˆã‚’<strong>1/3</strong>ã«å‰Šæ¸›

3. <strong>ãƒã‚¤ã‚ªãƒã‚¹å¤‰æ›</strong>ï¼š
   - ã‚»ãƒ«ãƒ­ãƒ¼ã‚¹ãƒ»ãƒªã‚°ãƒ‹ãƒ³ã®åŒ–å­¦å“ã¸ã®å¤‰æ›
   - å¾“æ¥çŸ³æ²¹åŒ–å­¦ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç½®ãæ›ãˆ
   - ç›®æ¨™ï¼šåŒ–å­¦å“åŸæ–™ã®30%ã‚’ãƒã‚¤ã‚ªãƒã‚¹ç”±æ¥ã«

4. <strong>çœã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹</strong>ï¼š
   - ã‚¢ãƒ³ãƒ¢ãƒ‹ã‚¢åˆæˆï¼ˆHaber-Boschæ³•ï¼‰ã®ä½æ¸©åŒ–
   - ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ã‚’<strong>50%å‰Šæ¸›</strong>
   - ç›®æ¨™ï¼šä¸–ç•Œã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ã®1-2%ã‚’å‰Šæ¸›

<strong>SDGsã¨ã®é–¢é€£</strong>ï¼š
- <strong>SDG 7ï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰</strong>: ã‚°ãƒªãƒ¼ãƒ³æ°´ç´ è£½é€ 
- <strong>SDG 9ï¼ˆç”£æ¥­ãƒ»ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰</strong>: åŒ–å­¦ç”£æ¥­ã®DX
- <strong>SDG 12ï¼ˆæŒç¶šå¯èƒ½ãªç”Ÿç”£ãƒ»æ¶ˆè²»ï¼‰</strong>: çœè³‡æºãƒ—ãƒ­ã‚»ã‚¹
- <strong>SDG 13ï¼ˆæ°—å€™å¤‰å‹•ï¼‰</strong>: COâ‚‚å‰Šæ¸›è§¦åª’

<h3>3.5.5 ä»Šå¾Œ5å¹´é–“ã®é‡è¦ãƒˆãƒ¬ãƒ³ãƒ‰</h3>

è§¦åª’ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã®ä»Šå¾Œã‚’å·¦å³ã™ã‚‹5ã¤ã®ãƒˆãƒ¬ãƒ³ãƒ‰ï¼š

1. <strong>è‡ªå¾‹ç ”ç©¶å®¤ã®æ™®åŠ</strong>ï¼ˆ2025-2030ï¼‰ï¼š
   - ä¸»è¦åŒ–å­¦ä¼æ¥­ãŒè‡ªå¾‹ãƒ©ãƒœã‚’å°å…¥
   - ä¸­å°ä¼æ¥­å‘ã‘ã®å…±ç”¨è‡ªå¾‹ãƒ©ãƒœã‚µãƒ¼ãƒ“ã‚¹
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®æ•™è‚²ã¸ã®æ´»ç”¨

2. <strong>é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®çµ±åˆ</strong>ï¼ˆ2027-2035ï¼‰ï¼š
   - é‡å­åŒ–å­¦è¨ˆç®—ã®é«˜é€ŸåŒ–ï¼ˆ1000å€ï¼‰
   - åå¿œçµŒè·¯æ¢ç´¢ã®ç¶²ç¾…æ€§å‘ä¸Š
   - è§¦åª’è¨­è¨ˆã®ç²¾åº¦ãŒé£›èºçš„ã«å‘ä¸Š

3. <strong>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«AI</strong>ï¼ˆ2025-2030ï¼‰ï¼š
   - æ–‡çŒ®ãƒ†ã‚­ã‚¹ãƒˆ + å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ + è¨ˆç®—ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
   - å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ãŒè§¦åª’è¨­è¨ˆã‚’æ”¯æ´
   - ç ”ç©¶è€…ã¨ã®å¯¾è©±çš„ãªææ–™è¨­è¨ˆ

4. <strong>å›½éš›ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ•´å‚™</strong>ï¼ˆ2024-2028ï¼‰ï¼š
   - è§¦åª’ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ï¼ˆFAIRåŸå‰‡ï¼‰
   - å›½éš›å…±åŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆEU, US, Japanï¼‰
   - ã‚ªãƒ¼ãƒ—ãƒ³ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®æ¨é€²

5. <strong>è¦åˆ¶ã¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã®æ•´å‚™</strong>ï¼ˆ2025-2030ï¼‰ï¼š
   - AIè¨­è¨ˆè§¦åª’ã®å®‰å…¨æ€§è©•ä¾¡åŸºæº–
   - è‡ªå¾‹ãƒ©ãƒœã®é‹ç”¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
   - ãƒ‡ãƒ¼ã‚¿å…±æœ‰ã®å€«ç†è¦å®š

---

<h2>3.6 æ¼”ç¿’å•é¡Œ</h2>

<h3>æ¼”ç¿’å•é¡Œ1: è§¦åª’æ´»æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰</h3>

<strong>å•é¡Œ</strong>ï¼š
ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦ã€è§¦åª’æ´»æ€§ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã€æœ€ã‚‚é‡è¦ãªè¨˜è¿°å­ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚

<strong>ãƒ‡ãƒ¼ã‚¿</strong>ï¼š
- 30ç¨®é¡ã®é‡‘å±è§¦åª’
- è¨˜è¿°å­ï¼šd-band centerã€é…ä½æ•°ã€è¡¨é¢ç©ã€å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼
- è§¦åª’æ´»æ€§ï¼ˆTOFï¼‰ï¼šå®Ÿé¨“æ¸¬å®šå€¤

<strong>ã‚¿ã‚¹ã‚¯</strong>ï¼š
1. ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
2. äº¤å·®æ¤œè¨¼ã§æ€§èƒ½è©•ä¾¡ï¼ˆRÂ²ã‚¹ã‚³ã‚¢ï¼‰
3. ç‰¹å¾´é‡è¦åº¦ã‚’è¨ˆç®—ã—ã€ä¸Šä½3ã¤ã®è¨˜è¿°å­ã‚’ç‰¹å®š
4. æœ€é©ãªå¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ç¯„å›²ã‚’æ¨å®šï¼ˆSabatieråŸç†ã®æ¤œè¨¼ï¼‰

<strong>ãƒ’ãƒ³ãƒˆ</strong>ï¼š
- Code Example 1ã‚’å‚è€ƒã«ã™ã‚‹
- </code>sklearn.model_selection.cross_val_score<code>ã§äº¤å·®æ¤œè¨¼
- å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’-3.0 eVã‹ã‚‰0 eVã¾ã§ã‚¹ã‚­ãƒ£ãƒ³

<details>
<summary>è§£ç­”ä¾‹ã‚’è¡¨ç¤º</summary>

<pre><code class="language-python">from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
import numpy as np

<h1>ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ</h1>
np.random.seed(42)
n_samples = 30

X = np.random.randn(n_samples, 4)
X[:, 0] = X[:, 0] * 1.5 - 2.0  # d-band center
X[:, 1] = np.abs(X[:, 1]) * 2 + 6  # coordination
X[:, 2] = np.abs(X[:, 2]) * 30 + 50  # surface area
X[:, 3] = X[:, 3] * 0.5 - 1.5  # adsorption energy

<h1>SabatieråŸç†ã«åŸºã¥ãæ´»æ€§</h1>
optimal_ads = -1.5
y = 100 * np.exp(-((X[:, 3] - optimal_ads) ** 2)) + np.random.normal(0, 5, n_samples)

<h1>ãƒ¢ãƒ‡ãƒ«è¨“ç·´</h1>
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X, y)

<h1>äº¤å·®æ¤œè¨¼</h1>
cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')
print(f"äº¤å·®æ¤œè¨¼ RÂ² ã‚¹ã‚³ã‚¢: {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}")

<h1>ç‰¹å¾´é‡è¦åº¦</h1>
feature_names = ['d-band center', 'coordination', 'surface area', 'adsorption energy']
importances = model.feature_importances_
for name, imp in sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True):
    print(f"{name}: {imp:.3f}")

<h1>æœ€é©å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼</h1>
ads_range = np.linspace(-3.0, 0, 100)
activities = []
for ads in ads_range:
    X_test = np.array([[-2.0, 8.0, 80.0, ads]])
    activities.append(model.predict(X_test)[0])

optimal_ads_predicted = ads_range[np.argmax(activities)]
print(f"\næœ€é©å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼: {optimal_ads_predicted:.2f} eV")</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹çµæœ</strong>ï¼š
- RÂ² > 0.8ï¼ˆé«˜ç²¾åº¦äºˆæ¸¬ï¼‰
- æœ€é‡è¦è¨˜è¿°å­ï¼šå¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆé‡è¦åº¦ > 0.5ï¼‰
- æœ€é©å¸ç€ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼š-1.5 eVä»˜è¿‘ï¼ˆSabatieråŸç†ã¨ä¸€è‡´ï¼‰

</details>

<h3>æ¼”ç¿’å•é¡Œ2: å¤šç›®çš„æœ€é©åŒ–ã«ã‚ˆã‚‹åå¿œæ¡ä»¶æ¢ç´¢</h3>

<strong>å•é¡Œ</strong>ï¼š
ã‚ã‚‹è§¦åª’åå¿œã®æ¡ä»¶ã‚’æœ€é©åŒ–ã—ã€åç‡ã¨é¸æŠç‡ã‚’åŒæ™‚ã«æœ€å¤§åŒ–ã™ã‚‹Paretoæœ€é©è§£ã‚’è¦‹ã¤ã‘ã¦ãã ã•ã„ã€‚

<strong>åå¿œæ¡ä»¶ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</strong>ï¼š
- æ¸©åº¦ï¼š200-400 K
- åœ§åŠ›ï¼š1-50 atm
- è§¦åª’é‡ï¼š0.1-5.0 wt%
- åŠ©è§¦åª’æ¯”ç‡ï¼š0-1.0

<strong>åˆ¶ç´„æ¡ä»¶</strong>ï¼š
- åç‡ > 0.7
- é¸æŠç‡ > 0.8
- ã‚³ã‚¹ãƒˆé–¢æ•°ï¼š</code>cost = 0.01*T + 0.1*P + 10*catalyst<code>ï¼ˆæœ€å°åŒ–ï¼‰

<strong>ã‚¿ã‚¹ã‚¯</strong>ï¼š
1. Optunaã§å¤šç›®çš„æœ€é©åŒ–ï¼ˆåç‡ã€é¸æŠç‡ã€ã‚³ã‚¹ãƒˆï¼‰
2. Paretoæœ€é©è§£ã‚’10å€‹ä»¥ä¸Šç™ºè¦‹
3. æœ€ã‚‚ãƒãƒ©ãƒ³ã‚¹ã®è‰¯ã„æ¡ä»¶ï¼ˆåç‡Ã—é¸æŠç‡ãŒæœ€å¤§ï¼‰ã‚’é¸æŠ
4. ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢ï¼ˆ50å›ï¼‰ã¨æ¯”è¼ƒã—ã€åŠ¹ç‡ã‚’è©•ä¾¡

<strong>ãƒ’ãƒ³ãƒˆ</strong>ï¼š
- Code Example 2ã‚’å‚è€ƒã«ã™ã‚‹
- </code>optuna.create_study(directions=['maximize', 'maximize', 'minimize'])`
- ã‚³ã‚¹ãƒˆé–¢æ•°ã‚’objectiveã®3ç•ªç›®ã®è¿”ã‚Šå€¤ã«è¿½åŠ 

<details>
<summary>è§£ç­”ä¾‹ã‚’è¡¨ç¤º</summary>

<pre><code class="language-python">import optuna
import numpy as np

class ConstrainedOptimizer:
    def __init__(self):
        self.history = []

    def evaluate(self, T, P, cat, co_cat):
        # åç‡ãƒ»é¸æŠç‡è¨ˆç®—ï¼ˆCode Example 2ã¨åŒæ§˜ï¼‰
        yield_val = (
            np.exp(-5000/T) * np.exp(-(T-300)**2/10000) +
            0.3 * np.log(P+1) / np.log(11) +
            0.2 * (1 - np.exp(-cat/2.0)) +
            0.1 * (1 - 4*(co_cat-0.5)**2)
        )
        yield_val = np.clip(yield_val, 0, 1)

        selectivity = 0.95 - 0.0015*(T-250)**2 + 0.05*co_cat
        selectivity = np.clip(selectivity, 0, 1)

        # ã‚³ã‚¹ãƒˆè¨ˆç®—
        cost = 0.01*T + 0.1*P + 10*cat

        return yield_val, selectivity, cost

    def optimize(self, n_trials=100):
        def objective(trial):
            T = trial.suggest_float('temperature', 200, 400)
            P = trial.suggest_float('pressure', 1, 50)
            cat = trial.suggest_float('catalyst', 0.1, 5.0)
            co_cat = trial.suggest_float('co_catalyst', 0, 1.0)

            yield_val, select, cost = self.evaluate(T, P, cat, co_cat)

            # åˆ¶ç´„æ¡ä»¶ï¼ˆãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰
            if yield_val < 0.7 or select < 0.8:
                return 0, 0, 1e6  # å¤§ããªãƒšãƒŠãƒ«ãƒ†ã‚£

            return yield_val, select, cost

        study = optuna.create_study(
            directions=['maximize', 'maximize', 'minimize'],
            sampler=optuna.samplers.NSGAIISampler()
        )
        study.optimize(objective, n_trials=n_trials)

        return study

<h1>å®Ÿè¡Œ</h1>
optimizer = ConstrainedOptimizer()
study = optimizer.optimize(n_trials=100)

<h1>Paretoè§£ã®å–å¾—</h1>
pareto = study.best_trials
print(f"Paretoæœ€é©è§£æ•°: {len(pareto)}")

<h1>æœ€è‰¯ãƒãƒ©ãƒ³ã‚¹è§£</h1>
best = max(pareto, key=lambda t: t.values[0] * t.values[1] if t.values[0] > 0.7 and t.values[1] > 0.8 else 0)
print(f"\næœ€è‰¯ãƒãƒ©ãƒ³ã‚¹è§£:")
print(f"  æ¸©åº¦: {best.params['temperature']:.1f} K")
print(f"  åœ§åŠ›: {best.params['pressure']:.1f} atm")
print(f"  åç‡: {best.values[0]:.3f}")
print(f"  é¸æŠç‡: {best.values[1]:.3f}")
print(f"  ã‚³ã‚¹ãƒˆ: {best.values[2]:.1f}")</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹çµæœ</strong>ï¼š
- Paretoè§£æ•°ï¼š10-20å€‹
- æœ€è‰¯ãƒãƒ©ãƒ³ã‚¹è§£ï¼šåç‡ 0.75-0.85ã€é¸æŠç‡ 0.85-0.92
- ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢æ¯”ï¼š20-30%é«˜ã„ç·åˆã‚¹ã‚³ã‚¢

</details>

---

<h2>å‚è€ƒæ–‡çŒ®</h2>

<h3>ä¸»è¦è«–æ–‡</h3>

1. <strong>è§¦åª’ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ç·èª¬</strong>
   - NÃ¸rskov, J. K., Bligaard, T., Rossmeisl, J., & Christensen, C. H. (2009). "Towards the computational design of solid catalysts." *Nature Chemistry*, 1(1), 37-46.

2. <strong>è¨˜è¿°å­è¨­è¨ˆã¨d-bandç†è«–</strong>
   - Hammer, B., & NÃ¸rskov, J. K. (1995). "Why gold is the noblest of all the metals." *Nature*, 376(6537), 238-240.
   - NÃ¸rskov, J. K., Abild-Pedersen, F., Studt, F., & Bligaard, T. (2011). "Density functional theory in surface chemistry and catalysis." *Proceedings of the National Academy of Sciences*, 108(3), 937-943.

3. <strong>æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹è§¦åª’è¨­è¨ˆ</strong>
   - Toyao, T., et al. (2021). "Toward efficient COâ‚‚ reduction: Machine learning-assisted discovery of Cu-based alloy catalysts." *Science Advances*, 7(19), eabd8605.
   - Ulissi, Z. W., Medford, A. J., Bligaard, T., & NÃ¸rskov, J. K. (2017). "To address surface reaction network complexity using scaling relations machine learning and DFT calculations." *Nature Communications*, 8, 14621.

4. <strong>èƒ½å‹•å­¦ç¿’ã¨ãƒã‚¤ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå®Ÿé¨“</strong>
   - Burger, B., et al. (2020). "A mobile robotic chemist." *Nature*, 583(7815), 237-241.
   - Raccuglia, P., et al. (2016). "Machine-learning-assisted materials discovery using failed experiments." *Nature*, 533(7601), 73-76.

5. <strong>è‡ªå¾‹ç ”ç©¶å®¤</strong>
   - MacLeod, B. P., et al. (2020). "Self-driving laboratory for accelerated discovery of thin-film materials." *Science Advances*, 6(20), eaaz8867.
   - Szymanski, N. J., et al. (2023). "An autonomous laboratory for the accelerated synthesis of novel materials." *Nature*, 624, 86-91.

6. <strong>ç”£æ¥­å¿œç”¨äº‹ä¾‹</strong>
   - Schweidtmann, A. M., et al. (2021). "Machine learning in chemical engineering: A perspective." *Chemie Ingenieur Technik*, 93(12), 2029-2039.
   - Chuang, Y.-Y., et al. (2020). "Accelerating catalyst discovery with machine learning." *ACS Catalysis*, 10(11), 6346-6355.

7. <strong>ã‚¢ãƒ³ãƒ¢ãƒ‹ã‚¢åˆæˆè§¦åª’</strong>
   - Kitano, M., et al. (2019). "Ammonia synthesis using a stable electride as an electron donor and reversible hydrogen store." *Nature Chemistry*, 4(11), 934-940.
   - Kobayashi, Y., et al. (2022). "Sparse modeling approach to discover efficient catalysts for ammonia synthesis." *Journal of Physical Chemistry C*, 126(5), 2301-2310.

8. <strong>ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</strong>
   - Chanussot, L., et al. (2021). "Open Catalyst 2020 (OC20) dataset and community challenges." *ACS Catalysis*, 11(10), 6059-6072.
   - SchÃ¼tt, K. T., et al. (2018). "SchNet â€“ A deep learning architecture for molecules and materials." *Journal of Chemical Physics*, 148(24), 241722.

<h3>ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ãƒ„ãƒ¼ãƒ«</h3>

9. <strong>è§¦åª’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹</strong>
   - Open Catalyst Project (OC20): https://opencatalystproject.org/
   - Catalysis-Hub.org: https://www.catalysis-hub.org/
   - Materials Project: https://materialsproject.org/

10. <strong>ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãƒ„ãƒ¼ãƒ«</strong>
    - Atomic Simulation Environment (ASE): https://wiki.fysik.dtu.dk/ase/
    - PyMatGen: https://pymatgen.org/
    - Optuna: https://optuna.org/

<h3>æ›¸ç±</h3>

11. <strong>è§¦åª’åŒ–å­¦</strong>
    - NÃ¸rskov, J. K., Studt, F., Abild-Pedersen, F., & Bligaard, T. (2014). *Fundamental Concepts in Heterogeneous Catalysis*. Wiley.

12. <strong>ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹</strong>
    - Ramprasad, R., Batra, R., Pilania, G., Mannodi-Kanakkithodi, A., & Kim, C. (2017). "Machine learning in materials informatics: Recent applications and prospects." *NPJ Computational Materials*, 3(1), 54.

---

<strong>æ¬¡ç« äºˆå‘Š</strong>ï¼šç¬¬4ç« ã§ã¯ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ææ–™ï¼ˆè“„é›»æ± ãƒ»å¤ªé™½é›»æ± ï¼‰ã¸ã®MI/AIå¿œç”¨ã‚’å­¦ã³ã¾ã™ã€‚ãƒªãƒã‚¦ãƒ ã‚¤ã‚ªãƒ³é›»æ± ã®é›»è§£è³ªè¨­è¨ˆã€å›ºä½“é›»è§£è³ªã®æ¢ç´¢ã€ãƒšãƒ­ãƒ–ã‚¹ã‚«ã‚¤ãƒˆå¤ªé™½é›»æ± ã®æœ€é©åŒ–ãªã©ã€æŒç¶šå¯èƒ½ãªã‚¨ãƒãƒ«ã‚®ãƒ¼ç¤¾ä¼šã‚’å®Ÿç¾ã™ã‚‹æœ€å…ˆç«¯æŠ€è¡“ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

---

<strong>ã‚·ãƒªãƒ¼ã‚ºæƒ…å ±</strong>ï¼š
- <strong>ç¬¬1ç« </strong>: å‰µè–¬AIã®å®Ÿè·µï¼ˆæ—¢åˆŠï¼‰
- <strong>ç¬¬2ç« </strong>: æ©Ÿèƒ½æ€§é«˜åˆ†å­ã®è¨­è¨ˆï¼ˆæº–å‚™ä¸­ï¼‰
- <strong>ç¬¬3ç« </strong>: è§¦åª’è¨­è¨ˆã®é©æ–°ï¼ˆæœ¬ç« ï¼‰
- <strong>ç¬¬4ç« </strong>: ã‚¨ãƒãƒ«ã‚®ãƒ¼ææ–™ã®æ¢ç´¢ï¼ˆæ¬¡ç« ï¼‰

---

ğŸ¤– *æœ¬ç« ã¯ã€AI Terakoya Knowledge Hubï¼ˆæ±åŒ—å¤§å­¦ æ©‹æœ¬ç ”ç©¶å®¤ï¼‰ãŒæä¾›ã™ã‚‹æ•™è‚²ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã§ã™ã€‚*

ğŸ“§ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ»è³ªå•ï¼šyusuke.hashimoto.b8@tohoku.ac.jp
<div class="navigation">
    <a href="chapter-2.html" class="nav-button">â† ç¬¬2ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
    <a href="chapter-4.html" class="nav-button">ç¬¬4ç«  â†’</a>
</div>
    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-18</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default'
                });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</body>
</html>
