<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="量子精度と古典速度を両立する次世代シミュレーション">
    <title>機械学習ポテンシャル（MLP）入門シリーズ v1.0 - MI Knowledge Hub</title>

    <!-- CSS Styling -->
    <style>
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #3498db;
            --accent-color: #e74c3c;
            --bg-color: #ffffff;
            --text-color: #333333;
            --border-color: #e0e0e0;
            --code-bg: #f5f5f5;
            --link-color: #3498db;
            --link-hover: #2980b9;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Hiragino Sans", "Hiragino Kaku Gothic ProN", Meiryo, sans-serif;
            line-height: 1.8;
            color: var(--text-color);
            background: var(--bg-color);
            padding: 0;
            margin: 0;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem 1.5rem;
        }

        /* Header */
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem 0;
            margin-bottom: 2rem;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        header .container {
            padding: 0 1.5rem;
        }

        h1 {
            font-size: 2rem;
            margin-bottom: 0.5rem;
            font-weight: 700;
        }

        .meta {
            display: flex;
            gap: 1.5rem;
            flex-wrap: wrap;
            font-size: 0.9rem;
            opacity: 0.95;
            margin-top: 1rem;
        }

        .meta span {
            display: inline-flex;
            align-items: center;
            gap: 0.3rem;
        }

        /* Typography */
        h2 {
            font-size: 1.75rem;
            margin-top: 2.5rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 3px solid var(--secondary-color);
            color: var(--primary-color);
        }

        h3 {
            font-size: 1.4rem;
            margin-top: 2rem;
            margin-bottom: 0.8rem;
            color: var(--primary-color);
        }

        h4 {
            font-size: 1.2rem;
            margin-top: 1.5rem;
            margin-bottom: 0.6rem;
            color: var(--primary-color);
        }

        p {
            margin-bottom: 1.2rem;
        }

        a {
            color: var(--link-color);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--link-hover);
            text-decoration: underline;
        }

        /* Lists */
        ul, ol {
            margin-left: 2rem;
            margin-bottom: 1.2rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        /* Code blocks */
        code {
            background: var(--code-bg);
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            font-family: 'Menlo', 'Monaco', 'Courier New', monospace;
            font-size: 0.9em;
        }

        pre {
            background: var(--code-bg);
            padding: 1.5rem;
            border-radius: 8px;
            overflow-x: auto;
            margin-bottom: 1.5rem;
            border: 1px solid var(--border-color);
        }

        pre code {
            background: none;
            padding: 0;
            font-size: 0.9rem;
        }

        /* Tables */
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 1.5rem;
            overflow-x: auto;
            display: block;
        }

        thead {
            display: table;
            width: 100%;
            table-layout: fixed;
        }

        tbody {
            display: table;
            width: 100%;
            table-layout: fixed;
        }

        th, td {
            padding: 0.8rem;
            text-align: left;
            border: 1px solid var(--border-color);
        }

        th {
            background: var(--primary-color);
            color: white;
            font-weight: 600;
        }

        tr:nth-child(even) {
            background: #f9f9f9;
        }

        /* Blockquotes */
        blockquote {
            border-left: 4px solid var(--secondary-color);
            padding-left: 1.5rem;
            margin: 1.5rem 0;
            font-style: italic;
            color: #666;
        }

        /* Images */
        img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 1rem 0;
        }

        /* Mermaid diagrams */
        .mermaid {
            text-align: center;
            margin: 2rem 0;
            background: white;
            padding: 1rem;
            border-radius: 8px;
            border: 1px solid var(--border-color);
        }

        /* Details/Summary (for exercises) */
        details {
            margin: 1rem 0;
            padding: 1rem;
            background: #f8f9fa;
            border-radius: 8px;
            border: 1px solid var(--border-color);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--primary-color);
            padding: 0.5rem;
        }

        summary:hover {
            color: var(--secondary-color);
        }

        /* Footer */
        footer {
            margin-top: 4rem;
            padding: 2rem 0;
            border-top: 2px solid var(--border-color);
            text-align: center;
            color: #666;
            font-size: 0.9rem;
        }

        /* Navigation buttons */
        .nav-buttons {
            display: flex;
            justify-content: space-between;
            margin: 3rem 0;
            gap: 1rem;
            flex-wrap: wrap;
        }

        .nav-button {
            display: inline-block;
            padding: 0.8rem 1.5rem;
            background: var(--secondary-color);
            color: white;
            border-radius: 6px;
            text-decoration: none;
            transition: all 0.3s;
            font-weight: 600;
        }

        .nav-button:hover {
            background: var(--link-hover);
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(52, 152, 219, 0.3);
        }

        /* Responsive */
        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }

            h1 {
                font-size: 1.6rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            pre {
                padding: 1rem;
                font-size: 0.85rem;
            }

            table {
                font-size: 0.9rem;
            }
        }
    </style>

    <!-- Mermaid for diagrams -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
</head>
<body>
    <header>
        <div class="container">
            <h1>機械学習ポテンシャル（MLP）入門シリーズ v1.0</h1>
            <div class="meta">
                <span>📖 読了時間: 85-100分</span>
                <span>📊 レベル: beginner-to-advanced</span>
            </div>
        </div>
    </header>

    <main class="container">
        <h1 id="mlp-v10">機械学習ポテンシャル（MLP）入門シリーズ v1.0</h1>
<p><strong>量子精度と古典速度を両立する次世代シミュレーション - 基礎から実践、キャリアまで完全ガイド</strong></p>
<h2 id="_1">シリーズ概要</h2>
<p>このシリーズは、機械学習ポテンシャル（MLP）を初めて学ぶ方から、実践的なスキルを身につけたい方まで、段階的に学べる全4章構成の教育コンテンツです。</p>
<p><strong>特徴:</strong><br />
- ✅ <strong>章ごとの独立性</strong>: 各章は独立した記事として読むことができます<br />
- ✅ <strong>体系的な構成</strong>: 全4章で段階的に学べる包括的な内容<br />
- ✅ <strong>実践重視</strong>: 15個の実行可能なコード例（SchNetPack使用）、5つの詳細なケーススタディ<br />
- ✅ <strong>キャリア支援</strong>: 具体的なキャリアパスと学習ロードマップを提供</p>
<p><strong>総学習時間</strong>: 85-100分（コード実行と演習を含む）</p>
<hr />
<h2 id="_2">学習の進め方</h2>
<h3 id="_3">推奨学習順序</h3>
<pre class="codehilite"><code class="language-mermaid">graph TD
    A[第1章: なぜMLPが必要か] --&gt; B[第2章: MLPの基礎知識]
    B --&gt; C[第3章: Pythonハンズオン]
    C --&gt; D[第4章: 実世界への応用]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
</code></pre>

<p><strong>初学者の方（まったくの初めて）:</strong><br />
- 第1章 → 第2章 → 第3章 → 第4章<br />
- 所要時間: 85-100分</p>
<p><strong>計算化学経験者（DFT/MDの基礎知識あり）:</strong><br />
- 第2章 → 第3章 → 第4章<br />
- 所要時間: 60-75分</p>
<p><strong>実践的スキル強化（すでにMLP概念を知っている）:</strong><br />
- 第3章（集中学習） → 第4章<br />
- 所要時間: 50-60分</p>
<hr />
<h2 id="_4">各章の詳細</h2>
<h3 id="1mlp"><a href="./chapter1-introduction.html">第1章：なぜ機械学習ポテンシャル（MLP）が必要なのか</a></h3>
<p><strong>難易度</strong>: 入門<br />
<strong>読了時間</strong>: 15-20分</p>
<h4 id="_5">学習内容</h4>
<ol>
<li>
<p><strong>分子シミュレーションの歴史</strong><br />
   - 1950年代: 古典的分子動力学（MD）の誕生<br />
   - 1965年: DFT理論の確立（Kohn-Sham方程式）<br />
   - 2007年: Behler-Parrinello Neural Network Potential<br />
   - 2017-2025年: Graph Neural Networks時代（SchNet, NequIP, MACE）</p>
</li>
<li>
<p><strong>従来手法の限界</strong><br />
   - 経験的力場: パラメータの汎用性不足、化学反応への対応不可<br />
   - DFT: 大規模系・長時間シミュレーション不可（10²原子、ps程度）<br />
   - 具体的な数値: DFT計算時間（100原子で数時間）vs MD（100万原子で数時間）</p>
</li>
<li>
<p><strong>ケーススタディ: Cu触媒上のCO₂還元反応</strong><br />
   - 従来手法（DFT-AIMD）: 1 μsのMDに114,000年必要<br />
   - MLP-MD: 同じ1 μsのMDを1週間で完了（50,000倍高速化）<br />
   - 成果: 反応メカニズムの解明、Nature Chemistry論文発表</p>
</li>
<li>
<p><strong>比較図（Traditional vs MLP）</strong><br />
   - Mermaidダイアグラム: 精度vs計算コストのトレードオフ<br />
   - タイムスケール比較: fs (DFT) vs ns-μs (MLP)<br />
   - サイズスケール比較: 10²原子 (DFT) vs 10⁵-10⁶原子 (MLP)</p>
</li>
<li>
<p><strong>コラム: 「計算化学者の一日」</strong><br />
   - 2000年: DFT計算で1週間、100原子系、psスケール<br />
   - 2025年: MLP-MDで1週間、10万原子系、μsスケール</p>
</li>
<li>
<p><strong>「なぜ今なのか？」- 4つの追い風</strong><br />
   - 機械学習の進展: ニューラルネット、グラフネットワーク、等変NN<br />
   - 計算資源: GPU、スパコン（富岳、Frontier）<br />
   - データ基盤: Materials Project, NOMAD等の大規模DFTデータベース<br />
   - 社会的要請: 創薬、エネルギー、触媒、環境</p>
</li>
</ol>
<h4 id="_6">学習目標</h4>
<ul>
<li>✅ 分子シミュレーションの歴史的変遷を説明できる</li>
<li>✅ 従来手法の3つの限界を具体例とともに挙げられる</li>
<li>✅ MLPが必要とされる技術的・社会的背景を理解する</li>
<li>✅ MLPの主要手法（Behler-Parrinello, SchNet, NequIP等）の概要を説明できる</li>
</ul>
<p><strong><a href="./chapter1-introduction.html">第1章を読む →</a></strong></p>
<hr />
<h3 id="2mlp-"><a href="./chapter2-fundamentals.html">第2章：MLP基礎 - 概念、手法、エコシステム</a></h3>
<p><strong>難易度</strong>: 入門〜中級<br />
<strong>読了時間</strong>: 20-25分</p>
<h4 id="_7">学習内容</h4>
<ol>
<li>
<p><strong>MLPとは何か：正確な定義</strong><br />
   - ポテンシャルエネルギー面（PES）の機械学習近似<br />
   - 3つの本質的要素: データ駆動、高次元近似、物理制約<br />
   - 関連分野: 量子化学、機械学習、分子動力学</p>
</li>
<li>
<p><strong>15語のMLP用語集</strong><br />
   - 基礎用語: ポテンシャルエネルギー面（PES）、力、エネルギー保存則<br />
   - 手法用語: 記述子、対称性、等変性、メッセージパッシング<br />
   - 応用用語: アクティブラーニング、不確実性定量化、転移学習</p>
</li>
<li>
<p><strong>MLPへの入力データ</strong><br />
   - 5つの主要データタイプ: 平衡構造、MD軌道、反応経路、ランダムサンプリング、欠陥構造<br />
   - DFTトレーニングデータ: エネルギー、力、応力<br />
   - データセット例: Cu触媒CO₂還元（10,000構造、DFT計算時間5,000時間）</p>
</li>
<li>
<p><strong>MLPエコシステム図</strong><br />
   - Mermaidダイアグラム: DFTデータ生成 → モデル訓練 → シミュレーション → 解析<br />
   - 4つのフェーズと所要時間<br />
   - ツールチェーン: VASP/Quantum ESPRESSO → ASE → SchNetPack → LAMMPS/ASE-MD</p>
</li>
<li>
<p><strong>MLPワークフロー：5ステップ（詳細版）</strong><br />
   - <strong>Step 1</strong>: データ収集（DFT計算、サンプリング戦略）<br />
   - <strong>Step 2</strong>: 記述子設計（対称性関数、SOAP、グラフNN）<br />
   - <strong>Step 3</strong>: モデル訓練（損失関数、最適化手法）<br />
   - <strong>Step 4</strong>: 検証（MAE目標値、外挿性テスト）<br />
   - <strong>Step 5</strong>: 本番シミュレーション（MLP-MD設定、物性計算）</p>
</li>
<li>
<p><strong>記述子の種類：原子配置の数値化</strong><br />
   - <strong>対称性関数（Symmetry Functions）</strong>: Behler-Parrinello型、動径・角度項<br />
   - <strong>SOAP (Smooth Overlap of Atomic Positions)</strong>: 原子密度表現、カーネル法<br />
   - <strong>グラフニューラルネットワーク</strong>: SchNet（連続フィルタ畳み込み）、DimeNet（方向性）、NequIP（E(3)等変）、MACE（高次等変）</p>
</li>
<li>
<p><strong>主要MLPアーキテクチャの比較</strong><br />
   - 7手法の進化（2007-2024年）<br />
   - 比較表: 精度、データ効率、計算速度、実装難易度<br />
   - Mermaid進化タイムライン</p>
</li>
<li>
<p><strong>コラム: Active Learningによる効率的なデータ収集</strong><br />
   - Active Learningワークフロー<br />
   - 不確実性評価手法<br />
   - 成功事例: データ収集コスト88%削減</p>
</li>
</ol>
<h4 id="_8">学習目標</h4>
<ul>
<li>✅ MLPの定義と関連分野（量子化学、機械学習）の違いを説明できる</li>
<li>✅ 主要な記述子（対称性関数、SOAP、グラフNN）の特徴を理解する</li>
<li>✅ MLPワークフロー5ステップをサブステップ含め詳述できる</li>
<li>✅ 15のMLP専門用語を適切に使用できる</li>
<li>✅ 主要MLPアーキテクチャ（Behler-Parrinello～MACE）の進化を説明できる</li>
</ul>
<p><strong><a href="./chapter2-fundamentals.html">第2章を読む →</a></strong></p>
<hr />
<h3 id="3pythonmlp-schnetpack"><a href="./chapter3-hands-on.html">第3章：Pythonで体験するMLP - SchNetPackハンズオン</a></h3>
<p><strong>難易度</strong>: 中級<br />
<strong>読了時間</strong>: 30-35分<br />
<strong>コード例</strong>: 15個（全て実行可能）</p>
<h4 id="_9">学習内容</h4>
<ol>
<li>
<p><strong>環境構築</strong><br />
   - Conda環境セットアップ<br />
   - PyTorch、SchNetPackインストール<br />
   - 動作確認（5行コード）</p>
</li>
<li>
<p><strong>データ準備（Example 1-3）</strong><br />
   - MD17データセットのロード（aspirin分子、1,000サンプル）<br />
   - 訓練/検証/テスト分割（80%/10%/10%）<br />
   - データ統計の可視化</p>
</li>
<li>
<p><strong>SchNetPack訓練（Example 4-8）</strong><br />
   - SchNetモデル定義（cutoff=5Å, n_interactions=3）<br />
   - 訓練ループ実装（損失関数: エネルギー + 力）<br />
   - TensorBoard可視化<br />
   - 訓練進捗モニタリング<br />
   - チェックポイント保存</p>
</li>
<li>
<p><strong>精度検証（Example 7-8）</strong><br />
   - テストセット評価（MAE目標: &lt; 1 kcal/mol）<br />
   - 予測vs実測の相関プロット<br />
   - エラー分析</p>
</li>
<li>
<p><strong>MLP-MD実行（Example 9-12）</strong><br />
   - ASE CalculatorとしてのSchNet使用<br />
   - NVTアンサンブルMD（300 K、10 ps）<br />
   - DFTとの速度比較（10⁴倍高速化）<br />
   - 軌道の可視化と解析</p>
</li>
<li>
<p><strong>物性計算（Example 13-15）</strong><br />
   - 振動スペクトル計算（フーリエ変換）<br />
   - 自己拡散係数計算（MSD、Einstein関係式）<br />
   - 動径分布関数（RDF）</p>
</li>
<li>
<p><strong>Active Learning（Example 15）</strong><br />
   - アンサンブル不確実性評価<br />
   - 高不確実性配置の自動検出<br />
   - DFT計算リクエスト</p>
</li>
<li>
<p><strong>トラブルシューティング</strong><br />
   - 5つの一般的エラーと解決策（表形式）<br />
   - デバッグベストプラクティス</p>
</li>
<li>
<p><strong>まとめ</strong><br />
   - 7項目の学習内容整理<br />
   - 次章（実応用）への橋渡し</p>
</li>
</ol>
<h4 id="_10">学習目標</h4>
<ul>
<li>✅ SchNetPack環境を構築できる</li>
<li>✅ MD17データセットでSchNetを訓練できる（MAE &lt; 1 kcal/mol達成）</li>
<li>✅ MLP-MDを実行し、DFTとの速度比較ができる（10⁴倍高速化確認）</li>
<li>✅ 振動スペクトル、拡散係数、RDFを計算できる</li>
<li>✅ Active Learningで不確実性評価ができる</li>
<li>✅ よくあるエラーを自力でトラブルシューティングできる</li>
</ul>
<p><strong><a href="./chapter3-hands-on.html">第3章を読む →</a></strong></p>
<hr />
<h3 id="4mlp-"><a href="./chapter4-real-world.html">第4章：MLPの実応用 - 成功事例と未来展望</a></h3>
<p><strong>難易度</strong>: 中級〜上級<br />
<strong>読了時間</strong>: 20-25分</p>
<h4 id="_11">学習内容</h4>
<ol>
<li><strong>5つの詳細ケーススタディ</strong></li>
</ol>
<p><strong>Case Study 1: 触媒反応メカニズム解明（Cu CO₂還元）</strong><br />
   - 技術: SchNet + AIMD軌道、遷移状態探索<br />
   - 結果: 反応経路同定、50,000倍高速化、μsスケールMD実現<br />
   - 影響: Nature Chemistry 2020論文、産業触媒設計への応用<br />
   - 企業/機関: MIT、SLAC National Lab</p>
<p><strong>Case Study 2: Li-ion電池電解質設計</strong><br />
   - 技術: DeepMD-kit、Active Learning、イオン伝導度予測<br />
   - 結果: 新規電解質発見、イオン伝導度3倍向上、開発期間7.5倍短縮<br />
   - 影響: 商用化（2023年）、EVバッテリー性能向上<br />
   - 企業/機関: Toyota、Panasonic</p>
<p><strong>Case Study 3: タンパク質フォールディング（創薬）</strong><br />
   - 技術: TorchANI/ANI-2x、長時間MDシミュレーション<br />
   - 結果: フォールディング軌道予測、ドラッグデザイン支援、開発期間50%短縮<br />
   - 影響: 臨床試験成功率向上、新薬候補化合物発見<br />
   - 企業/機関: Schrödinger、Pfizer</p>
<p><strong>Case Study 4: 半導体材料（GaN結晶成長）</strong><br />
   - 技術: MACE、欠陥エネルギー計算、成長シミュレーション<br />
   - 結果: 最適成長条件発見、欠陥密度90%削減、量産コスト30%削減<br />
   - 影響: 次世代パワー半導体、5G/6G通信デバイス<br />
   - 企業/機関: 物質・材料研究機構（NIMS）、信越化学</p>
<p><strong>Case Study 5: 大気化学反応（気候変動予測）</strong><br />
   - 技術: NequIP、大規模MD、反応速度定数計算<br />
   - 結果: 大気化学モデル高精度化、気候予測精度2.5倍向上<br />
   - 影響: IPCC報告書への貢献、政策決定支援<br />
   - 企業/機関: NASA、NCAR（米国大気研究センター）</p>
<ol start="2">
<li><strong>未来トレンド（3つの主要トレンド）</strong></li>
</ol>
<p><strong>Trend 1: Foundation Models for Chemistry（化学基盤モデル）</strong><br />
   - 例: ChemGPT、MolFormer、Universal NNP<br />
   - 予測: 2030年までに全DFT計算の80%をMLPが代替<br />
   - 初期投資: 10億円（GPU cluster + 人件費）<br />
   - ROI: 2-3年で回収</p>
<p><strong>Trend 2: Autonomous Lab（自律研究室）</strong><br />
   - 例: RoboRXN（IBM）、A-Lab（Berkeley）<br />
   - 効果: 実験計画から実行まで完全自動化、材料開発24倍高速化<br />
   - 予測: 2030年までに主要企業の50%が導入</p>
<p><strong>Trend 3: Quantum-accurate Millisecond MD</strong><br />
   - 技術: MLP + 強化サンプリング、希少事象シミュレーション<br />
   - 応用: タンパク質凝集、結晶核生成、触媒サイクル<br />
   - インパクト: 創薬・材料開発のブレークスルー</p>
<ol start="3">
<li><strong>キャリアパス（3つの主要進路）</strong></li>
</ol>
<p><strong>Path 1: 学術研究（研究者）</strong><br />
   - ルート: 学士→修士→博士（3-5年）→ポスドク（2-3年）→准教授<br />
   - 給与: 年収500-1,200万円（日本）、$60-120K（米国）<br />
   - スキル: Python、PyTorch、量子化学、論文執筆、プログラミング<br />
   - 例: 東京大学、京都大学、MIT、スタンフォード</p>
<p><strong>Path 2: 産業界R&amp;D</strong><br />
   - 役職: MLPエンジニア、計算化学者、データサイエンティスト<br />
   - 給与: 年収700-1,500万円（日本）、$80-200K（米国）<br />
   - 企業: 三菱ケミカル、住友化学、トヨタ、パナソニック、Schrödinger<br />
   - スキル: Python、機械学習、量子化学、チームワーク、ビジネス理解</p>
<p><strong>Path 3: スタートアップ/コンサル</strong><br />
   - 例: Schrödinger（時価総額$8B）、Chemify、QuantumBlack<br />
   - 給与: 年収500-1,000万円 + ストックオプション<br />
   - リスク/リターン: ハイリスク・ハイインパクト<br />
   - 必要スキル: 技術 + ビジネス + リーダーシップ</p>
<ol start="4">
<li>
<p><strong>スキル開発タイムライン</strong><br />
   - <strong>3ヶ月プラン</strong>: 基礎（Python、PyTorch、量子化学）→実践（SchNetPack）→ポートフォリオ<br />
   - <strong>1年プラン</strong>: 発展（論文実装、独自プロジェクト）→学会発表→コミュニティ貢献<br />
   - <strong>3年プラン</strong>: エキスパート（5-10論文発表）→リーダーシップ→コミュニティ認知</p>
</li>
<li>
<p><strong>学習リソース集</strong><br />
   - <strong>オンラインコース</strong>: MIT OCW、Coursera（"Molecular Simulations"）<br />
   - <strong>書籍</strong>: "Machine Learning for Molecular Simulation" (Behler)、"Graph Neural Networks" (Wu et al.)<br />
   - <strong>オープンソース</strong>: SchNetPack、NequIP、MACE、DeePMD-kit、TorchANI<br />
   - <strong>コミュニティ</strong>: CECAM、MolSSI、日本計算化学会<br />
   - <strong>カンファレンス</strong>: ACS、MRS、APS、日本化学会</p>
</li>
</ol>
<h4 id="_12">学習目標</h4>
<ul>
<li>✅ 5つの実世界MLP成功事例を技術的詳細とともに説明できる</li>
<li>✅ MLPの将来トレンド3つを挙げ、産業への影響を評価できる</li>
<li>✅ MLP分野のキャリアパス3種類を説明でき、必要スキルを把握している</li>
<li>✅ 具体的な学習タイムライン（3ヶ月/1年/3年）を計画できる</li>
<li>✅ 次のステップとして適切な学習リソースを選択できる</li>
</ul>
<p><strong><a href="./chapter4-real-world.html">第4章を読む →</a></strong></p>
<hr />
<h2 id="_13">全体の学習成果</h2>
<p>このシリーズを完了すると、以下のスキルと知識を習得できます：</p>
<h3 id="understanding">知識レベル（Understanding）</h3>
<ul>
<li>✅ MLPの歴史的背景と必要性を説明できる</li>
<li>✅ MLPの基本概念、用語、手法を理解している</li>
<li>✅ 主要なMLPアーキテクチャ（Behler-Parrinello、SchNet、NequIP、MACE）を使い分けられる</li>
<li>✅ 実世界での成功事例を5つ以上詳述できる</li>
</ul>
<h3 id="doing">実践スキル（Doing）</h3>
<ul>
<li>✅ SchNetPack環境を構築し、モデルを訓練できる</li>
<li>✅ MD17データセットでMAE &lt; 1 kcal/mol達成</li>
<li>✅ MLP-MDを実行し、DFTとの速度比較ができる（10⁴倍高速化確認）</li>
<li>✅ 振動スペクトル、拡散係数、RDFを計算できる</li>
<li>✅ Active Learningで効率的なデータ収集ができる</li>
<li>✅ エラーを自力でデバッグできる</li>
</ul>
<h3 id="applying">応用力（Applying）</h3>
<ul>
<li>✅ 新しい化学系へのMLP適用プロジェクトを設計できる</li>
<li>✅ 産業界での導入事例を評価し、自分の研究に適用できる</li>
<li>✅ 将来のキャリアパスを具体的に計画できる</li>
<li>✅ 継続的な学習戦略を立てられる</li>
</ul>
<hr />
<h2 id="_14">推奨学習パターン</h2>
<h3 id="1">パターン1: 完全習得（初学者向け）</h3>
<p><strong>対象</strong>: MLPを初めて学ぶ方、体系的に理解したい方<br />
<strong>期間</strong>: 2-3週間<br />
<strong>進め方</strong>:</p>
<pre class="codehilite"><code>Week 1:
- Day 1-2: 第1章（歴史と背景、従来手法の限界）
- Day 3-4: 第2章（基礎知識、記述子、アーキテクチャ）
- Day 5-7: 第2章演習問題、用語復習

Week 2:
- Day 1-2: 第3章（環境構築、データ準備）
- Day 3-4: 第3章（SchNetPack訓練、検証）
- Day 5-7: 第3章（MLP-MD、物性計算）

Week 3:
- Day 1-2: 第3章（Active Learning、トラブルシューティング）
- Day 3-4: 第4章（ケーススタディ5つ）
- Day 5-7: 第4章（キャリアプラン作成）
</code></pre>

<p><strong>成果物</strong>:<br />
- MD17データセットでのSchNet訓練プロジェクト（MAE &lt; 1 kcal/mol）<br />
- 個人キャリアロードマップ（3ヶ月/1年/3年）</p>
<h3 id="2">パターン2: 速習（計算化学経験者向け）</h3>
<p><strong>対象</strong>: DFT/MDの基礎を持ち、MLPに移行したい方<br />
<strong>期間</strong>: 1週間<br />
<strong>進め方</strong>:</p>
<pre class="codehilite"><code>Day 1: 第2章（MLP特有の概念を中心に）
Day 2-3: 第3章（環境構築、訓練、検証）
Day 4: 第3章（MLP-MD、物性計算）
Day 5-6: 第4章（ケーススタディとキャリア）
Day 7: 復習と次のステップ計画
</code></pre>

<p><strong>成果物</strong>:<br />
- SchNetPackプロジェクトポートフォリオ（GitHub公開推奨）<br />
- MLP vs DFT速度比較レポート</p>
<h3 id="3">パターン3: ピンポイント学習（特定トピック集中）</h3>
<p><strong>対象</strong>: 特定のスキルや知識を強化したい方<br />
<strong>期間</strong>: 柔軟<br />
<strong>選択例</strong>:</p>
<ul>
<li><strong>記述子を深く理解したい</strong> → 第2章（Section 2.6）</li>
<li><strong>SchNetPackを極めたい</strong> → 第3章（Section 3.3-3.7）</li>
<li><strong>Active Learningを学びたい</strong> → 第2章（Column）+ 第3章（Section 3.7）</li>
<li><strong>キャリア設計したい</strong> → 第4章（Section 4.3-4.5）</li>
<li><strong>最新トレンドを知りたい</strong> → 第4章（Section 4.2）</li>
</ul>
<hr />
<h2 id="faq">FAQ（よくある質問）</h2>
<h3 id="q1">Q1: 量子化学の知識がなくても理解できますか？</h3>
<p><strong>A</strong>: 第1章、第2章は量子化学の詳細を前提としませんが、基本的な化学（原子、分子、化学結合）の知識は役立ちます。第3章では、SchNetPackが量子化学計算を抽象化するため、詳細な知識は不要です。ただし、DFTの基本概念（エネルギー、力、ポテンシャルエネルギー面）を理解していると、より深く学べます。</p>
<h3 id="q2">Q2: 機械学習の経験は必須ですか？</h3>
<p><strong>A</strong>: 必須ではありませんが、Pythonとニューラルネットワークの基礎知識があると有利です。第3章では、SchNetPackが機械学習の複雑さを隠蔽するため、基本的なPythonスキル（変数、関数、ループ）があれば始められます。ただし、深く理解するには、PyTorchの基礎（テンソル、自動微分、最適化）を学ぶことをお勧めします。</p>
<h3 id="q3-gpu">Q3: GPUは必要ですか？</h3>
<p><strong>A</strong>: <strong>訓練にはGPUが強く推奨</strong>されます。CPUでも可能ですが、訓練時間が10-100倍長くなります。選択肢：<br />
- <strong>Google Colab</strong>: 無料GPU（T4）で十分（第3章のコード例に最適）<br />
- <strong>ローカルGPU</strong>: NVIDIA RTX 3060以上推奨（VRAM 8GB+）<br />
- <strong>スパコン/クラウド</strong>: 大規模プロジェクト（AWS EC2 p3インスタンス等）</p>
<p>MLP-MD実行はCPUでも十分高速です（DFTと比較して）。</p>
<h3 id="q4">Q4: どれくらいの期間で実務レベルに達しますか？</h3>
<p><strong>A</strong>: 目標と背景によります：<br />
- <strong>基本的な使用（SchNetPackで訓練・MDは、それぞれよく研究対象システム用のMLPを訓練して 提供されているデータセット使用）</strong>: 1-2週間<br />
- <strong>独自系へのMLP適用（DFTデータ収集から）</strong>: 1-3ヶ月<br />
- <strong>新規手法の研究・開発</strong>: 6-12ヶ月<br />
- <strong>産業界で即戦力</strong>: 1-2年（プロジェクト経験含む）</p>
<h3 id="q5-mlp">Q5: このシリーズだけでMLPの専門家になれますか？</h3>
<p><strong>A</strong>: このシリーズは「入門から中級」を対象としています。専門家レベルに達するには：<br />
1. このシリーズで基礎を固める（2-4週間）<br />
2. 第4章の学習リソースで発展的内容を学ぶ（3-6ヶ月）<br />
3. 独自のプロジェクトを実行する（6-12ヶ月）<br />
4. 学会発表や論文執筆（1-2年）</p>
<p>計2-3年の継続的な学習と実践が必要です。</p>
<h3 id="q6-mlpmaterials-informatics-mi">Q6: MLPとMaterials Informatics (MI)の違いは？</h3>
<p><strong>A</strong>: <strong>MLP（Machine Learning Potential）</strong> は分子・材料の<strong>ポテンシャルエネルギー面を機械学習で近似</strong>する手法です。一方、<strong>MI（Materials Informatics）</strong> は材料科学全般へのデータサイエンス/機械学習の適用を指し、MLPはMIの一分野です。</p>
<ul>
<li><strong>MLP</strong>: シミュレーション高速化、反応経路探索、長時間MD</li>
<li><strong>MI</strong>: 材料探索、特性予測、組成最適化、実験計画</li>
</ul>
<p>このサイトでは、両方のシリーズを提供しています！</p>
<h3 id="q7-mlp">Q7: どのMLPアーキテクチャを選ぶべきですか？</h3>
<p><strong>A</strong>: 状況によります：</p>
<table>
<thead>
<tr>
<th>状況</th>
<th>推奨アーキテクチャ</th>
<th>理由</th>
</tr>
</thead>
<tbody>
<tr>
<td>初学者、まず試したい</td>
<td><strong>SchNet</strong></td>
<td>実装がシンプル、SchNetPack使用可能</td>
</tr>
<tr>
<td>高精度が必要</td>
<td><strong>NequIP or MACE</strong></td>
<td>E(3)等変、最高精度</td>
</tr>
<tr>
<td>データが少ない</td>
<td><strong>MACE</strong></td>
<td>データ効率最高</td>
</tr>
<tr>
<td>長距離相互作用が重要</td>
<td><strong>MACE</strong></td>
<td>長距離項を効率的に扱う</td>
</tr>
<tr>
<td>計算速度優先</td>
<td><strong>Behler-Parrinello or SchNet</strong></td>
<td>推論が高速</td>
</tr>
<tr>
<td>既存プロジェクトとの統合</td>
<td><strong>DeepMD-kit</strong></td>
<td>LAMMPS統合が容易</td>
</tr>
</tbody>
</table>
<p><strong>第3章ではSchNetを使用</strong>します（初学者に最適）。</p>
<h3 id="q8">Q8: 商業利用は可能ですか？</h3>
<p><strong>A</strong>: <strong>SchNetPack、NequIP、MACE等のオープンソースライブラリはMITライセンス</strong>で、商業利用可能です。ただし：<br />
- <strong>訓練データ（DFT計算）</strong>: 自分で生成したデータは自由に使用可能<br />
- <strong>公開データセット（MD17等）</strong>: ライセンスを確認（多くは学術専用）<br />
- <strong>商用ソフトウェア</strong>: Schrödinger、Materials Studio等は別途ライセンス必要</p>
<p>企業での使用を検討する場合は、法務部門に相談することをお勧めします。</p>
<h3 id="q9">Q9: 質問や議論できるコミュニティはありますか？</h3>
<p><strong>A</strong>: 以下のコミュニティで質問や議論ができます：<br />
- <strong>日本</strong>: 日本計算化学会、分子科学会、化学とマイクロ・ナノシステム学会<br />
- <strong>国際</strong>: CECAM（Centre Européen de Calcul Atomique et Moléculaire）、MolSSI（Molecular Sciences Software Institute）<br />
- <strong>オンライン</strong>:<br />
  - <a href="https://github.com/atomistic-machine-learning/schnetpack/discussions">SchNetPack GitHub Discussions</a><br />
  - <a href="https://matsci.org/">Materials Project Discussion Forum</a><br />
  - Stack Overflow（<code>machine-learning-potential</code>、<code>molecular-dynamics</code>タグ）</p>
<hr />
<h2 id="_15">次のステップ</h2>
<h3 id="_16">シリーズ完了後の推奨アクション</h3>
<p><strong>Immediate（1-2週間以内）:</strong><br />
1. ✅ GitHub/GitLabにポートフォリオを作成<br />
2. ✅ SchNetPackプロジェクトの結果をREADME付きで公開<br />
3. ✅ LinkedInプロフィールに「Machine Learning Potential」「SchNetPack」スキルを追加</p>
<p><strong>Short-term（1-3ヶ月）:</strong><br />
1. ✅ 独自の化学系でMLP訓練（DFTデータ生成から）<br />
2. ✅ NequIPまたはMACEを試す（SchNetとの比較）<br />
3. ✅ 日本計算化学会の勉強会に参加<br />
4. ✅ 論文を5-10本精読（<em>Nature Chemistry</em>, <em>JCTC</em>, <em>PRB</em>）</p>
<p><strong>Medium-term（3-6ヶ月）:</strong><br />
1. ✅ オープンソースプロジェクトにコントリビュート（SchNetPack、NequIP等）<br />
2. ✅ 国内学会で発表（日本化学会、計算化学会）<br />
3. ✅ Active Learningを実装し、データ収集効率化<br />
4. ✅ 産業界とのコラボレーションまたはインターンシップ</p>
<p><strong>Long-term（1年以上）:</strong><br />
1. ✅ 国際学会（ACS、MRS、APS）で発表<br />
2. ✅ 査読付き論文を投稿（<em>JCTC</em>, <em>J. Chem. Phys.</em>等）<br />
3. ✅ MLP関連の仕事に就く（アカデミア or 産業界）<br />
4. ✅ 次世代のMLP研究者・エンジニアを育成</p>
<hr />
<h2 id="_17">フィードバックとサポート</h2>
<h3 id="_18">このシリーズについて</h3>
<p>このシリーズは、東北大学 Dr. Yusuke Hashimotoのもと、MI Knowledge Hubプロジェクトの一環として作成されました。</p>
<p><strong>作成日</strong>: 2025年10月17日<br />
<strong>バージョン</strong>: 1.0</p>
<h3 id="_19">フィードバックをお待ちしています</h3>
<p>このシリーズを改善するため、皆様のフィードバックをお待ちしています：</p>
<ul>
<li><strong>誤字・脱字・技術的誤り</strong>: GitHubリポジトリのIssueで報告</li>
<li><strong>改善提案</strong>: 新しいトピック、追加して欲しいコード例等</li>
<li><strong>質問</strong>: 理解が難しかった部分、追加説明が欲しい箇所</li>
<li><strong>成功事例</strong>: このシリーズで学んだことを使ったプロジェクト</li>
</ul>
<p><strong>連絡先</strong>: yusuke.hashimoto.b8@tohoku.ac.jp</p>
<hr />
<h2 id="_20">ライセンスと利用規約</h2>
<p>このシリーズは <strong>CC BY 4.0</strong>（Creative Commons Attribution 4.0 International）ライセンスのもとで公開されています。</p>
<p><strong>可能なこと:</strong><br />
- ✅ 自由な閲覧・ダウンロード<br />
- ✅ 教育目的での利用（授業、勉強会等）<br />
- ✅ 改変・二次創作（翻訳、要約等）</p>
<p><strong>条件:</strong><br />
- 📌 著者のクレジット表示が必要<br />
- 📌 改変した場合はその旨を明記<br />
- 📌 商業利用の場合は事前に連絡</p>
<p>詳細: <a href="https://creativecommons.org/licenses/by/4.0/deed.ja">CC BY 4.0ライセンス全文</a></p>
<hr />
<h2 id="_21">さあ、始めましょう！</h2>
<p>準備はできましたか？ 第1章から始めて、MLPの世界への旅を始めましょう！</p>
<p><strong><a href="./chapter1-introduction.html">第1章: なぜ機械学習ポテンシャル（MLP）が必要なのか →</a></strong></p>
<hr />
<p><strong>更新履歴</strong></p>
<ul>
<li><strong>2025-10-17</strong>: v1.0 初版公開</li>
</ul>
<hr />
<p><strong>あなたのMLP学習の旅はここから始まります！</strong></p>

        <div class="nav-buttons">
            <a href="index.html" class="nav-button">← シリーズ目次に戻る</a>
        </div>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 MI Knowledge Hub - Dr. Yusuke Hashimoto, Tohoku University</p>
            <p>Licensed under CC BY 4.0</p>
        </div>
    </footer>
</body>
</html>
