<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬2ç« ï¼šQSAR/QSPRå…¥é–€ - ç‰©æ€§äºˆæ¸¬ã®åŸºç¤ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>QSAR/QSPRå…¥é–€ - ç‰©æ€§äºˆæ¸¬ã®åŸºç¤</h1>
            <p class="subtitle"></p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: åˆç´šã€œä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 12å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 4å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h1>ç¬¬2ç« ï¼šQSAR/QSPRå…¥é–€ - ç‰©æ€§äºˆæ¸¬ã®åŸºç¤</h1>

<h2>ã“ã®ç« ã§å­¦ã¶ã“ã¨</h2>

ã“ã®ç« ã§ã¯ã€åˆ†å­è¨˜è¿°å­ã®è¨ˆç®—ã¨QSAR/QSPRãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®åŸºç¤ã‚’å­¦ã³ã¾ã™ã€‚åˆ†å­æ§‹é€ ã‹ã‚‰ç‰©æ€§ã‚’äºˆæ¸¬ã™ã‚‹æŠ€è¡“ã¯ã€å‰µè–¬ã‚„ææ–™é–‹ç™ºã®åŠ¹ç‡åŒ–ã«ä¸å¯æ¬ ã§ã™ã€‚

<h3>å­¦ç¿’ç›®æ¨™</h3>

- âœ… 1D/2D/3Dåˆ†å­è¨˜è¿°å­ã®ç¨®é¡ã¨ä½¿ã„åˆ†ã‘ã‚’ç†è§£ã—ã¦ã„ã‚‹
- âœ… mordredã§åŒ…æ‹¬çš„ãªè¨˜è¿°å­ã‚’è¨ˆç®—ã§ãã‚‹
- âœ… QSAR/QSPRãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã€è©•ä¾¡ã§ãã‚‹
- âœ… ç‰¹å¾´é‡é¸æŠã¨è§£é‡ˆã«ã‚ˆã‚Šã€æ§‹é€ -ç‰©æ€§ç›¸é–¢ã‚’ç†è§£ã§ãã‚‹
- âœ… æº¶è§£åº¦äºˆæ¸¬ãªã©å®Ÿãƒ‡ãƒ¼ã‚¿ã«æ©Ÿæ¢°å­¦ç¿’ã‚’é©ç”¨ã§ãã‚‹

---

<h2>2.1 åˆ†å­è¨˜è¿°å­ã®åŸºç¤</h2>

<strong>åˆ†å­è¨˜è¿°å­ï¼ˆMolecular Descriptorï¼‰</strong>ã¯ã€åˆ†å­æ§‹é€ ã‚’æ•°å€¤åŒ–ã—ãŸã‚‚ã®ã§ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

<pre><code class="language-mermaid">graph TD
    A[åˆ†å­æ§‹é€ ] --> B[åˆ†å­è¨˜è¿°å­è¨ˆç®—]
    B --> C[1Dè¨˜è¿°å­]
    B --> D[2Dè¨˜è¿°å­]
    B --> E[3Dè¨˜è¿°å­]

    C --> F[åˆ†å­é‡ã€logPã€TPSA]
    D --> G[æŒ‡ç´‹ã€ã‚°ãƒ©ãƒ•è¨˜è¿°å­]
    E --> H[ç«‹ä½“é…åº§ä¾å­˜è¨˜è¿°å­]

    F --> I[æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«]
    G --> I
    H --> I
    I --> J[ç‰©æ€§äºˆæ¸¬]

    style A fill:#e3f2fd
    style I fill:#4CAF50,color:#fff
    style J fill:#FF9800,color:#fff</code></pre>

<h3>2.1.1 1Dè¨˜è¿°å­ï¼šåˆ†å­å…¨ä½“ã®æ€§è³ª</h3>

1Dè¨˜è¿°å­ã¯ã€åˆ†å­æ§‹é€ ã«ä¾å­˜ã—ãªã„åŸºæœ¬çš„ãªæ€§è³ªã‚’è¡¨ã—ã¾ã™ã€‚

<strong>ä¸»è¦ãª1Dè¨˜è¿°å­</strong>ï¼š

| è¨˜è¿°å­ | èª¬æ˜ | ç”¨é€” |
|--------|------|------|
| <strong>åˆ†å­é‡ï¼ˆMWï¼‰</strong> | åˆ†å­ã®è³ªé‡ | è†œé€éæ€§äºˆæ¸¬ |
| <strong>logP</strong> | è„‚æº¶æ€§ï¼ˆæ°´-ã‚ªã‚¯ã‚¿ãƒãƒ¼ãƒ«åˆ†é…ä¿‚æ•°ï¼‰ | å¸åæ€§äºˆæ¸¬ |
| <strong>TPSA</strong> | æ¥µæ€§è¡¨é¢ç© | è¡€æ¶²è„³é–¢é–€é€éæ€§ |
| <strong>HBA/HBD</strong> | æ°´ç´ çµåˆå—å®¹ä½“/ä¾›ä¸ä½“æ•° | Lipinskiãƒ«ãƒ¼ãƒ« |
| <strong>å›è»¢å¯èƒ½çµåˆæ•°</strong> | åˆ†å­ã®æŸ”è»Ÿæ€§ | çµåˆè¦ªå’Œæ€§ |

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹1: åŸºæœ¬çš„ãª1Dè¨˜è¿°å­ã®è¨ˆç®—</h4>

<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import Descriptors
import pandas as pd

<h1>ã‚µãƒ³ãƒ—ãƒ«åŒ»è–¬å“</h1>
drugs = {
    "Aspirin": "CC(=O)Oc1ccccc1C(=O)O",
    "Ibuprofen": "CC(C)Cc1ccc(cc1)C(C)C(=O)O",
    "Paracetamol": "CC(=O)Nc1ccc(O)cc1",
    "Caffeine": "CN1C=NC2=C1C(=O)N(C(=O)N2C)C"
}

<h1>è¨˜è¿°å­è¨ˆç®—</h1>
data = []
for name, smiles in drugs.items():
    mol = Chem.MolFromSmiles(smiles)
    data.append({
        'Name': name,
        'MW': Descriptors.MolWt(mol),
        'LogP': Descriptors.MolLogP(mol),
        'TPSA': Descriptors.TPSA(mol),
        'HBA': Descriptors.NumHAcceptors(mol),
        'HBD': Descriptors.NumHDonors(mol),
        'RotBonds': Descriptors.NumRotatableBonds(mol)
    })

df = pd.DataFrame(data)
print(df.to_string(index=False))</code></pre>

<strong>å‡ºåŠ›ä¾‹:</strong>
<pre><code>        Name      MW  LogP  TPSA  HBA  HBD  RotBonds
     Aspirin  180.16  1.19 63.60    4    1         3
   Ibuprofen  206.28  3.50 37.30    2    1         4
 Paracetamol  151.16  0.46 49.33    2    2         1
    Caffeine  194.19 -0.07 58.44    6    0         0</code></pre>

<h3>2.1.2 2Dè¨˜è¿°å­ï¼šåˆ†å­æŒ‡ç´‹ã¨ã‚°ãƒ©ãƒ•è¨˜è¿°å­</h3>

2Dè¨˜è¿°å­ã¯ã€åˆ†å­ã®ãƒˆãƒãƒ­ã‚¸ãƒ¼ï¼ˆçµåˆé–¢ä¿‚ï¼‰ã‚’åæ˜ ã—ã¾ã™ã€‚

<h4>MorganæŒ‡ç´‹ï¼ˆECFPï¼‰</h4>

MorganæŒ‡ç´‹ã¯ã€å„åŸå­ã®å‘¨è¾ºç’°å¢ƒã‚’ãƒãƒƒã‚·ãƒ¥åŒ–ã—ãŸãƒ“ãƒƒãƒˆãƒ™ã‚¯ãƒˆãƒ«ã§ã™ã€‚

<pre><code class="language-mermaid">graph LR
    A[ä¸­å¿ƒåŸå­] --> B[åŠå¾„1ã®ç’°å¢ƒ]
    B --> C[åŠå¾„2ã®ç’°å¢ƒ]
    C --> D[ãƒãƒƒã‚·ãƒ¥åŒ–]
    D --> E[ãƒ“ãƒƒãƒˆãƒ™ã‚¯ãƒˆãƒ«]

    style A fill:#e3f2fd
    style E fill:#4CAF50,color:#fff</code></pre>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹2: MorganæŒ‡ç´‹ã®è¨ˆç®—</h4>

<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import AllChem
import numpy as np

<h1>åˆ†å­ã®æº–å‚™</h1>
smiles_list = [
    "CCO",  # ã‚¨ã‚¿ãƒãƒ¼ãƒ«
    "CCCO",  # ãƒ—ãƒ­ãƒ‘ãƒãƒ¼ãƒ«ï¼ˆé¡ä¼¼ï¼‰
    "c1ccccc1"  # ãƒ™ãƒ³ã‚¼ãƒ³ï¼ˆç•°ãªã‚‹ï¼‰
]

<h1>MorganæŒ‡ç´‹ã®è¨ˆç®—ï¼ˆåŠå¾„2ã€ãƒ“ãƒƒãƒˆé•·2048ï¼‰</h1>
fps = []
for smiles in smiles_list:
    mol = Chem.MolFromSmiles(smiles)
    fp = AllChem.GetMorganFingerprintAsBitVect(
        mol,
        radius=2,
        nBits=2048
    )
    fps.append(fp)

<h1>Tanimotoé¡ä¼¼åº¦ã®è¨ˆç®—</h1>
from rdkit import DataStructs

print("Tanimotoé¡ä¼¼åº¦è¡Œåˆ—:")
for i, fp1 in enumerate(fps):
    similarities = []
    for j, fp2 in enumerate(fps):
        sim = DataStructs.TanimotoSimilarity(fp1, fp2)
        similarities.append(f"{sim:.3f}")
    print(f"{smiles_list[i]:15s} {' '.join(similarities)}")</code></pre>

<strong>å‡ºåŠ›ä¾‹:</strong>
<pre><code>Tanimotoé¡ä¼¼åº¦è¡Œåˆ—:
CCO             1.000 0.571 0.111
CCCO            0.571 1.000 0.103
c1ccccc1        0.111 0.103 1.000</code></pre>

<strong>è§£é‡ˆ</strong>: ã‚¨ã‚¿ãƒãƒ¼ãƒ«ã¨ãƒ—ãƒ­ãƒ‘ãƒãƒ¼ãƒ«ã¯é¡ä¼¼åº¦0.571ã¨é«˜ãã€ãƒ™ãƒ³ã‚¼ãƒ³ã¨ã¯ä½ã„é¡ä¼¼åº¦ã‚’ç¤ºã—ã¾ã™ã€‚

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹3: MACCSéµï¼ˆæ§‹é€ çš„ç‰¹å¾´ï¼‰</h4>

<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import MACCSkeys
import numpy as np

<h1>MACCSéµã¯166ãƒ“ãƒƒãƒˆã®æ§‹é€ çš„ç‰¹å¾´</h1>
smiles = "CC(=O)Oc1ccccc1C(=O)O"  # ã‚¢ã‚¹ãƒ”ãƒªãƒ³
mol = Chem.MolFromSmiles(smiles)

<h1>MACCSéµã®è¨ˆç®—</h1>
maccs = MACCSkeys.GenMACCSKeys(mol)

<h1>ãƒ“ãƒƒãƒˆãŒç«‹ã£ã¦ã„ã‚‹ç‰¹å¾´ã‚’è¡¨ç¤º</h1>
on_bits = [i for i in range(len(maccs)) if maccs[i]]
print(f"ã‚¢ã‚¹ãƒ”ãƒªãƒ³ã®æ§‹é€ çš„ç‰¹å¾´ï¼ˆON bitsï¼‰: {len(on_bits)} / 166")
print(f"ç‰¹å¾´ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {on_bits[:20]}...")  # æœ€åˆã®20å€‹</code></pre>

<strong>å‡ºåŠ›ä¾‹:</strong>
<pre><code>ã‚¢ã‚¹ãƒ”ãƒªãƒ³ã®æ§‹é€ çš„ç‰¹å¾´ï¼ˆON bitsï¼‰: 38 / 166
ç‰¹å¾´ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: [1, 7, 10, 21, 32, 35, 47, 48, 56, 60, ...]</code></pre>

<h3>2.1.3 3Dè¨˜è¿°å­ï¼šç«‹ä½“é…åº§ä¾å­˜è¨˜è¿°å­</h3>

3Dè¨˜è¿°å­ã¯ã€åˆ†å­ã®ç«‹ä½“æ§‹é€ ã‚’è€ƒæ…®ã—ãŸè¨˜è¿°å­ã§ã™ã€‚

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹4: 3Dè¨˜è¿°å­ã®è¨ˆç®—</h4>

<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import AllChem, Descriptors3D
import pandas as pd

<h1>åˆ†å­ã®æº–å‚™</h1>
smiles = "CC(C)Cc1ccc(cc1)C(C)C(=O)O"  # ã‚¤ãƒ–ãƒ—ãƒ­ãƒ•ã‚§ãƒ³
mol = Chem.MolFromSmiles(smiles)

<h1>3Dåº§æ¨™ã‚’ç”Ÿæˆ</h1>
AllChem.EmbedMolecule(mol, randomSeed=42)
AllChem.MMFFOptimizeMolecule(mol)

<h1>3Dè¨˜è¿°å­ã®è¨ˆç®—</h1>
descriptors_3d = {
    'PMI1': Descriptors3D.PMI1(mol),  # ä¸»æ…£æ€§ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ1
    'PMI2': Descriptors3D.PMI2(mol),  # ä¸»æ…£æ€§ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ2
    'PMI3': Descriptors3D.PMI3(mol),  # ä¸»æ…£æ€§ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ3
    'NPR1': Descriptors3D.NPR1(mol),  # æ­£è¦åŒ–ä¸»æ…£æ€§æ¯”1
    'NPR2': Descriptors3D.NPR2(mol),  # æ­£è¦åŒ–ä¸»æ…£æ€§æ¯”2
    'RadiusOfGyration': Descriptors3D.RadiusOfGyration(mol),
    'InertialShapeFactor': Descriptors3D.InertialShapeFactor(mol),
    'Asphericity': Descriptors3D.Asphericity(mol),
    'Eccentricity': Descriptors3D.Eccentricity(mol)
}

df = pd.DataFrame([descriptors_3d])
print(df.T)</code></pre>

<strong>å‡ºåŠ›ä¾‹:</strong>
<pre><code>                              0
PMI1                    197.45
PMI2                    598.32
PMI3                    712.18
NPR1                      0.28
NPR2                      0.84
RadiusOfGyration          3.42
InertialShapeFactor       0.18
Asphericity               0.23
Eccentricity              0.89</code></pre>

<h3>2.1.4 mordredã«ã‚ˆã‚‹åŒ…æ‹¬çš„è¨˜è¿°å­è¨ˆç®—</h3>

mordredã¯1,800ç¨®é¡ä»¥ä¸Šã®è¨˜è¿°å­ã‚’ä¸€æ‹¬è¨ˆç®—ã§ãã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹5: mordredã§å…¨è¨˜è¿°å­ã‚’è¨ˆç®—</h4>

<pre><code class="language-python"><h1>mordredã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</h1>
<h1>pip install mordred</h1>

from mordred import Calculator, descriptors
from rdkit import Chem
import pandas as pd

<h1>Calculatorã®åˆæœŸåŒ–ï¼ˆå…¨è¨˜è¿°å­ï¼‰</h1>
calc = Calculator(descriptors, ignore_3D=True)

<h1>åˆ†å­ãƒªã‚¹ãƒˆ</h1>
smiles_list = [
    "CCO",
    "CC(=O)Oc1ccccc1C(=O)O",
    "CN1C=NC2=C1C(=O)N(C(=O)N2C)C"
]

mols = [Chem.MolFromSmiles(smi) for smi in smiles_list]

<h1>è¨˜è¿°å­è¨ˆç®—ï¼ˆæ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆã‚ã‚Šï¼‰</h1>
df = calc.pandas(mols)

print(f"è¨ˆç®—ã•ã‚ŒãŸè¨˜è¿°å­æ•°: {len(df.columns)}")
print(f"åˆ†å­æ•°: {len(df)}")
print("\næœ€åˆã®10å€‹ã®è¨˜è¿°å­:")
print(df.iloc[:, :10])

<h1>NaNã‚„ç„¡é™å¤§ã‚’é™¤å»</h1>
df_clean = df.select_dtypes(include=[np.number])
df_clean = df_clean.replace([np.inf, -np.inf], np.nan)
df_clean = df_clean.dropna(axis=1, how='any')

print(f"\nã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®è¨˜è¿°å­æ•°: {len(df_clean.columns)}")</code></pre>

<strong>å‡ºåŠ›ä¾‹:</strong>
<pre><code>è¨ˆç®—ã•ã‚ŒãŸè¨˜è¿°å­æ•°: 1826
åˆ†å­æ•°: 3

æœ€åˆã®10å€‹ã®è¨˜è¿°å­:
   ABC    ABCGG  nAcid  nBase  SpAbs_A  SpMax_A  SpDiam_A  ...
0  3.46    3.82      0      0     2.57     1.29      2.31  ...
1  16.52  17.88      1      0    13.45     2.34      5.67  ...
2  15.78  16.45      0      6    12.87     2.12      5.34  ...

ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®è¨˜è¿°å­æ•°: 1654</code></pre>

---

<h2>2.2 QSAR/QSPRãƒ¢ãƒ‡ãƒªãƒ³ã‚°</h2>

<h3>å®šç¾©</h3>

- <strong>QSARï¼ˆQuantitative Structure-Activity Relationshipï¼‰</strong>: æ§‹é€ -æ´»æ€§ç›¸é–¢
  - ç”Ÿç‰©æ´»æ€§ï¼ˆIC50ã€EC50ãªã©ï¼‰ã®äºˆæ¸¬
  - å‰µè–¬ã«ãŠã‘ã‚‹å€™è£œåŒ–åˆç‰©ã®é¸å®š

- <strong>QSPRï¼ˆQuantitative Structure-Property Relationshipï¼‰</strong>: æ§‹é€ -ç‰©æ€§ç›¸é–¢
  - ç‰©ç†åŒ–å­¦çš„æ€§è³ªï¼ˆæº¶è§£åº¦ã€èç‚¹ãªã©ï¼‰ã®äºˆæ¸¬
  - ææ–™è¨­è¨ˆã«ãŠã‘ã‚‹ç‰©æ€§æœ€é©åŒ–

<pre><code class="language-mermaid">graph TD
    A[åˆ†å­æ§‹é€ <br/>SMILES] --> B[è¨˜è¿°å­è¨ˆç®—]
    B --> C[ç‰¹å¾´é‡è¡Œåˆ—<br/>X]

    D[å®Ÿæ¸¬å€¤<br/>æ´»æ€§ãƒ»ç‰©æ€§] --> E[ç›®çš„å¤‰æ•°<br/>y]

    C --> F[æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«]
    E --> F

    F --> G[è¨“ç·´]
    G --> H[è©•ä¾¡]
    H --> I{æ€§èƒ½OK?}
    I -->|No| J[ç‰¹å¾´é‡é¸æŠ/<br/>ãƒ¢ãƒ‡ãƒ«å¤‰æ›´]
    J --> F
    I -->|Yes| K[æ–°è¦åˆ†å­ã®äºˆæ¸¬]

    style A fill:#e3f2fd
    style K fill:#4CAF50,color:#fff</code></pre>

<h3>2.2.1 ç·šå½¢ãƒ¢ãƒ‡ãƒ«</h3>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹6: Ridgeãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ç‰©æ€§äºˆæ¸¬</h4>

<pre><code class="language-python">from sklearn.linear_model import Ridge, Lasso
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
import numpy as np

<h1>ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã¯mordredãªã©ã§è¨ˆç®—ï¼‰</h1>
<h1>X: è¨˜è¿°å­è¡Œåˆ—ã€y: æº¶è§£åº¦</h1>
np.random.seed(42)
n_samples = 100
n_features = 50

X = np.random.randn(n_samples, n_features)
y = X[:, 0] * 2 + X[:, 1] * (-1.5) + np.random.randn(n_samples) * 0.5

<h1>ãƒ‡ãƒ¼ã‚¿åˆ†å‰²</h1>
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

<h1>æ¨™æº–åŒ–</h1>
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

<h1>Ridgeãƒ¢ãƒ‡ãƒ«</h1>
ridge = Ridge(alpha=1.0)
ridge.fit(X_train_scaled, y_train)

<h1>äºˆæ¸¬</h1>
y_pred_train = ridge.predict(X_train_scaled)
y_pred_test = ridge.predict(X_test_scaled)

<h1>è©•ä¾¡</h1>
print("Ridgeå›å¸°ã®æ€§èƒ½:")
print(f"è¨“ç·´ RÂ²: {r2_score(y_train, y_pred_train):.3f}")
print(f"ãƒ†ã‚¹ãƒˆ RÂ²: {r2_score(y_test, y_pred_test):.3f}")
print(f"ãƒ†ã‚¹ãƒˆ RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_test)):.3f}")

<h1>Lassoãƒ¢ãƒ‡ãƒ«ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã®å°å…¥ï¼‰</h1>
lasso = Lasso(alpha=0.1)
lasso.fit(X_train_scaled, y_train)

<h1>éã‚¼ãƒ­ä¿‚æ•°ã®æ•°ï¼ˆé¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ï¼‰</h1>
non_zero = np.sum(lasso.coef_ != 0)
print(f"\nLassoãŒé¸æŠã—ãŸç‰¹å¾´é‡: {non_zero} / {n_features}")</code></pre>

<strong>å‡ºåŠ›ä¾‹:</strong>
<pre><code>Ridgeå›å¸°ã®æ€§èƒ½:
è¨“ç·´ RÂ²: 0.923
ãƒ†ã‚¹ãƒˆ RÂ²: 0.891
ãƒ†ã‚¹ãƒˆ RMSE: 0.542

LassoãŒé¸æŠã—ãŸç‰¹å¾´é‡: 18 / 50</code></pre>

<h3>2.2.2 éç·šå½¢ãƒ¢ãƒ‡ãƒ«</h3>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹7: Random Forestã«ã‚ˆã‚‹äºˆæ¸¬</h4>

<pre><code class="language-python">from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt

<h1>Random Forestãƒ¢ãƒ‡ãƒ«</h1>
rf = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    random_state=42
)

<h1>äº¤å·®æ¤œè¨¼</h1>
cv_scores = cross_val_score(
    rf, X_train_scaled, y_train,
    cv=5,
    scoring='r2'
)

print(f"Random Forestäº¤å·®æ¤œè¨¼ RÂ²: {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}")

<h1>è¨“ç·´</h1>
rf.fit(X_train_scaled, y_train)
y_pred_rf = rf.predict(X_test_scaled)

print(f"ãƒ†ã‚¹ãƒˆ RÂ²: {r2_score(y_test, y_pred_rf):.3f}")
print(f"ãƒ†ã‚¹ãƒˆ RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rf)):.3f}")

<h1>äºˆæ¸¬vså®Ÿæ¸¬ãƒ—ãƒ­ãƒƒãƒˆ</h1>
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred_rf, alpha=0.6, edgecolors='k')
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         'r--', lw=2, label='Perfect prediction')
plt.xlabel('Actual', fontsize=12)
plt.ylabel('Predicted', fontsize=12)
plt.title('Random Forest: Predicted vs Actual', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('rf_prediction.png', dpi=300)
plt.close()</code></pre>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹8: LightGBMã«ã‚ˆã‚‹é«˜é€Ÿäºˆæ¸¬</h4>

<pre><code class="language-python"><h1>LightGBMã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</h1>
<h1>pip install lightgbm</h1>

import lightgbm as lgb

<h1>LightGBMãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</h1>
train_data = lgb.Dataset(X_train_scaled, label=y_train)
test_data = lgb.Dataset(X_test_scaled, label=y_test, reference=train_data)

<h1>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</h1>
params = {
    'objective': 'regression',
    'metric': 'rmse',
    'boosting_type': 'gbdt',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'verbose': -1
}

<h1>è¨“ç·´</h1>
gbm = lgb.train(
    params,
    train_data,
    num_boost_round=100,
    valid_sets=[test_data],
    callbacks=[lgb.early_stopping(stopping_rounds=10)]
)

<h1>äºˆæ¸¬</h1>
y_pred_lgb = gbm.predict(X_test_scaled, num_iteration=gbm.best_iteration)

print(f"LightGBM ãƒ†ã‚¹ãƒˆ RÂ²: {r2_score(y_test, y_pred_lgb):.3f}")
print(f"LightGBM ãƒ†ã‚¹ãƒˆ RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lgb)):.3f}")</code></pre>

<strong>å‡ºåŠ›ä¾‹:</strong>
<pre><code>Random Forestäº¤å·®æ¤œè¨¼ RÂ²: 0.912 Â± 0.034
ãƒ†ã‚¹ãƒˆ RÂ²: 0.924
ãƒ†ã‚¹ãƒˆ RMSE: 0.451

LightGBM ãƒ†ã‚¹ãƒˆ RÂ²: 0.931
LightGBM ãƒ†ã‚¹ãƒˆ RMSE: 0.429</code></pre>

---

<h2>2.3 ç‰¹å¾´é‡é¸æŠã¨è§£é‡ˆ</h2>

<h3>2.3.1 ç›¸é–¢åˆ†æã«ã‚ˆã‚‹å†—é•·æ€§é™¤å»</h3>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹9: ç›¸é–¢è¡Œåˆ—ã¨å†—é•·ç‰¹å¾´é‡ã®å‰Šé™¤</h4>

<pre><code class="language-python">import seaborn as sns
import matplotlib.pyplot as plt

<h1>ç›¸é–¢è¡Œåˆ—ã®è¨ˆç®—</h1>
corr_matrix = pd.DataFrame(X_train_scaled).corr()

<h1>é«˜ç›¸é–¢ãƒšã‚¢ã®æ¤œå‡ºï¼ˆé–¾å€¤0.95ï¼‰</h1>
threshold = 0.95
high_corr_pairs = []

for i in range(len(corr_matrix.columns)):
    for j in range(i+1, len(corr_matrix.columns)):
        if abs(corr_matrix.iloc[i, j]) > threshold:
            high_corr_pairs.append((i, j, corr_matrix.iloc[i, j]))

print(f"é«˜ç›¸é–¢ãƒšã‚¢ï¼ˆ|r| > {threshold}ï¼‰: {len(high_corr_pairs)}çµ„")

<h1>å†—é•·ç‰¹å¾´é‡ã®å‰Šé™¤</h1>
columns_to_drop = set()
for i, j, corr in high_corr_pairs:
    columns_to_drop.add(j)  # jç•ªç›®ã‚’å‰Šé™¤ï¼ˆä»»æ„ã®é¸æŠï¼‰

X_train_reduced = np.delete(X_train_scaled, list(columns_to_drop), axis=1)
X_test_reduced = np.delete(X_test_scaled, list(columns_to_drop), axis=1)

print(f"å‰Šæ¸›å‰ã®ç‰¹å¾´é‡æ•°: {X_train_scaled.shape[1]}")
print(f"å‰Šæ¸›å¾Œã®ç‰¹å¾´é‡æ•°: {X_train_reduced.shape[1]}")

<h1>ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®æç”»ï¼ˆæœ€åˆã®20ç‰¹å¾´é‡ã®ã¿ï¼‰</h1>
plt.figure(figsize=(12, 10))
sns.heatmap(
    corr_matrix.iloc[:20, :20],
    annot=True,
    fmt='.2f',
    cmap='coolwarm',
    center=0,
    square=True,
    linewidths=0.5
)
plt.title('ç›¸é–¢è¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆæœ€åˆã®20ç‰¹å¾´é‡ï¼‰', fontsize=14)
plt.tight_layout()
plt.savefig('correlation_heatmap.png', dpi=300)
plt.close()</code></pre>

<h3>2.3.2 ç‰¹å¾´é‡é‡è¦åº¦ã®åˆ†æ</h3>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹10: SHAPã«ã‚ˆã‚‹ç‰¹å¾´é‡è§£é‡ˆ</h4>

<pre><code class="language-python"><h1>SHAPã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</h1>
<h1>pip install shap</h1>

import shap

<h1>Random Forestãƒ¢ãƒ‡ãƒ«ã§å†è¨“ç·´</h1>
rf_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    random_state=42
)
rf_model.fit(X_train_scaled, y_train)

<h1>SHAPå€¤ã®è¨ˆç®—</h1>
explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(X_test_scaled)

<h1>ç‰¹å¾´é‡é‡è¦åº¦ã®å¯è¦–åŒ–</h1>
plt.figure(figsize=(10, 6))
shap.summary_plot(
    shap_values,
    X_test_scaled,
    feature_names=[f'F{i}' for i in range(X_test_scaled.shape[1])],
    show=False,
    max_display=20
)
plt.title('SHAPç‰¹å¾´é‡é‡è¦åº¦', fontsize=14)
plt.tight_layout()
plt.savefig('shap_summary.png', dpi=300)
plt.close()

<h1>å€‹åˆ¥ã‚µãƒ³ãƒ—ãƒ«ã®èª¬æ˜</h1>
plt.figure(figsize=(10, 6))
shap.waterfall_plot(
    shap.Explanation(
        values=shap_values[0],
        base_values=explainer.expected_value,
        data=X_test_scaled[0],
        feature_names=[f'F{i}' for i in range(X_test_scaled.shape[1])]
    ),
    max_display=15,
    show=False
)
plt.title('ã‚µãƒ³ãƒ—ãƒ«1ã®äºˆæ¸¬èª¬æ˜', fontsize=14)
plt.tight_layout()
plt.savefig('shap_waterfall.png', dpi=300)
plt.close()

print("SHAPè§£é‡ˆã®å¯è¦–åŒ–ã‚’ä¿å­˜ã—ã¾ã—ãŸ")</code></pre>

---

<h2>2.4 ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ï¼šæº¶è§£åº¦äºˆæ¸¬</h2>

<h3>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: ESOLï¼ˆEstimated Solubilityï¼‰</h3>

ESOLãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€1,128ç¨®é¡ã®åŒ–åˆç‰©ã®æ°´æº¶è§£åº¦ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹11: ESOLãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å–å¾—ã¨å‰å‡¦ç†</h4>

<pre><code class="language-python">from rdkit import Chem
from rdkit.Chem import Descriptors
import pandas as pd
import numpy as np

<h1>ESOLãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿</h1>
<h1>ãƒ‡ãƒ¼ã‚¿ã¯ https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv ã‹ã‚‰å–å¾—</h1>
url = "https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv"
df_esol = pd.read_csv(url)

print(f"ãƒ‡ãƒ¼ã‚¿æ•°: {len(df_esol)}")
print(f"\nã‚«ãƒ©ãƒ : {df_esol.columns.tolist()}")
print(f"\nãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­:")
print(df_esol.head())

<h1>SMILESã‹ã‚‰åˆ†å­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ</h1>
df_esol['mol'] = df_esol['smiles'].apply(Chem.MolFromSmiles)

<h1>ç„¡åŠ¹ãªSMILESã‚’é™¤å»</h1>
df_esol = df_esol[df_esol['mol'].notna()]
print(f"\næœ‰åŠ¹ãªåˆ†å­æ•°: {len(df_esol)}")

<h1>RDKitè¨˜è¿°å­ã®è¨ˆç®—</h1>
descriptors_list = [
    'MolWt', 'MolLogP', 'NumHAcceptors', 'NumHDonors',
    'TPSA', 'NumRotatableBonds', 'NumAromaticRings',
    'NumHeteroatoms', 'RingCount', 'FractionCsp3'
]

for desc_name in descriptors_list:
    desc_func = getattr(Descriptors, desc_name)
    df_esol[desc_name] = df_esol['mol'].apply(desc_func)

<h1>MorganæŒ‡ç´‹ã®è¿½åŠ </h1>
from rdkit.Chem import AllChem

def get_morgan_fp(mol):
    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024)
    return np.array(fp)

fp_array = np.array([get_morgan_fp(mol) for mol in df_esol['mol']])

<h1>ç‰¹å¾´é‡è¡Œåˆ—ã®ä½œæˆ</h1>
X_descriptors = df_esol[descriptors_list].values
X_fingerprints = fp_array
X_combined = np.hstack([X_descriptors, X_fingerprints])

<h1>ç›®çš„å¤‰æ•°ï¼ˆæº¶è§£åº¦ logSï¼‰</h1>
y = df_esol['measured log solubility in mols per litre'].values

print(f"\nç‰¹å¾´é‡è¡Œåˆ—ã®å½¢çŠ¶:")
print(f"è¨˜è¿°å­ã®ã¿: {X_descriptors.shape}")
print(f"æŒ‡ç´‹ã®ã¿: {X_fingerprints.shape}")
print(f"çµåˆå¾Œ: {X_combined.shape}")</code></pre>

<strong>å‡ºåŠ›ä¾‹:</strong>
<pre><code>ãƒ‡ãƒ¼ã‚¿æ•°: 1128

ã‚«ãƒ©ãƒ : ['Compound ID', 'smiles', 'measured log solubility in mols per litre', ...]

æœ‰åŠ¹ãªåˆ†å­æ•°: 1128

ç‰¹å¾´é‡è¡Œåˆ—ã®å½¢çŠ¶:
è¨˜è¿°å­ã®ã¿: (1128, 10)
æŒ‡ç´‹ã®ã¿: (1128, 1024)
çµåˆå¾Œ: (1128, 1034)</code></pre>

<h4>ã‚³ãƒ¼ãƒ‰ä¾‹12: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒã¨æœ€é©åŒ–</h4>

<pre><code class="language-python">from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt

<h1>ãƒ‡ãƒ¼ã‚¿åˆ†å‰²</h1>
X_train, X_test, y_train, y_test = train_test_split(
    X_combined, y, test_size=0.2, random_state=42
)

<h1>æ¨™æº–åŒ–</h1>
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

<h1>ãƒ¢ãƒ‡ãƒ«1: Ridgeå›å¸°</h1>
ridge = Ridge(alpha=1.0)
ridge.fit(X_train_scaled, y_train)
y_pred_ridge = ridge.predict(X_test_scaled)

<h1>ãƒ¢ãƒ‡ãƒ«2: Random Forestï¼ˆãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ï¼‰</h1>
param_grid_rf = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10]
}

rf_grid = GridSearchCV(
    RandomForestRegressor(random_state=42),
    param_grid_rf,
    cv=5,
    scoring='r2',
    n_jobs=-1
)
rf_grid.fit(X_train_scaled, y_train)
y_pred_rf = rf_grid.predict(X_test_scaled)

print(f"Random Forestãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {rf_grid.best_params_}")

<h1>ãƒ¢ãƒ‡ãƒ«3: LightGBM</h1>
import lightgbm as lgb

lgb_train = lgb.Dataset(X_train_scaled, y_train)
lgb_test = lgb.Dataset(X_test_scaled, y_test, reference=lgb_train)

params_lgb = {
    'objective': 'regression',
    'metric': 'rmse',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9,
    'verbose': -1
}

gbm = lgb.train(
    params_lgb,
    lgb_train,
    num_boost_round=200,
    valid_sets=[lgb_test],
    callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=False)]
)
y_pred_lgb = gbm.predict(X_test_scaled, num_iteration=gbm.best_iteration)

<h1>æ€§èƒ½æ¯”è¼ƒ</h1>
models = {
    'Ridge': y_pred_ridge,
    'Random Forest': y_pred_rf,
    'LightGBM': y_pred_lgb
}

print("\n=== ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ ===")
for name, y_pred in models.items():
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    print(f"\n{name}:")
    print(f"  RÂ²: {r2:.3f}")
    print(f"  RMSE: {rmse:.3f}")
    print(f"  MAE: {mae:.3f}")

<h1>äºˆæ¸¬vså®Ÿæ¸¬ãƒ—ãƒ­ãƒƒãƒˆï¼ˆ3ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒï¼‰</h1>
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for ax, (name, y_pred) in zip(axes, models.items()):
    ax.scatter(y_test, y_pred, alpha=0.6, edgecolors='k')
    ax.plot([y_test.min(), y_test.max()],
            [y_test.min(), y_test.max()],
            'r--', lw=2)
    ax.set_xlabel('Actual log(S)', fontsize=12)
    ax.set_ylabel('Predicted log(S)', fontsize=12)
    ax.set_title(f'{name} (RÂ² = {r2_score(y_test, y_pred):.3f})',
                 fontsize=14)
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('esol_model_comparison.png', dpi=300)
plt.close()

print("\nãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ")</code></pre>

<strong>å‡ºåŠ›ä¾‹:</strong>
<pre><code>Random Forestãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {'max_depth': 15, 'min_samples_split': 2, 'n_estimators': 200}

=== ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ ===

Ridge:
  RÂ²: 0.789
  RMSE: 0.712
  MAE: 0.543

Random Forest:
  RÂ²: 0.891
  RMSE: 0.511
  MAE: 0.382

LightGBM:
  RÂ²: 0.912
  RMSE: 0.459
  MAE: 0.341

ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ</code></pre>

<strong>è§£é‡ˆ</strong>:
- <strong>LightGBM</strong>ãŒæœ€é«˜æ€§èƒ½ï¼ˆRÂ² = 0.912ï¼‰
- <strong>Random Forest</strong>ã‚‚å„ªç§€ï¼ˆRÂ² = 0.891ï¼‰
- <strong>Ridge</strong>ã¯ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚æ€§èƒ½ãŒã‚„ã‚„ä½ã„

---

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>æ¼”ç¿’1: åˆ†å­è¨˜è¿°å­ã®ç†è§£</h3>

ä»¥ä¸‹ã®è¨˜è¿°å­ã«ã¤ã„ã¦ã€ãã‚Œãã‚Œã®æ„å‘³ã¨å‰µè–¬ã«ãŠã‘ã‚‹é‡è¦æ€§ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

1. <strong>logPï¼ˆè„‚æº¶æ€§ï¼‰</strong>: é«˜ã„å€¤ã¯ã©ã®ã‚ˆã†ãªæ€§è³ªã‚’ç¤ºã™ã‹ï¼Ÿ
2. <strong>TPSAï¼ˆæ¥µæ€§è¡¨é¢ç©ï¼‰</strong>: è¡€æ¶²è„³é–¢é–€é€éæ€§ã¨ã®é–¢ä¿‚ã¯ï¼Ÿ
3. <strong>åˆ†å­é‡</strong>: Lipinskiã®ãƒ«ãƒ¼ãƒ«ã‚ªãƒ–ãƒ•ã‚¡ã‚¤ãƒ–ã«ãŠã‘ã‚‹é–¾å€¤ã¯ï¼Ÿ

<details>
<summary>è§£ç­”ä¾‹</summary>

1. <strong>logPï¼ˆè„‚æº¶æ€§ï¼‰</strong>
   - æ°´-ã‚ªã‚¯ã‚¿ãƒãƒ¼ãƒ«åˆ†é…ä¿‚æ•°ã®å¯¾æ•°å€¤
   - é«˜ã„å€¤ï¼ˆä¾‹: logP > 5ï¼‰: è„‚æº¶æ€§ãŒé«˜ãã€è†œé€éæ€§ã¯è‰¯ã„ãŒæ°´æº¶æ€§ãŒä½ã„
   - ä½ã„å€¤ï¼ˆä¾‹: logP < 0ï¼‰: æ°´æº¶æ€§ãŒé«˜ã„ãŒã€è†œé€éæ€§ãŒä½ã„
   - <strong>å‰µè–¬ã§ã®é‡è¦æ€§</strong>: çµŒå£å¸åæ€§ã‚„è¡€æ¶²è„³é–¢é–€é€éæ€§ã«å½±éŸ¿

2. <strong>TPSAï¼ˆæ¥µæ€§è¡¨é¢ç©ï¼‰</strong>
   - åˆ†å­ä¸­ã®æ¥µæ€§åŸå­ï¼ˆN, Oãªã©ï¼‰ã®è¡¨é¢ç©ã®åˆè¨ˆ
   - TPSA < 140 Ã…Â²: çµŒå£å¸åæ€§ãŒè‰¯å¥½
   - TPSA < 60 Ã…Â²: è¡€æ¶²è„³é–¢é–€ã‚’é€éã—ã‚„ã™ã„
   - <strong>å‰µè–¬ã§ã®é‡è¦æ€§</strong>: CNSè–¬ã®è¨­è¨ˆã«å¿…é ˆ

3. <strong>åˆ†å­é‡</strong>
   - Lipinskiã®ãƒ«ãƒ¼ãƒ«ã‚ªãƒ–ãƒ•ã‚¡ã‚¤ãƒ–: MW < 500 Da
   - é«˜åˆ†å­é‡ï¼ˆ> 500 Daï¼‰: è†œé€éæ€§ãŒä½ä¸‹
   - <strong>å‰µè–¬ã§ã®é‡è¦æ€§</strong>: çµŒå£å¸åæ€§ã®äºˆæ¸¬

</details>

---

<h3>æ¼”ç¿’2: ç‰¹å¾´é‡é¸æŠã®å®Ÿè£…</h3>

ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š

1. ESOLãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¨˜è¿°å­ã‚’è¨ˆç®—
2. ç›¸é–¢ä¿‚æ•° > 0.9 ã®ç‰¹å¾´é‡ãƒšã‚¢ã‚’æ¤œå‡º
3. å†—é•·ãªç‰¹å¾´é‡ã‚’å‰Šé™¤ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å†è¨“ç·´
4. æ€§èƒ½å¤‰åŒ–ã‚’è©•ä¾¡

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
import numpy as np
import pandas as pd

<h1>ç›¸é–¢è¡Œåˆ—ã®è¨ˆç®—</h1>
X_df = pd.DataFrame(X_train_scaled)
corr_matrix = X_df.corr()

<h1>é«˜ç›¸é–¢ãƒšã‚¢ã®æ¤œå‡º</h1>
threshold = 0.9
high_corr_pairs = []
for i in range(len(corr_matrix.columns)):
    for j in range(i+1, len(corr_matrix.columns)):
        if abs(corr_matrix.iloc[i, j]) > threshold:
            high_corr_pairs.append((i, j, corr_matrix.iloc[i, j]))

print(f"é«˜ç›¸é–¢ãƒšã‚¢æ•°: {len(high_corr_pairs)}")

<h1>å†—é•·ç‰¹å¾´é‡ã®å‰Šé™¤</h1>
columns_to_drop = set([j for i, j, _ in high_corr_pairs])
X_train_reduced = np.delete(X_train_scaled, list(columns_to_drop), axis=1)
X_test_reduced = np.delete(X_test_scaled, list(columns_to_drop), axis=1)

print(f"å‰Šæ¸›å‰: {X_train_scaled.shape[1]} ç‰¹å¾´é‡")
print(f"å‰Šæ¸›å¾Œ: {X_train_reduced.shape[1]} ç‰¹å¾´é‡")

<h1>ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆå‰Šæ¸›å‰ï¼‰</h1>
rf_original = RandomForestRegressor(n_estimators=100, random_state=42)
rf_original.fit(X_train_scaled, y_train)
y_pred_orig = rf_original.predict(X_test_scaled)
r2_orig = r2_score(y_test, y_pred_orig)

<h1>ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆå‰Šæ¸›å¾Œï¼‰</h1>
rf_reduced = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reduced.fit(X_train_reduced, y_train)
y_pred_red = rf_reduced.predict(X_test_reduced)
r2_red = r2_score(y_test, y_pred_red)

print(f"\nRÂ² (å‰Šæ¸›å‰): {r2_orig:.3f}")
print(f"RÂ² (å‰Šæ¸›å¾Œ): {r2_red:.3f}")
print(f"æ€§èƒ½å¤‰åŒ–: {r2_red - r2_orig:+.3f}")</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:</strong>
<pre><code>é«˜ç›¸é–¢ãƒšã‚¢æ•°: 145
å‰Šæ¸›å‰: 1034 ç‰¹å¾´é‡
å‰Šæ¸›å¾Œ: 889 ç‰¹å¾´é‡

RÂ² (å‰Šæ¸›å‰): 0.891
RÂ² (å‰Šæ¸›å¾Œ): 0.887
æ€§èƒ½å¤‰åŒ–: -0.004</code></pre>

<strong>è§£é‡ˆ</strong>: ã‚ãšã‹ãªæ€§èƒ½ä½ä¸‹ï¼ˆ0.004ï¼‰ã§145å€‹ã®å†—é•·ç‰¹å¾´é‡ã‚’å‰Šé™¤ã§ãã€ãƒ¢ãƒ‡ãƒ«ãŒç°¡æ½”ã«ãªã‚Šã¾ã—ãŸã€‚

</details>

---

<h3>æ¼”ç¿’3: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</h3>

LightGBMã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–ã—ã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®RÂ²ã‚’0.92ä»¥ä¸Šã«ã—ã¦ãã ã•ã„ã€‚

<strong>ãƒ’ãƒ³ãƒˆ</strong>:
- <code>num_leaves</code>ï¼ˆè‘‰ã®æ•°ï¼‰
- <code>learning_rate</code>ï¼ˆå­¦ç¿’ç‡ï¼‰
- <code>feature_fraction</code>ï¼ˆç‰¹å¾´é‡ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¯”ç‡ï¼‰

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import lightgbm as lgb
from sklearn.model_selection import RandomizedSearchCV
import numpy as np

<h1>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã®å®šç¾©</h1>
param_dist = {
    'num_leaves': [15, 31, 63, 127],
    'learning_rate': [0.01, 0.05, 0.1],
    'n_estimators': [100, 200, 300],
    'feature_fraction': [0.7, 0.8, 0.9, 1.0],
    'bagging_fraction': [0.7, 0.8, 0.9, 1.0],
    'bagging_freq': [0, 5, 10],
    'min_child_samples': [10, 20, 30]
}

<h1>LightGBMãƒ¢ãƒ‡ãƒ«</h1>
lgbm = lgb.LGBMRegressor(random_state=42, verbose=-1)

<h1>ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</h1>
random_search = RandomizedSearchCV(
    lgbm,
    param_distributions=param_dist,
    n_iter=50,
    cv=5,
    scoring='r2',
    random_state=42,
    n_jobs=-1
)

random_search.fit(X_train_scaled, y_train)

print(f"ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {random_search.best_params_}")
print(f"ãƒ™ã‚¹ãƒˆCV RÂ²: {random_search.best_score_:.3f}")

<h1>ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®è©•ä¾¡</h1>
y_pred_optimized = random_search.predict(X_test_scaled)
r2_optimized = r2_score(y_test, y_pred_optimized)
rmse_optimized = np.sqrt(mean_squared_error(y_test, y_pred_optimized))

print(f"\nãƒ†ã‚¹ãƒˆ RÂ²: {r2_optimized:.3f}")
print(f"ãƒ†ã‚¹ãƒˆ RMSE: {rmse_optimized:.3f}")

if r2_optimized >= 0.92:
    print("âœ… ç›®æ¨™é”æˆï¼ RÂ² â‰¥ 0.92")
else:
    print(f"âŒ ç›®æ¨™æœªé”æˆã€‚ã‚ã¨ {0.92 - r2_optimized:.3f} å¿…è¦")</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:</strong>
<pre><code>ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {'num_leaves': 63, 'n_estimators': 300, 'min_child_samples': 10,
                  'learning_rate': 0.05, 'feature_fraction': 0.9,
                  'bagging_freq': 5, 'bagging_fraction': 0.9}
ãƒ™ã‚¹ãƒˆCV RÂ²: 0.908

ãƒ†ã‚¹ãƒˆ RÂ²: 0.923
ãƒ†ã‚¹ãƒˆ RMSE: 0.429

âœ… ç›®æ¨™é”æˆï¼ RÂ² â‰¥ 0.92</code></pre>

</details>

---

<h3>æ¼”ç¿’4: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰</h3>

Ridgeã€Random Forestã€LightGBMã®3ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’å¹³å‡åŒ–ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰ã—ã€æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã¦ãã ã•ã„ã€‚

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python"><h1>å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´</h1>
from sklearn.linear_model import Ridge
from sklearn.ensemble import RandomForestRegressor
import lightgbm as lgb

<h1>Ridge</h1>
ridge = Ridge(alpha=1.0)
ridge.fit(X_train_scaled, y_train)
y_pred_ridge = ridge.predict(X_test_scaled)

<h1>Random Forest</h1>
rf = RandomForestRegressor(n_estimators=200, max_depth=15, random_state=42)
rf.fit(X_train_scaled, y_train)
y_pred_rf = rf.predict(X_test_scaled)

<h1>LightGBM</h1>
lgb_train = lgb.Dataset(X_train_scaled, y_train)
params = {
    'objective': 'regression',
    'metric': 'rmse',
    'num_leaves': 63,
    'learning_rate': 0.05,
    'verbose': -1
}
gbm = lgb.train(params, lgb_train, num_boost_round=200)
y_pred_lgb = gbm.predict(X_test_scaled)

<h1>ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆå˜ç´”å¹³å‡ï¼‰</h1>
y_pred_ensemble = (y_pred_ridge + y_pred_rf + y_pred_lgb) / 3

<h1>æ€§èƒ½æ¯”è¼ƒ</h1>
print("=== å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®æ€§èƒ½ ===\n")
models = {
    'Ridge': y_pred_ridge,
    'Random Forest': y_pred_rf,
    'LightGBM': y_pred_lgb,
    'Ensemble (å¹³å‡)': y_pred_ensemble
}

for name, y_pred in models.items():
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    print(f"{name:20s} RÂ²: {r2:.3f}  RMSE: {rmse:.3f}")

<h1>é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆæ€§èƒ½ã«å¿œã˜ãŸé‡ã¿ï¼‰</h1>
weights = [0.1, 0.4, 0.5]  # Ridge, RF, LightGBM
y_pred_weighted = (
    weights[0] * y_pred_ridge +
    weights[1] * y_pred_rf +
    weights[2] * y_pred_lgb
)

r2_weighted = r2_score(y_test, y_pred_weighted)
rmse_weighted = np.sqrt(mean_squared_error(y_test, y_pred_weighted))

print(f"\né‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«  RÂ²: {r2_weighted:.3f}  RMSE: {rmse_weighted:.3f}")</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:</strong>
<pre><code>=== å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®æ€§èƒ½ ===

Ridge                RÂ²: 0.789  RMSE: 0.712
Random Forest        RÂ²: 0.891  RMSE: 0.511
LightGBM             RÂ²: 0.912  RMSE: 0.459
Ensemble (å¹³å‡)       RÂ²: 0.918  RMSE: 0.443

é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«  RÂ²: 0.920  RMSE: 0.437</code></pre>

<strong>è§£é‡ˆ</strong>: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«ã‚ˆã‚Šã€æœ€è‰¯ã®å˜ä¸€ãƒ¢ãƒ‡ãƒ«ï¼ˆLightGBMï¼‰ã‚ˆã‚Šã‚‚ã•ã‚‰ã«æ€§èƒ½ãŒå‘ä¸Šã—ã¾ã—ãŸã€‚

</details>

---

<h2>ã¾ã¨ã‚</h2>

ã“ã®ç« ã§ã¯ã€ä»¥ä¸‹ã‚’å­¦ã³ã¾ã—ãŸï¼š

<h3>å­¦ç¿’ã—ãŸå†…å®¹</h3>

1. <strong>åˆ†å­è¨˜è¿°å­</strong>
   - 1Dè¨˜è¿°å­ï¼šåˆ†å­é‡ã€logPã€TPSA
   - 2Dè¨˜è¿°å­ï¼šMorganæŒ‡ç´‹ã€MACCSéµ
   - 3Dè¨˜è¿°å­ï¼šç«‹ä½“é…åº§ä¾å­˜è¨˜è¿°å­
   - mordredã«ã‚ˆã‚‹åŒ…æ‹¬çš„è¨ˆç®—ï¼ˆ1,800ç¨®é¡ä»¥ä¸Šï¼‰

2. <strong>QSAR/QSPRãƒ¢ãƒ‡ãƒªãƒ³ã‚°</strong>
   - ç·šå½¢ãƒ¢ãƒ‡ãƒ«ï¼ˆRidgeã€Lassoï¼‰
   - éç·šå½¢ãƒ¢ãƒ‡ãƒ«ï¼ˆRandom Forestã€LightGBMï¼‰
   - ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ï¼ˆRÂ²ã€RMSEã€MAEï¼‰

3. <strong>ç‰¹å¾´é‡é¸æŠã¨è§£é‡ˆ</strong>
   - ç›¸é–¢åˆ†æã«ã‚ˆã‚‹å†—é•·æ€§é™¤å»
   - SHAP/LIMEã«ã‚ˆã‚‹ç‰¹å¾´é‡é‡è¦åº¦
   - ã©ã®éƒ¨åˆ†æ§‹é€ ãŒç‰©æ€§ã«å¯„ä¸ã™ã‚‹ã‹

4. <strong>å®Ÿè·µï¼šESOLæº¶è§£åº¦äºˆæ¸¬</strong>
   - ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨å‰å‡¦ç†
   - è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ
   - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
   - ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’

<h3>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h3>

ç¬¬3ç« ã§ã¯ã€åŒ–å­¦ç©ºé–“æ¢ç´¢ã¨é¡ä¼¼æ€§æ¤œç´¢ã‚’å­¦ã³ã¾ã™ã€‚

<strong>[ç¬¬3ç« ï¼šåŒ–å­¦ç©ºé–“æ¢ç´¢ã¨é¡ä¼¼æ€§æ¤œç´¢ â†’](./chapter-3.md)</strong>

---

<h2>å‚è€ƒæ–‡çŒ®</h2>

1. Todeschini, R., & Consonni, V. (2009). *Molecular Descriptors for Chemoinformatics*. Wiley-VCH. ISBN: 978-3527318520
2. Delaney, J. S. (2004). "ESOL: Estimating aqueous solubility directly from molecular structure." *Journal of Chemical Information and Computer Sciences*, 44(3), 1000-1005. DOI: 10.1021/ci034243x
3. Moriwaki, H. et al. (2018). "Mordred: a molecular descriptor calculator." *Journal of Cheminformatics*, 10, 4. DOI: 10.1186/s13321-018-0258-y
4. Lundberg, S. M., & Lee, S. I. (2017). "A unified approach to interpreting model predictions." *Advances in Neural Information Processing Systems*, 30.

---

<strong>[â† ç¬¬1ç« ](./chapter-1.md)</strong> | <strong>[ã‚·ãƒªãƒ¼ã‚ºãƒˆãƒƒãƒ—ã¸](./index.md)</strong> | <strong>[ç¬¬3ç« ã¸ â†’](./chapter-3.md)</strong>
<div class="navigation">
    <a href="chapter-1.html" class="nav-button">â† ç¬¬1ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
    <a href="chapter-3.html" class="nav-button">ç¬¬3ç«  â†’</a>
</div>
    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-18</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default'
                });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</body>
</html>
