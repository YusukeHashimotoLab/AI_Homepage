# ç¬¬2ç« : ææ–™å‘ã‘Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

**å­¦ç¿’æ™‚é–“**: 30-35åˆ† | **é›£æ˜“åº¦**: ä¸­ç´šã€œä¸Šç´š

## ğŸ“‹ ã“ã®ç« ã§å­¦ã¶ã“ã¨

- ææ–™ç§‘å­¦ã«ç‰¹åŒ–ã—ãŸTransformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è¨­è¨ˆåŸç†
- Matformer: Materials Transformer for Property Prediction
- CrystalFormer: Crystal Structure Representation
- ChemBERTa: åˆ†å­SMILESè¡¨ç¾å­¦ç¿’
- Perceiver IO: å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿çµ±åˆ
- å®Ÿè£…æ¼”ç¿’: Matformerã§ææ–™ç‰¹æ€§äºˆæ¸¬

---

## 2.1 ææ–™ç§‘å­¦ç‰¹åŒ–Transformerã®å¿…è¦æ€§

### æ±ç”¨Transformerã®é™ç•Œ

**è‡ªç„¶è¨€èªå‡¦ç†ç”¨Transformerã‚’ãã®ã¾ã¾ä½¿ã†å•é¡Œ**:
- âŒ åˆ†å­ãƒ»ææ–™ã®3Dæ§‹é€ æƒ…å ±ãŒå¤±ã‚ã‚Œã‚‹
- âŒ åŒ–å­¦çµåˆã‚„åŸå­é–“è·é›¢ã‚’è€ƒæ…®ã§ããªã„
- âŒ å‘¨æœŸçš„å¢ƒç•Œæ¡ä»¶ï¼ˆçµæ™¶ï¼‰ã‚’æ‰±ãˆãªã„
- âŒ ç‰©ç†çš„åˆ¶ç´„ï¼ˆä¿å­˜å‰‡ã€å¯¾ç§°æ€§ï¼‰ã‚’ç„¡è¦–

### ææ–™ç‰¹åŒ–Transformerã®ç‰¹å¾´

**å¿…è¦ãªæ‹¡å¼µ**:
- âœ… **3Dæ§‹é€ ã®åŸ‹ã‚è¾¼ã¿**: åŸå­åº§æ¨™ã€è·é›¢ã€è§’åº¦
- âœ… **å‘¨æœŸçš„å¢ƒç•Œæ¡ä»¶**: çµæ™¶æ ¼å­ã®ç¹°ã‚Šè¿”ã—
- âœ… **ç‰©ç†çš„åˆ¶ç´„**: å¯¾ç§°æ€§ã€ç­‰å¤‰æ€§
- âœ… **å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿çµ±åˆ**: æ§‹é€  + çµ„æˆ + å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿

```mermaid
graph TD
    A[æ±ç”¨Transformer] --> B[ææ–™ç‰¹åŒ–Transformer]
    B --> C[3Dæ§‹é€ åŸ‹ã‚è¾¼ã¿]
    B --> D[å‘¨æœŸå¢ƒç•Œæ¡ä»¶]
    B --> E[ç‰©ç†åˆ¶ç´„]
    B --> F[å¤šæ§˜ãƒ‡ãƒ¼ã‚¿çµ±åˆ]

    C --> G[Matformer]
    D --> G
    E --> H[CrystalFormer]
    F --> I[Perceiver IO]

    style G fill:#e1f5ff
    style H fill:#ffe1f5
    style I fill:#f5ffe1
```

---

## 2.2 Matformer: Materials Transformer

### æ¦‚è¦

**Matformer** (Chen et al., 2022)ã¯ã€ææ–™ã®çµæ™¶æ§‹é€ ã‹ã‚‰ç‰¹æ€§ã‚’äºˆæ¸¬ã™ã‚‹Transformerãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚

**ç‰¹å¾´**:
- **Nested Transformer**: åŸå­ãƒ¬ãƒ™ãƒ«ã¨ã‚¯ãƒªã‚¹ã‚¿ãƒ«ãƒ¬ãƒ™ãƒ«ã®éšå±¤çš„å‡¦ç†
- **Distance-aware Attention**: åŸå­é–“è·é›¢ã‚’è€ƒæ…®
- **Elastic Inference**: è¨ˆç®—é‡ã¨ãƒ¡ãƒ¢ãƒªã‚’å‹•çš„ã«èª¿æ•´

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
graph TB
    subgraph Input
        A1[åŸå­åº§æ¨™] --> B[åŸå­åŸ‹ã‚è¾¼ã¿]
        A2[åŸå­ç•ªå·] --> B
        A3[æ ¼å­å®šæ•°] --> B
    end

    B --> C[Positional Encoding]
    C --> D[Distance Matrix]

    subgraph "Nested Transformer"
        D --> E1[Atom-level Attention]
        E1 --> E2[Structure-level Attention]
    end

    E2 --> F[Pooling]
    F --> G[Prediction Head]
    G --> H[ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—/å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼]

    style E1 fill:#e1f5ff
    style E2 fill:#ffe1e1
```

### åŸå­åŸ‹ã‚è¾¼ã¿ï¼ˆAtom Embeddingï¼‰

```python
import torch
import torch.nn as nn
import numpy as np

class AtomEmbedding(nn.Module):
    def __init__(self, num_atoms=118, d_model=256):
        """
        åŸå­åŸ‹ã‚è¾¼ã¿å±¤

        Args:
            num_atoms: åŸå­ã®ç¨®é¡æ•°ï¼ˆå‘¨æœŸè¡¨ã€118å…ƒç´ ï¼‰
            d_model: åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ
        """
        super(AtomEmbedding, self).__init__()
        self.embedding = nn.Embedding(num_atoms, d_model)

    def forward(self, atomic_numbers):
        """
        Args:
            atomic_numbers: (batch_size, num_atoms) åŸå­ç•ªå·
        Returns:
            embeddings: (batch_size, num_atoms, d_model)
        """
        return self.embedding(atomic_numbers)

# ä½¿ç”¨ä¾‹: NaClçµæ™¶
batch_size = 2
num_atoms = 8  # å˜ä½æ ¼å­å†…ã®åŸå­æ•°

# åŸå­ç•ªå·: Na(11), Cl(17)
atomic_numbers = torch.tensor([
    [11, 17, 11, 17, 11, 17, 11, 17],  # ã‚µãƒ³ãƒ—ãƒ«1
    [11, 17, 11, 17, 11, 17, 11, 17]   # ã‚µãƒ³ãƒ—ãƒ«2
])

atom_emb = AtomEmbedding(num_atoms=118, d_model=256)
embeddings = atom_emb(atomic_numbers)
print(f"Atom embeddings shape: {embeddings.shape}")  # (2, 8, 256)
```

### Distance-aware Attention

**åŸå­é–“è·é›¢ã‚’è€ƒæ…®ã—ãŸAttention**:

```python
class DistanceAwareAttention(nn.Module):
    def __init__(self, d_model, num_heads, max_distance=10.0):
        """
        è·é›¢ã‚’è€ƒæ…®ã—ãŸAttention

        Args:
            d_model: ãƒ¢ãƒ‡ãƒ«æ¬¡å…ƒ
            num_heads: Attentionãƒ˜ãƒƒãƒ‰æ•°
            max_distance: æœ€å¤§è·é›¢ï¼ˆÃ…ï¼‰
        """
        super(DistanceAwareAttention, self).__init__()
        self.d_model = d_model
        self.num_heads = num_heads
        self.d_k = d_model // num_heads
        self.max_distance = max_distance

        self.W_q = nn.Linear(d_model, d_model)
        self.W_k = nn.Linear(d_model, d_model)
        self.W_v = nn.Linear(d_model, d_model)
        self.W_o = nn.Linear(d_model, d_model)

        # è·é›¢åŸ‹ã‚è¾¼ã¿
        self.distance_embedding = nn.Linear(1, num_heads)

    def forward(self, x, distance_matrix):
        """
        Args:
            x: (batch_size, num_atoms, d_model)
            distance_matrix: (batch_size, num_atoms, num_atoms) åŸå­é–“è·é›¢ï¼ˆÃ…ï¼‰
        """
        batch_size = x.size(0)

        # Q, K, V
        Q = self.W_q(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        K = self.W_k(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)
        V = self.W_v(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)

        # Attention scores
        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.d_k)

        # è·é›¢ãƒã‚¤ã‚¢ã‚¹
        # è·é›¢ãŒè¿‘ã„ã»ã©å¤§ããªå€¤ã€é ã„ã»ã©å°ã•ãªå€¤
        distance_bias = self.distance_embedding(distance_matrix.unsqueeze(-1))  # (batch, num_atoms, num_atoms, num_heads)
        distance_bias = distance_bias.permute(0, 3, 1, 2)  # (batch, num_heads, num_atoms, num_atoms)

        # ã‚¬ã‚¦ã‚¹é–¢æ•°ã§è·é›¢ã‚’å¤‰æ›ï¼ˆè¿‘ã„åŸå­ã»ã©é«˜ã„ã‚¹ã‚³ã‚¢ï¼‰
        distance_factor = torch.exp(-distance_matrix.unsqueeze(1) / 2.0)  # (batch, 1, num_atoms, num_atoms)

        scores = scores + distance_bias * distance_factor

        # Softmax
        attention_weights = torch.softmax(scores, dim=-1)

        # Attentionã®é©ç”¨
        output = torch.matmul(attention_weights, V)
        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)
        output = self.W_o(output)

        return output, attention_weights

# ä½¿ç”¨ä¾‹
d_model = 256
num_heads = 8
num_atoms = 8

dist_attn = DistanceAwareAttention(d_model, num_heads)

x = torch.randn(2, num_atoms, d_model)
# NaClçµæ™¶ã®åŸå­é–“è·é›¢ï¼ˆç°¡ç•¥ç‰ˆï¼‰
distance_matrix = torch.tensor([
    [[0.0, 2.8, 3.9, 4.8, 3.9, 5.5, 4.8, 6.7],  # åŸå­1ã‹ã‚‰ã®è·é›¢
     [2.8, 0.0, 2.8, 3.9, 5.5, 3.9, 6.7, 4.8],
     # ... çœç•¥
     [6.7, 4.8, 5.5, 3.9, 4.8, 3.9, 2.8, 0.0]]
]).repeat(2, 1, 1)  # batch_sizeåˆ†è¤‡è£½

output, attn_weights = dist_attn(x, distance_matrix)
print(f"Output shape: {output.shape}")  # (2, 8, 256)
```

### Matformerãƒ–ãƒ­ãƒƒã‚¯

```python
class MatformerBlock(nn.Module):
    def __init__(self, d_model, num_heads, d_ff=1024, dropout=0.1):
        """
        Matformerã®åŸºæœ¬ãƒ–ãƒ­ãƒƒã‚¯

        Args:
            d_model: ãƒ¢ãƒ‡ãƒ«æ¬¡å…ƒ
            num_heads: Attentionãƒ˜ãƒƒãƒ‰æ•°
            d_ff: Feed-Forwardå±¤ã®ä¸­é–“æ¬¡å…ƒ
            dropout: ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡
        """
        super(MatformerBlock, self).__init__()

        self.distance_attention = DistanceAwareAttention(d_model, num_heads)
        self.norm1 = nn.LayerNorm(d_model)
        self.dropout1 = nn.Dropout(dropout)

        # Feed-Forward Network
        self.ffn = nn.Sequential(
            nn.Linear(d_model, d_ff),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(d_ff, d_model)
        )
        self.norm2 = nn.LayerNorm(d_model)
        self.dropout2 = nn.Dropout(dropout)

    def forward(self, x, distance_matrix):
        # Distance-aware Attention + Residual
        attn_output, _ = self.distance_attention(x, distance_matrix)
        x = self.norm1(x + self.dropout1(attn_output))

        # Feed-Forward + Residual
        ffn_output = self.ffn(x)
        x = self.norm2(x + self.dropout2(ffn_output))

        return x
```

---

## 2.3 CrystalFormer: çµæ™¶æ§‹é€ Transformer

### æ¦‚è¦

**CrystalFormer**ã¯ã€çµæ™¶ã®å‘¨æœŸçš„å¢ƒç•Œæ¡ä»¶ã‚’è€ƒæ…®ã—ãŸTransformerã§ã™ã€‚

**ç‰¹å¾´**:
- **Wyckoffä½ç½®åŸ‹ã‚è¾¼ã¿**: çµæ™¶ã®å¯¾ç§°æ€§ã‚’è€ƒæ…®
- **Fractional Coordinates**: åˆ†æ•°åº§æ¨™ã§ã®è¡¨ç¾
- **Space Group Encoding**: ç©ºé–“ç¾¤æƒ…å ±ã®åŸ‹ã‚è¾¼ã¿

### åˆ†æ•°åº§æ¨™åŸ‹ã‚è¾¼ã¿

```python
class FractionalCoordinateEncoding(nn.Module):
    def __init__(self, d_model):
        super(FractionalCoordinateEncoding, self).__init__()
        self.coord_linear = nn.Linear(3, d_model)

    def forward(self, fractional_coords):
        """
        Args:
            fractional_coords: (batch_size, num_atoms, 3) åˆ†æ•°åº§æ¨™ [0, 1)
        Returns:
            encoding: (batch_size, num_atoms, d_model)
        """
        # ä¸‰è§’é–¢æ•°åŸ‹ã‚è¾¼ã¿
        freqs = torch.arange(1, d_model // 6 + 1, dtype=torch.float32)
        coords_expanded = fractional_coords.unsqueeze(-1) * freqs

        encoding = torch.cat([
            torch.sin(2 * np.pi * coords_expanded),
            torch.cos(2 * np.pi * coords_expanded)
        ], dim=-1)

        # ç·šå½¢å¤‰æ›ã§æ¬¡å…ƒèª¿æ•´
        encoding = encoding.flatten(start_dim=2)
        encoding = self.coord_linear(encoding)

        return encoding
```

### å‘¨æœŸå¢ƒç•Œæ¡ä»¶ã®è€ƒæ…®

```python
def compute_periodic_distance(coords1, coords2, lattice_matrix):
    """
    å‘¨æœŸå¢ƒç•Œæ¡ä»¶ã‚’è€ƒæ…®ã—ãŸè·é›¢è¨ˆç®—

    Args:
        coords1: (num_atoms1, 3) åˆ†æ•°åº§æ¨™
        coords2: (num_atoms2, 3) åˆ†æ•°åº§æ¨™
        lattice_matrix: (3, 3) æ ¼å­ãƒ™ã‚¯ãƒˆãƒ«è¡Œåˆ—
    Returns:
        distances: (num_atoms1, num_atoms2) æœ€çŸ­è·é›¢ï¼ˆÃ…ï¼‰
    """
    # ãƒ‡ã‚«ãƒ«ãƒˆåº§æ¨™ã«å¤‰æ›
    cart1 = torch.matmul(coords1, lattice_matrix)
    cart2 = torch.matmul(coords2, lattice_matrix)

    # ã™ã¹ã¦ã®å‘¨æœŸã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’è€ƒæ…®ï¼ˆ-1, 0, 1ã®ç¯„å›²ï¼‰
    offsets = torch.tensor([
        [i, j, k] for i in [-1, 0, 1]
                  for j in [-1, 0, 1]
                  for k in [-1, 0, 1]
    ], dtype=torch.float32)  # 27é€šã‚Š

    min_distances = []
    for offset in offsets:
        offset_cart = torch.matmul(offset, lattice_matrix)
        shifted_cart2 = cart2 + offset_cart

        # è·é›¢è¨ˆç®—
        diff = cart1.unsqueeze(1) - shifted_cart2.unsqueeze(0)
        distances = torch.norm(diff, dim=-1)
        min_distances.append(distances)

    # æœ€çŸ­è·é›¢ã‚’é¸æŠ
    min_distances = torch.stack(min_distances, dim=-1)
    min_distances, _ = torch.min(min_distances, dim=-1)

    return min_distances

# ä½¿ç”¨ä¾‹: å˜ç´”ç«‹æ–¹æ ¼å­
fractional_coords = torch.tensor([
    [0.0, 0.0, 0.0],  # åŸå­1
    [0.5, 0.5, 0.5]   # åŸå­2
])

lattice_matrix = torch.tensor([
    [5.0, 0.0, 0.0],
    [0.0, 5.0, 0.0],
    [0.0, 0.0, 5.0]
])  # 5Ã…ã®ç«‹æ–¹æ ¼å­

distances = compute_periodic_distance(fractional_coords, fractional_coords, lattice_matrix)
print("Distance matrix (Ã…):")
print(distances)
```

---

## 2.4 ChemBERTa: åˆ†å­SMILESè¡¨ç¾å­¦ç¿’

### æ¦‚è¦

**ChemBERTa**ã¯ã€åˆ†å­ã®SMILESæ–‡å­—åˆ—ã‚’BERTã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚

**ç‰¹å¾´**:
- **RoBERTa**ãƒ™ãƒ¼ã‚¹ï¼ˆBERTæ”¹è‰¯ç‰ˆï¼‰
- **10Måˆ†å­**ã§äº‹å‰å­¦ç¿’
- **è»¢ç§»å­¦ç¿’**ã§å°‘é‡ãƒ‡ãƒ¼ã‚¿ã§ã‚‚é«˜ç²¾åº¦

### SMILESãƒˆãƒ¼ã‚¯ãƒ³åŒ–

```python
from transformers import RobertaTokenizer

class SMILESTokenizer:
    def __init__(self):
        # ChemBERTaç”¨ã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶
        self.tokenizer = RobertaTokenizer.from_pretrained("seyonec/ChemBERTa-zinc-base-v1")

    def encode(self, smiles_list):
        """
        SMILESæ–‡å­—åˆ—ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–

        Args:
            smiles_list: SMILESã®ãƒªã‚¹ãƒˆ
        Returns:
            input_ids: ãƒˆãƒ¼ã‚¯ãƒ³ID
            attention_mask: ãƒã‚¹ã‚¯
        """
        encoded = self.tokenizer(
            smiles_list,
            padding=True,
            truncation=True,
            max_length=128,
            return_tensors='pt'
        )
        return encoded['input_ids'], encoded['attention_mask']

# ä½¿ç”¨ä¾‹
smiles_list = [
    'CCO',  # ã‚¨ã‚¿ãƒãƒ¼ãƒ«
    'CC(C)Cc1ccc(cc1)C(C)C(=O)O',  # ã‚¤ãƒ–ãƒ—ãƒ­ãƒ•ã‚§ãƒ³
    'CN1C=NC2=C1C(=O)N(C(=O)N2C)C'  # ã‚«ãƒ•ã‚§ã‚¤ãƒ³
]

tokenizer = SMILESTokenizer()
input_ids, attention_mask = tokenizer.encode(smiles_list)

print(f"Input IDs shape: {input_ids.shape}")
print(f"Attention mask shape: {attention_mask.shape}")
print(f"First molecule tokens: {input_ids[0][:10]}")
```

### ChemBERTaãƒ¢ãƒ‡ãƒ«ã®ä½¿ç”¨

```python
from transformers import RobertaModel

class ChemBERTaEmbedding(nn.Module):
    def __init__(self, pretrained_model="seyonec/ChemBERTa-zinc-base-v1"):
        super(ChemBERTaEmbedding, self).__init__()
        self.bert = RobertaModel.from_pretrained(pretrained_model)

    def forward(self, input_ids, attention_mask):
        """
        Args:
            input_ids: (batch_size, seq_len)
            attention_mask: (batch_size, seq_len)
        Returns:
            embeddings: (batch_size, hidden_size)
        """
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)

        # [CLS]ãƒˆãƒ¼ã‚¯ãƒ³ã®åŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨
        cls_embedding = outputs.last_hidden_state[:, 0, :]

        return cls_embedding

# åˆ†å­ç‰¹æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
class MoleculePropertyPredictor(nn.Module):
    def __init__(self, hidden_size=768, num_properties=1):
        super(MoleculePropertyPredictor, self).__init__()
        self.chemberta = ChemBERTaEmbedding()
        self.predictor = nn.Sequential(
            nn.Linear(hidden_size, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, num_properties)
        )

    def forward(self, input_ids, attention_mask):
        embeddings = self.chemberta(input_ids, attention_mask)
        predictions = self.predictor(embeddings)
        return predictions

# ä½¿ç”¨ä¾‹
model = MoleculePropertyPredictor(num_properties=1)  # ä¾‹: logPäºˆæ¸¬
predictions = model(input_ids, attention_mask)
print(f"Predictions shape: {predictions.shape}")  # (3, 1)
```

---

## 2.5 Perceiver IO: å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿çµ±åˆ

### æ¦‚è¦

**Perceiver IO**ã¯ã€ç•°ãªã‚‹ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦å‡¦ç†ã§ãã‚‹Transformerã§ã™ã€‚

**ææ–™ç§‘å­¦ã§ã®å¿œç”¨**:
- æ§‹é€ ãƒ‡ãƒ¼ã‚¿ + çµ„æˆãƒ‡ãƒ¼ã‚¿
- å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ + è¨ˆç®—ãƒ‡ãƒ¼ã‚¿
- ç”»åƒ + ãƒ†ã‚­ã‚¹ãƒˆ + æ•°å€¤

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
graph TB
    A1[æ§‹é€ ãƒ‡ãƒ¼ã‚¿] --> C[Cross-Attention]
    A2[çµ„æˆãƒ‡ãƒ¼ã‚¿] --> C
    A3[å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿] --> C

    B[Latent Array] --> C
    C --> D[Latent Transformer]
    D --> E[Cross-Attention Decoder]
    E --> F[äºˆæ¸¬çµæœ]

    style C fill:#e1f5ff
    style D fill:#ffe1e1
```

### ç°¡æ˜“å®Ÿè£…

```python
class PerceiverBlock(nn.Module):
    def __init__(self, latent_dim, input_dim, num_latents=64):
        super(PerceiverBlock, self).__init__()
        self.num_latents = num_latents
        self.latent_dim = latent_dim

        # Latent arrayï¼ˆå­¦ç¿’å¯èƒ½ï¼‰
        self.latents = nn.Parameter(torch.randn(num_latents, latent_dim))

        # Cross-Attention: Latent â†’ Input
        self.cross_attn = nn.MultiheadAttention(latent_dim, num_heads=8, batch_first=True)

        # Self-Attention: Latent â†’ Latent
        self.self_attn = nn.MultiheadAttention(latent_dim, num_heads=8, batch_first=True)

        # å…¥åŠ›ã‚’åŸ‹ã‚è¾¼ã¿
        self.input_projection = nn.Linear(input_dim, latent_dim)

    def forward(self, x):
        """
        Args:
            x: (batch_size, seq_len, input_dim) å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        Returns:
            latents: (batch_size, num_latents, latent_dim)
        """
        batch_size = x.size(0)

        # å…¥åŠ›ã‚’åŸ‹ã‚è¾¼ã¿
        x_embed = self.input_projection(x)

        # Latentã‚’è¤‡è£½
        latents = self.latents.unsqueeze(0).repeat(batch_size, 1, 1)

        # Cross-Attention: Latent (Query) â† Input (Key, Value)
        latents, _ = self.cross_attn(latents, x_embed, x_embed)

        # Self-Attention: Latentå†…éƒ¨
        latents, _ = self.self_attn(latents, latents, latents)

        return latents

# ä½¿ç”¨ä¾‹: æ§‹é€ ãƒ‡ãƒ¼ã‚¿ã¨çµ„æˆãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
batch_size = 2
seq_len = 20
input_dim = 128
latent_dim = 256

perceiver = PerceiverBlock(latent_dim, input_dim, num_latents=32)

# æ§‹é€ ãƒ‡ãƒ¼ã‚¿ï¼ˆä¾‹: åŸå­åº§æ¨™ï¼‰
structure_data = torch.randn(batch_size, seq_len, input_dim)

latents = perceiver(structure_data)
print(f"Latent representation shape: {latents.shape}")  # (2, 32, 256)
```

---

## 2.6 å®Ÿè£…æ¼”ç¿’: Matformerã§ææ–™ç‰¹æ€§äºˆæ¸¬

### å®Œå…¨ãªå®Ÿè£…ä¾‹

```python
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
class MaterialsDataset(Dataset):
    def __init__(self, num_samples=100):
        self.num_samples = num_samples

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã¯Materials Projectãªã©ã‹ã‚‰å–å¾—ï¼‰
        num_atoms = 8
        atomic_numbers = torch.randint(1, 30, (num_atoms,))  # åŸå­ç•ªå·
        positions = torch.randn(num_atoms, 3)  # åŸå­åº§æ¨™ï¼ˆÃ…ï¼‰
        distance_matrix = torch.cdist(positions, positions)  # è·é›¢è¡Œåˆ—

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆeVï¼‰
        target = torch.randn(1)

        return atomic_numbers, distance_matrix, target

# Matformerãƒ¢ãƒ‡ãƒ«ï¼ˆç°¡ç•¥ç‰ˆï¼‰
class SimpleMatformer(nn.Module):
    def __init__(self, d_model=256, num_heads=8, num_layers=4):
        super(SimpleMatformer, self).__init__()

        self.atom_embedding = AtomEmbedding(num_atoms=118, d_model=d_model)

        self.layers = nn.ModuleList([
            MatformerBlock(d_model, num_heads)
            for _ in range(num_layers)
        ])

        self.pooling = nn.AdaptiveAvgPool1d(1)
        self.predictor = nn.Sequential(
            nn.Linear(d_model, 128),
            nn.ReLU(),
            nn.Linear(128, 1)
        )

    def forward(self, atomic_numbers, distance_matrix):
        # åŸå­åŸ‹ã‚è¾¼ã¿
        x = self.atom_embedding(atomic_numbers)

        # Matformerãƒ–ãƒ­ãƒƒã‚¯
        for layer in self.layers:
            x = layer(x, distance_matrix)

        # Global pooling
        x = x.transpose(1, 2)  # (batch, d_model, num_atoms)
        x = self.pooling(x).squeeze(-1)  # (batch, d_model)

        # äºˆæ¸¬
        output = self.predictor(x)
        return output

# è¨“ç·´
def train_matformer():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # ãƒ‡ãƒ¼ã‚¿
    dataset = MaterialsDataset(num_samples=100)
    dataloader = DataLoader(dataset, batch_size=8, shuffle=True)

    # ãƒ¢ãƒ‡ãƒ«
    model = SimpleMatformer(d_model=256, num_heads=8, num_layers=4).to(device)

    # æœ€é©åŒ–
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

    # è¨“ç·´ãƒ«ãƒ¼ãƒ—
    model.train()
    for epoch in range(5):
        total_loss = 0
        for atomic_numbers, distance_matrix, target in dataloader:
            atomic_numbers = atomic_numbers.to(device)
            distance_matrix = distance_matrix.to(device)
            target = target.to(device)

            # Forward
            predictions = model(atomic_numbers, distance_matrix)
            loss = criterion(predictions, target)

            # Backward
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        avg_loss = total_loss / len(dataloader)
        print(f"Epoch {epoch+1}, Loss: {avg_loss:.4f}")

    return model

# å®Ÿè¡Œ
trained_model = train_matformer()
```

---

## 2.7 ã¾ã¨ã‚

### é‡è¦ãƒã‚¤ãƒ³ãƒˆ

1. **Matformer**: è·é›¢ã‚’è€ƒæ…®ã—ãŸAttentionã€éšå±¤çš„æ§‹é€ 
2. **CrystalFormer**: å‘¨æœŸå¢ƒç•Œæ¡ä»¶ã€åˆ†æ•°åº§æ¨™ã€ç©ºé–“ç¾¤
3. **ChemBERTa**: SMILESè¡¨ç¾å­¦ç¿’ã€è»¢ç§»å­¦ç¿’
4. **Perceiver IO**: å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿çµ±åˆ

### æ¬¡ç« ã¸ã®æº–å‚™

ç¬¬3ç« ã§ã¯ã€äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆMatBERTã€MolBERTï¼‰ã¨ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å­¦ã³ã¾ã™ã€‚

---

## ğŸ“ æ¼”ç¿’å•é¡Œ

### å•é¡Œ1: æ¦‚å¿µç†è§£
Distance-aware AttentionãŒé€šå¸¸ã®Attentionã‚ˆã‚Šææ–™ç§‘å­¦ã§å„ªã‚Œã¦ã„ã‚‹ç†ç”±ã‚’3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚

<details>
<summary>è§£ç­”ä¾‹</summary>

1. **åŒ–å­¦çµåˆã®è€ƒæ…®**: åŸå­é–“è·é›¢ãŒè¿‘ã„ã»ã©ç›¸äº’ä½œç”¨ãŒå¼·ã„ã¨ã„ã†ç‰©ç†æ³•å‰‡ã‚’åæ˜ 
2. **é•·è·é›¢ç›¸äº’ä½œç”¨ã®æŠ‘åˆ¶**: é ã„åŸå­ã¸ã®ä¸è¦ãªAttentionã‚’æ¸›ã‚‰ã—ã€è¨ˆç®—åŠ¹ç‡å‘ä¸Š
3. **è§£é‡ˆæ€§ã®å‘ä¸Š**: Attentioné‡ã¿ãŒåŒ–å­¦çš„ã«æ„å‘³ã®ã‚ã‚‹çµåˆå¼·åº¦ã¨å¯¾å¿œ
</details>

### å•é¡Œ2: å®Ÿè£…
å‘¨æœŸå¢ƒç•Œæ¡ä»¶ã‚’è€ƒæ…®ã›ãšã«è·é›¢ã‚’è¨ˆç®—ã™ã‚‹å˜ç´”ãªé–¢æ•°ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

```python
def compute_simple_distance(coords1, coords2):
    """
    å˜ç´”ãªè·é›¢è¨ˆç®—ï¼ˆå‘¨æœŸå¢ƒç•Œæ¡ä»¶ãªã—ï¼‰

    Args:
        coords1: (num_atoms1, 3)
        coords2: (num_atoms2, 3)
    Returns:
        distances: (num_atoms1, num_atoms2)
    """
    # ã“ã“ã«å®Ÿè£…
    pass
```

<details>
<summary>è§£ç­”ä¾‹</summary>

```python
def compute_simple_distance(coords1, coords2):
    diff = coords1.unsqueeze(1) - coords2.unsqueeze(0)
    distances = torch.norm(diff, dim=-1)
    return distances
```
</details>

### å•é¡Œ3: å¿œç”¨
ChemBERTaã‚’ä½¿ã£ã¦ã€åˆ†å­ã®æ°´æº¶è§£åº¦ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚å¿…è¦ãªå±¤ã¨æ§‹æˆã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

<details>
<summary>è§£ç­”ä¾‹</summary>

```python
class SolubilityPredictor(nn.Module):
    def __init__(self):
        super(SolubilityPredictor, self).__init__()
        self.chemberta = ChemBERTaEmbedding()  # 768æ¬¡å…ƒ

        self.predictor = nn.Sequential(
            nn.Linear(768, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, 1)  # æº¶è§£åº¦ï¼ˆé€£ç¶šå€¤ï¼‰
        )

    def forward(self, input_ids, attention_mask):
        embeddings = self.chemberta(input_ids, attention_mask)
        solubility = self.predictor(embeddings)
        return solubility
```

**è¨­è¨ˆç†ç”±**:
- ChemBERTaã§åˆ†å­ã®ä¸€èˆ¬çš„ãªç‰¹å¾´ã‚’æŠ½å‡º
- 3å±¤ã®å…¨çµåˆå±¤ã§æº¶è§£åº¦ã«ç‰¹åŒ–ã—ãŸè¡¨ç¾ã«å¤‰æ›
- Dropoutã§éå­¦ç¿’ã‚’é˜²æ­¢
- å‡ºåŠ›ã¯é€£ç¶šå€¤ï¼ˆlog10(mol/L)ãªã©ï¼‰
</details>

---

**æ¬¡ç« **: **[ç¬¬3ç« : äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¨è»¢ç§»å­¦ç¿’](chapter-3.md)**

---

**ä½œæˆè€…**: æ©‹æœ¬ä½‘ä»‹ï¼ˆæ±åŒ—å¤§å­¦ï¼‰
**æœ€çµ‚æ›´æ–°**: 2025å¹´10æœˆ17æ—¥
