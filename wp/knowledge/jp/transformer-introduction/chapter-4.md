# ç¬¬4ç« : ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¨é€†è¨­è¨ˆ

**å­¦ç¿’æ™‚é–“**: 20-25åˆ† | **é›£æ˜“åº¦**: ä¸Šç´š

## ğŸ“‹ ã“ã®ç« ã§å­¦ã¶ã“ã¨

- æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ï¼ˆDiffusion Modelsï¼‰ã®åŸç†
- æ¡ä»¶ä»˜ãç”Ÿæˆï¼ˆConditional Generationï¼‰
- åˆ†å­ç”Ÿæˆã¨SMILESç”Ÿæˆ
- ææ–™é€†è¨­è¨ˆï¼ˆInverse Designï¼‰
- ç”£æ¥­å¿œç”¨ã¨ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹

---

## 4.1 ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¨ã¯

### ææ–™ç§‘å­¦ã«ãŠã‘ã‚‹ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®é‡è¦æ€§

**å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆé †å•é¡Œï¼‰**:
```
ææ–™æ§‹é€  â†’ ç‰¹æ€§äºˆæ¸¬
```

**é€†è¨­è¨ˆï¼ˆé€†å•é¡Œï¼‰**:
```
æœ›ã¾ã—ã„ç‰¹æ€§ â†’ ææ–™æ§‹é€ ç”Ÿæˆ
```

**ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®åˆ©ç‚¹**:
- âœ… åºƒå¤§ãªæ¢ç´¢ç©ºé–“ã‹ã‚‰å€™è£œã‚’è‡ªå‹•ç”Ÿæˆ
- âœ… å¤šç›®çš„æœ€é©åŒ–ï¼ˆè¤‡æ•°ã®ç‰¹æ€§ã‚’åŒæ™‚ã«æº€è¶³ï¼‰
- âœ… åˆæˆå¯èƒ½æ€§ã‚’è€ƒæ…®ã—ãŸç”Ÿæˆ
- âœ… äººé–“ã®ç›´æ„Ÿã‚’è¶…ãˆãŸæ–°è¦æ§‹é€ ã®ç™ºè¦‹

```mermaid
graph LR
    A[ç›®æ¨™ç‰¹æ€§] --> B[ç”Ÿæˆãƒ¢ãƒ‡ãƒ«]
    C[åˆ¶ç´„æ¡ä»¶] --> B
    B --> D[å€™è£œææ–™]
    D --> E[ç‰¹æ€§äºˆæ¸¬]
    E --> F{ç›®æ¨™é”æˆ?}
    F -->|No| B
    F -->|Yes| G[å®Ÿé¨“æ¤œè¨¼]

    style B fill:#e1f5ff
    style G fill:#ffe1e1
```

---

## 4.2 æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®åŸç†

### æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¨ã¯

**åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢**: ãƒã‚¤ã‚ºè¿½åŠ ãƒ—ãƒ­ã‚»ã‚¹ã‚’é€†è»¢ã—ã¦ã€ãƒã‚¤ã‚ºã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ

**Forward Processï¼ˆãƒã‚¤ã‚ºè¿½åŠ ï¼‰**:
$$
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)
$$

**Reverse Processï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰**:
$$
p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
$$

### è¦–è¦šçš„ç†è§£

```mermaid
graph LR
    X0[å…ƒãƒ‡ãƒ¼ã‚¿ xâ‚€] -->|ãƒã‚¤ã‚ºè¿½åŠ | X1[xâ‚]
    X1 -->|ãƒã‚¤ã‚ºè¿½åŠ | X2[xâ‚‚]
    X2 -->|...| XT[ç´”ç²‹ãƒã‚¤ã‚º xâ‚œ]

    XT -->|ãƒã‚¤ã‚ºé™¤å»| X2R[xâ‚‚]
    X2R -->|ãƒã‚¤ã‚ºé™¤å»| X1R[xâ‚]
    X1R -->|ãƒã‚¤ã‚ºé™¤å»| X0R[ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ xâ‚€]

    style X0 fill:#e1f5ff
    style XT fill:#ffe1e1
    style X0R fill:#e1ffe1
```

### ç°¡æ˜“å®Ÿè£…

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

class SimpleDiffusionModel(nn.Module):
    def __init__(self, input_dim, hidden_dim=256, num_timesteps=1000):
        super(SimpleDiffusionModel, self).__init__()
        self.num_timesteps = num_timesteps

        # ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
        self.betas = torch.linspace(1e-4, 0.02, num_timesteps)
        self.alphas = 1.0 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)

        # ãƒã‚¤ã‚ºäºˆæ¸¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        self.noise_predictor = nn.Sequential(
            nn.Linear(input_dim + 1, hidden_dim),  # +1ã¯ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim)
        )

    def forward_process(self, x0, t):
        """
        Forward process: ãƒã‚¤ã‚ºè¿½åŠ 

        Args:
            x0: å…ƒãƒ‡ãƒ¼ã‚¿ (batch_size, input_dim)
            t: ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ— (batch_size,)
        Returns:
            xt: ãƒã‚¤ã‚ºãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
            noise: è¿½åŠ ã•ã‚ŒãŸãƒã‚¤ã‚º
        """
        batch_size = x0.size(0)

        # ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«
        alpha_t = self.alphas_cumprod[t].view(-1, 1)
        sqrt_alpha_t = torch.sqrt(alpha_t)
        sqrt_one_minus_alpha_t = torch.sqrt(1 - alpha_t)

        # ãƒã‚¤ã‚ºã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        noise = torch.randn_like(x0)

        # ãƒã‚¤ã‚ºã‚’è¿½åŠ 
        xt = sqrt_alpha_t * x0 + sqrt_one_minus_alpha_t * noise

        return xt, noise

    def predict_noise(self, xt, t):
        """
        ãƒã‚¤ã‚ºã‚’äºˆæ¸¬

        Args:
            xt: ãƒã‚¤ã‚ºãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
            t: ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—
        Returns:
            predicted_noise: äºˆæ¸¬ã•ã‚ŒãŸãƒã‚¤ã‚º
        """
        # ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã‚’åŸ‹ã‚è¾¼ã¿
        t_embed = t.float().unsqueeze(1) / self.num_timesteps

        # ãƒã‚¤ã‚ºäºˆæ¸¬
        x_with_t = torch.cat([xt, t_embed], dim=1)
        predicted_noise = self.noise_predictor(x_with_t)

        return predicted_noise

    def reverse_process(self, xt, t):
        """
        Reverse process: ãƒã‚¤ã‚ºé™¤å»ï¼ˆ1ã‚¹ãƒ†ãƒƒãƒ—ï¼‰

        Args:
            xt: ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿
            t: ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—
        Returns:
            x_prev: 1ã‚¹ãƒ†ãƒƒãƒ—å‰ã®ãƒ‡ãƒ¼ã‚¿
        """
        # ãƒã‚¤ã‚ºã‚’äºˆæ¸¬
        predicted_noise = self.predict_noise(xt, t)

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        alpha_t = self.alphas[t].view(-1, 1)
        alpha_t_cumprod = self.alphas_cumprod[t].view(-1, 1)
        beta_t = self.betas[t].view(-1, 1)

        # å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¨ˆç®—
        x_prev = (1 / torch.sqrt(alpha_t)) * (
            xt - (beta_t / torch.sqrt(1 - alpha_t_cumprod)) * predicted_noise
        )

        # ãƒã‚¤ã‚ºã‚’è¿½åŠ ï¼ˆt > 0ã®å ´åˆï¼‰
        if t[0] > 0:
            noise = torch.randn_like(xt)
            x_prev = x_prev + torch.sqrt(beta_t) * noise

        return x_prev

    def generate(self, batch_size, input_dim):
        """
        ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ

        Args:
            batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º
            input_dim: ãƒ‡ãƒ¼ã‚¿æ¬¡å…ƒ
        Returns:
            x0: ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
        """
        # ç´”ç²‹ãƒã‚¤ã‚ºã‹ã‚‰é–‹å§‹
        xt = torch.randn(batch_size, input_dim)

        # é€†ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œ
        for t in reversed(range(self.num_timesteps)):
            t_batch = torch.full((batch_size,), t, dtype=torch.long)
            xt = self.reverse_process(xt, t_batch)

        return xt

# ä½¿ç”¨ä¾‹: åˆ†å­è¨˜è¿°å­ã®ç”Ÿæˆ
input_dim = 128  # è¨˜è¿°å­ã®æ¬¡å…ƒ
diffusion_model = SimpleDiffusionModel(input_dim, hidden_dim=256, num_timesteps=100)

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
x0 = torch.randn(64, input_dim)  # 64åˆ†å­ã®è¨˜è¿°å­

# Forward processï¼ˆãƒã‚¤ã‚ºè¿½åŠ ï¼‰
t = torch.randint(0, 100, (64,))
xt, noise = diffusion_model.forward_process(x0, t)

# ãƒã‚¤ã‚ºäºˆæ¸¬
predicted_noise = diffusion_model.predict_noise(xt, t)

# æå¤±
loss = F.mse_loss(predicted_noise, noise)
print(f"Training loss: {loss.item():.4f}")

# ç”Ÿæˆ
generated_data = diffusion_model.generate(batch_size=10, input_dim=input_dim)
print(f"Generated data shape: {generated_data.shape}")
```

---

## 4.3 æ¡ä»¶ä»˜ãç”Ÿæˆ

### æ¦‚è¦

**æ¡ä»¶ä»˜ãç”Ÿæˆ**: ç›®æ¨™ç‰¹æ€§ã‚’æ¡ä»¶ã¨ã—ã¦ä¸ãˆã¦ç”Ÿæˆ

**ä¾‹**:
```python
# æ¡ä»¶: ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ— = 2.0 eVã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ < 0
# ç”Ÿæˆ: æ¡ä»¶ã‚’æº€ãŸã™ææ–™æ§‹é€ 
```

### å®Ÿè£…: Conditional Diffusion

```python
class ConditionalDiffusionModel(nn.Module):
    def __init__(self, input_dim, condition_dim, hidden_dim=256, num_timesteps=1000):
        super(ConditionalDiffusionModel, self).__init__()
        self.num_timesteps = num_timesteps

        # ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
        self.betas = torch.linspace(1e-4, 0.02, num_timesteps)
        self.alphas = 1.0 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)

        # æ¡ä»¶ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€
        self.condition_encoder = nn.Sequential(
            nn.Linear(condition_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim)
        )

        # ãƒã‚¤ã‚ºäºˆæ¸¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆæ¡ä»¶ä»˜ãï¼‰
        self.noise_predictor = nn.Sequential(
            nn.Linear(input_dim + hidden_dim + 1, hidden_dim),  # +1ã¯ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim)
        )

    def predict_noise(self, xt, t, condition):
        """
        æ¡ä»¶ä»˜ããƒã‚¤ã‚ºäºˆæ¸¬

        Args:
            xt: ãƒã‚¤ã‚ºãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ (batch_size, input_dim)
            t: ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ— (batch_size,)
            condition: æ¡ä»¶ï¼ˆç›®æ¨™ç‰¹æ€§ï¼‰ (batch_size, condition_dim)
        Returns:
            predicted_noise: äºˆæ¸¬ã•ã‚ŒãŸãƒã‚¤ã‚º
        """
        # æ¡ä»¶ã‚’åŸ‹ã‚è¾¼ã¿
        condition_embed = self.condition_encoder(condition)

        # ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã‚’åŸ‹ã‚è¾¼ã¿
        t_embed = t.float().unsqueeze(1) / self.num_timesteps

        # çµåˆ
        x_with_condition = torch.cat([xt, condition_embed, t_embed], dim=1)

        # ãƒã‚¤ã‚ºäºˆæ¸¬
        predicted_noise = self.noise_predictor(x_with_condition)

        return predicted_noise

    def generate_conditional(self, condition, input_dim):
        """
        æ¡ä»¶ä»˜ããƒ‡ãƒ¼ã‚¿ç”Ÿæˆ

        Args:
            condition: æ¡ä»¶ (batch_size, condition_dim)
            input_dim: ãƒ‡ãƒ¼ã‚¿æ¬¡å…ƒ
        Returns:
            x0: ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
        """
        batch_size = condition.size(0)

        # ç´”ç²‹ãƒã‚¤ã‚ºã‹ã‚‰é–‹å§‹
        xt = torch.randn(batch_size, input_dim)

        # é€†ãƒ—ãƒ­ã‚»ã‚¹
        for t in reversed(range(self.num_timesteps)):
            t_batch = torch.full((batch_size,), t, dtype=torch.long)

            # ãƒã‚¤ã‚ºäºˆæ¸¬
            predicted_noise = self.predict_noise(xt, t_batch, condition)

            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            alpha_t = self.alphas[t]
            alpha_t_cumprod = self.alphas_cumprod[t]
            beta_t = self.betas[t]

            # å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¨ˆç®—
            xt = (1 / torch.sqrt(alpha_t)) * (
                xt - (beta_t / torch.sqrt(1 - alpha_t_cumprod)) * predicted_noise
            )

            # ãƒã‚¤ã‚ºã‚’è¿½åŠ ï¼ˆt > 0ã®å ´åˆï¼‰
            if t > 0:
                noise = torch.randn_like(xt)
                xt = xt + torch.sqrt(beta_t) * noise

        return xt

# ä½¿ç”¨ä¾‹
input_dim = 128
condition_dim = 3  # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã€ç£æ°—ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ

conditional_model = ConditionalDiffusionModel(input_dim, condition_dim, hidden_dim=256, num_timesteps=100)

# ç›®æ¨™ç‰¹æ€§
target_properties = torch.tensor([
    [2.0, -0.5, 0.0],  # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—2.0eVã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼-0.5eVã€éç£æ€§
    [3.5, -1.0, 2.0],  # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—3.5eVã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼-1.0eVã€ç£æ€§
])

# æ¡ä»¶ä»˜ãç”Ÿæˆ
generated_materials = conditional_model.generate_conditional(target_properties, input_dim)
print(f"Generated materials shape: {generated_materials.shape}")  # (2, 128)
```

---

## 4.4 åˆ†å­ç”Ÿæˆ: SMILESç”Ÿæˆ

### æ¦‚è¦

**SMILESï¼ˆSimplified Molecular Input Line Entry Systemï¼‰**: åˆ†å­ã‚’æ–‡å­—åˆ—ã§è¡¨ç¾

**ä¾‹**:
- ã‚¨ã‚¿ãƒãƒ¼ãƒ«: `CCO`
- ãƒ™ãƒ³ã‚¼ãƒ³: `c1ccccc1`
- ã‚¢ã‚¹ãƒ”ãƒªãƒ³: `CC(=O)Oc1ccccc1C(=O)O`

### Transformer-based SMILESç”Ÿæˆ

```python
from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer

class SMILESGenerator(nn.Module):
    def __init__(self, vocab_size=1000, d_model=512, num_layers=6):
        super(SMILESGenerator, self).__init__()

        # GPT-2 config
        config = GPT2Config(
            vocab_size=vocab_size,
            n_positions=512,
            n_embd=d_model,
            n_layer=num_layers,
            n_head=8
        )

        self.gpt = GPT2LMHeadModel(config)

    def forward(self, input_ids, labels=None):
        """
        Args:
            input_ids: (batch_size, seq_len)
            labels: (batch_size, seq_len) æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
        """
        outputs = self.gpt(input_ids, labels=labels)
        return outputs

    def generate_smiles(self, start_token_id, max_length=100, temperature=1.0):
        """
        SMILESæ–‡å­—åˆ—ã‚’ç”Ÿæˆ

        Args:
            start_token_id: é–‹å§‹ãƒˆãƒ¼ã‚¯ãƒ³ID
            max_length: æœ€å¤§é•·
            temperature: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¸©åº¦ï¼ˆé«˜ã„ã»ã©ãƒ©ãƒ³ãƒ€ãƒ ï¼‰
        Returns:
            generated_ids: ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ID
        """
        generated = [start_token_id]

        for _ in range(max_length):
            input_ids = torch.tensor([generated])
            outputs = self.gpt(input_ids)
            logits = outputs.logits[:, -1, :] / temperature

            # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            probs = F.softmax(logits, dim=-1)
            next_token = torch.multinomial(probs, num_samples=1).item()

            generated.append(next_token)

            # çµ‚äº†ãƒˆãƒ¼ã‚¯ãƒ³ãªã‚‰åœæ­¢
            if next_token == 2:  # [EOS]
                break

        return generated

# æ¡ä»¶ä»˜ãSMILESç”Ÿæˆ
class ConditionalSMILESGenerator(nn.Module):
    def __init__(self, vocab_size=1000, condition_dim=10, d_model=512):
        super(ConditionalSMILESGenerator, self).__init__()

        # æ¡ä»¶ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€
        self.condition_encoder = nn.Linear(condition_dim, d_model)

        # GPT-2 config
        config = GPT2Config(
            vocab_size=vocab_size,
            n_positions=512,
            n_embd=d_model,
            n_layer=6,
            n_head=8
        )
        self.gpt = GPT2LMHeadModel(config)

    def forward(self, input_ids, condition):
        """
        Args:
            input_ids: (batch_size, seq_len)
            condition: (batch_size, condition_dim) ç›®æ¨™ç‰¹æ€§
        """
        batch_size, seq_len = input_ids.shape

        # æ¡ä»¶ã‚’åŸ‹ã‚è¾¼ã¿
        condition_embed = self.condition_encoder(condition).unsqueeze(1)  # (batch, 1, d_model)

        # ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿
        token_embeddings = self.gpt.transformer.wte(input_ids)

        # æ¡ä»¶ã‚’å…ˆé ­ã«è¿½åŠ 
        embeddings = torch.cat([condition_embed, token_embeddings], dim=1)

        # GPT-2 forwardï¼ˆåŸ‹ã‚è¾¼ã¿ã‹ã‚‰ç›´æ¥ï¼‰
        outputs = self.gpt(inputs_embeds=embeddings)

        return outputs

# ä½¿ç”¨ä¾‹: æº¶è§£åº¦ãŒé«˜ã„åˆ†å­ã‚’ç”Ÿæˆ
condition_dim = 5  # logP, æº¶è§£åº¦, åˆ†å­é‡, HBãƒ‰ãƒŠãƒ¼æ•°, HBã‚¢ã‚¯ã‚»ãƒ—ã‚¿ãƒ¼æ•°
target_properties = torch.tensor([[1.5, 10.0, 250.0, 2.0, 3.0]])  # é«˜æº¶è§£åº¦

conditional_smiles_gen = ConditionalSMILESGenerator(vocab_size=1000, condition_dim=condition_dim)
```

---

## 4.5 ææ–™é€†è¨­è¨ˆã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```mermaid
graph TB
    A[ç›®æ¨™ç‰¹æ€§å®šç¾©] --> B[æ¡ä»¶ä»˜ãç”Ÿæˆãƒ¢ãƒ‡ãƒ«]
    B --> C[å€™è£œææ–™ç”Ÿæˆ]
    C --> D[ç‰¹æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«]
    D --> E{ç›®æ¨™é”æˆ?}
    E -->|No| F[å€™è£œé™¤å¤–]
    F --> B
    E -->|Yes| G[åˆæˆå¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯]
    G --> H{åˆæˆå¯èƒ½?}
    H -->|No| F
    H -->|Yes| I[å®‰å®šæ€§è¨ˆç®—]
    I --> J{å®‰å®š?}
    J -->|No| F
    J -->|Yes| K[å®Ÿé¨“å€™è£œãƒªã‚¹ãƒˆ]

    style A fill:#e1f5ff
    style K fill:#e1ffe1
```

### å®Ÿè£…ä¾‹

```python
class MaterialsInverseDesign:
    def __init__(self, generator, predictor, synthesizability_checker):
        """
        ææ–™é€†è¨­è¨ˆã‚·ã‚¹ãƒ†ãƒ 

        Args:
            generator: æ¡ä»¶ä»˜ãç”Ÿæˆãƒ¢ãƒ‡ãƒ«
            predictor: ç‰¹æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
            synthesizability_checker: åˆæˆå¯èƒ½æ€§ãƒã‚§ãƒƒã‚«ãƒ¼
        """
        self.generator = generator
        self.predictor = predictor
        self.synthesizability_checker = synthesizability_checker

    def design_materials(self, target_properties, num_candidates=100, threshold=0.1):
        """
        ææ–™ã‚’é€†è¨­è¨ˆ

        Args:
            target_properties: ç›®æ¨™ç‰¹æ€§ (condition_dim,)
            num_candidates: ç”Ÿæˆã™ã‚‹å€™è£œæ•°
            threshold: è¨±å®¹èª¤å·®
        Returns:
            valid_materials: æ¤œè¨¼ã‚’é€šéã—ãŸææ–™ãƒªã‚¹ãƒˆ
        """
        valid_materials = []

        for i in range(num_candidates):
            # 1. å€™è£œç”Ÿæˆ
            candidate = self.generator.generate_conditional(
                target_properties.unsqueeze(0),
                input_dim=128
            )

            # 2. ç‰¹æ€§äºˆæ¸¬
            predicted_properties = self.predictor(candidate)

            # 3. ç›®æ¨™ã¨ã®æ¯”è¼ƒ
            error = torch.abs(predicted_properties - target_properties).mean()
            if error > threshold:
                continue

            # 4. åˆæˆå¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
            if not self.synthesizability_checker(candidate):
                continue

            # 5. å®‰å®šæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆçœç•¥ï¼‰

            # åˆæ ¼
            valid_materials.append({
                'structure': candidate,
                'predicted_properties': predicted_properties,
                'error': error.item()
            })

        # èª¤å·®ã§ã‚½ãƒ¼ãƒˆ
        valid_materials.sort(key=lambda x: x['error'])

        return valid_materials

# ä½¿ç”¨ä¾‹
def simple_synthesizability_checker(structure):
    """
    ç°¡æ˜“åˆæˆå¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆå®Ÿéš›ã¯ã‚ˆã‚Šè¤‡é›‘ï¼‰
    """
    # ã“ã“ã§ã¯å¸¸ã«Trueã‚’è¿”ã™ï¼ˆå®Ÿéš›ã¯Retrosynãªã©ã‚’ä½¿ç”¨ï¼‰
    return True

# ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰
inverse_design_system = MaterialsInverseDesign(
    generator=conditional_model,
    predictor=lambda x: torch.randn(x.size(0), 3),  # ãƒ€ãƒŸãƒ¼äºˆæ¸¬å™¨
    synthesizability_checker=simple_synthesizability_checker
)

# ç›®æ¨™ç‰¹æ€§
target = torch.tensor([2.5, -0.8, 0.0])  # ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã€ç£æ°—ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ

# é€†è¨­è¨ˆå®Ÿè¡Œ
designed_materials = inverse_design_system.design_materials(target, num_candidates=50)
print(f"Found {len(designed_materials)} valid materials")

# ä¸Šä½3ã¤ã‚’è¡¨ç¤º
for i, material in enumerate(designed_materials[:3]):
    print(f"\nMaterial {i+1}:")
    print(f"  Predicted properties: {material['predicted_properties']}")
    print(f"  Error: {material['error']:.4f}")
```

---

## 4.6 ç”£æ¥­å¿œç”¨ã¨ã‚­ãƒ£ãƒªã‚¢

### å®Ÿä¸–ç•Œã®æˆåŠŸäº‹ä¾‹

#### 1. å‰µè–¬: æ–°è¦æŠ—ç”Ÿç‰©è³ªã®ç™ºè¦‹

**MIT (2020)**:
- **æ‰‹æ³•**: æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã§åˆ†å­ç”Ÿæˆ
- **æˆæœ**: halicinï¼ˆæ–°è¦æŠ—ç”Ÿç‰©è³ªï¼‰ç™ºè¦‹
- **ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ**: å¾“æ¥æ‰‹æ³•ã‚ˆã‚Š100å€é«˜é€Ÿ

#### 2. é›»æ± ææ–™: é«˜ã‚¨ãƒãƒ«ã‚®ãƒ¼å¯†åº¦é›»è§£è³ª

**Stanford/Toyota (2022)**:
- **æ‰‹æ³•**: Transformer + å¼·åŒ–å­¦ç¿’
- **æˆæœ**: ãƒªãƒã‚¦ãƒ ä¼å°åº¦1.5å€ã®å›ºä½“é›»è§£è³ª
- **ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ**: å…¨å›ºä½“é›»æ± ã®å®Ÿç”¨åŒ–åŠ é€Ÿ

#### 3. è§¦åª’: COâ‚‚é‚„å…ƒè§¦åª’

**CMU (2023)**:
- **æ‰‹æ³•**: æ¡ä»¶ä»˜ãç”Ÿæˆ + DFTè¨ˆç®—
- **æˆæœ**: åŠ¹ç‡10å€ã®è§¦åª’ç™ºè¦‹
- **ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ**: ã‚«ãƒ¼ãƒœãƒ³ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«å®Ÿç¾ã¸ã®è²¢çŒ®

### ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹

**AIææ–™è¨­è¨ˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢**:
- **è·ç¨®**: è£½è–¬ã€åŒ–å­¦ã€ææ–™ãƒ¡ãƒ¼ã‚«ãƒ¼ã®R&D
- **å¹´å**: 800-1500ä¸‡å††ï¼ˆæ—¥æœ¬ï¼‰ã€$120k-$250kï¼ˆç±³å›½ï¼‰
- **å¿…è¦ã‚¹ã‚­ãƒ«**: Transformerã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€ææ–™ç§‘å­¦

**ç ”ç©¶è€…ï¼ˆã‚¢ã‚«ãƒ‡ãƒŸã‚¢ï¼‰**:
- **è·ç¨®**: å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã®PI
- **ç ”ç©¶åˆ†é‡**: AIææ–™ç§‘å­¦ã€è¨ˆç®—ææ–™ç§‘å­¦
- **ç«¶äº‰åŠ›**: Nature/Scienceç´šã®è«–æ–‡ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹

**ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—å‰µæ¥­**:
- **ä¾‹**: Insilico Medicineï¼ˆå‰µè–¬AIï¼‰ã€Citrine Informaticsï¼ˆææ–™AIï¼‰
- **è³‡é‡‘èª¿é”**: ã‚·ãƒªãƒ¼ã‚ºAã€œCã€æ•°å„„ã€œæ•°åå„„å††
- **æˆåŠŸä¾‹**: IPOã€å¤§æ‰‹ä¼æ¥­ã¸ã®è²·å

---

## 4.7 ã¾ã¨ã‚

### é‡è¦ãƒã‚¤ãƒ³ãƒˆ

1. **æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«**: ãƒã‚¤ã‚ºã‹ã‚‰é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
2. **æ¡ä»¶ä»˜ãç”Ÿæˆ**: ç›®æ¨™ç‰¹æ€§ã‚’æŒ‡å®šã—ã¦ææ–™è¨­è¨ˆ
3. **SMILESç”Ÿæˆ**: Transformerã§åˆ†å­æ§‹é€ ã‚’ç”Ÿæˆ
4. **é€†è¨­è¨ˆ**: ç‰¹æ€§ã‹ã‚‰æ§‹é€ ã¸ã®é€†å‘ãæ¢ç´¢
5. **ç”£æ¥­å¿œç”¨**: å‰µè–¬ã€é›»æ± ã€è§¦åª’ã§å®Ÿç”¨åŒ–é€²ã‚€

### ã‚·ãƒªãƒ¼ã‚ºã®ã¾ã¨ã‚

**ç¬¬1ç« **: TransformeråŸºç¤ã€Attentionæ©Ÿæ§‹
**ç¬¬2ç« **: ææ–™ç‰¹åŒ–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆMatformerã€ChemBERTaï¼‰
**ç¬¬3ç« **: äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€è»¢ç§»å­¦ç¿’
**ç¬¬4ç« **: ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€é€†è¨­è¨ˆ

**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**:
1. å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§çµŒé¨“ã‚’ç©ã‚€
2. æœ€æ–°è«–æ–‡ã‚’èª­ã‚“ã§çŸ¥è­˜ã‚’æ›´æ–°
3. Kaggleã‚³ãƒ³ãƒšã«å‚åŠ ã—ã¦å®ŸåŠ›ã‚’è©¦ã™
4. ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‚åŠ ã—ã¦æƒ…å ±äº¤æ›

---

## ğŸ“ æ¼”ç¿’å•é¡Œ

### å•é¡Œ1: æ¦‚å¿µç†è§£
æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ãŒå¾“æ¥ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ï¼ˆVAEã€GANï¼‰ã¨æ¯”ã¹ã¦å„ªã‚Œã¦ã„ã‚‹ç‚¹ã‚’3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚

<details>
<summary>è§£ç­”ä¾‹</summary>

1. **å­¦ç¿’ã®å®‰å®šæ€§**: GANã®ã‚ˆã†ãªmode collapseãŒèµ·ã“ã‚Šã«ãã„
2. **ã‚µãƒ³ãƒ—ãƒ«å“è³ª**: é«˜å“è³ªã§å¤šæ§˜ãªã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆå¯èƒ½
3. **æŸ”è»Ÿãªæ¡ä»¶ä»˜ã‘**: æ§˜ã€…ãªæ¡ä»¶ï¼ˆç‰¹æ€§ã€åˆ¶ç´„ï¼‰ã‚’å®¹æ˜“ã«çµ„ã¿è¾¼ã‚ã‚‹

è¿½åŠ :
- **è§£é‡ˆæ€§**: ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ãŒæ®µéšçš„ã§ç†è§£ã—ã‚„ã™ã„
- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã‚‚åŠ¹ç‡çš„ã«å­¦ç¿’
</details>

### å•é¡Œ2: å®Ÿè£…
æ¡ä»¶ä»˜ãç”Ÿæˆã§ã€è¤‡æ•°ã®ç›®æ¨™ç‰¹æ€§ï¼ˆãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰ã‚’åŒæ™‚ã«æº€ãŸã™ææ–™ã‚’ç”Ÿæˆã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚

```python
def multi_objective_generation(generator, target_bandgap, target_formation_energy, num_samples=10):
    """
    å¤šç›®çš„æœ€é©åŒ–ã§ææ–™ã‚’ç”Ÿæˆ

    Args:
        generator: æ¡ä»¶ä»˜ãç”Ÿæˆãƒ¢ãƒ‡ãƒ«
        target_bandgap: ç›®æ¨™ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆeVï¼‰
        target_formation_energy: ç›®æ¨™å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆeV/atomï¼‰
        num_samples: ç”Ÿæˆæ•°
    Returns:
        generated_materials: ç”Ÿæˆã•ã‚ŒãŸææ–™ã®ãƒªã‚¹ãƒˆ
    """
    # ã“ã“ã«å®Ÿè£…
    pass
```

<details>
<summary>è§£ç­”ä¾‹</summary>

```python
def multi_objective_generation(generator, target_bandgap, target_formation_energy, num_samples=10):
    # æ¡ä»¶ã‚’ä½œæˆ
    condition = torch.tensor([[target_bandgap, target_formation_energy]])
    condition = condition.repeat(num_samples, 1)

    # ç”Ÿæˆ
    generated_materials = generator.generate_conditional(condition, input_dim=128)

    return generated_materials

# ä½¿ç”¨ä¾‹
target_bg = 2.0  # 2.0 eV
target_fe = -0.5  # -0.5 eV/atom

materials = multi_objective_generation(conditional_model, target_bg, target_fe, num_samples=20)
print(f"Generated {materials.shape[0]} materials")
```
</details>

### å•é¡Œ3: å¿œç”¨
ææ–™é€†è¨­è¨ˆã«ãŠã„ã¦ã€ç”Ÿæˆã•ã‚ŒãŸå€™è£œææ–™ã‚’è©•ä¾¡ã™ã‚‹éš›ã®é‡è¦ãªåŸºæº–ã‚’5ã¤æŒ™ã’ã€ãã‚Œãã‚Œã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

<details>
<summary>è§£ç­”ä¾‹</summary>

1. **ç›®æ¨™ç‰¹æ€§ã®é”æˆåº¦**:
   - äºˆæ¸¬ç‰¹æ€§ãŒç›®æ¨™å€¤ã«ã©ã‚Œã ã‘è¿‘ã„ã‹
   - è¤‡æ•°ç‰¹æ€§ã®å ´åˆã€ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©æ€§

2. **åˆæˆå¯èƒ½æ€§**:
   - æ—¢çŸ¥ã®åˆæˆæ‰‹æ³•ã§ä½œè£½å¯èƒ½ã‹
   - å‰é§†ä½“ã®å…¥æ‰‹å¯èƒ½æ€§
   - åˆæˆæ¡ä»¶ï¼ˆæ¸©åº¦ã€åœ§åŠ›ï¼‰ã®å®Ÿç¾å¯èƒ½æ€§

3. **ç†±åŠ›å­¦çš„å®‰å®šæ€§**:
   - å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒè² ï¼ˆå®‰å®šç›¸ï¼‰
   - ä»–ã®çµæ™¶æ§‹é€ ã¨æ¯”è¼ƒã—ã¦æœ€å®‰å®š
   - åˆ†è§£åå¿œã«å¯¾ã™ã‚‹å®‰å®šæ€§

4. **åŒ–å­¦çš„å¦¥å½“æ€§**:
   - åŸå­ä¾¡å‰‡ã‚’æº€ãŸã™
   - çµåˆè·é›¢ãƒ»è§’åº¦ãŒå¦¥å½“
   - æ—¢çŸ¥ã®åŒ–å­¦ç³»ã¨æ•´åˆ

5. **ã‚³ã‚¹ãƒˆã¨ç’°å¢ƒè² è·**:
   - æ§‹æˆå…ƒç´ ã®ä¾¡æ ¼ã¨åŸ‹è”µé‡
   - æœ‰å®³å…ƒç´ ï¼ˆCdã€Pbç­‰ï¼‰ã®ä½¿ç”¨
   - ãƒªã‚µã‚¤ã‚¯ãƒ«å¯èƒ½æ€§
</details>

---

## ğŸ“ ã‚·ãƒªãƒ¼ã‚ºå®Œäº†ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼

ã“ã®ã‚·ãƒªãƒ¼ã‚ºã‚’å®Œäº†ã—ãŸã‚ãªãŸã¯ã€Transformerã¨ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®åŸºç¤ã‹ã‚‰å¿œç”¨ã¾ã§ã€ææ–™ç§‘å­¦ã§ã®æ´»ç”¨æ–¹æ³•ã‚’ç¿’å¾—ã—ã¾ã—ãŸã€‚

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**:
   - Materials Projectãƒ‡ãƒ¼ã‚¿ã§ææ–™ç‰¹æ€§äºˆæ¸¬
   - QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§åˆ†å­ç”Ÿæˆ
   - ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

2. **è«–æ–‡å®Ÿè£…**:
   - Matformerè«–æ–‡ã‚’èª­ã‚“ã§å®Ÿè£…
   - æœ€æ–°ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«è«–æ–‡ã«æŒ‘æˆ¦

3. **ã‚³ãƒ³ãƒšãƒ†ã‚£ãƒ¼ã‚·ãƒ§ãƒ³**:
   - Open Catalyst Challenge
   - Kaggleã®åˆ†å­äºˆæ¸¬ã‚³ãƒ³ãƒš

4. **ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å‚åŠ **:
   - Hugging Face Forum
   - Materials Project Community
   - ææ–™ç§‘å­¦ã®ã‚«ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ï¼ˆMRSã€APSï¼‰

---

## ğŸ”— å‚è€ƒè³‡æ–™

### è«–æ–‡
- Ho et al. (2020) "Denoising Diffusion Probabilistic Models"
- Chen et al. (2022) "Matformer: Nested Transformer for Elastic Inference"
- Xie et al. (2021) "Crystal Diffusion Variational Autoencoder"
- Stokes et al. (2020) "A Deep Learning Approach to Antibiotic Discovery" (Nature)

### ãƒ„ãƒ¼ãƒ«
- [Hugging Face Diffusers](https://github.com/huggingface/diffusers)
- [RDKit](https://www.rdkit.org/) - åˆ†å­å‡¦ç†
- [Materials Project API](https://materialsproject.org/)

### æ¬¡ã®ã‚·ãƒªãƒ¼ã‚º
- **å¼·åŒ–å­¦ç¿’å…¥é–€**: ææ–™æ¢ç´¢ã¸ã®å¼·åŒ–å­¦ç¿’é©ç”¨
- **GNNå…¥é–€**: ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§åˆ†å­ãƒ»ææ–™è¡¨ç¾

---

**ä½œæˆè€…**: æ©‹æœ¬ä½‘ä»‹ï¼ˆæ±åŒ—å¤§å­¦ï¼‰
**æœ€çµ‚æ›´æ–°**: 2025å¹´10æœˆ17æ—¥
**ã‚·ãƒªãƒ¼ã‚º**: Transformerãƒ»Foundation Modelså…¥é–€ï¼ˆå…¨4ç« å®Œï¼‰

**ãƒ©ã‚¤ã‚»ãƒ³ã‚¹**: CC BY 4.0
