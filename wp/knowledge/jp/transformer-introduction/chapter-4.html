<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Untitled - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Untitled</h1>
            
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 20-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 5å€‹</span>
            </div>
        </div>
    </header>

    <main class="container">
        <p><h1>ç¬¬4ç« : ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¨é€†è¨­è¨ˆ</h1></p>

<p><strong>å­¦ç¿’æ™‚é–“</strong>: 20-25åˆ† | <strong>é›£æ˜“åº¦</strong>: ä¸Šç´š</p>

<p><h2>ğŸ“‹ ã“ã®ç« ã§å­¦ã¶ã“ã¨</h2></p>

<ul>
<li>æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ï¼ˆDiffusion Modelsï¼‰ã®åŸç†</li>
<li>æ¡ä»¶ä»˜ãç”Ÿæˆï¼ˆConditional Generationï¼‰</li>
<li>åˆ†å­ç”Ÿæˆã¨SMILESç”Ÿæˆ</li>
<li>ææ–™é€†è¨­è¨ˆï¼ˆInverse Designï¼‰</li>
<li>ç”£æ¥­å¿œç”¨ã¨ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹</li>
</ul>

<p>---</p>

<p><h2>4.1 ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¨ã¯</h2></p>

<p><h3>ææ–™ç§‘å­¦ã«ãŠã‘ã‚‹ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®é‡è¦æ€§</h3></p>

<p><strong>å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆé †å•é¡Œï¼‰</strong>:</p>
<p><pre><code class="language-">ææ–™æ§‹é€  â†’ ç‰¹æ€§äºˆæ¸¬</p>
<p></code></pre></p>

<p><strong>é€†è¨­è¨ˆï¼ˆé€†å•é¡Œï¼‰</strong>:</p>
<p><pre><code class="language-">æœ›ã¾ã—ã„ç‰¹æ€§ â†’ ææ–™æ§‹é€ ç”Ÿæˆ</p>
<p></code></pre></p>

<p><strong>ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®åˆ©ç‚¹</strong>:</p>
<ul>
<li>âœ… åºƒå¤§ãªæ¢ç´¢ç©ºé–“ã‹ã‚‰å€™è£œã‚’è‡ªå‹•ç”Ÿæˆ</li>
<li>âœ… å¤šç›®çš„æœ€é©åŒ–ï¼ˆè¤‡æ•°ã®ç‰¹æ€§ã‚’åŒæ™‚ã«æº€è¶³ï¼‰</li>
<li>âœ… åˆæˆå¯èƒ½æ€§ã‚’è€ƒæ…®ã—ãŸç”Ÿæˆ</li>
<li>âœ… äººé–“ã®ç›´æ„Ÿã‚’è¶…ãˆãŸæ–°è¦æ§‹é€ ã®ç™ºè¦‹</li>
</ul>

<p><pre><code class="language-mermaid">graph LR</p>
<p>    A[ç›®æ¨™ç‰¹æ€§] --> B[ç”Ÿæˆãƒ¢ãƒ‡ãƒ«]</p>
<p>    C[åˆ¶ç´„æ¡ä»¶] --> B</p>
<p>    B --> D[å€™è£œææ–™]</p>
<p>    D --> E[ç‰¹æ€§äºˆæ¸¬]</p>
<p>    E --> F{ç›®æ¨™é”æˆ?}</p>
<p>    F -->|No| B</p>
<p>    F -->|Yes| G[å®Ÿé¨“æ¤œè¨¼]</p>

<p>    style B fill:#e1f5ff</p>
<p>    style G fill:#ffe1e1</p>
<p></code></pre></p>

<p>---</p>

<p><h2>4.2 æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®åŸç†</h2></p>

<p><h3>æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¨ã¯</h3></p>

<p><strong>åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢</strong>: ãƒã‚¤ã‚ºè¿½åŠ ãƒ—ãƒ­ã‚»ã‚¹ã‚’é€†è»¢ã—ã¦ã€ãƒã‚¤ã‚ºã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ</p>

<p><strong>Forward Processï¼ˆãƒã‚¤ã‚ºè¿½åŠ ï¼‰</strong>:</p>
<p>$$</p>
<p>q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)</p>
<p>$$</p>

<p><strong>Reverse Processï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰</strong>:</p>
<p>$$</p>
<p>p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))</p>
<p>$$</p>

<p><h3>è¦–è¦šçš„ç†è§£</h3></p>

<p><pre><code class="language-mermaid">graph LR</p>
<p>    X0[å…ƒãƒ‡ãƒ¼ã‚¿ xâ‚€] -->|ãƒã‚¤ã‚ºè¿½åŠ | X1[xâ‚]</p>
<p>    X1 -->|ãƒã‚¤ã‚ºè¿½åŠ | X2[xâ‚‚]</p>
<p>    X2 -->|...| XT[ç´”ç²‹ãƒã‚¤ã‚º xâ‚œ]</p>

<p>    XT -->|ãƒã‚¤ã‚ºé™¤å»| X2R[xâ‚‚]</p>
<p>    X2R -->|ãƒã‚¤ã‚ºé™¤å»| X1R[xâ‚]</p>
<p>    X1R -->|ãƒã‚¤ã‚ºé™¤å»| X0R[ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ xâ‚€]</p>

<p>    style X0 fill:#e1f5ff</p>
<p>    style XT fill:#ffe1e1</p>
<p>    style X0R fill:#e1ffe1</p>
<p></code></pre></p>

<p><h3>ç°¡æ˜“å®Ÿè£…</h3></p>

<p><pre><code class="language-python">import torch</p>
<p>import torch.nn as nn</p>
<p>import torch.nn.functional as F</p>
<p>import numpy as np</p>

<p>class SimpleDiffusionModel(nn.Module):</p>
<p>    def __init__(self, input_dim, hidden_dim=256, num_timesteps=1000):</p>
<p>        super(SimpleDiffusionModel, self).__init__()</p>
<p>        self.num_timesteps = num_timesteps</p>

<p>        <h1>ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«</h1></p>
<p>        self.betas = torch.linspace(1e-4, 0.02, num_timesteps)</p>
<p>        self.alphas = 1.0 - self.betas</p>
<p>        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)</p>

<p>        <h1>ãƒã‚¤ã‚ºäºˆæ¸¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯</h1></p>
<p>        self.noise_predictor = nn.Sequential(</p>
<p>            nn.Linear(input_dim + 1, hidden_dim),  <h1>+1ã¯ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—</h1></p>
<p>            nn.ReLU(),</p>
<p>            nn.Linear(hidden_dim, hidden_dim),</p>
<p>            nn.ReLU(),</p>
<p>            nn.Linear(hidden_dim, input_dim)</p>
<p>        )</p>

<p>    def forward_process(self, x0, t):</p>
<p>        """</p>
<p>        Forward process: ãƒã‚¤ã‚ºè¿½åŠ </p>

<p>        Args:</p>
<p>            x0: å…ƒãƒ‡ãƒ¼ã‚¿ (batch_size, input_dim)</p>
<p>            t: ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ— (batch_size,)</p>
<p>        Returns:</p>
<p>            xt: ãƒã‚¤ã‚ºãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿</p>
<p>            noise: è¿½åŠ ã•ã‚ŒãŸãƒã‚¤ã‚º</p>
<p>        """</p>
<p>        batch_size = x0.size(0)</p>

<p>        <h1>ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«</h1></p>
<p>        alpha_t = self.alphas_cumprod[t].view(-1, 1)</p>
<p>        sqrt_alpha_t = torch.sqrt(alpha_t)</p>
<p>        sqrt_one_minus_alpha_t = torch.sqrt(1 - alpha_t)</p>

<p>        <h1>ãƒã‚¤ã‚ºã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</h1></p>
<p>        noise = torch.randn_like(x0)</p>

<p>        <h1>ãƒã‚¤ã‚ºã‚’è¿½åŠ </h1></p>
<p>        xt = sqrt_alpha_t <em> x0 + sqrt_one_minus_alpha_t </em> noise</p>

<p>        return xt, noise</p>

<p>    def predict_noise(self, xt, t):</p>
<p>        """</p>
<p>        ãƒã‚¤ã‚ºã‚’äºˆæ¸¬</p>

<p>        Args:</p>
<p>            xt: ãƒã‚¤ã‚ºãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿</p>
<p>            t: ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—</p>
<p>        Returns:</p>
<p>            predicted_noise: äºˆæ¸¬ã•ã‚ŒãŸãƒã‚¤ã‚º</p>
<p>        """</p>
<p>        <h1>ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã‚’åŸ‹ã‚è¾¼ã¿</h1></p>
<p>        t_embed = t.float().unsqueeze(1) / self.num_timesteps</p>

<p>        <h1>ãƒã‚¤ã‚ºäºˆæ¸¬</h1></p>
<p>        x_with_t = torch.cat([xt, t_embed], dim=1)</p>
<p>        predicted_noise = self.noise_predictor(x_with_t)</p>

<p>        return predicted_noise</p>

<p>    def reverse_process(self, xt, t):</p>
<p>        """</p>
<p>        Reverse process: ãƒã‚¤ã‚ºé™¤å»ï¼ˆ1ã‚¹ãƒ†ãƒƒãƒ—ï¼‰</p>

<p>        Args:</p>
<p>            xt: ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿</p>
<p>            t: ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—</p>
<p>        Returns:</p>
<p>            x_prev: 1ã‚¹ãƒ†ãƒƒãƒ—å‰ã®ãƒ‡ãƒ¼ã‚¿</p>
<p>        """</p>
<p>        <h1>ãƒã‚¤ã‚ºã‚’äºˆæ¸¬</h1></p>
<p>        predicted_noise = self.predict_noise(xt, t)</p>

<p>        <h1>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</h1></p>
<p>        alpha_t = self.alphas[t].view(-1, 1)</p>
<p>        alpha_t_cumprod = self.alphas_cumprod[t].view(-1, 1)</p>
<p>        beta_t = self.betas[t].view(-1, 1)</p>

<p>        <h1>å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¨ˆç®—</h1></p>
<p>        x_prev = (1 / torch.sqrt(alpha_t)) * (</p>
<p>            xt - (beta_t / torch.sqrt(1 - alpha_t_cumprod)) * predicted_noise</p>
<p>        )</p>

<p>        <h1>ãƒã‚¤ã‚ºã‚’è¿½åŠ ï¼ˆt > 0ã®å ´åˆï¼‰</h1></p>
<p>        if t[0] > 0:</p>
<p>            noise = torch.randn_like(xt)</p>
<p>            x_prev = x_prev + torch.sqrt(beta_t) * noise</p>

<p>        return x_prev</p>

<p>    def generate(self, batch_size, input_dim):</p>
<p>        """</p>
<p>        ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ</p>

<p>        Args:</p>
<p>            batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º</p>
<p>            input_dim: ãƒ‡ãƒ¼ã‚¿æ¬¡å…ƒ</p>
<p>        Returns:</p>
<p>            x0: ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿</p>
<p>        """</p>
<p>        <h1>ç´”ç²‹ãƒã‚¤ã‚ºã‹ã‚‰é–‹å§‹</h1></p>
<p>        xt = torch.randn(batch_size, input_dim)</p>

<p>        <h1>é€†ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œ</h1></p>
<p>        for t in reversed(range(self.num_timesteps)):</p>
<p>            t_batch = torch.full((batch_size,), t, dtype=torch.long)</p>
<p>            xt = self.reverse_process(xt, t_batch)</p>

<p>        return xt</p>

<p><h1>ä½¿ç”¨ä¾‹: åˆ†å­è¨˜è¿°å­ã®ç”Ÿæˆ</h1></p>
<p>input_dim = 128  <h1>è¨˜è¿°å­ã®æ¬¡å…ƒ</h1></p>
<p>diffusion_model = SimpleDiffusionModel(input_dim, hidden_dim=256, num_timesteps=100)</p>

<p><h1>è¨“ç·´ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰</h1></p>
<p>x0 = torch.randn(64, input_dim)  <h1>64åˆ†å­ã®è¨˜è¿°å­</h1></p>

<p><h1>Forward processï¼ˆãƒã‚¤ã‚ºè¿½åŠ ï¼‰</h1></p>
<p>t = torch.randint(0, 100, (64,))</p>
<p>xt, noise = diffusion_model.forward_process(x0, t)</p>

<p><h1>ãƒã‚¤ã‚ºäºˆæ¸¬</h1></p>
<p>predicted_noise = diffusion_model.predict_noise(xt, t)</p>

<p><h1>æå¤±</h1></p>
<p>loss = F.mse_loss(predicted_noise, noise)</p>
<p>print(f"Training loss: {loss.item():.4f}")</p>

<p><h1>ç”Ÿæˆ</h1></p>
<p>generated_data = diffusion_model.generate(batch_size=10, input_dim=input_dim)</p>
<p>print(f"Generated data shape: {generated_data.shape}")</p>
<p></code></pre></p>

<p>---</p>

<p><h2>4.3 æ¡ä»¶ä»˜ãç”Ÿæˆ</h2></p>

<p><h3>æ¦‚è¦</h3></p>

<p><strong>æ¡ä»¶ä»˜ãç”Ÿæˆ</strong>: ç›®æ¨™ç‰¹æ€§ã‚’æ¡ä»¶ã¨ã—ã¦ä¸ãˆã¦ç”Ÿæˆ</p>

<p><strong>ä¾‹</strong>:</p>
<p><pre><code class="language-python"><h1>æ¡ä»¶: ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ— = 2.0 eVã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ < 0</h1></p>
<p><h1>ç”Ÿæˆ: æ¡ä»¶ã‚’æº€ãŸã™ææ–™æ§‹é€ </h1></p>
<p></code></pre></p>

<p><h3>å®Ÿè£…: Conditional Diffusion</h3></p>

<p><pre><code class="language-python">class ConditionalDiffusionModel(nn.Module):</p>
<p>    def __init__(self, input_dim, condition_dim, hidden_dim=256, num_timesteps=1000):</p>
<p>        super(ConditionalDiffusionModel, self).__init__()</p>
<p>        self.num_timesteps = num_timesteps</p>

<p>        <h1>ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«</h1></p>
<p>        self.betas = torch.linspace(1e-4, 0.02, num_timesteps)</p>
<p>        self.alphas = 1.0 - self.betas</p>
<p>        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)</p>

<p>        <h1>æ¡ä»¶ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€</h1></p>
<p>        self.condition_encoder = nn.Sequential(</p>
<p>            nn.Linear(condition_dim, hidden_dim),</p>
<p>            nn.ReLU(),</p>
<p>            nn.Linear(hidden_dim, hidden_dim)</p>
<p>        )</p>

<p>        <h1>ãƒã‚¤ã‚ºäºˆæ¸¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆæ¡ä»¶ä»˜ãï¼‰</h1></p>
<p>        self.noise_predictor = nn.Sequential(</p>
<p>            nn.Linear(input_dim + hidden_dim + 1, hidden_dim),  <h1>+1ã¯ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—</h1></p>
<p>            nn.ReLU(),</p>
<p>            nn.Linear(hidden_dim, hidden_dim),</p>
<p>            nn.ReLU(),</p>
<p>            nn.Linear(hidden_dim, input_dim)</p>
<p>        )</p>

<p>    def predict_noise(self, xt, t, condition):</p>
<p>        """</p>
<p>        æ¡ä»¶ä»˜ããƒã‚¤ã‚ºäºˆæ¸¬</p>

<p>        Args:</p>
<p>            xt: ãƒã‚¤ã‚ºãŒè¿½åŠ ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ (batch_size, input_dim)</p>
<p>            t: ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ— (batch_size,)</p>
<p>            condition: æ¡ä»¶ï¼ˆç›®æ¨™ç‰¹æ€§ï¼‰ (batch_size, condition_dim)</p>
<p>        Returns:</p>
<p>            predicted_noise: äºˆæ¸¬ã•ã‚ŒãŸãƒã‚¤ã‚º</p>
<p>        """</p>
<p>        <h1>æ¡ä»¶ã‚’åŸ‹ã‚è¾¼ã¿</h1></p>
<p>        condition_embed = self.condition_encoder(condition)</p>

<p>        <h1>ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã‚’åŸ‹ã‚è¾¼ã¿</h1></p>
<p>        t_embed = t.float().unsqueeze(1) / self.num_timesteps</p>

<p>        <h1>çµåˆ</h1></p>
<p>        x_with_condition = torch.cat([xt, condition_embed, t_embed], dim=1)</p>

<p>        <h1>ãƒã‚¤ã‚ºäºˆæ¸¬</h1></p>
<p>        predicted_noise = self.noise_predictor(x_with_condition)</p>

<p>        return predicted_noise</p>

<p>    def generate_conditional(self, condition, input_dim):</p>
<p>        """</p>
<p>        æ¡ä»¶ä»˜ããƒ‡ãƒ¼ã‚¿ç”Ÿæˆ</p>

<p>        Args:</p>
<p>            condition: æ¡ä»¶ (batch_size, condition_dim)</p>
<p>            input_dim: ãƒ‡ãƒ¼ã‚¿æ¬¡å…ƒ</p>
<p>        Returns:</p>
<p>            x0: ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿</p>
<p>        """</p>
<p>        batch_size = condition.size(0)</p>

<p>        <h1>ç´”ç²‹ãƒã‚¤ã‚ºã‹ã‚‰é–‹å§‹</h1></p>
<p>        xt = torch.randn(batch_size, input_dim)</p>

<p>        <h1>é€†ãƒ—ãƒ­ã‚»ã‚¹</h1></p>
<p>        for t in reversed(range(self.num_timesteps)):</p>
<p>            t_batch = torch.full((batch_size,), t, dtype=torch.long)</p>

<p>            <h1>ãƒã‚¤ã‚ºäºˆæ¸¬</h1></p>
<p>            predicted_noise = self.predict_noise(xt, t_batch, condition)</p>

<p>            <h1>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</h1></p>
<p>            alpha_t = self.alphas[t]</p>
<p>            alpha_t_cumprod = self.alphas_cumprod[t]</p>
<p>            beta_t = self.betas[t]</p>

<p>            <h1>å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¨ˆç®—</h1></p>
<p>            xt = (1 / torch.sqrt(alpha_t)) * (</p>
<p>                xt - (beta_t / torch.sqrt(1 - alpha_t_cumprod)) * predicted_noise</p>
<p>            )</p>

<p>            <h1>ãƒã‚¤ã‚ºã‚’è¿½åŠ ï¼ˆt > 0ã®å ´åˆï¼‰</h1></p>
<p>            if t > 0:</p>
<p>                noise = torch.randn_like(xt)</p>
<p>                xt = xt + torch.sqrt(beta_t) * noise</p>

<p>        return xt</p>

<p><h1>ä½¿ç”¨ä¾‹</h1></p>
<p>input_dim = 128</p>
<p>condition_dim = 3  <h1>ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã€ç£æ°—ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ</h1></p>

<p>conditional_model = ConditionalDiffusionModel(input_dim, condition_dim, hidden_dim=256, num_timesteps=100)</p>

<p><h1>ç›®æ¨™ç‰¹æ€§</h1></p>
<p>target_properties = torch.tensor([</p>
<p>    [2.0, -0.5, 0.0],  <h1>ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—2.0eVã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼-0.5eVã€éç£æ€§</h1></p>
<p>    [3.5, -1.0, 2.0],  <h1>ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—3.5eVã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼-1.0eVã€ç£æ€§</h1></p>
<p>])</p>

<p><h1>æ¡ä»¶ä»˜ãç”Ÿæˆ</h1></p>
<p>generated_materials = conditional_model.generate_conditional(target_properties, input_dim)</p>
<p>print(f"Generated materials shape: {generated_materials.shape}")  <h1>(2, 128)</h1></p>
<p></code></pre></p>

<p>---</p>

<p><h2>4.4 åˆ†å­ç”Ÿæˆ: SMILESç”Ÿæˆ</h2></p>

<p><h3>æ¦‚è¦</h3></p>

<p><strong>SMILESï¼ˆSimplified Molecular Input Line Entry Systemï¼‰</strong>: åˆ†å­ã‚’æ–‡å­—åˆ—ã§è¡¨ç¾</p>

<p><strong>ä¾‹</strong>:</p>
<ul>
<li>ã‚¨ã‚¿ãƒãƒ¼ãƒ«: <code>CCO</code></li>
<li>ãƒ™ãƒ³ã‚¼ãƒ³: <code>c1ccccc1</code></li>
<li>ã‚¢ã‚¹ãƒ”ãƒªãƒ³: <code>CC(=O)Oc1ccccc1C(=O)O</code></li>
</ul>

<p><h3>Transformer-based SMILESç”Ÿæˆ</h3></p>

<p><pre><code class="language-python">from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer</p>

<p>class SMILESGenerator(nn.Module):</p>
<p>    def __init__(self, vocab_size=1000, d_model=512, num_layers=6):</p>
<p>        super(SMILESGenerator, self).__init__()</p>

<p>        <h1>GPT-2 config</h1></p>
<p>        config = GPT2Config(</p>
<p>            vocab_size=vocab_size,</p>
<p>            n_positions=512,</p>
<p>            n_embd=d_model,</p>
<p>            n_layer=num_layers,</p>
<p>            n_head=8</p>
<p>        )</p>

<p>        self.gpt = GPT2LMHeadModel(config)</p>

<p>    def forward(self, input_ids, labels=None):</p>
<p>        """</p>
<p>        Args:</p>
<p>            input_ids: (batch_size, seq_len)</p>
<p>            labels: (batch_size, seq_len) æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ</p>
<p>        """</p>
<p>        outputs = self.gpt(input_ids, labels=labels)</p>
<p>        return outputs</p>

<p>    def generate_smiles(self, start_token_id, max_length=100, temperature=1.0):</p>
<p>        """</p>
<p>        SMILESæ–‡å­—åˆ—ã‚’ç”Ÿæˆ</p>

<p>        Args:</p>
<p>            start_token_id: é–‹å§‹ãƒˆãƒ¼ã‚¯ãƒ³ID</p>
<p>            max_length: æœ€å¤§é•·</p>
<p>            temperature: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¸©åº¦ï¼ˆé«˜ã„ã»ã©ãƒ©ãƒ³ãƒ€ãƒ ï¼‰</p>
<p>        Returns:</p>
<p>            generated_ids: ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ID</p>
<p>        """</p>
<p>        generated = [start_token_id]</p>

<p>        for _ in range(max_length):</p>
<p>            input_ids = torch.tensor([generated])</p>
<p>            outputs = self.gpt(input_ids)</p>
<p>            logits = outputs.logits[:, -1, :] / temperature</p>

<p>            <h1>ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</h1></p>
<p>            probs = F.softmax(logits, dim=-1)</p>
<p>            next_token = torch.multinomial(probs, num_samples=1).item()</p>

<p>            generated.append(next_token)</p>

<p>            <h1>çµ‚äº†ãƒˆãƒ¼ã‚¯ãƒ³ãªã‚‰åœæ­¢</h1></p>
<p>            if next_token == 2:  <h1>[EOS]</h1></p>
<p>                break</p>

<p>        return generated</p>

<p><h1>æ¡ä»¶ä»˜ãSMILESç”Ÿæˆ</h1></p>
<p>class ConditionalSMILESGenerator(nn.Module):</p>
<p>    def __init__(self, vocab_size=1000, condition_dim=10, d_model=512):</p>
<p>        super(ConditionalSMILESGenerator, self).__init__()</p>

<p>        <h1>æ¡ä»¶ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€</h1></p>
<p>        self.condition_encoder = nn.Linear(condition_dim, d_model)</p>

<p>        <h1>GPT-2 config</h1></p>
<p>        config = GPT2Config(</p>
<p>            vocab_size=vocab_size,</p>
<p>            n_positions=512,</p>
<p>            n_embd=d_model,</p>
<p>            n_layer=6,</p>
<p>            n_head=8</p>
<p>        )</p>
<p>        self.gpt = GPT2LMHeadModel(config)</p>

<p>    def forward(self, input_ids, condition):</p>
<p>        """</p>
<p>        Args:</p>
<p>            input_ids: (batch_size, seq_len)</p>
<p>            condition: (batch_size, condition_dim) ç›®æ¨™ç‰¹æ€§</p>
<p>        """</p>
<p>        batch_size, seq_len = input_ids.shape</p>

<p>        <h1>æ¡ä»¶ã‚’åŸ‹ã‚è¾¼ã¿</h1></p>
<p>        condition_embed = self.condition_encoder(condition).unsqueeze(1)  <h1>(batch, 1, d_model)</h1></p>

<p>        <h1>ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿</h1></p>
<p>        token_embeddings = self.gpt.transformer.wte(input_ids)</p>

<p>        <h1>æ¡ä»¶ã‚’å…ˆé ­ã«è¿½åŠ </h1></p>
<p>        embeddings = torch.cat([condition_embed, token_embeddings], dim=1)</p>

<p>        <h1>GPT-2 forwardï¼ˆåŸ‹ã‚è¾¼ã¿ã‹ã‚‰ç›´æ¥ï¼‰</h1></p>
<p>        outputs = self.gpt(inputs_embeds=embeddings)</p>

<p>        return outputs</p>

<p><h1>ä½¿ç”¨ä¾‹: æº¶è§£åº¦ãŒé«˜ã„åˆ†å­ã‚’ç”Ÿæˆ</h1></p>
<p>condition_dim = 5  <h1>logP, æº¶è§£åº¦, åˆ†å­é‡, HBãƒ‰ãƒŠãƒ¼æ•°, HBã‚¢ã‚¯ã‚»ãƒ—ã‚¿ãƒ¼æ•°</h1></p>
<p>target_properties = torch.tensor([[1.5, 10.0, 250.0, 2.0, 3.0]])  <h1>é«˜æº¶è§£åº¦</h1></p>

<p>conditional_smiles_gen = ConditionalSMILESGenerator(vocab_size=1000, condition_dim=condition_dim)</p>
<p></code></pre></p>

<p>---</p>

<p><h2>4.5 ææ–™é€†è¨­è¨ˆã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼</h2></p>

<p><h3>å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼</h3></p>

<p><pre><code class="language-mermaid">graph TB</p>
<p>    A[ç›®æ¨™ç‰¹æ€§å®šç¾©] --> B[æ¡ä»¶ä»˜ãç”Ÿæˆãƒ¢ãƒ‡ãƒ«]</p>
<p>    B --> C[å€™è£œææ–™ç”Ÿæˆ]</p>
<p>    C --> D[ç‰¹æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«]</p>
<p>    D --> E{ç›®æ¨™é”æˆ?}</p>
<p>    E -->|No| F[å€™è£œé™¤å¤–]</p>
<p>    F --> B</p>
<p>    E -->|Yes| G[åˆæˆå¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯]</p>
<p>    G --> H{åˆæˆå¯èƒ½?}</p>
<p>    H -->|No| F</p>
<p>    H -->|Yes| I[å®‰å®šæ€§è¨ˆç®—]</p>
<p>    I --> J{å®‰å®š?}</p>
<p>    J -->|No| F</p>
<p>    J -->|Yes| K[å®Ÿé¨“å€™è£œãƒªã‚¹ãƒˆ]</p>

<p>    style A fill:#e1f5ff</p>
<p>    style K fill:#e1ffe1</p>
<p></code></pre></p>

<p><h3>å®Ÿè£…ä¾‹</h3></p>

<p><pre><code class="language-python">class MaterialsInverseDesign:</p>
<p>    def __init__(self, generator, predictor, synthesizability_checker):</p>
<p>        """</p>
<p>        ææ–™é€†è¨­è¨ˆã‚·ã‚¹ãƒ†ãƒ </p>

<p>        Args:</p>
<p>            generator: æ¡ä»¶ä»˜ãç”Ÿæˆãƒ¢ãƒ‡ãƒ«</p>
<p>            predictor: ç‰¹æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«</p>
<p>            synthesizability_checker: åˆæˆå¯èƒ½æ€§ãƒã‚§ãƒƒã‚«ãƒ¼</p>
<p>        """</p>
<p>        self.generator = generator</p>
<p>        self.predictor = predictor</p>
<p>        self.synthesizability_checker = synthesizability_checker</p>

<p>    def design_materials(self, target_properties, num_candidates=100, threshold=0.1):</p>
<p>        """</p>
<p>        ææ–™ã‚’é€†è¨­è¨ˆ</p>

<p>        Args:</p>
<p>            target_properties: ç›®æ¨™ç‰¹æ€§ (condition_dim,)</p>
<p>            num_candidates: ç”Ÿæˆã™ã‚‹å€™è£œæ•°</p>
<p>            threshold: è¨±å®¹èª¤å·®</p>
<p>        Returns:</p>
<p>            valid_materials: æ¤œè¨¼ã‚’é€šéã—ãŸææ–™ãƒªã‚¹ãƒˆ</p>
<p>        """</p>
<p>        valid_materials = []</p>

<p>        for i in range(num_candidates):</p>
<p>            <h1>1. å€™è£œç”Ÿæˆ</h1></p>
<p>            candidate = self.generator.generate_conditional(</p>
<p>                target_properties.unsqueeze(0),</p>
<p>                input_dim=128</p>
<p>            )</p>

<p>            <h1>2. ç‰¹æ€§äºˆæ¸¬</h1></p>
<p>            predicted_properties = self.predictor(candidate)</p>

<p>            <h1>3. ç›®æ¨™ã¨ã®æ¯”è¼ƒ</h1></p>
<p>            error = torch.abs(predicted_properties - target_properties).mean()</p>
<p>            if error > threshold:</p>
<p>                continue</p>

<p>            <h1>4. åˆæˆå¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯</h1></p>
<p>            if not self.synthesizability_checker(candidate):</p>
<p>                continue</p>

<p>            <h1>5. å®‰å®šæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆçœç•¥ï¼‰</h1></p>

<p>            <h1>åˆæ ¼</h1></p>
<p>            valid_materials.append({</p>
<p>                'structure': candidate,</p>
<p>                'predicted_properties': predicted_properties,</p>
<p>                'error': error.item()</p>
<p>            })</p>

<p>        <h1>èª¤å·®ã§ã‚½ãƒ¼ãƒˆ</h1></p>
<p>        valid_materials.sort(key=lambda x: x['error'])</p>

<p>        return valid_materials</p>

<p><h1>ä½¿ç”¨ä¾‹</h1></p>
<p>def simple_synthesizability_checker(structure):</p>
<p>    """</p>
<p>    ç°¡æ˜“åˆæˆå¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆå®Ÿéš›ã¯ã‚ˆã‚Šè¤‡é›‘ï¼‰</p>
<p>    """</p>
<p>    <h1>ã“ã“ã§ã¯å¸¸ã«Trueã‚’è¿”ã™ï¼ˆå®Ÿéš›ã¯Retrosynãªã©ã‚’ä½¿ç”¨ï¼‰</h1></p>
<p>    return True</p>

<p><h1>ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰</h1></p>
<p>inverse_design_system = MaterialsInverseDesign(</p>
<p>    generator=conditional_model,</p>
<p>    predictor=lambda x: torch.randn(x.size(0), 3),  <h1>ãƒ€ãƒŸãƒ¼äºˆæ¸¬å™¨</h1></p>
<p>    synthesizability_checker=simple_synthesizability_checker</p>
<p>)</p>

<p><h1>ç›®æ¨™ç‰¹æ€§</h1></p>
<p>target = torch.tensor([2.5, -0.8, 0.0])  <h1>ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã€ç£æ°—ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆ</h1></p>

<p><h1>é€†è¨­è¨ˆå®Ÿè¡Œ</h1></p>
<p>designed_materials = inverse_design_system.design_materials(target, num_candidates=50)</p>
<p>print(f"Found {len(designed_materials)} valid materials")</p>

<p><h1>ä¸Šä½3ã¤ã‚’è¡¨ç¤º</h1></p>
<p>for i, material in enumerate(designed_materials[:3]):</p>
<p>    print(f"\nMaterial {i+1}:")</p>
<p>    print(f"  Predicted properties: {material['predicted_properties']}")</p>
<p>    print(f"  Error: {material['error']:.4f}")</p>
<p></code></pre></p>

<p>---</p>

<p><h2>4.6 ç”£æ¥­å¿œç”¨ã¨ã‚­ãƒ£ãƒªã‚¢</h2></p>

<p><h3>å®Ÿä¸–ç•Œã®æˆåŠŸäº‹ä¾‹</h3></p>

<p><h4>1. å‰µè–¬: æ–°è¦æŠ—ç”Ÿç‰©è³ªã®ç™ºè¦‹</h4></p>

<p><strong>MIT (2020)</strong>:</p>
<ul>
<li><strong>æ‰‹æ³•</strong>: æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã§åˆ†å­ç”Ÿæˆ</li>
<li><strong>æˆæœ</strong>: halicinï¼ˆæ–°è¦æŠ—ç”Ÿç‰©è³ªï¼‰ç™ºè¦‹</li>
<li><strong>ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ</strong>: å¾“æ¥æ‰‹æ³•ã‚ˆã‚Š100å€é«˜é€Ÿ</li>
</ul>

<p><h4>2. é›»æ± ææ–™: é«˜ã‚¨ãƒãƒ«ã‚®ãƒ¼å¯†åº¦é›»è§£è³ª</h4></p>

<p><strong>Stanford/Toyota (2022)</strong>:</p>
<ul>
<li><strong>æ‰‹æ³•</strong>: Transformer + å¼·åŒ–å­¦ç¿’</li>
<li><strong>æˆæœ</strong>: ãƒªãƒã‚¦ãƒ ä¼å°åº¦1.5å€ã®å›ºä½“é›»è§£è³ª</li>
<li><strong>ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ</strong>: å…¨å›ºä½“é›»æ± ã®å®Ÿç”¨åŒ–åŠ é€Ÿ</li>
</ul>

<p><h4>3. è§¦åª’: COâ‚‚é‚„å…ƒè§¦åª’</h4></p>

<p><strong>CMU (2023)</strong>:</p>
<ul>
<li><strong>æ‰‹æ³•</strong>: æ¡ä»¶ä»˜ãç”Ÿæˆ + DFTè¨ˆç®—</li>
<li><strong>æˆæœ</strong>: åŠ¹ç‡10å€ã®è§¦åª’ç™ºè¦‹</li>
<li><strong>ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ</strong>: ã‚«ãƒ¼ãƒœãƒ³ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«å®Ÿç¾ã¸ã®è²¢çŒ®</li>
</ul>

<p><h3>ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹</h3></p>

<p><strong>AIææ–™è¨­è¨ˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢</strong>:</p>
<ul>
<li><strong>è·ç¨®</strong>: è£½è–¬ã€åŒ–å­¦ã€ææ–™ãƒ¡ãƒ¼ã‚«ãƒ¼ã®R&D</li>
<li><strong>å¹´å</strong>: 800-1500ä¸‡å††ï¼ˆæ—¥æœ¬ï¼‰ã€$120k-$250kï¼ˆç±³å›½ï¼‰</li>
<li><strong>å¿…è¦ã‚¹ã‚­ãƒ«</strong>: Transformerã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€ææ–™ç§‘å­¦</li>
</ul>

<p><strong>ç ”ç©¶è€…ï¼ˆã‚¢ã‚«ãƒ‡ãƒŸã‚¢ï¼‰</strong>:</p>
<ul>
<li><strong>è·ç¨®</strong>: å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã®PI</li>
<li><strong>ç ”ç©¶åˆ†é‡</strong>: AIææ–™ç§‘å­¦ã€è¨ˆç®—ææ–™ç§‘å­¦</li>
<li><strong>ç«¶äº‰åŠ›</strong>: Nature/Scienceç´šã®è«–æ–‡ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹</li>
</ul>

<p><strong>ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—å‰µæ¥­</strong>:</p>
<ul>
<li><strong>ä¾‹</strong>: Insilico Medicineï¼ˆå‰µè–¬AIï¼‰ã€Citrine Informaticsï¼ˆææ–™AIï¼‰</li>
<li><strong>è³‡é‡‘èª¿é”</strong>: ã‚·ãƒªãƒ¼ã‚ºAã€œCã€æ•°å„„ã€œæ•°åå„„å††</li>
<li><strong>æˆåŠŸä¾‹</strong>: IPOã€å¤§æ‰‹ä¼æ¥­ã¸ã®è²·å</li>
</ul>

<p>---</p>

<p><h2>4.7 ã¾ã¨ã‚</h2></p>

<p><h3>é‡è¦ãƒã‚¤ãƒ³ãƒˆ</h3></p>

<ol>
<li><strong>æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«</strong>: ãƒã‚¤ã‚ºã‹ã‚‰é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ</li>
<li><strong>æ¡ä»¶ä»˜ãç”Ÿæˆ</strong>: ç›®æ¨™ç‰¹æ€§ã‚’æŒ‡å®šã—ã¦ææ–™è¨­è¨ˆ</li>
<li><strong>SMILESç”Ÿæˆ</strong>: Transformerã§åˆ†å­æ§‹é€ ã‚’ç”Ÿæˆ</li>
<li><strong>é€†è¨­è¨ˆ</strong>: ç‰¹æ€§ã‹ã‚‰æ§‹é€ ã¸ã®é€†å‘ãæ¢ç´¢</li>
<li><strong>ç”£æ¥­å¿œç”¨</strong>: å‰µè–¬ã€é›»æ± ã€è§¦åª’ã§å®Ÿç”¨åŒ–é€²ã‚€</li>
</ol>

<p><h3>ã‚·ãƒªãƒ¼ã‚ºã®ã¾ã¨ã‚</h3></p>

<p><strong>ç¬¬1ç« </strong>: TransformeråŸºç¤ã€Attentionæ©Ÿæ§‹</p>
<p><strong>ç¬¬2ç« </strong>: ææ–™ç‰¹åŒ–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆMatformerã€ChemBERTaï¼‰</p>
<p><strong>ç¬¬3ç« </strong>: äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€è»¢ç§»å­¦ç¿’</p>
<p><strong>ç¬¬4ç« </strong>: ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€é€†è¨­è¨ˆ</p>

<p><strong>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</strong>:</p>
<ol>
<li>å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§çµŒé¨“ã‚’ç©ã‚€</li>
<li>æœ€æ–°è«–æ–‡ã‚’èª­ã‚“ã§çŸ¥è­˜ã‚’æ›´æ–°</li>
<li>Kaggleã‚³ãƒ³ãƒšã«å‚åŠ ã—ã¦å®ŸåŠ›ã‚’è©¦ã™</li>
<li>ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‚åŠ ã—ã¦æƒ…å ±äº¤æ›</li>
</ol>

<p>---</p>

<p><h2>ğŸ“ æ¼”ç¿’å•é¡Œ</h2></p>

<p><h3>å•é¡Œ1: æ¦‚å¿µç†è§£</h3></p>
<p>æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ãŒå¾“æ¥ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ï¼ˆVAEã€GANï¼‰ã¨æ¯”ã¹ã¦å„ªã‚Œã¦ã„ã‚‹ç‚¹ã‚’3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚</p>

<p><details></p>
<p><summary>è§£ç­”ä¾‹</summary></p>

<ol>
<li><strong>å­¦ç¿’ã®å®‰å®šæ€§</strong>: GANã®ã‚ˆã†ãªmode collapseãŒèµ·ã“ã‚Šã«ãã„</li>
<li><strong>ã‚µãƒ³ãƒ—ãƒ«å“è³ª</strong>: é«˜å“è³ªã§å¤šæ§˜ãªã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆå¯èƒ½</li>
<li><strong>æŸ”è»Ÿãªæ¡ä»¶ä»˜ã‘</strong>: æ§˜ã€…ãªæ¡ä»¶ï¼ˆç‰¹æ€§ã€åˆ¶ç´„ï¼‰ã‚’å®¹æ˜“ã«çµ„ã¿è¾¼ã‚ã‚‹</li>
</ol>

<p>è¿½åŠ :</p>
<ul>
<li><strong>è§£é‡ˆæ€§</strong>: ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ãŒæ®µéšçš„ã§ç†è§£ã—ã‚„ã™ã„</li>
<li><strong>ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£</strong>: å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã‚‚åŠ¹ç‡çš„ã«å­¦ç¿’</li>
</ul>
<p></details></p>

<p><h3>å•é¡Œ2: å®Ÿè£…</h3></p>
<p>æ¡ä»¶ä»˜ãç”Ÿæˆã§ã€è¤‡æ•°ã®ç›®æ¨™ç‰¹æ€§ï¼ˆãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã€å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰ã‚’åŒæ™‚ã«æº€ãŸã™ææ–™ã‚’ç”Ÿæˆã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚</p>

<p><pre><code class="language-python">def multi_objective_generation(generator, target_bandgap, target_formation_energy, num_samples=10):</p>
<p>    """</p>
<p>    å¤šç›®çš„æœ€é©åŒ–ã§ææ–™ã‚’ç”Ÿæˆ</p>

<p>    Args:</p>
<p>        generator: æ¡ä»¶ä»˜ãç”Ÿæˆãƒ¢ãƒ‡ãƒ«</p>
<p>        target_bandgap: ç›®æ¨™ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ï¼ˆeVï¼‰</p>
<p>        target_formation_energy: ç›®æ¨™å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆeV/atomï¼‰</p>
<p>        num_samples: ç”Ÿæˆæ•°</p>
<p>    Returns:</p>
<p>        generated_materials: ç”Ÿæˆã•ã‚ŒãŸææ–™ã®ãƒªã‚¹ãƒˆ</p>
<p>    """</p>
<p>    <h1>ã“ã“ã«å®Ÿè£…</h1></p>
<p>    pass</p>
<p></code></pre></p>

<p><details></p>
<p><summary>è§£ç­”ä¾‹</summary></p>

<p><pre><code class="language-python">def multi_objective_generation(generator, target_bandgap, target_formation_energy, num_samples=10):</p>
<p>    <h1>æ¡ä»¶ã‚’ä½œæˆ</h1></p>
<p>    condition = torch.tensor([[target_bandgap, target_formation_energy]])</p>
<p>    condition = condition.repeat(num_samples, 1)</p>

<p>    <h1>ç”Ÿæˆ</h1></p>
<p>    generated_materials = generator.generate_conditional(condition, input_dim=128)</p>

<p>    return generated_materials</p>

<p><h1>ä½¿ç”¨ä¾‹</h1></p>
<p>target_bg = 2.0  <h1>2.0 eV</h1></p>
<p>target_fe = -0.5  <h1>-0.5 eV/atom</h1></p>

<p>materials = multi_objective_generation(conditional_model, target_bg, target_fe, num_samples=20)</p>
<p>print(f"Generated {materials.shape[0]} materials")</p>
<p></code></pre></p>
<p></details></p>

<p><h3>å•é¡Œ3: å¿œç”¨</h3></p>
<p>ææ–™é€†è¨­è¨ˆã«ãŠã„ã¦ã€ç”Ÿæˆã•ã‚ŒãŸå€™è£œææ–™ã‚’è©•ä¾¡ã™ã‚‹éš›ã®é‡è¦ãªåŸºæº–ã‚’5ã¤æŒ™ã’ã€ãã‚Œãã‚Œã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚</p>

<p><details></p>
<p><summary>è§£ç­”ä¾‹</summary></p>

<ol>
<li><strong>ç›®æ¨™ç‰¹æ€§ã®é”æˆåº¦</strong>:</li>
</ol>
<p>   - äºˆæ¸¬ç‰¹æ€§ãŒç›®æ¨™å€¤ã«ã©ã‚Œã ã‘è¿‘ã„ã‹</p>
<p>   - è¤‡æ•°ç‰¹æ€§ã®å ´åˆã€ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©æ€§</p>

<ol>
<li><strong>åˆæˆå¯èƒ½æ€§</strong>:</li>
</ol>
<p>   - æ—¢çŸ¥ã®åˆæˆæ‰‹æ³•ã§ä½œè£½å¯èƒ½ã‹</p>
<p>   - å‰é§†ä½“ã®å…¥æ‰‹å¯èƒ½æ€§</p>
<p>   - åˆæˆæ¡ä»¶ï¼ˆæ¸©åº¦ã€åœ§åŠ›ï¼‰ã®å®Ÿç¾å¯èƒ½æ€§</p>

<ol>
<li><strong>ç†±åŠ›å­¦çš„å®‰å®šæ€§</strong>:</li>
</ol>
<p>   - å½¢æˆã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒè² ï¼ˆå®‰å®šç›¸ï¼‰</p>
<p>   - ä»–ã®çµæ™¶æ§‹é€ ã¨æ¯”è¼ƒã—ã¦æœ€å®‰å®š</p>
<p>   - åˆ†è§£åå¿œã«å¯¾ã™ã‚‹å®‰å®šæ€§</p>

<ol>
<li><strong>åŒ–å­¦çš„å¦¥å½“æ€§</strong>:</li>
</ol>
<p>   - åŸå­ä¾¡å‰‡ã‚’æº€ãŸã™</p>
<p>   - çµåˆè·é›¢ãƒ»è§’åº¦ãŒå¦¥å½“</p>
<p>   - æ—¢çŸ¥ã®åŒ–å­¦ç³»ã¨æ•´åˆ</p>

<ol>
<li><strong>ã‚³ã‚¹ãƒˆã¨ç’°å¢ƒè² è·</strong>:</li>
</ol>
<p>   - æ§‹æˆå…ƒç´ ã®ä¾¡æ ¼ã¨åŸ‹è”µé‡</p>
<p>   - æœ‰å®³å…ƒç´ ï¼ˆCdã€Pbç­‰ï¼‰ã®ä½¿ç”¨</p>
<p>   - ãƒªã‚µã‚¤ã‚¯ãƒ«å¯èƒ½æ€§</p>
<p></details></p>

<p>---</p>

<p><h2>ğŸ“ ã‚·ãƒªãƒ¼ã‚ºå®Œäº†ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼</h2></p>

<p>ã“ã®ã‚·ãƒªãƒ¼ã‚ºã‚’å®Œäº†ã—ãŸã‚ãªãŸã¯ã€Transformerã¨ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®åŸºç¤ã‹ã‚‰å¿œç”¨ã¾ã§ã€ææ–™ç§‘å­¦ã§ã®æ´»ç”¨æ–¹æ³•ã‚’ç¿’å¾—ã—ã¾ã—ãŸã€‚</p>

<p><h3>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h3></p>

<ol>
<li><strong>å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</strong>:</li>
</ol>
<p>   - Materials Projectãƒ‡ãƒ¼ã‚¿ã§ææ–™ç‰¹æ€§äºˆæ¸¬</p>
<p>   - QM9ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§åˆ†å­ç”Ÿæˆ</p>
<p>   - ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°</p>

<ol>
<li><strong>è«–æ–‡å®Ÿè£…</strong>:</li>
</ol>
<p>   - Matformerè«–æ–‡ã‚’èª­ã‚“ã§å®Ÿè£…</p>
<p>   - æœ€æ–°ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«è«–æ–‡ã«æŒ‘æˆ¦</p>

<ol>
<li><strong>ã‚³ãƒ³ãƒšãƒ†ã‚£ãƒ¼ã‚·ãƒ§ãƒ³</strong>:</li>
</ol>
<p>   - Open Catalyst Challenge</p>
<p>   - Kaggleã®åˆ†å­äºˆæ¸¬ã‚³ãƒ³ãƒš</p>

<ol>
<li><strong>ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å‚åŠ </strong>:</li>
</ol>
<p>   - Hugging Face Forum</p>
<p>   - Materials Project Community</p>
<p>   - ææ–™ç§‘å­¦ã®ã‚«ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ï¼ˆMRSã€APSï¼‰</p>

<p>---</p>

<p><h2>ğŸ”— å‚è€ƒè³‡æ–™</h2></p>

<p><h3>è«–æ–‡</h3></p>
<ul>
<li>Ho et al. (2020) "Denoising Diffusion Probabilistic Models"</li>
<li>Chen et al. (2022) "Matformer: Nested Transformer for Elastic Inference"</li>
<li>Xie et al. (2021) "Crystal Diffusion Variational Autoencoder"</li>
<li>Stokes et al. (2020) "A Deep Learning Approach to Antibiotic Discovery" (Nature)</li>
</ul>

<p><h3>ãƒ„ãƒ¼ãƒ«</h3></p>
<ul>
<li><a href="https://github.com/huggingface/diffusers">Hugging Face Diffusers</a></li>
<li><a href="https://www.rdkit.org/">RDKit</a> - åˆ†å­å‡¦ç†</li>
<li><a href="https://materialsproject.org/">Materials Project API</a></li>
</ul>

<p><h3>æ¬¡ã®ã‚·ãƒªãƒ¼ã‚º</h3></p>
<ul>
<li><strong>å¼·åŒ–å­¦ç¿’å…¥é–€</strong>: ææ–™æ¢ç´¢ã¸ã®å¼·åŒ–å­¦ç¿’é©ç”¨</li>
<li><strong>GNNå…¥é–€</strong>: ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§åˆ†å­ãƒ»ææ–™è¡¨ç¾</li>
</ul>

<p>---</p>

<p><strong>ä½œæˆè€…</strong>: æ©‹æœ¬ä½‘ä»‹ï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
<p><strong>æœ€çµ‚æ›´æ–°</strong>: 2025å¹´10æœˆ17æ—¥</p>
<p><strong>ã‚·ãƒªãƒ¼ã‚º</strong>: Transformerãƒ»Foundation Modelså…¥é–€ï¼ˆå…¨4ç« å®Œï¼‰</p>

<p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: CC BY 4.0</p>


        
        <div class="navigation">
            <a href="chapter-5.html" class="nav-button">æ¬¡ç« : ç¬¬5ç«  â†’</a>
            <a href="index.html" class="nav-button">â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
            <a href="chapter-3.html" class="nav-button">â† å‰ç« : ç¬¬3ç« </a>
        </div>
    
    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimoto(æ±åŒ—å¤§å­¦)</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-17</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default'
                });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</body>
</html>