<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>第3章：ジョブスケジューリングと並列化（SLURM, PBS） - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>第3章：ジョブスケジューリングと並列化（SLURM, PBS）</h1>
            
            <div class="meta">
                <span class="meta-item">📖 読了時間: 25-30分</span>
<span class="meta-item">📊 難易度: 上級</span>
            </div>
        </div>
    </header>

    <main class="container">
        <h1>第3章：ジョブスケジューリングと並列化（SLURM, PBS）</h1>

<h2>学習目標</h2>

<p>この章を読むことで、以下を習得できます：</p>

<ul>
<li>✅ SLURMスクリプトを作成してジョブを投入できる</li>
<li>✅ MPI並列計算の効率を評価できる</li>
<li>✅ Pythonでジョブ管理スクリプトを書ける</li>
<li>✅ 1000材料規模の並列計算を設計できる</li>
<li>✅ ベンチマークによるチューニングができる</li>
</ul>

<p>---</p>

<h2>3.1 ジョブスケジューラの基礎</h2>

<h3>SLURM vs PBS vs Torque</h3>

<p>| 特徴 | SLURM | PBS Pro | Torque |</p>
<p>|-----|-------|---------|--------|</p>
<p>| 開発元 | SchedMD | Altair | Adaptive Computing |</p>
<p>| ライセンス | GPL（一部商用） | 商用 | オープンソース |</p>
<p>| 採用例 | TSUBAME、TOP500の多く | NASA、DOE国立研究所 | 多くの大学 |</p>
<p>| コマンド | <code>sbatch</code>, <code>squeue</code> | <code>qsub</code>, <code>qstat</code> | <code>qsub</code>, <code>qstat</code> |</p>
<p>| 推奨用途 | 大規模HPC | エンタープライズ | 中小規模HPC |</p>

<h3>SLURMの基本概念</h3>

<pre><code class="language-mermaid">graph TD
<p>A[ユーザー] -->|sbatch| B[ジョブキュー]</p>
<p>B --> C{スケジューラ}</p>
<p>C -->|リソース割当| D[計算ノード1]</p>
<p>C -->|リソース割当| E[計算ノード2]</p>
<p>C -->|リソース割当| F[計算ノードN]</p>

<p>D --> G[ジョブ完了]</p>
<p>E --> G</p>
<p>F --> G</p>

<p>style C fill:#4ecdc4</p>
</code></pre>

<strong>主要コマンド</strong>:

<pre><code class="language-bash"><h1>ジョブ投入</h1>
<p>sbatch job.sh</p>

<h1>ジョブ状態確認</h1>
<p>squeue -u username</p>

<h1>ジョブキャンセル</h1>
<p>scancel job_id</p>

<h1>ノード情報</h1>
<p>sinfo</p>

<h1>ジョブ詳細</h1>
<p>scontrol show job job_id</p>
</code></pre>

<p>---</p>

<h2>3.2 SLURMスクリプト作成</h2>

<h3>基本的なSLURMスクリプト</h3>

<pre><code class="language-bash">#!/bin/bash
<p>#SBATCH --job-name=vasp_relax       # ジョブ名</p>
<p>#SBATCH --output=slurm-%j.out       # 標準出力（%j=ジョブID）</p>
<p>#SBATCH --error=slurm-%j.err        # 標準エラー</p>
<p>#SBATCH --nodes=1                   # ノード数</p>
<p>#SBATCH --ntasks-per-node=48        # ノードあたりMPIプロセス数</p>
<p>#SBATCH --cpus-per-task=1           # タスクあたりスレッド数</p>
<p>#SBATCH --time=24:00:00             # 時間制限（24時間）</p>
<p>#SBATCH --partition=standard        # パーティション（キュー）</p>
<p>#SBATCH --account=project_name      # プロジェクト名</p>

<h1>環境設定</h1>
<p>module purge</p>
<p>module load intel/2021.2</p>
<p>module load vasp/6.3.0</p>

<h1>作業ディレクトリ</h1>
<p>cd $SLURM_SUBMIT_DIR</p>

<h1>VASP実行</h1>
<p>echo "ジョブ開始: $(date)"</p>
<p>echo "ホスト: $(hostname)"</p>
<p>echo "ノード数: $SLURM_JOB_NUM_NODES"</p>
<p>echo "プロセス数: $SLURM_NTASKS"</p>

<p>mpirun -np $SLURM_NTASKS vasp_std</p>

<p>echo "ジョブ終了: $(date)"</p>
</code></pre>

<h3>アレイジョブによる並列実行</h3>

<strong>100材料を並列計算</strong>:

<pre><code class="language-bash">#!/bin/bash
<p>#SBATCH --job-name=vasp_array</p>
<p>#SBATCH --output=logs/slurm-%A_%a.out  # %A=アレイジョブID, %a=タスクID</p>
<p>#SBATCH --error=logs/slurm-%A_%a.err</p>
<p>#SBATCH --nodes=1</p>
<p>#SBATCH --ntasks-per-node=48</p>
<p>#SBATCH --time=24:00:00</p>
<p>#SBATCH --array=1-100%10              # 1-100のタスク、同時10個まで</p>

<h1>環境設定</h1>
<p>module load vasp/6.3.0</p>

<h1>材料リスト読み込み</h1>
<p>MATERIAL_LIST="materials.txt"</p>
<p>MATERIAL=$(sed -n "${SLURM_ARRAY_TASK_ID}p" $MATERIAL_LIST)</p>

<p>echo "処理中: タスクID=${SLURM_ARRAY_TASK_ID}, 材料=${MATERIAL}"</p>

<h1>作業ディレクトリ</h1>
<p>WORK_DIR="calculations/${MATERIAL}"</p>
<p>cd $WORK_DIR</p>

<h1>VASP実行</h1>
<p>mpirun -np 48 vasp_std</p>

<h1>収束チェック</h1>
<p>if grep -q "reached required accuracy" OUTCAR; then</p>
<p>echo "SUCCESS: ${MATERIAL}" >> ../completed.log</p>
<p>else</p>
<p>echo "FAILED: ${MATERIAL}" >> ../failed.log</p>
<p>fi</p>
</code></pre>

<strong>materials.txt</strong>の例:
<pre><code class="language-">LiCoO2
<p>LiNiO2</p>
<p>LiMnO2</p>
<p>LiFePO4</p>
<p>...（100行）</p>
</code></pre>

<h3>依存関係のあるジョブチェーン</h3>

<pre><code class="language-bash"><h1>Step 1: 構造最適化</h1>
<p>JOB1=$(sbatch --parsable relax.sh)</p>
<p>echo "構造最適化ジョブID: $JOB1"</p>

<h1>Step 2: 静的計算（構造最適化後に実行）</h1>
<p>JOB2=$(sbatch --parsable --dependency=afterok:$JOB1 static.sh)</p>
<p>echo "静的計算ジョブID: $JOB2"</p>

<h1>Step 3: バンド構造（静的計算後に実行）</h1>
<p>JOB3=$(sbatch --parsable --dependency=afterok:$JOB2 band.sh)</p>
<p>echo "バンド構造ジョブID: $JOB3"</p>

<h1>Step 4: データ解析（全て完了後）</h1>
<p>sbatch --dependency=afterok:$JOB3 analysis.sh</p>
</code></pre>

<p>---</p>

<h2>3.3 MPIによる並列計算</h2>

<h3>並列化の種類</h3>

<pre><code class="language-python"><h1>1. タスク並列（推奨：ハイスループット計算）</h1>
<h1>100材料を100ノードで同時計算</h1>
<h1>スケーリング効率: 100%</h1>

<h1>2. データ並列（VASP: KPAR設定）</h1>
<h1>k-pointを4グループに分割</h1>
<p>INCAR: KPAR = 4</p>
<h1>スケーリング効率: 80-90%</h1>

<h1>3. MPI並列（プロセス間通信）</h1>
<h1>1計算を48コアで分散</h1>
<p>mpirun -np 48 vasp_std</p>
<h1>スケーリング効率: 50-70%</h1>
</code></pre>

<h3>スケーリング効率の測定</h3>

<pre><code class="language-python">import subprocess
<p>import time</p>
<p>import numpy as np</p>
<p>import matplotlib.pyplot as plt</p>

<p>def benchmark_scaling(structure, core_counts=[1, 2, 4, 8, 16, 32, 48]):</p>
<p>"""</p>
<p>並列化効率をベンチマーク</p>

<p>Parameters:</p>
<p>-----------</p>
<p>structure : str</p>
<p>テスト構造</p>
<p>core_counts : list</p>
<p>テストするコア数</p>

<p>Returns:</p>
<p>--------</p>
<p>efficiency : dict</p>
<p>コア数ごとの効率</p>
<p>"""</p>
<p>timings = {}</p>

<p>for n_cores in core_counts:</p>
<p># VASP実行</p>
<p>start = time.time()</p>

<p>result = subprocess.run(</p>
<p>[f"mpirun -np {n_cores} vasp_std"],</p>
<p>shell=True,</p>
<p>cwd=f"benchmark_{n_cores}cores"</p>
<p>)</p>

<p>elapsed = time.time() - start</p>
<p>timings[n_cores] = elapsed</p>

<p>print(f"{n_cores}コア: {elapsed:.1f}秒")</p>

<p># 効率計算</p>
<p>base_time = timings[1]</p>
<p>efficiency = {}</p>

<p>for n_cores, t in timings.items():</p>
<p>ideal_time = base_time / n_cores</p>
<p>actual_speedup = base_time / t</p>
<p>ideal_speedup = n_cores</p>

<p>eff = (actual_speedup / ideal_speedup) * 100</p>
<p>efficiency[n_cores] = eff</p>

<p>return efficiency, timings</p>

<h1>結果プロット</h1>
<p>def plot_scaling(efficiency, timings):</p>
<p>fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))</p>

<p>cores = list(timings.keys())</p>
<p>times = list(timings.values())</p>
<p>effs = [efficiency[c] for c in cores]</p>

<p># スピードアップ</p>
<p>ax1.plot(cores, [timings[1]/t for t in times], 'o-', label='実測')</p>
<p>ax1.plot(cores, cores, '--', label='理想（線形）')</p>
<p>ax1.set_xlabel('コア数')</p>
<p>ax1.set_ylabel('スピードアップ')</p>
<p>ax1.set_xscale('log', base=2)</p>
<p>ax1.set_yscale('log', base=2)</p>
<p>ax1.legend()</p>
<p>ax1.grid(True)</p>

<p># 効率</p>
<p>ax2.plot(cores, effs, 'o-', color='green')</p>
<p>ax2.axhline(y=80, color='red', linestyle='--', label='80%目標')</p>
<p>ax2.set_xlabel('コア数')</p>
<p>ax2.set_ylabel('並列化効率 (%)')</p>
<p>ax2.set_xscale('log', base=2)</p>
<p>ax2.legend()</p>
<p>ax2.grid(True)</p>

<p>plt.tight_layout()</p>
<p>plt.savefig('scaling_benchmark.png', dpi=300)</p>
<p>plt.show()</p>
</code></pre>

<h3>VASPの並列化パラメータ最適化</h3>

<pre><code class="language-python">def optimize_vasp_parallelization(n_kpoints, n_bands, n_cores=48):
<p>"""</p>
<p>VASP並列化パラメータの最適化</p>

<p>Parameters:</p>
<p>-----------</p>
<p>n_kpoints : int</p>
<p>k-point数</p>
<p>n_bands : int</p>
<p>バンド数</p>
<p>n_cores : int</p>
<p>利用可能なコア数</p>

<p>Returns:</p>
<p>--------</p>
<p>params : dict</p>
<p>最適パラメータ</p>
<p>"""</p>
<p># KPAR: k-point並列（最も効率的）</p>
<p># 2の累乗で、k-point数の約数</p>
<p>kpar_options = [1, 2, 4, 8, 16]</p>
<p>valid_kpar = [k for k in kpar_options if n_kpoints % k == 0 and k <= n_cores]</p>

<p># NCORE: バンド並列</p>
<p># 通常4-8が最適</p>
<p>ncore = min(4, n_cores // max(valid_kpar))</p>

<p># 推奨設定</p>
<p>recommended = {</p>
<p>'KPAR': max(valid_kpar),</p>
<p>'NCORE': ncore,</p>
<p>'cores_per_kpar_group': n_cores // max(valid_kpar),</p>
<p>}</p>

<p>print("並列化パラメータ推奨値:")</p>
<p>print(f"  KPAR = {recommended['KPAR']} (k-point並列)")</p>
<p>print(f"  NCORE = {recommended['NCORE']} (バンド並列)")</p>
<p>print(f"  1 KPARグループあたり{recommended['cores_per_kpar_group']}コア")</p>

<p>return recommended</p>

<h1>使用例</h1>
<p>params = optimize_vasp_parallelization(n_kpoints=64, n_bands=200, n_cores=48)</p>
<h1>推奨:</h1>
<h1>  KPAR = 16 (k-point並列)</h1>
<h1>  NCORE = 3 (バンド並列)</h1>
<h1>  1 KPARグループあたり3コア</h1>
</code></pre>

<p>---</p>

<h2>3.4 Pythonによるジョブ管理</h2>

<h3>ジョブ投入と監視</h3>

<pre><code class="language-python">import subprocess
<p>import time</p>
<p>import re</p>

<p>class SLURMJobManager:</p>
<p>"""SLURMジョブ管理クラス"""</p>

<p>def submit_job(self, script_path):</p>
<p>"""</p>
<p>ジョブを投入</p>

<p>Returns:</p>
<p>--------</p>
<p>job_id : int</p>
<p>ジョブID</p>
<p>"""</p>
<p>result = subprocess.run(</p>
<p>['sbatch', script_path],</p>
<p>capture_output=True,</p>
<p>text=True</p>
<p>)</p>

<p># "Submitted batch job 12345"からIDを抽出</p>
<p>match = re.search(r'(\d+)', result.stdout)</p>
<p>if match:</p>
<p>job_id = int(match.group(1))</p>
<p>print(f"ジョブ投入: ID={job_id}")</p>
<p>return job_id</p>
<p>else:</p>
<p>raise RuntimeError(f"ジョブ投入失敗: {result.stderr}")</p>

<p>def get_job_status(self, job_id):</p>
<p>"""</p>
<p>ジョブ状態を取得</p>

<p>Returns:</p>
<p>--------</p>
<p>status : str</p>
<p>'PENDING', 'RUNNING', 'COMPLETED', 'FAILED', 'CANCELLED'</p>
<p>"""</p>
<p>result = subprocess.run(</p>
<p>['squeue', '-j', str(job_id), '-h', '-o', '%T'],</p>
<p>capture_output=True,</p>
<p>text=True</p>
<p>)</p>

<p>if result.stdout.strip():</p>
<p>return result.stdout.strip()</p>
<p>else:</p>
<p># キューにない → 完了または失敗</p>
<p>result = subprocess.run(</p>
<p>['sacct', '-j', str(job_id), '-X', '-n', '-o', 'State'],</p>
<p>capture_output=True,</p>
<p>text=True</p>
<p>)</p>
<p>return result.stdout.strip()</p>

<p>def wait_for_completion(self, job_id, check_interval=60):</p>
<p>"""</p>
<p>ジョブ完了を待機</p>

<p>Parameters:</p>
<p>-----------</p>
<p>job_id : int</p>
<p>ジョブID</p>
<p>check_interval : int</p>
<p>チェック間隔（秒）</p>
<p>"""</p>
<p>while True:</p>
<p>status = self.get_job_status(job_id)</p>

<p>if status in ['COMPLETED', 'FAILED', 'CANCELLED']:</p>
<p>print(f"ジョブ{job_id}: {status}")</p>
<p>return status</p>

<p>print(f"ジョブ{job_id}: {status}...待機中")</p>
<p>time.sleep(check_interval)</p>

<p>def submit_array_job(self, script_path, n_tasks, max_concurrent=10):</p>
<p>"""</p>
<p>アレイジョブを投入</p>

<p>Parameters:</p>
<p>-----------</p>
<p>n_tasks : int</p>
<p>タスク数</p>
<p>max_concurrent : int</p>
<p>同時実行数</p>
<p>"""</p>
<p>result = subprocess.run(</p>
<p>['sbatch', f'--array=1-{n_tasks}%{max_concurrent}', script_path],</p>
<p>capture_output=True,</p>
<p>text=True</p>
<p>)</p>

<p>match = re.search(r'(\d+)', result.stdout)</p>
<p>if match:</p>
<p>job_id = int(match.group(1))</p>
<p>print(f"アレイジョブ投入: ID={job_id}, タスク数={n_tasks}")</p>
<p>return job_id</p>
<p>else:</p>
<p>raise RuntimeError(f"投入失敗: {result.stderr}")</p>

<h1>使用例</h1>
<p>manager = SLURMJobManager()</p>

<h1>単一ジョブ</h1>
<p>job_id = manager.submit_job('relax.sh')</p>
<p>status = manager.wait_for_completion(job_id)</p>

<h1>アレイジョブ</h1>
<p>array_id = manager.submit_array_job('array_job.sh', n_tasks=100, max_concurrent=20)</p>
</code></pre>

<h3>大規模ジョブ管理（1000材料）</h3>

<pre><code class="language-python">import os
<p>from pathlib import Path</p>
<p>import json</p>

<p>def manage_large_scale_calculation(materials, batch_size=100):</p>
<p>"""</p>
<p>1000材料を効率的に管理</p>

<p>Parameters:</p>
<p>-----------</p>
<p>materials : list</p>
<p>材料のリスト</p>
<p>batch_size : int</p>
<p>バッチサイズ</p>
<p>"""</p>
<p>manager = SLURMJobManager()</p>
<p>n_materials = len(materials)</p>

<p>print(f"総材料数: {n_materials}")</p>
<p>print(f"バッチサイズ: {batch_size}")</p>

<p># バッチに分割</p>
<p>n_batches = (n_materials + batch_size - 1) // batch_size</p>
<p>print(f"バッチ数: {n_batches}")</p>

<p>job_ids = []</p>

<p>for batch_idx in range(n_batches):</p>
<p>start_idx = batch_idx * batch_size</p>
<p>end_idx = min((batch_idx + 1) * batch_size, n_materials)</p>
<p>batch_materials = materials[start_idx:end_idx]</p>

<p>print(f"\nバッチ {batch_idx+1}/{n_batches}")</p>
<p>print(f"  材料数: {len(batch_materials)}")</p>

<p># バッチ用材料リスト作成</p>
<p>list_file = f"batch_{batch_idx+1}_materials.txt"</p>
<p>with open(list_file, 'w') as f:</p>
<p>for mat in batch_materials:</p>
<p>f.write(f"{mat}\n")</p>

<p># アレイジョブ投入</p>
<p>job_id = manager.submit_array_job(</p>
<p>'vasp_array.sh',</p>
<p>n_tasks=len(batch_materials),</p>
<p>max_concurrent=20</p>
<p>)</p>

<p>job_ids.append(job_id)</p>

<p># 進捗監視</p>
<p>print("\n進捗監視中...")</p>
<p>completed = 0</p>

<p>while completed < len(job_ids):</p>
<p>time.sleep(300)  # 5分ごとにチェック</p>

<p>for i, job_id in enumerate(job_ids):</p>
<p>status = manager.get_job_status(job_id)</p>

<p>if status == 'COMPLETED' and i not in completed_jobs:</p>
<p>completed += 1</p>
<p>print(f"バッチ {i+1} 完了 ({completed}/{len(job_ids)})")</p>

<p>print("全バッチ完了！")</p>

<h1>使用例</h1>
<p>materials = [f"material_{i:04d}" for i in range(1, 1001)]</p>
<p>manage_large_scale_calculation(materials, batch_size=100)</p>
</code></pre>

<p>---</p>

<h2>3.5 演習問題</h2>

<h3>問題1（難易度: easy）</h3>

<strong>問題</strong>: 以下の条件でSLURMスクリプトを作成してください：

<ul>
<li>ジョブ名: <code>si_bandgap</code></li>
<li>ノード数: 2</li>
<li>ノードあたりプロセス数: 24</li>
<li>時間制限: 12時間</li>
<li>パーティション: <code>gpu</code></li>
</ul>

<details>
<summary>解答例</summary>

<pre><code class="language-bash">#!/bin/bash
<p>#SBATCH --job-name=si_bandgap</p>
<p>#SBATCH --output=slurm-%j.out</p>
<p>#SBATCH --error=slurm-%j.err</p>
<p>#SBATCH --nodes=2</p>
<p>#SBATCH --ntasks-per-node=24</p>
<p>#SBATCH --time=12:00:00</p>
<p>#SBATCH --partition=gpu</p>

<p>module load vasp/6.3.0</p>

<p>cd $SLURM_SUBMIT_DIR</p>

<p>mpirun -np 48 vasp_std</p>
</code></pre>

</details>

<h3>問題2（難易度: medium）</h3>

<strong>問題</strong>: 50個の構造最適化計算を、10個ずつ同時実行するアレイジョブを作成してください。

<details>
<summary>解答例</summary>

<pre><code class="language-bash">#!/bin/bash
<p>#SBATCH --job-name=relax_array</p>
<p>#SBATCH --output=logs/slurm-%A_%a.out</p>
<p>#SBATCH --error=logs/slurm-%A_%a.err</p>
<p>#SBATCH --nodes=1</p>
<p>#SBATCH --ntasks-per-node=48</p>
<p>#SBATCH --time=24:00:00</p>
<p>#SBATCH --array=1-50%10</p>

<p>module load vasp/6.3.0</p>

<p>MATERIAL=$(sed -n "${SLURM_ARRAY_TASK_ID}p" materials.txt)</p>

<p>cd calculations/${MATERIAL}</p>

<p>mpirun -np 48 vasp_std</p>
</code></pre>

</details>

<h3>問題3（難易度: hard）</h3>

<strong>問題</strong>: Pythonで、1000材料のVASP計算を管理するスクリプトを作成してください。要件：

<ol>
<li>50材料ずつバッチ処理</li>
<li>各バッチは20タスク同時実行</li>
<li>完了・失敗をログ記録</li>
<li>失敗したタスクを自動リトライ</li>
</ol>

<details>
<summary>解答例</summary>

<pre><code class="language-python">import os
<p>import time</p>
<p>import json</p>
<p>from pathlib import Path</p>

<p>class HighThroughputManager:</p>
<p>def __init__(self, materials, batch_size=50, max_concurrent=20):</p>
<p>self.materials = materials</p>
<p>self.batch_size = batch_size</p>
<p>self.max_concurrent = max_concurrent</p>
<p>self.manager = SLURMJobManager()</p>

<p>self.results = {</p>
<p>'completed': [],</p>
<p>'failed': [],</p>
<p>'retry': []</p>
<p>}</p>

<p>def run_batch(self, batch_materials, batch_id):</p>
<p>"""バッチ実行"""</p>
<p># 材料リスト作成</p>
<p>list_file = f"batch_{batch_id}.txt"</p>
<p>with open(list_file, 'w') as f:</p>
<p>for mat in batch_materials:</p>
<p>f.write(f"{mat}\n")</p>

<p># ジョブ投入</p>
<p>job_id = self.manager.submit_array_job(</p>
<p>'vasp_array.sh',</p>
<p>n_tasks=len(batch_materials),</p>
<p>max_concurrent=self.max_concurrent</p>
<p>)</p>

<p># 完了待ち</p>
<p>status = self.manager.wait_for_completion(job_id)</p>

<p># 結果チェック</p>
<p>self.check_results(batch_materials, batch_id)</p>

<p>def check_results(self, batch_materials, batch_id):</p>
<p>"""結果確認"""</p>
<p>for mat in batch_materials:</p>
<p>outcar = f"calculations/{mat}/OUTCAR"</p>

<p>if not os.path.exists(outcar):</p>
<p>self.results['failed'].append(mat)</p>
<p>continue</p>

<p>with open(outcar, 'r') as f:</p>
<p>content = f.read()</p>
<p>if 'reached required accuracy' in content:</p>
<p>self.results['completed'].append(mat)</p>
<p>else:</p>
<p>self.results['failed'].append(mat)</p>

<p># ログ保存</p>
<p>with open(f'batch_{batch_id}_results.json', 'w') as f:</p>
<p>json.dump(self.results, f, indent=2)</p>

<p>def retry_failed(self, max_retries=2):</p>
<p>"""失敗タスクをリトライ"""</p>
<p>for retry_count in range(max_retries):</p>
<p>if not self.results['failed']:</p>
<p>break</p>

<p>print(f"\nリトライ {retry_count+1}/{max_retries}")</p>
<p>print(f"  失敗タスク数: {len(self.results['failed'])}")</p>

<p>failed_materials = self.results['failed'].copy()</p>
<p>self.results['failed'] = []</p>

<p>self.run_batch(failed_materials, f'retry_{retry_count+1}')</p>

<p>def execute_all(self):</p>
<p>"""全材料を実行"""</p>
<p>n_batches = (len(self.materials) + self.batch_size - 1) // self.batch_size</p>

<p>for batch_idx in range(n_batches):</p>
<p>start = batch_idx * self.batch_size</p>
<p>end = min((batch_idx + 1) * self.batch_size, len(self.materials))</p>
<p>batch_materials = self.materials[start:end]</p>

<p>print(f"\nバッチ {batch_idx+1}/{n_batches}")</p>
<p>self.run_batch(batch_materials, batch_idx+1)</p>

<p># リトライ</p>
<p>self.retry_failed(max_retries=2)</p>

<p># 最終レポート</p>
<p>print("\n最終結果:")</p>
<p>print(f"  成功: {len(self.results['completed'])}")</p>
<p>print(f"  失敗: {len(self.results['failed'])}")</p>

<p>return self.results</p>

<h1>実行</h1>
<p>materials = [f"material_{i:04d}" for i in range(1, 1001)]</p>
<p>manager = HighThroughputManager(materials, batch_size=50, max_concurrent=20)</p>
<p>results = manager.execute_all()</p>
</code></pre>

</details>

<p>---</p>

<h2>3.6 まとめ</h2>

<strong>キーポイント</strong>:

<ol>
<li><strong>SLURM</strong>: 大規模HPCで広く使用されるジョブスケジューラ</li>
<li><strong>アレイジョブ</strong>: 多数の材料を効率的に並列実行</li>
<li><strong>MPI並列</strong>: スケーリング効率を測定・最適化</li>
<li><strong>Python管理</strong>: 大規模計算の自動化と監視</li>
</ol>

<strong>次のステップ</strong>:

<p>第4章では、<strong>FireWorksとAiiDAによるワークフロー管理</strong>を学びます。</p>

<strong><a href="./chapter-4.md">第4章: データ管理とポストプロセス →</a></strong>

<p>---</p>

<strong>ライセンス</strong>: CC BY 4.0
<strong>作成日</strong>: 2025-10-17
<strong>作成者</strong>: Dr. Yusuke Hashimoto, Tohoku University


        <div class="navigation">
            <a href="chapter-2.html" class="nav-button">← 前章: 第2章</a>
<a href="chapter-4.html" class="nav-button">次章: 第4章 →</a>
        </div>
    </main>

    <footer>
        <p><strong>作成者</strong>: AI Terakoya Content Team</p>
        <p><strong>監修</strong>: Dr. Yusuke Hashimoto（東北大学）</p>
        <p><strong>バージョン</strong>: 1.0 | <strong>作成日</strong>: 2025-10-17</p>
        <p><strong>ライセンス</strong>: Creative Commons BY 4.0</p>
        <p>© 2025 AI Terakoya. All rights reserved.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default'
                });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</body>
</html>
