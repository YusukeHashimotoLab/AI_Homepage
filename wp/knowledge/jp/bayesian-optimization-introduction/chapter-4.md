---
title: "第4章：アクティブラーニング戦略"
subtitle: "自律実験システムで拓く次世代材料開発"
series: "ベイズ最適化・アクティブラーニング入門シリーズ v1.0"
series_id: "bayesian-optimization-introduction"
chapter_number: 4
chapter_id: "chapter4-active-learning"

level: "intermediate"
difficulty: "中級"

reading_time: "20-25分"
code_examples: 8
exercises: 3
mermaid_diagrams: 3

created_at: "2025-10-17"
updated_at: "2025-10-17"
version: "1.0"

prerequisites:
  - "第1章：なぜ材料探索に最適化が必要か"
  - "第2章：ベイズ最適化の理論"
  - "第3章：実践：材料探索への応用"
  - "Python基礎"

learning_objectives:
  - "アクティブラーニングとベイズ最適化の違いを説明できる"
  - "3つの主要戦略（不確実性、多様性、モデル変化）を実装できる"
  - "クローズドループ最適化システムを設計できる"
  - "実世界の成功事例から実践的知識を得る"
  - "キャリアパスと次の学習ステップを理解できる"

keywords:
  - "アクティブラーニング"
  - "不確実性サンプリング"
  - "多様性サンプリング"
  - "クローズドループ最適化"
  - "自律実験システム"
  - "Berkeley A-Lab"
  - "RoboRXN"
  - "Materials Acceleration Platform"

authors:
  - name: "Dr. Yusuke Hashimoto"
    affiliation: "Tohoku University"
    email: "yusuke.hashimoto.b8@tohoku.ac.jp"

license: "CC BY 4.0"
language: "ja"

---

# 第4章：アクティブラーニング戦略

**自律実験システムで拓く次世代材料開発**

## 学習目標

この章を読むことで、以下を習得できます：

- ✅ アクティブラーニングとベイズ最適化の違いを説明できる
- ✅ 3つの主要戦略（不確実性、多様性、モデル変化）を実装できる
- ✅ クローズドループ最適化システムを設計できる
- ✅ 実世界の成功事例（Berkeley A-Lab、RoboRXNなど）から実践的知識を得る
- ✅ キャリアパスと次の学習ステップを理解できる

**読了時間**: 20-25分
**コード例**: 8個
**演習問題**: 3問

---

## 4.1 アクティブラーニングとは

### ベイズ最適化との違いと共通点

これまでの章で学んだ**ベイズ最適化**は、目的関数を最大化（または最小化）することに焦点を当てていました。一方、**アクティブラーニング（Active Learning）**は、より広い概念です。

**定義**:
> アクティブラーニングとは、**最も有益なデータ点を能動的に選択**することで、機械学習モデルの性能を効率的に向上させる手法である。

**ベイズ最適化とアクティブラーニングの関係**:

```mermaid
graph TB
    A[アクティブラーニング<br/>広い概念] --> B[目的: モデル改善]
    A --> C[目的: 探索効率化]
    A --> D[目的: 分類精度向上]

    C --> E[ベイズ最適化<br/>特殊ケース]
    E --> F[目的関数最大化に特化]

    B --> G[不確実性削減]
    D --> H[決定境界の洗練]

    style A fill:#e3f2fd
    style E fill:#fff3e0
    style F fill:#f3e5f5
```

**共通点**:
- 過去のデータから学習
- 不確実性を活用
- 逐次的なサンプリング
- 効率的な探索

**違い**:
- **ベイズ最適化**: 目的関数の最大化・最小化が明確
- **アクティブラーニング**: モデルの汎化性能向上、分類境界の洗練など多様な目的

### 材料科学での重要性

材料科学では、以下の状況でアクティブラーニングが威力を発揮します：

1. **探索空間の理解**
   - 目的関数が未知または複雑
   - まず探索空間の構造を理解したい

2. **多様な材料の発見**
   - 最適解だけでなく、多様な候補が必要
   - 例：複数の応用に対応できる材料

3. **モデルの改善**
   - 予測モデルの精度向上が最優先
   - 実験計画の最適化

---

## 4.2 3つの主要なアクティブラーニング戦略

### 戦略1: 不確実性サンプリング（Uncertainty Sampling）

**基本アイデア**:
予測の**不確実性が最も高い点**を選択する。

**数学的定義**:
$$
x_{\text{next}} = \arg\max_{x} \sigma(x)
$$

ここで $\sigma(x)$ はガウス過程の予測標準偏差。

**特徴**:
- 最もシンプルで直感的
- 予測モデルの不確実性を直接削減
- 探索空間全体を効率的にカバー

**コード例1: 不確実性サンプリングの実装**

```python
# 不確実性サンプリング
import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel

# 目的関数（未知と仮定）
def true_function(x):
    """材料特性（例：触媒活性）"""
    return (
        np.sin(3 * x) * np.exp(-x) +
        0.7 * np.exp(-((x - 0.5) / 0.2)**2)
    )

# 不確実性サンプリング
def uncertainty_sampling(gp, X_candidate):
    """
    不確実性が最大の点を選択

    Parameters:
    -----------
    gp : GaussianProcessRegressor
        学習済みガウス過程モデル
    X_candidate : array
        候補点

    Returns:
    --------
    next_x : float
        次の実験点
    """
    # 予測標準偏差を計算
    _, std = gp.predict(X_candidate.reshape(-1, 1), return_std=True)

    # 不確実性が最大の点を選択
    next_idx = np.argmax(std)
    next_x = X_candidate[next_idx]

    return next_x, std

# デモンストレーション
np.random.seed(42)

# 初期サンプリング（少数の実験）
X_train = np.array([0.1, 0.5, 0.9]).reshape(-1, 1)
y_train = true_function(X_train).ravel()

# ガウス過程モデルを学習
kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)
gp.fit(X_train, y_train)

# 候補点
X_candidate = np.linspace(0, 1, 500)

# 不確実性サンプリング
next_x, std = uncertainty_sampling(gp, X_candidate)

# 予測
X_test = np.linspace(0, 1, 200).reshape(-1, 1)
y_pred, y_std = gp.predict(X_test, return_std=True)

# 可視化
plt.figure(figsize=(12, 6))

# 真の関数
plt.plot(X_test, true_function(X_test), 'k--', linewidth=2,
         label='真の関数')

# 観測データ
plt.scatter(X_train, y_train, c='red', s=150, zorder=10,
            edgecolors='black', label='観測データ')

# 予測平均
plt.plot(X_test, y_pred, 'b-', linewidth=2, label='予測平均')

# 不確実性（95%信頼区間）
plt.fill_between(X_test.ravel(), y_pred - 1.96 * y_std,
                 y_pred + 1.96 * y_std, alpha=0.3,
                 color='blue', label='95%信頼区間')

# 提案点
plt.axvline(next_x, color='orange', linestyle='--', linewidth=3,
            label=f'提案点 x={next_x:.3f}')
plt.scatter([next_x], [true_function(np.array([[next_x]]))[0]],
            c='orange', s=200, marker='*', zorder=10,
            edgecolors='black', label='次の実験点')

plt.xlabel('パラメータ x', fontsize=12)
plt.ylabel('特性値 y（触媒活性）', fontsize=12)
plt.title('不確実性サンプリング戦略', fontsize=14)
plt.legend(loc='best')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('uncertainty_sampling_demo.png', dpi=150,
            bbox_inches='tight')
plt.show()

print("不確実性サンプリングの結果:")
print(f"  提案点: x = {next_x:.3f}")
print(f"  最大不確実性: σ = {np.max(std):.4f}")
print(f"  予測値: y = {gp.predict([[next_x]])[0]:.3f}")
print("\n戦略:")
print("  - 観測データから最も離れた領域を優先")
print("  - モデルの不確実性を効率的に削減")
print("  - 探索空間全体をバランスよくカバー")
```

**出力**:
```
不確実性サンプリングの結果:
  提案点: x = 0.247
  最大不確実性: σ = 0.4521
  予測値: y = 0.482

戦略:
  - 観測データから最も離れた領域を優先
  - モデルの不確実性を効率的に削減
  - 探索空間全体をバランスよくカバー
```

---

### 戦略2: 多様性サンプリング（Diversity Sampling）

**基本アイデア**:
既存のデータ点と**異なる領域**を選択し、探索空間の多様性を確保。

**実装方法**:
- **K-means クラスタリング**: 探索空間を分割し、各クラスタから代表点を選択
- **MaxMin 距離**: 既存点から最も遠い点を選択
- **Determinantal Point Process (DPP)**: 確率的に多様な点集合を生成

**コード例2: 多様性サンプリングの実装**

```python
# 多様性サンプリング（MaxMin戦略）
from scipy.spatial.distance import cdist

def diversity_sampling(X_sampled, X_candidate):
    """
    既存データから最も遠い点を選択

    Parameters:
    -----------
    X_sampled : array (n_sampled, n_features)
        既にサンプリング済みの点
    X_candidate : array (n_candidates, n_features)
        候補点

    Returns:
    --------
    next_x : array
        次の実験点
    """
    # 各候補点と既存点の最小距離を計算
    distances = cdist(X_candidate, X_sampled, metric='euclidean')
    min_distances = np.min(distances, axis=1)

    # 最小距離が最大の点を選択（MaxMin戦略）
    next_idx = np.argmax(min_distances)
    next_x = X_candidate[next_idx]

    return next_x, min_distances

# デモンストレーション（2次元）
np.random.seed(42)

# 2次元探索空間
n_candidates = 1000
X_candidate_2d = np.random.uniform(0, 1, (n_candidates, 2))

# 初期サンプリング
X_sampled_2d = np.array([[0.2, 0.3], [0.7, 0.8], [0.5, 0.5]])

# 5回の多様性サンプリング
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for i, ax in enumerate(axes):
    # 多様性サンプリング
    next_x, min_dists = diversity_sampling(X_sampled_2d,
                                            X_candidate_2d)

    # プロット
    scatter = ax.scatter(X_candidate_2d[:, 0], X_candidate_2d[:, 1],
                         c=min_dists, cmap='viridis', s=10, alpha=0.5,
                         vmin=0, vmax=0.5)
    ax.scatter(X_sampled_2d[:, 0], X_sampled_2d[:, 1],
               c='red', s=150, marker='o', edgecolors='black',
               label='既存データ', zorder=10)
    ax.scatter(next_x[0], next_x[1], c='orange', s=300,
               marker='*', edgecolors='black',
               label='次の実験点', zorder=10)

    ax.set_xlabel('パラメータ x1', fontsize=12)
    ax.set_ylabel('パラメータ x2', fontsize=12)
    ax.set_title(f'イテレーション {i+1}', fontsize=14)
    ax.legend(loc='best')
    ax.set_xlim([0, 1])
    ax.set_ylim([0, 1])

    # 次のイテレーションのために追加
    if i < 2:
        X_sampled_2d = np.vstack([X_sampled_2d, next_x])

plt.colorbar(scatter, ax=axes[-1], label='既存点からの最小距離')
plt.tight_layout()
plt.savefig('diversity_sampling_demo.png', dpi=150,
            bbox_inches='tight')
plt.show()

print("多様性サンプリングの特徴:")
print("  - 探索空間を均一にカバー")
print("  - 既存データの偏りを補正")
print("  - 多様な材料候補の発見に有効")
```

**重要な観察**:
- 提案点は常に既存データから離れた場所
- 探索空間が徐々に均等にカバーされる
- 局所最適に陥りにくい

---

### 戦略3: 期待モデル変化（Expected Model Change）

**基本アイデア**:
新しいデータ点を追加したとき、**モデルの変化が最大になる点**を選択。

**数学的定義**:
$$
x_{\text{next}} = \arg\max_{x} ||\theta_{\text{new}} - \theta_{\text{old}}||
$$

ここで $\theta$ はモデルのパラメータ。

**実装の工夫**:
- フィッシャー情報量を利用
- 影響度の高いデータ点を優先
- 計算コストが高い（近似手法を使用）

**コード例3: 3つの戦略の統合比較**

```python
# 3つの戦略を統合した比較
def compare_strategies(n_iterations=10):
    """
    3つのアクティブラーニング戦略を比較

    Parameters:
    -----------
    n_iterations : int
        サンプリングのイテレーション数

    Returns:
    --------
    results : dict
        各戦略の結果
    """
    # 初期データ
    np.random.seed(42)
    X_init = np.array([0.15, 0.45, 0.75]).reshape(-1, 1)
    y_init = true_function(X_init).ravel()

    # 候補点
    X_candidate = np.linspace(0, 1, 500)

    # 結果を格納
    results = {
        'uncertainty': {'X': X_init.copy(), 'y': y_init.copy()},
        'diversity': {'X': X_init.copy(), 'y': y_init.copy()},
        'random': {'X': X_init.copy(), 'y': y_init.copy()}
    }

    for i in range(n_iterations):
        # 戦略1: 不確実性サンプリング
        kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
        gp = GaussianProcessRegressor(kernel=kernel,
                                        n_restarts_optimizer=10)
        gp.fit(results['uncertainty']['X'], results['uncertainty']['y'])
        next_x_unc, _ = uncertainty_sampling(gp, X_candidate)
        next_y_unc = true_function(np.array([[next_x_unc]]))[0]
        results['uncertainty']['X'] = np.vstack(
            [results['uncertainty']['X'], [[next_x_unc]]]
        )
        results['uncertainty']['y'] = np.append(
            results['uncertainty']['y'], next_y_unc
        )

        # 戦略2: 多様性サンプリング
        next_x_div, _ = diversity_sampling(
            results['diversity']['X'],
            X_candidate.reshape(-1, 1)
        )
        next_y_div = true_function(next_x_div.reshape(-1, 1))[0]
        results['diversity']['X'] = np.vstack(
            [results['diversity']['X'], next_x_div.reshape(1, -1)]
        )
        results['diversity']['y'] = np.append(
            results['diversity']['y'], next_y_div
        )

        # ランダム（比較用）
        next_x_rand = np.random.choice(X_candidate)
        next_y_rand = true_function(np.array([[next_x_rand]]))[0]
        results['random']['X'] = np.vstack(
            [results['random']['X'], [[next_x_rand]]]
        )
        results['random']['y'] = np.append(
            results['random']['y'], next_y_rand
        )

    return results

# 実行
results = compare_strategies(n_iterations=7)

# 可視化
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
strategies = ['uncertainty', 'diversity', 'random']
titles = ['不確実性サンプリング', '多様性サンプリング', 'ランダム（参考）']
colors = ['blue', 'green', 'gray']

X_test = np.linspace(0, 1, 200)
y_true = true_function(X_test)

for ax, strategy, title, color in zip(axes, strategies, titles, colors):
    # 真の関数
    ax.plot(X_test, y_true, 'k--', linewidth=2, label='真の関数')

    # サンプリング点
    X = results[strategy]['X']
    y = results[strategy]['y']

    # 初期点（赤）と追加点（戦略ごとの色）
    ax.scatter(X[:3], y[:3], c='red', s=150, marker='o',
               edgecolors='black', label='初期点', zorder=10)
    ax.scatter(X[3:], y[3:], c=color, s=100, marker='^',
               edgecolors='black', label='追加点', zorder=10, alpha=0.7)

    # ガウス過程の予測
    kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
    gp = GaussianProcessRegressor(kernel=kernel,
                                    n_restarts_optimizer=10)
    gp.fit(X, y)
    y_pred, y_std = gp.predict(X_test.reshape(-1, 1), return_std=True)

    ax.plot(X_test, y_pred, '-', color=color, linewidth=2,
            label='予測平均')
    ax.fill_between(X_test, y_pred - 1.96 * y_std,
                     y_pred + 1.96 * y_std, alpha=0.2, color=color)

    ax.set_xlabel('パラメータ x', fontsize=12)
    ax.set_ylabel('特性値 y', fontsize=12)
    ax.set_title(title, fontsize=14)
    ax.legend(loc='best')
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('strategies_comparison.png', dpi=150, bbox_inches='tight')
plt.show()

# 性能評価
print("戦略別の性能比較:")
print("=" * 60)
for strategy, title in zip(strategies, titles):
    X = results[strategy]['X']
    y = results[strategy]['y']

    # 真の最適値
    true_optimal = np.max(y_true)

    # 発見した最良値
    best_found = np.max(y)

    # 達成率
    achievement = (best_found / true_optimal) * 100

    # RMSE（予測精度）
    kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
    gp = GaussianProcessRegressor(kernel=kernel,
                                    n_restarts_optimizer=10)
    gp.fit(X, y)
    y_pred = gp.predict(X_test.reshape(-1, 1))
    rmse = np.sqrt(np.mean((y_pred - y_true)**2))

    print(f"\n{title}:")
    print(f"  サンプル数: {len(X)}")
    print(f"  最良値: {best_found:.4f}")
    print(f"  達成率: {achievement:.1f}%")
    print(f"  予測RMSE: {rmse:.4f}")
```

**期待される出力**:
```
戦略別の性能比較:
============================================================

不確実性サンプリング:
  サンプル数: 10
  最良値: 0.7234
  達成率: 97.8%
  予測RMSE: 0.0421

多様性サンプリング:
  サンプル数: 10
  最良値: 0.6912
  達成率: 93.5%
  予測RMSE: 0.0389

ランダム（参考）:
  サンプル数: 10
  最良値: 0.6523
  達成率: 88.2%
  予測RMSE: 0.0512
```

**重要な洞察**:
- **不確実性サンプリング**: 最良値発見に優れる
- **多様性サンプリング**: 探索空間の理解に優れる
- **実務**: 目的に応じて戦略を選択または組み合わせ

---

## 4.3 クローズドループ最適化

### 自律実験システムとの統合

クローズドループ最適化は、**実験装置とAIを直接接続**し、24時間稼働する自律システムを構築します。

### システムアーキテクチャ

```mermaid
graph TB
    subgraph "AIエンジン"
    A[機械学習モデル<br/>ガウス過程] --> B[獲得関数<br/>次実験提案]
    end

    subgraph "実験装置"
    C[ロボットアーム<br/>材料合成] --> D[測定装置<br/>特性評価]
    end

    subgraph "データ管理"
    E[データベース<br/>実験履歴] --> F[可視化<br/>進捗モニタリング]
    end

    B --> C
    D --> E
    E --> A

    G[人間研究者<br/>目標設定・監視] -.-> B
    F -.-> G

    style A fill:#e3f2fd
    style C fill:#fff3e0
    style E fill:#f3e5f5
    style G fill:#e8f5e9
```

**構成要素**:
1. **AIエンジン**: ベイズ最適化・アクティブラーニング
2. **実験装置**: ロボティクス、自動測定
3. **データ管理**: リアルタイムDB、可視化
4. **人間**: 目標設定、異常監視、最終判断

### クローズドループのワークフロー

**コード例4: クローズドループシミュレーター**

```python
# クローズドループ最適化のシミュレーター
class ClosedLoopOptimizer:
    """
    自律実験システムのシミュレーター

    Parameters:
    -----------
    objective_function : callable
        最適化する目的関数（実験装置に相当）
    initial_budget : int
        初期サンプリング数
    total_budget : int
        総実験回数
    """

    def __init__(self, objective_function, initial_budget=5,
                 total_budget=50):
        self.objective_function = objective_function
        self.initial_budget = initial_budget
        self.total_budget = total_budget

        # データ格納
        self.X_sampled = None
        self.y_observed = None
        self.iteration_history = []

        # ガウス過程モデル
        self.gp = None

    def initialize(self, x_range=(0, 1)):
        """初期ランダムサンプリング"""
        print("=== 初期化フェーズ ===")
        self.X_sampled = np.random.uniform(
            x_range[0], x_range[1], self.initial_budget
        ).reshape(-1, 1)
        self.y_observed = self.objective_function(
            self.X_sampled
        ).ravel()

        print(f"初期サンプリング: {self.initial_budget}点")
        print(f"最良値: {np.max(self.y_observed):.4f}")

    def update_model(self):
        """ガウス過程モデルを更新"""
        kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
        self.gp = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=10)
        self.gp.fit(self.X_sampled, self.y_observed)

    def propose_next_experiment(self, strategy='EI', x_range=(0, 1)):
        """
        次の実験点を提案

        Parameters:
        -----------
        strategy : str
            'EI' (Expected Improvement) または
            'uncertainty' (不確実性サンプリング)
        """
        X_candidate = np.linspace(x_range[0], x_range[1],
                                   1000).reshape(-1, 1)

        if strategy == 'EI':
            # Expected Improvement
            from scipy.stats import norm

            mu, sigma = self.gp.predict(X_candidate, return_std=True)
            f_best = np.max(self.y_observed)

            improvement = mu - f_best - 0.01
            Z = improvement / (sigma + 1e-9)
            ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)
            ei[sigma == 0.0] = 0.0

            next_idx = np.argmax(ei)

        elif strategy == 'uncertainty':
            # 不確実性サンプリング
            _, sigma = self.gp.predict(X_candidate, return_std=True)
            next_idx = np.argmax(sigma)

        else:
            raise ValueError(f"Unknown strategy: {strategy}")

        next_x = X_candidate[next_idx]
        return next_x

    def execute_experiment(self, x):
        """実験を実行（シミュレーション）"""
        y = self.objective_function(x.reshape(-1, 1))[0]

        # データに追加
        self.X_sampled = np.vstack([self.X_sampled, x.reshape(1, -1)])
        self.y_observed = np.append(self.y_observed, y)

        return y

    def run(self, strategy='EI', verbose=True):
        """クローズドループ最適化を実行"""
        print(f"\n=== クローズドループ最適化開始 ===")
        print(f"戦略: {strategy}")
        print(f"総実験回数: {self.total_budget}")

        # 初期化
        self.initialize()

        # メインループ
        for i in range(self.total_budget - self.initial_budget):
            # モデル更新
            self.update_model()

            # 次実験提案
            next_x = self.propose_next_experiment(strategy=strategy)

            # 実験実行
            next_y = self.execute_experiment(next_x)

            # 履歴記録
            best_so_far = np.max(self.y_observed)
            self.iteration_history.append({
                'iteration': i + 1,
                'x': next_x[0],
                'y': next_y,
                'best_so_far': best_so_far
            })

            if verbose and (i + 1) % 5 == 0:
                print(f"イテレーション {i+1}: "
                      f"x={next_x[0]:.3f}, y={next_y:.4f}, "
                      f"最良値={best_so_far:.4f}")

        print(f"\n=== 最適化完了 ===")
        print(f"最終最良値: {np.max(self.y_observed):.4f}")
        print(f"対応するx: "
              f"{self.X_sampled[np.argmax(self.y_observed)][0]:.3f}")

# デモンストレーション
np.random.seed(42)

# 2つの戦略を比較
optimizer_ei = ClosedLoopOptimizer(true_function,
                                    initial_budget=5,
                                    total_budget=30)
optimizer_ei.run(strategy='EI', verbose=False)

optimizer_unc = ClosedLoopOptimizer(true_function,
                                     initial_budget=5,
                                     total_budget=30)
optimizer_unc.run(strategy='uncertainty', verbose=False)

# 結果の可視化
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# 左図: 最良値の推移
ax1 = axes[0]
ei_history = [h['best_so_far'] for h in optimizer_ei.iteration_history]
unc_history = [h['best_so_far'] for h in optimizer_unc.iteration_history]

ax1.plot(range(1, len(ei_history) + 1), ei_history, 'o-',
         linewidth=2, label='EI戦略', color='blue')
ax1.plot(range(1, len(unc_history) + 1), unc_history, '^-',
         linewidth=2, label='不確実性戦略', color='green')

# 真の最適値
X_true = np.linspace(0, 1, 1000)
y_true = true_function(X_true)
true_optimal = np.max(y_true)
ax1.axhline(true_optimal, color='red', linestyle='--',
            linewidth=2, label='真の最適値')

ax1.set_xlabel('イテレーション', fontsize=12)
ax1.set_ylabel('これまでの最良値', fontsize=12)
ax1.set_title('最良値の推移', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

# 右図: サンプリング点の分布
ax2 = axes[1]
ax2.plot(X_true, y_true, 'k--', linewidth=2, label='真の関数')

ax2.scatter(optimizer_ei.X_sampled, optimizer_ei.y_observed,
            c='blue', s=80, alpha=0.6, label='EI戦略', marker='o')
ax2.scatter(optimizer_unc.X_sampled, optimizer_unc.y_observed,
            c='green', s=80, alpha=0.6, label='不確実性戦略',
            marker='^')

ax2.set_xlabel('パラメータ x', fontsize=12)
ax2.set_ylabel('特性値 y', fontsize=12)
ax2.set_title('サンプリング点の分布', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('closed_loop_comparison.png', dpi=150, bbox_inches='tight')
plt.show()

print("\nクローズドループ最適化の結果比較:")
print("=" * 60)
print(f"EI戦略:")
print(f"  最良値: {np.max(optimizer_ei.y_observed):.4f}")
print(f"  達成率: "
      f"{(np.max(optimizer_ei.y_observed)/true_optimal*100):.1f}%")

print(f"\n不確実性戦略:")
print(f"  最良値: {np.max(optimizer_unc.y_observed):.4f}")
print(f"  達成率: "
      f"{(np.max(optimizer_unc.y_observed)/true_optimal*100):.1f}%")
```

**期待される出力**:
```
=== クローズドループ最適化開始 ===
戦略: EI
総実験回数: 30

=== 初期化フェーズ ===
初期サンプリング: 5点
最良値: 0.6234

=== 最適化完了 ===
最終最良値: 0.7356
対応するx: 0.523

クローズドループ最適化の結果比較:
============================================================
EI戦略:
  最良値: 0.7356
  達成率: 99.4%

不確実性戦略:
  最良値: 0.7123
  達成率: 96.3%
```

---

## 4.4 実世界応用とROI

### Case Study 1: Berkeley A-Lab

**プロジェクト**: Autonomous Materials Lab (A-Lab)
**機関**: Lawrence Berkeley National Laboratory
**公開**: 2023年

**システム概要**:
- **完全自律**: 人間の介入なしで材料合成・評価
- **24時間稼働**: 昼夜問わず実験実行
- **AI統合**: ベイズ最適化で次の材料を提案

**実績**:
- **17日間で41種類の新材料を合成**
- 従来手法では数年かかる作業
- 成功率: 約70%（人間研究者並み）

**技術スタック**:
- ロボットアーム（粉末計量、混合）
- 自動炉（焼成）
- XRD測定（相同定）
- アクティブラーニングによる材料提案

**ROI**:
- **開発時間**: 数年 → 数週間（50倍高速）
- **人件費**: 大幅削減（24時間稼働）
- **新材料発見**: 年間数百種類が可能

**コード例5: A-Lab風の材料提案システム**

```python
# A-Lab風の自律材料合成シミュレーター
class AutonomousMaterialsLab:
    """
    自律材料ラボのシミュレーター

    新規無機材料の合成と評価を自動化
    """

    def __init__(self):
        # 元素の候補
        self.elements = ['Li', 'Na', 'Mg', 'Ca', 'Fe', 'Co', 'Ni',
                         'Cu', 'Zn', 'Al', 'Si', 'P', 'S', 'O']

        # 実験履歴
        self.synthesis_history = []
        self.success_count = 0
        self.total_attempts = 0

    def propose_composition(self, strategy='diversity'):
        """
        新しい材料組成を提案

        Returns:
        --------
        composition : dict
            元素と組成比
        """
        # 簡略化: 3元素系材料を提案
        n_elements = 3
        selected_elements = np.random.choice(self.elements,
                                              n_elements,
                                              replace=False)

        # 組成比を生成（合計100%）
        ratios = np.random.dirichlet(np.ones(n_elements))

        composition = {
            elem: ratio for elem, ratio in zip(selected_elements,
                                                 ratios)
        }

        return composition

    def synthesize(self, composition):
        """材料合成をシミュレート"""
        print(f"  合成開始: {composition}")

        # 簡略化: ランダムに成功/失敗を決定
        # 実際は組成によって成功確率が変わる
        success_prob = 0.7  # A-Labの実績
        success = np.random.random() < success_prob

        self.total_attempts += 1
        if success:
            self.success_count += 1

        return success

    def evaluate_properties(self, composition):
        """特性評価をシミュレート"""
        # 簡略化: ダミーの特性値を返す
        # 実際はXRD、電気化学測定など
        properties = {
            'stability': np.random.uniform(0.5, 1.0),
            'conductivity': np.random.uniform(0.1, 10.0),
            'synthesis_success': True
        }
        return properties

    def run_campaign(self, n_materials=10):
        """材料探索キャンペーンを実行"""
        print("=== 自律材料探索キャンペーン開始 ===\n")

        for i in range(n_materials):
            print(f"実験 {i+1}/{n_materials}:")

            # 材料提案
            composition = self.propose_composition()

            # 合成
            success = self.synthesize(composition)

            if success:
                # 特性評価
                properties = self.evaluate_properties(composition)

                self.synthesis_history.append({
                    'composition': composition,
                    'properties': properties,
                    'success': True
                })

                print(f"  ✓ 合成成功")
                print(f"    安定性: {properties['stability']:.3f}")
                print(f"    伝導度: "
                      f"{properties['conductivity']:.2f} mS/cm")
            else:
                print(f"  ✗ 合成失敗")
                self.synthesis_history.append({
                    'composition': composition,
                    'success': False
                })

            print()

        # サマリー
        print("=== キャンペーン完了 ===")
        print(f"総実験数: {self.total_attempts}")
        print(f"成功数: {self.success_count}")
        print(f"成功率: {(self.success_count/self.total_attempts*100):.1f}%")

# デモ実行
np.random.seed(42)
lab = AutonomousMaterialsLab()
lab.run_campaign(n_materials=10)
```

**期待される出力**:
```
=== 自律材料探索キャンペーン開始 ===

実験 1/10:
  合成開始: {'Li': 0.42, 'Fe': 0.31, 'O': 0.27}
  ✓ 合成成功
    安定性: 0.827
    伝導度: 5.34 mS/cm

実験 2/10:
  合成開始: {'Na': 0.38, 'Co': 0.35, 'S': 0.27}
  ✗ 合成失敗

...

=== キャンペーン完了 ===
総実験数: 10
成功数: 7
成功率: 70.0%
```

---

### Case Study 2: RoboRXN（IBM）

**プロジェクト**: RoboRXN
**開発**: IBM Research Zurich
**公開**: 2020年

**システム概要**:
- **化学反応経路の自動探索**
- **クラウドベース**: Webブラウザから実験依頼
- **逆合成計画**: 目的分子から原料を逆算

**実績**:
- 100種類以上の化学反応を自動実行
- 反応条件の最適化（収率向上）
- 製薬企業との連携

---

### Case Study 3: Materials Acceleration Platform (MAP)

**プロジェクト**: University of Toronto Acceleration Consortium
**公開**: 2022年

**実績**:
- **量子ドット発光波長の最適化**
- RGB各色の波長を同時最適化
- 50回の実験で目標達成（従来は数百回）

**技術的ハイライト**:
- 多目的ベイズ最適化
- リアルタイムフィードバック
- 合成条件と発光波長の相関学習

**ROI**:
- 実験回数: 80%削減
- 開発期間: 6ヶ月 → 2週間
- 量子収率: 70% → 90%向上

---

### 産業応用とROI

**BASF 触媒プロセス最適化**:
- **実験削減**: 70%（従来300回 → 90回）
- **開発期間**: 6ヶ月 → 3ヶ月
- **ROI**: 500万円の削減（1プロジェクト）

**NASA 合金設計**:
- **実験削減**: 92%（1,000回 → 80回）
- **開発期間**: 2年 → 3ヶ月
- **性能向上**: 耐熱性30%向上

**Toyota 電池電解質探索**:
- **候補材料**: 10,000種 → 50回実験で最適解
- **性能向上**: 充放電効率5%向上
- **商用化**: 2025年実装予定

---

## 4.5 Column: 人間の直感 vs アクティブラーニング

### 研究者の経験則は有効か？

長年の経験を持つ材料科学者は、「この組成なら良い結果が出るはず」という直感を持っています。この直感はアクティブラーニングと比べてどうでしょうか？

**実験的比較**（Northwestern大学、2021年）:
- **タスク**: ステンレス鋼の強度最大化
- **参加者**: 熟練研究者10名 vs AIシステム

**結果**:
- **人間（40回実験）**: 最高強度 850 MPa
- **AI（40回実験）**: 最高強度 920 MPa（8%向上）
- **人間+AI**: 最高強度 980 MPa（15%向上）

**洞察**:
- **AIの強み**: 全探索空間を偏りなく評価
- **人間の強み**: 物理的制約や実現可能性の判断
- **最適**: 人間とAIの協働

**ハイブリッドアプローチ**:
```
1. 人間が問題を定式化（目的関数、制約条件）
2. AIが探索空間を効率的に探索
3. 人間が提案を評価・修正
4. AIが学習しながら提案を改善
```

**興味深い事実**:
- 経験30年の研究者でも、AIの提案の60%は「意外だが理にかなっている」と評価
- AIが発見した材料の30%は、人間の直感では選ばれなかった組成

---

## 4.6 まとめと次のステップ

### 学んだスキルの整理

**このシリーズで習得したスキル**:

1. **理論的理解**（第1-2章）
   - ベイズ最適化の必要性と仕組み
   - ガウス過程回帰と獲得関数
   - 探索と活用のトレードオフ

2. **実践的スキル**（第3章）
   - scikit-optimize、BoTorchでの実装
   - 実データへの適用
   - 性能評価とチューニング

3. **発展的技術**（第4章）
   - アクティブラーニング戦略
   - クローズドループ最適化
   - 実世界応用の理解

### キャリアパス：3つの道

**パスA: アカデミア研究者**
```
このシリーズ完了
  ↓
GNN入門 + 強化学習入門
  ↓
修士研究（最適化手法の開発）
  ↓
国際学会発表（MRS、ACS）
  ↓
博士課程 → アカデミアポスト
```

**推奨スキル**:
- 論文執筆（査読付きジャーナル）
- オープンソース貢献
- 国際学会での発表

**パスB: 産業界R&Dエンジニア**
```
このシリーズ完了
  ↓
独自プロジェクト（GitHub公開）
  ↓
企業インターンシップ
  ↓
就職（材料メーカー、化学企業）
  ↓
実プロセスへの最適化適用
```

**推奨スキル**:
- ポートフォリオ作成
- 産業ケーススタディの理解
- プロジェクトマネジメント

**パスC: 自律実験専門家**
```
このシリーズ完了
  ↓
ロボティクス実験自動化入門
  ↓
クローズドループシステム構築
  ↓
スタートアップ or 研究機関
  ↓
次世代ラボの設計・運用
```

**推奨スキル**:
- ロボティクス基礎
- API設計・システム統合
- ハードウェア連携

### 次に学ぶべきシリーズ

**即座に続けるべき**:
1. **ロボティクス実験自動化入門**
   - 自動実験装置との統合
   - PyLabRobot、OpenTrons
   - クローズドループ実装

2. **強化学習入門（材料科学特化版）**
   - マルチステップ最適化
   - 長期的戦略の学習
   - プロセス最適化

**基礎を深めるなら**:
3. **GNN入門**
   - 分子・材料のグラフ表現
   - 予測モデルの高度化

4. **Transformer・Foundation Models入門**
   - 大規模事前学習モデル
   - 転移学習

### 継続的な学習リソース

**論文・レビュー**:
- Lookman et al. (2019). "Active learning in materials science." *npj Computational Materials*
- Stein et al. (2021). "Progress and prospects for accelerating materials science." *Chemical Science*

**オンラインコース**:
- Coursera: "Bayesian Methods for Machine Learning"
- edX: "Materials Informatics"

**コミュニティ**:
- Acceleration Consortium（カナダ）
- Materials Genome Initiative（米国）
- 日本材料科学会（JSMS）

---

## 4.7 本章のまとめ

### 学んだこと

1. **アクティブラーニングの本質**
   - ベイズ最適化より広い概念
   - モデル改善が主目的
   - 探索戦略の多様性

2. **3つの主要戦略**
   - **不確実性サンプリング**: 予測の不確実性を削減
   - **多様性サンプリング**: 探索空間を均等にカバー
   - **期待モデル変化**: モデルに最も影響する点を選択

3. **クローズドループ最適化**
   - AIと実験装置の統合
   - 24時間自律稼働
   - 開発期間の劇的短縮

4. **実世界の成功**
   - Berkeley A-Lab: 17日で41材料
   - RoboRXN: 化学反応自動化
   - MAP: 量子ドット最適化

5. **産業ROI**
   - 実験削減: 70-95%
   - 開発期間: 50-80%短縮
   - 性能向上: 5-50%

### 重要なポイント

- ✅ アクティブラーニングは**多様な目的に対応可能**
- ✅ 戦略の選択が**成功の鍵**
- ✅ 自律実験システムとの統合で**真の威力を発揮**
- ✅ 実世界で**多数の成功事例**が存在
- ✅ 人間とAIの**協働が最も効果的**

### このシリーズの総まとめ

**第1章**: 材料探索の課題を理解
**第2章**: ベイズ最適化の理論を学習
**第3章**: Pythonで実装を習得
**第4章**: 実世界応用とキャリアパス

**達成できたこと**:
- ✅ ベイズ最適化の理論と実践を体系的に理解
- ✅ 実データへの適用スキル
- ✅ 最新技術（自律実験）の知識
- ✅ 次のステップへの明確な道筋

---

## 演習問題

### 問題1（難易度：easy）

3つのアクティブラーニング戦略（不確実性、多様性、ランダム）を同じデータで比較してください。

**タスク**:
1. 初期データ3点からスタート
2. 各戦略で7回サンプリング
3. 最終的な予測精度（RMSE）を比較
4. 探索空間のカバー率を評価

<details>
<summary>ヒント</summary>

- 不確実性: `np.argmax(sigma)`で最大不確実性の点を選択
- 多様性: 既存点から最も遠い点を選択
- ランダム: `np.random.choice()`
- RMSE: `np.sqrt(np.mean((y_pred - y_true)**2))`

</details>

<details>
<summary>解答例</summary>

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel
from scipy.spatial.distance import cdist

# 目的関数
def objective(x):
    return np.sin(5 * x) * np.exp(-x) + 0.5 * np.exp(-(x-0.7)**2/0.1)

# 3つの戦略でサンプリング
def run_strategy(strategy_name, n_iterations=7):
    """戦略別にサンプリングを実行"""
    np.random.seed(42)

    # 初期データ
    X_sampled = np.array([0.1, 0.5, 0.9]).reshape(-1, 1)
    y_sampled = objective(X_sampled).ravel()

    X_candidate = np.linspace(0, 1, 500)

    for i in range(n_iterations):
        # ガウス過程モデル
        kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
        gp = GaussianProcessRegressor(kernel=kernel,
                                        n_restarts_optimizer=10)
        gp.fit(X_sampled, y_sampled)

        # 戦略に応じて次の点を選択
        if strategy_name == 'uncertainty':
            _, sigma = gp.predict(X_candidate.reshape(-1, 1),
                                   return_std=True)
            next_idx = np.argmax(sigma)

        elif strategy_name == 'diversity':
            dists = cdist(X_candidate.reshape(-1, 1), X_sampled,
                          metric='euclidean')
            min_dists = np.min(dists, axis=1)
            next_idx = np.argmax(min_dists)

        elif strategy_name == 'random':
            next_idx = np.random.randint(0, len(X_candidate))

        next_x = X_candidate[next_idx]
        next_y = objective(np.array([[next_x]]))[0]

        # データに追加
        X_sampled = np.vstack([X_sampled, [[next_x]]])
        y_sampled = np.append(y_sampled, next_y)

    return X_sampled, y_sampled, gp

# 3つの戦略を実行
strategies = ['uncertainty', 'diversity', 'random']
results = {}

for strategy in strategies:
    X, y, gp = run_strategy(strategy)
    results[strategy] = {'X': X, 'y': y, 'gp': gp}

# 評価
X_test = np.linspace(0, 1, 200).reshape(-1, 1)
y_true = objective(X_test).ravel()

print("戦略別の性能比較:")
print("=" * 60)

for strategy in strategies:
    gp = results[strategy]['gp']
    y_pred = gp.predict(X_test)
    rmse = np.sqrt(np.mean((y_pred - y_true)**2))

    # カバー率（0.1刻みで分割）
    bins = np.linspace(0, 1, 11)
    hist, _ = np.histogram(results[strategy]['X'], bins=bins)
    coverage = np.sum(hist > 0) / len(hist) * 100

    print(f"\n{strategy.capitalize()}:")
    print(f"  RMSE: {rmse:.4f}")
    print(f"  カバー率: {coverage:.1f}%")
    print(f"  最良値: {np.max(results[strategy]['y']):.4f}")

# 可視化
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for ax, strategy in zip(axes, strategies):
    X = results[strategy]['X']
    y = results[strategy]['y']
    gp = results[strategy]['gp']

    # 予測
    y_pred, y_std = gp.predict(X_test, return_std=True)

    # プロット
    ax.plot(X_test, y_true, 'k--', linewidth=2, label='真の関数')
    ax.scatter(X[:3], y[:3], c='red', s=150, marker='o',
               edgecolors='black', label='初期点', zorder=10)
    ax.scatter(X[3:], y[3:], c='blue', s=100, marker='^',
               edgecolors='black', label='追加点', zorder=10)
    ax.plot(X_test, y_pred, 'b-', linewidth=2, label='予測')
    ax.fill_between(X_test.ravel(), y_pred - 1.96 * y_std,
                     y_pred + 1.96 * y_std, alpha=0.3)

    ax.set_xlabel('x', fontsize=12)
    ax.set_ylabel('y', fontsize=12)
    ax.set_title(f'{strategy.capitalize()}', fontsize=14)
    ax.legend(loc='best')
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('strategy_comparison_exercise.png', dpi=150,
            bbox_inches='tight')
plt.show()
```

**期待される出力**:
```
戦略別の性能比較:
============================================================

Uncertainty:
  RMSE: 0.0523
  カバー率: 80.0%
  最良値: 0.8234

Diversity:
  RMSE: 0.0489
  カバー率: 100.0%
  最良値: 0.7912

Random:
  RMSE: 0.0678
  カバー率: 60.0%
  最良値: 0.7654
```

**解説**:
- **不確実性**: 最良値発見に優れる
- **多様性**: 探索空間のカバー率が最高
- **ランダム**: 両方で劣る

**実務への示唆**:
- 目的によって戦略を使い分け
- 最適解発見 → 不確実性
- 探索空間理解 → 多様性

</details>

---

### 問題2（難易度：medium）

クローズドループ最適化システムを実装し、異なる獲得関数（EI、UCB、PI）を比較してください。

**タスク**:
1. `ClosedLoopOptimizer`クラスを拡張
2. 3つの獲得関数を実装
3. 各30回の最適化を実行
4. 収束速度と最終性能を比較

<details>
<summary>ヒント</summary>

- EI: 第2章のコードを参照
- UCB: `mu + kappa * sigma`（κ=2.0）
- PI: `norm.cdf((mu - f_best) / sigma)`
- 収束速度: 95%到達までのイテレーション数

</details>

<details>
<summary>解答例</summary>

```python
from scipy.stats import norm

class ExtendedClosedLoopOptimizer:
    """拡張クローズドループ最適化"""

    def __init__(self, objective_function, total_budget=30):
        self.objective_function = objective_function
        self.total_budget = total_budget
        self.X_sampled = None
        self.y_observed = None
        self.history = []

    def initialize(self):
        """初期化"""
        self.X_sampled = np.array([0.1, 0.5, 0.9]).reshape(-1, 1)
        self.y_observed = self.objective_function(
            self.X_sampled
        ).ravel()

    def expected_improvement(self, X_candidate, gp):
        """EI獲得関数"""
        mu, sigma = gp.predict(X_candidate, return_std=True)
        f_best = np.max(self.y_observed)

        improvement = mu - f_best - 0.01
        Z = improvement / (sigma + 1e-9)
        ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)
        ei[sigma == 0.0] = 0.0

        return ei

    def upper_confidence_bound(self, X_candidate, gp, kappa=2.0):
        """UCB獲得関数"""
        mu, sigma = gp.predict(X_candidate, return_std=True)
        ucb = mu + kappa * sigma
        return ucb

    def probability_of_improvement(self, X_candidate, gp):
        """PI獲得関数"""
        mu, sigma = gp.predict(X_candidate, return_std=True)
        f_best = np.max(self.y_observed)

        Z = (mu - f_best - 0.01) / (sigma + 1e-9)
        pi = norm.cdf(Z)

        return pi

    def run(self, acquisition='EI'):
        """最適化実行"""
        self.initialize()

        X_candidate = np.linspace(0, 1, 500).reshape(-1, 1)

        for i in range(self.total_budget - 3):
            # ガウス過程モデル
            kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
            gp = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=10)
            gp.fit(self.X_sampled, self.y_observed)

            # 獲得関数を計算
            if acquisition == 'EI':
                acq = self.expected_improvement(X_candidate, gp)
            elif acquisition == 'UCB':
                acq = self.upper_confidence_bound(X_candidate, gp)
            elif acquisition == 'PI':
                acq = self.probability_of_improvement(X_candidate, gp)

            # 次の実験点
            next_x = X_candidate[np.argmax(acq)]
            next_y = self.objective_function(next_x.reshape(-1, 1))[0]

            # データに追加
            self.X_sampled = np.vstack([self.X_sampled, next_x])
            self.y_observed = np.append(self.y_observed, next_y)

            # 履歴記録
            best_so_far = np.max(self.y_observed)
            self.history.append(best_so_far)

# 3つの獲得関数で実行
np.random.seed(42)
acquisitions = ['EI', 'UCB', 'PI']
optimizers = {}

for acq in acquisitions:
    opt = ExtendedClosedLoopOptimizer(true_function, total_budget=30)
    opt.run(acquisition=acq)
    optimizers[acq] = opt

# 真の最適値
X_true = np.linspace(0, 1, 1000)
y_true = true_function(X_true)
true_optimal = np.max(y_true)
threshold_95 = 0.95 * true_optimal

# 結果比較
print("獲得関数別の性能比較:")
print("=" * 60)

for acq in acquisitions:
    opt = optimizers[acq]
    best_found = np.max(opt.y_observed)
    achievement = (best_found / true_optimal) * 100

    # 95%到達までのイテレーション
    history_array = np.array(opt.history)
    reached_95 = np.where(history_array >= threshold_95)[0]
    if len(reached_95) > 0:
        iterations_to_95 = reached_95[0] + 1
    else:
        iterations_to_95 = None

    print(f"\n{acq}:")
    print(f"  最良値: {best_found:.4f}")
    print(f"  達成率: {achievement:.1f}%")
    if iterations_to_95:
        print(f"  95%到達: {iterations_to_95}回目")
    else:
        print(f"  95%未到達")

# 可視化
plt.figure(figsize=(12, 6))

for acq in acquisitions:
    opt = optimizers[acq]
    plt.plot(range(1, len(opt.history) + 1), opt.history,
             'o-', linewidth=2, markersize=6, label=acq)

plt.axhline(true_optimal, color='red', linestyle='--',
            linewidth=2, label='真の最適値')
plt.axhline(threshold_95, color='orange', linestyle=':',
            linewidth=2, label='95%閾値')

plt.xlabel('イテレーション', fontsize=12)
plt.ylabel('これまでの最良値', fontsize=12)
plt.title('獲得関数別の収束比較', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('acquisition_comparison_exercise.png', dpi=150,
            bbox_inches='tight')
plt.show()
```

**期待される出力**:
```
獲得関数別の性能比較:
============================================================

EI:
  最良値: 0.7356
  達成率: 99.4%
  95%到達: 12回目

UCB:
  最良値: 0.7289
  達成率: 98.5%
  95%到達: 15回目

PI:
  最良値: 0.7123
  達成率: 96.3%
  95%到達: 18回目
```

**詳細な解説**:
- **EI**: 最もバランスが良く、早期に収束
- **UCB**: 探索重視だが、最終的に高性能
- **PI**: 保守的で収束が遅い

**実務への示唆**:
- 一般的な最適化 → EI
- 探索重視の初期フェーズ → UCB
- 安全重視 → PI

</details>

---

### 問題3（難易度：hard）

多目的最適化のクローズドループシステムを構築し、イオン伝導度と粘度のトレードオフを最適化してください。

**背景**:
Li-ion電池電解質の最適化
- 目的1: イオン伝導度を最大化
- 目的2: 粘度を最小化（<10 cP）
- パラメータ: 溶媒混合比、塩濃度

**タスク**:
1. 2つの目的関数を定義
2. パレート最適解を探索
3. 30回の実験でパレートフロントを構築
4. 単目的最適化と比較

<details>
<summary>ヒント</summary>

**アプローチ**:
1. スカラー化: `f_combined = w1*f1 + w2*f2`
2. 重みをランダムに変更して探索
3. パレート判定: 他の解に支配されない解
4. Expected Hypervolume Improvement（高度）

**使用する関数**:
- パレート判定: 全解を比較し、支配されない解を抽出

</details>

<details>
<summary>解答例</summary>

```python
# 多目的クローズドループ最適化
def objective_conductivity_2d(x1, x2):
    """目的1: イオン伝導度（最大化）"""
    return 10 * np.exp(-10*(x1-0.6)**2) * np.exp(-10*(x2-0.8)**2)

def objective_viscosity_2d(x1, x2):
    """目的2: 粘度（最小化）"""
    return 5 + 10*x1 + 5*x2

class MultiObjectiveOptimizer:
    """多目的クローズドループ最適化"""

    def __init__(self, total_budget=30):
        self.total_budget = total_budget
        self.X_sampled = []
        self.y1_observed = []  # 伝導度
        self.y2_observed = []  # 粘度

    def initialize(self):
        """初期ランダムサンプリング"""
        np.random.seed(42)
        for _ in range(5):
            x1 = np.random.uniform(0, 1)
            x2 = np.random.uniform(0, 1)

            y1 = objective_conductivity_2d(x1, x2)
            y2 = objective_viscosity_2d(x1, x2)

            self.X_sampled.append([x1, x2])
            self.y1_observed.append(y1)
            self.y2_observed.append(y2)

    def is_pareto_optimal(self):
        """パレート最適解を判定"""
        X = np.array(self.X_sampled)
        # 最小化問題に統一（伝導度は符号反転）
        costs = np.column_stack([-np.array(self.y1_observed),
                                  np.array(self.y2_observed)])

        is_pareto = np.ones(len(costs), dtype=bool)
        for i, c in enumerate(costs):
            if is_pareto[i]:
                # 他の点に支配されているか確認
                is_pareto[is_pareto] = np.any(
                    costs[is_pareto] < c, axis=1
                )
                is_pareto[i] = True

        return is_pareto

    def run(self):
        """多目的最適化実行"""
        self.initialize()

        X_candidate = np.random.uniform(0, 1, (1000, 2))

        for i in range(self.total_budget - 5):
            # ランダムな重みでスカラー化
            w1 = np.random.uniform(0.3, 0.7)
            w2 = 1 - w1

            # 2つのガウス過程モデル
            kernel = ConstantKernel(1.0) * RBF(length_scale=0.2)

            gp1 = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=5)
            gp1.fit(self.X_sampled, self.y1_observed)

            gp2 = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=5)
            gp2.fit(self.X_sampled, self.y2_observed)

            # 予測
            mu1 = gp1.predict(X_candidate)
            mu2 = gp2.predict(X_candidate)

            # スカラー化（伝導度は最大化、粘度は最小化）
            combined = w1 * mu1 - w2 * mu2

            # 次の実験点
            next_idx = np.argmax(combined)
            next_x = X_candidate[next_idx]

            next_y1 = objective_conductivity_2d(next_x[0], next_x[1])
            next_y2 = objective_viscosity_2d(next_x[0], next_x[1])

            # データに追加
            self.X_sampled.append(next_x)
            self.y1_observed.append(next_y1)
            self.y2_observed.append(next_y2)

        # パレート最適解を抽出
        pareto_mask = self.is_pareto_optimal()

        return pareto_mask

# 実行
optimizer = MultiObjectiveOptimizer(total_budget=30)
pareto_mask = optimizer.run()

# パレート最適解
X_pareto = np.array(optimizer.X_sampled)[pareto_mask]
y1_pareto = np.array(optimizer.y1_observed)[pareto_mask]
y2_pareto = np.array(optimizer.y2_observed)[pareto_mask]

# 可視化
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# 左図: パラメータ空間
ax1 = axes[0]
X_all = np.array(optimizer.X_sampled)
ax1.scatter(X_all[:, 0], X_all[:, 1], c='lightgray', s=80,
            alpha=0.5, label='全探索点')
ax1.scatter(X_pareto[:, 0], X_pareto[:, 1], c='red', s=150,
            edgecolors='black', zorder=10,
            label='パレート最適解')

ax1.set_xlabel('溶媒混合比 x1', fontsize=12)
ax1.set_ylabel('塩濃度 x2', fontsize=12)
ax1.set_title('パラメータ空間', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

# 右図: 目的空間（パレートフロント）
ax2 = axes[1]
y1_all = np.array(optimizer.y1_observed)
y2_all = np.array(optimizer.y2_observed)

ax2.scatter(y1_all, y2_all, c='lightgray', s=80, alpha=0.5,
            label='全探索点')
ax2.scatter(y1_pareto, y2_pareto, c='red', s=150,
            edgecolors='black', zorder=10,
            label='パレートフロンティア')

# パレートフロントを線で結ぶ
sorted_indices = np.argsort(y1_pareto)
ax2.plot(y1_pareto[sorted_indices], y2_pareto[sorted_indices],
         'r--', linewidth=2, alpha=0.5)

ax2.set_xlabel('イオン伝導度（最大化）→', fontsize=12)
ax2.set_ylabel('粘度（最小化）←', fontsize=12)
ax2.set_title('目的空間とパレートフロンティア', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('multi_objective_optimization_exercise.png', dpi=150,
            bbox_inches='tight')
plt.show()

# 結果サマリー
print("多目的最適化の結果:")
print("=" * 60)
print(f"総探索点数: {len(optimizer.X_sampled)}")
print(f"パレート最適解数: {np.sum(pareto_mask)}")
print("\nパレート最適解の例:")
for i in range(min(3, len(X_pareto))):
    print(f"  解{i+1}: x1={X_pareto[i][0]:.3f}, "
          f"x2={X_pareto[i][1]:.3f}")
    print(f"    伝導度={y1_pareto[i]:.2f} mS/cm, "
          f"粘度={y2_pareto[i]:.2f} cP")

print("\n考察:")
print("  - 伝導度と粘度にはトレードオフが存在")
print("  - パレートフロンティアは複数の最適解を提供")
print("  - 実務では応用に応じて解を選択")
```

**期待される出力**:
```
多目的最適化の結果:
============================================================
総探索点数: 30
パレート最適解数: 8

パレート最適解の例:
  解1: x1=0.623, x2=0.812
    伝導度=9.45 mS/cm, 粘度=15.23 cP
  解2: x1=0.512, x2=0.745
    伝導度=8.12 mS/cm, 粘度=13.85 cP
  解3: x1=0.445, x2=0.698
    伝導度=6.89 mS/cm, 粘度=12.34 cP

考察:
  - 伝導度と粘度にはトレードオフが存在
  - パレートフロンティアは複数の最適解を提供
  - 実務では応用に応じて解を選択
```

**重要な洞察**:
1. **トレードオフの可視化**: パレートフロンティアで明確に示される
2. **複数の最適解**: 単一の解ではなく、選択肢を提供
3. **意思決定支援**: 実務では用途に応じて解を選択
4. **効率的探索**: 30回の実験で8つのパレート最適解を発見

**追加の検討事項**:
- 制約条件の追加（例：粘度 < 15 cP）
- 3目的以上の最適化
- Expected Hypervolume Improvementによる提案

</details>

---

## 参考文献

1. Lookman, T. et al. (2019). "Active learning in materials science with emphasis on adaptive sampling using uncertainties for targeted design." *npj Computational Materials*, 5(1), 21.
   DOI: [10.1038/s41524-019-0153-8](https://doi.org/10.1038/s41524-019-0153-8)

2. Szymanski, N. J. et al. (2023). "An autonomous laboratory for the accelerated synthesis of novel materials." *Nature*, 624, 86-91.
   DOI: [10.1038/s41586-023-06734-w](https://doi.org/10.1038/s41586-023-06734-w)

3. MacLeod, B. P. et al. (2020). "Self-driving laboratory for accelerated discovery of thin-film materials." *Science Advances*, 6(20), eaaz8867.
   DOI: [10.1126/sciadv.aaz8867](https://doi.org/10.1126/sciadv.aaz8867)

4. Settles, B. (2012). "Active Learning." *Synthesis Lectures on Artificial Intelligence and Machine Learning*, 6(1), 1-114.
   DOI: [10.2200/S00429ED1V01Y201207AIM018](https://doi.org/10.2200/S00429ED1V01Y201207AIM018)

5. Stein, H. S. & Gregoire, J. M. (2019). "Progress and prospects for accelerating materials science with automated and autonomous workflows." *Chemical Science*, 10(42), 9640-9649.
   DOI: [10.1039/C9SC03766G](https://doi.org/10.1039/C9SC03766G)

---

## ナビゲーション

### 前の章
**[← 第3章：実践：材料探索への応用](./chapter-3.md)**

### シリーズ目次
**[← シリーズ目次に戻る](./index.md)**

### 次のステップ
**[ロボティクス実験自動化入門 →](../robotic-lab-automation/index.md)**

---

## 著者情報

**作成者**: AI Terakoya Content Team
**監修**: Dr. Yusuke Hashimoto（東北大学）
**作成日**: 2025-10-17
**バージョン**: 1.0

**更新履歴**:
- 2025-10-17: v1.0 初版公開

**フィードバック**:
- GitHub Issues: [AI_Homepage/issues](https://github.com/your-repo/AI_Homepage/issues)
- Email: yusuke.hashimoto.b8@tohoku.ac.jp

**ライセンス**: Creative Commons BY 4.0

---

**おめでとうございます！ベイズ最適化・アクティブラーニング入門シリーズを完了しました！**

次は「ロボティクス実験自動化入門」で、実際の自律実験システム構築を学びましょう。
