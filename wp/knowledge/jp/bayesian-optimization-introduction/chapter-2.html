<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Á¨¨2Á´†Ôºö„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÁêÜË´ñ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Á¨¨2Á´†Ôºö„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÁêÜË´ñ</h1>
            <p class="subtitle">„Ç¨„Ç¶„ÇπÈÅéÁ®ã„Å®Áç≤ÂæóÈñ¢Êï∞„ÅßÊé¢Á¥¢„ÇíÊúÄÈÅ©Âåñ„Åô„Çã</p>
            <div class="meta">
                <span class="meta-item">üìñ Ë™≠‰∫ÜÊôÇÈñì: 25-30ÂàÜ</span>
                <span class="meta-item">üìä Èõ£ÊòìÂ∫¶: ÂàùÁ¥ö</span>
                <span class="meta-item">üíª „Ç≥„Éº„Éâ‰æã: 10ÂÄã</span>
                <span class="meta-item">üìù ÊºîÁøíÂïèÈ°å: 3Âïè</span>
            </div>
        </div>
    </header>

    <main class="container">

<h1>Á¨¨2Á´†Ôºö„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÁêÜË´ñ</h1>

<strong>„Ç¨„Ç¶„ÇπÈÅéÁ®ã„Å®Áç≤ÂæóÈñ¢Êï∞„ÅßÊé¢Á¥¢„ÇíÊúÄÈÅ©Âåñ„Åô„Çã</strong>

<h2>Â≠¶ÁøíÁõÆÊ®ô</h2>

„Åì„ÅÆÁ´†„ÇíË™≠„ÇÄ„Åì„Å®„Åß„ÄÅ‰ª•‰∏ã„ÇíÁøíÂæó„Åß„Åç„Åæ„ÅôÔºö

- ‚úÖ „Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞„ÅÆÂü∫Êú¨ÂéüÁêÜ„ÇíÁêÜËß£„Åß„Åç„Çã
- ‚úÖ ‰ª£ÁêÜ„É¢„Éá„É´„ÅÆÂΩπÂâ≤„Å®ÊßãÁØâÊñπÊ≥ï„ÇíË™¨Êòé„Åß„Åç„Çã
- ‚úÖ 3„Å§„ÅÆ‰∏ªË¶Å„Å™Áç≤ÂæóÈñ¢Êï∞ÔºàEI„ÄÅPI„ÄÅUCBÔºâ„ÇíÂÆüË£Ö„Åß„Åç„Çã
- ‚úÖ Êé¢Á¥¢„Å®Ê¥ªÁî®„ÅÆ„Éà„É¨„Éº„Éâ„Ç™„Éï„ÇíÊï∞Âºè„ÅßË°®Áèæ„Åß„Åç„Çã
- ‚úÖ ‰∏çÁ¢∫ÂÆüÊÄß„ÅÆÂÆöÈáèÂåñ„Å®„Åù„ÅÆÈáçË¶ÅÊÄß„ÇíÁêÜËß£„Åß„Åç„Çã

<strong>Ë™≠‰∫ÜÊôÇÈñì</strong>: 25-30ÂàÜ
<strong>„Ç≥„Éº„Éâ‰æã</strong>: 10ÂÄã
<strong>ÊºîÁøíÂïèÈ°å</strong>: 3Âïè

---

<h2>2.1 ‰ª£ÁêÜ„É¢„Éá„É´„Å®„ÅØ</h2>

<h3>„Å™„Åú‰ª£ÁêÜ„É¢„Éá„É´„ÅåÂøÖË¶Å„Åã</h3>

ÊùêÊñôÊé¢Á¥¢„Å´„Åä„ÅÑ„Å¶„ÄÅÁúü„ÅÆÁõÆÁöÑÈñ¢Êï∞Ôºà‰æãÔºö„Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶„ÄÅËß¶Â™íÊ¥ªÊÄßÔºâ„ÇíË©ï‰æ°„Åô„Çã„Å´„ÅØ<strong>ÂÆüÈ®ì„ÅåÂøÖË¶Å</strong>„Åß„Åô„ÄÇ„Åó„Åã„Åó„ÄÅÂÆüÈ®ì„ÅØÔºö

- <strong>ÊôÇÈñì„Åå„Åã„Åã„Çã</strong>: 1„Çµ„É≥„Éó„É´Êï∞ÊôÇÈñìÔΩûÊï∞Êó•
- <strong>„Ç≥„Çπ„Éà„ÅåÈ´ò„ÅÑ</strong>: ÊùêÊñôË≤ª„ÄÅË£ÖÁΩÆË≤ª„ÄÅ‰∫∫‰ª∂Ë≤ª
- <strong>ÂõûÊï∞„Å´Âà∂Èôê</strong>: ‰∫àÁÆó„ÉªÊôÇÈñì„ÅÆÂà∂Á¥Ñ

„Åù„Åì„Åß„ÄÅ<strong>Â∞ëÊï∞„ÅÆÂÆüÈ®ìÁµêÊûú„Åã„ÇâÁõÆÁöÑÈñ¢Êï∞„ÇíÊé®ÂÆö„Åô„Çã„É¢„Éá„É´</strong>„ÇíÊßãÁØâ„Åó„Åæ„Åô„ÄÇ„Åì„Çå„Åå<strong>‰ª£ÁêÜ„É¢„Éá„É´ÔºàSurrogate ModelÔºâ</strong>„Åß„Åô„ÄÇ

<h3>‰ª£ÁêÜ„É¢„Éá„É´„ÅÆÂΩπÂâ≤</h3>

<div class="mermaid">graph LR
    A[Â∞ëÊï∞„ÅÆÂÆüÈ®ì„Éá„Éº„Çø<br/>‰æã: 10-20ÁÇπ] --> B[‰ª£ÁêÜ„É¢„Éá„É´ÊßãÁØâ<br/>„Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞]
    B --> C[Êú™Áü•È†òÂüü„ÅÆ‰∫àÊ∏¨<br/>Âπ≥Âùá + ‰∏çÁ¢∫ÂÆüÊÄß]
    C --> D[Áç≤ÂæóÈñ¢Êï∞„ÅÆË®àÁÆó<br/>Ê¨°„ÅÆÂÆüÈ®ìÁÇπ„ÇíÊèêÊ°à]
    D --> E[ÂÆüÈ®ìÂÆüË°å<br/>Êñ∞„Éá„Éº„ÇøÂèñÂæó]
    E --> B

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fce4ec</div>

<strong>‰ª£ÁêÜ„É¢„Éá„É´„ÅÆË¶Å‰ª∂</strong>:
1. <strong>Â∞ëÊï∞„Éá„Éº„Çø„Åß„ÇÇÊ©üËÉΩ</strong>: 10-20ÁÇπÁ®ãÂ∫¶„Åß‰∫àÊ∏¨ÂèØËÉΩ
2. <strong>‰∏çÁ¢∫ÂÆüÊÄß„ÇíÂÆöÈáèÂåñ</strong>: ‰∫àÊ∏¨„ÅÆ‰ø°È†ºÊÄß„ÇíË©ï‰æ°
3. <strong>È´òÈÄü</strong>: ‰ΩïÂçÉÁÇπ„Åß„ÇÇÁû¨ÊôÇ„Å´‰∫àÊ∏¨
4. <strong>ÊüîËªü</strong>: Ë§áÈõë„Å™Èñ¢Êï∞ÂΩ¢Áä∂„Å´ÂØæÂøú

<strong>„Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞ÔºàGaussian Process RegressionÔºâ</strong>„ÅØ„ÄÅ„Åì„Çå„Çâ„ÅÆË¶Å‰ª∂„ÇíÊ∫Ä„Åü„ÅôÂº∑Âäõ„Å™ÊâãÊ≥ï„Åß„Åô„ÄÇ

---

<h2>2.2 „Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞„ÅÆÂü∫Á§é</h2>

<h3>„Ç¨„Ç¶„ÇπÈÅéÁ®ã„Å®„ÅØ</h3>

<strong>„Ç¨„Ç¶„ÇπÈÅéÁ®ãÔºàGaussian Process, GPÔºâ</strong>„ÅØ„ÄÅÈñ¢Êï∞„ÅÆÁ¢∫ÁéáÂàÜÂ∏É„ÇíÂÆöÁæ©„Åô„ÇãÊâãÊ≥ï„Åß„Åô„ÄÇ

<strong>ÂÆöÁæ©</strong>:
> „Ç¨„Ç¶„ÇπÈÅéÁ®ã„Å®„ÅØ„ÄÅ‰ªªÊÑè„ÅÆÊúâÈôêÂÄã„ÅÆÁÇπ„Åß„ÅÆÈñ¢Êï∞ÂÄ§„Åå<strong>Â§öÂ§âÈáè„Ç¨„Ç¶„ÇπÂàÜÂ∏É„Å´Âæì„ÅÜ</strong>„Çà„ÅÜ„Å™Á¢∫ÁéáÈÅéÁ®ã„Åß„ÅÇ„Çã„ÄÇ

<strong>Áõ¥ÊÑüÁöÑÁêÜËß£</strong>:
- 1„Å§„ÅÆÈñ¢Êï∞„Åß„ÅØ„Å™„Åè„ÄÅ<strong>ÁÑ°Êï∞„ÅÆÈñ¢Êï∞„ÅÆÂàÜÂ∏É</strong>„ÇíËÄÉ„Åà„Çã
- Ë¶≥Ê∏¨„Éá„Éº„Çø„Å´Âü∫„Å•„ÅÑ„Å¶„ÄÅÈñ¢Êï∞„ÅÆÂàÜÂ∏É„ÇíÊõ¥Êñ∞
- ÂêÑÁÇπ„Åß„ÅÆ‰∫àÊ∏¨ÂÄ§„ÅØ<strong>Âπ≥Âùá„Å®ÂàÜÊï£</strong>„ÅßË°®Áèæ

<h3>„Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÅÆÊï∞Â≠¶ÁöÑÂÆöÁæ©</h3>

„Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÅØ„ÄÅ<strong>Âπ≥ÂùáÈñ¢Êï∞</strong>$m(x)$„Å®<strong>„Ç´„Éº„Éç„É´Èñ¢Êï∞ÔºàÂÖ±ÂàÜÊï£Èñ¢Êï∞Ôºâ</strong>$k(x, x')$„ÅßÂÆåÂÖ®„Å´ÂÆöÁæ©„Åï„Çå„Åæ„ÅôÔºö

$$
f(x) \sim \mathcal{GP}(m(x), k(x, x'))
$$

<strong>Âπ≥ÂùáÈñ¢Êï∞</strong> $m(x)$:
- ÈÄöÂ∏∏„ÅØ $m(x) = 0$ „Å®‰ªÆÂÆöÔºà„Éá„Éº„Çø„Åã„ÇâÂ≠¶ÁøíÔºâ

<strong>„Ç´„Éº„Éç„É´Èñ¢Êï∞</strong> $k(x, x')$:
- 2ÁÇπÈñì„ÅÆ„ÄåÈ°û‰ººÂ∫¶„Äç„ÇíË°®„Åô
- ÂÖ•Âäõ„ÅåËøë„ÅÑ„Åª„Å©„ÄÅÂá∫Âäõ„ÇÇ‰ºº„Å¶„ÅÑ„Çã„Å®‰ªÆÂÆö

<h3>‰ª£Ë°®ÁöÑ„Å™„Ç´„Éº„Éç„É´Èñ¢Êï∞</h3>

<strong>1. RBFÔºàRadial Basis FunctionÔºâ„Ç´„Éº„Éç„É´</strong>

$$
k(x, x') = \sigma^2 \exp\left(-\frac{||x - x'||^2}{2\ell^2}\right)
$$

- $\sigma^2$: ÂàÜÊï£ÔºàÂá∫Âäõ„ÅÆ„Çπ„Ç±„Éº„É´Ôºâ
- $\ell$: Èï∑„Åï„Çπ„Ç±„Éº„É´Ôºà„Å©„Çå„Å†„ÅëÊªë„Çâ„Åã„ÅãÔºâ

<strong>ÁâπÂæ¥</strong>:
- ÊúÄ„ÇÇ‰∏ÄËà¨ÁöÑ
- ÁÑ°ÈôêÂõûÂæÆÂàÜÂèØËÉΩÔºàÊªë„Çâ„Åã„Å™Èñ¢Êï∞Ôºâ
- ÊùêÊñôÁâπÊÄß‰∫àÊ∏¨„Å´ÈÅ©„Åó„Å¶„ÅÑ„Çã

<strong>„Ç≥„Éº„Éâ‰æã1: RBF„Ç´„Éº„Éç„É´„ÅÆÂèØË¶ñÂåñ</strong>

<pre><code class="language-python"><h1>RBF„Ç´„Éº„Éç„É´„ÅÆÂèØË¶ñÂåñ</h1>
import numpy as np
import matplotlib.pyplot as plt

def rbf_kernel(x1, x2, sigma=1.0, length_scale=1.0):
    """
    RBF„Ç´„Éº„Éç„É´Èñ¢Êï∞

    Parameters:
    -----------
    x1, x2 : array
        ÂÖ•ÂäõÁÇπ
    sigma : float
        Ê®ôÊ∫ñÂÅèÂ∑ÆÔºàÂá∫Âäõ„ÅÆ„Çπ„Ç±„Éº„É´Ôºâ
    length_scale : float
        Èï∑„Åï„Çπ„Ç±„Éº„É´ÔºàÂÖ•Âäõ„ÅÆÁõ∏Èñ¢Ë∑ùÈõ¢Ôºâ

    Returns:
    --------
    float : „Ç´„Éº„Éç„É´ÂÄ§ÔºàÈ°û‰ººÂ∫¶Ôºâ
    """
    distance = np.abs(x1 - x2)
    return sigma<strong>2 * np.exp(-0.5 * (distance / length_scale)</strong>2)

<h1>Áï∞„Å™„ÇãÈï∑„Åï„Çπ„Ç±„Éº„É´„Åß„Ç´„Éº„Éç„É´„ÇíÂèØË¶ñÂåñ</h1>
x_ref = 0.5  # ÂèÇÁÖßÁÇπ
x_range = np.linspace(0, 1, 100)

plt.figure(figsize=(12, 4))

<h1>Â∑¶Âõ≥: Èï∑„Åï„Çπ„Ç±„Éº„É´„ÅÆÂΩ±Èüø</h1>
plt.subplot(1, 3, 1)
for length_scale in [0.05, 0.1, 0.2, 0.5]:
    k_values = [rbf_kernel(x_ref, x, sigma=1.0,
                           length_scale=length_scale)
                for x in x_range]
    plt.plot(x_range, k_values,
             label=f'$\\ell$ = {length_scale}', linewidth=2)
plt.axvline(x_ref, color='black', linestyle='--', alpha=0.5)
plt.xlabel('x', fontsize=12)
plt.ylabel('k(0.5, x)', fontsize=12)
plt.title('Èï∑„Åï„Çπ„Ç±„Éº„É´„ÅÆÂΩ±Èüø', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

<h1>‰∏≠Â§ÆÂõ≥: Ë§áÊï∞„ÅÆÂèÇÁÖßÁÇπ</h1>
plt.subplot(1, 3, 2)
for x_ref_temp in [0.2, 0.5, 0.8]:
    k_values = [rbf_kernel(x_ref_temp, x, sigma=1.0,
                           length_scale=0.1)
                for x in x_range]
    plt.plot(x_range, k_values,
             label=f'x_ref = {x_ref_temp}', linewidth=2)
plt.xlabel('x', fontsize=12)
plt.ylabel('k(x_ref, x)', fontsize=12)
plt.title('ÂèÇÁÖßÁÇπ„ÅÆÂΩ±Èüø', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

<h1>Âè≥Âõ≥: „Ç´„Éº„Éç„É´Ë°åÂàó„ÅÆÂèØË¶ñÂåñ</h1>
plt.subplot(1, 3, 3)
x_grid = np.linspace(0, 1, 50)
K = np.zeros((len(x_grid), len(x_grid)))
for i, x1 in enumerate(x_grid):
    for j, x2 in enumerate(x_grid):
        K[i, j] = rbf_kernel(x1, x2, sigma=1.0, length_scale=0.1)

plt.imshow(K, cmap='viridis', origin='lower', extent=[0, 1, 0, 1])
plt.colorbar(label='„Ç´„Éº„Éç„É´ÂÄ§')
plt.xlabel('x', fontsize=12)
plt.ylabel("x'", fontsize=12)
plt.title('„Ç´„Éº„Éç„É´Ë°åÂàó', fontsize=14)

plt.tight_layout()
plt.savefig('rbf_kernel_visualization.png', dpi=150,
            bbox_inches='tight')
plt.show()

print("RBF„Ç´„Éº„Éç„É´„ÅÆÁâπÊÄß:")
print("  - Èï∑„Åï„Çπ„Ç±„Éº„É´„ÅåÂ∞è„Åï„ÅÑ ‚Üí Â±ÄÊâÄÁöÑ„Å™Áõ∏Èñ¢ÔºàÈã≠„ÅÑ„Éî„Éº„ÇØÔºâ")
print("  - Èï∑„Åï„Çπ„Ç±„Éº„É´„ÅåÂ§ß„Åç„ÅÑ ‚Üí Â∫ÉÁØÑÂõ≤„ÅÆÁõ∏Èñ¢Ôºà„Å™„Å†„Çâ„Åã„Å™Êõ≤Á∑öÔºâ")
print("  - ÂØæËßíÁ∑ö‰∏äÔºàx = x'Ôºâ„Åß„Ç´„Éº„Éç„É´ÂÄ§„ÅåÊúÄÂ§ß")</code></pre>

<strong>ÈáçË¶Å„Å™„Éù„Ç§„É≥„Éà</strong>:
- <strong>Èï∑„Åï„Çπ„Ç±„Éº„É´ $\ell$</strong>: Èñ¢Êï∞„ÅÆÊªë„Çâ„Åã„Åï„ÇíÂà∂Âæ°
  - Â∞è„Åï„ÅÑ $\ell$ ‚Üí ÊÄ•Â≥ª„Å™Â§âÂåñ„ÇíË®±ÂÆπ
  - Â§ß„Åç„ÅÑ $\ell$ ‚Üí Êªë„Çâ„Åã„Å™Èñ¢Êï∞„Çí‰ªÆÂÆö
- <strong>ÊùêÊñôÁßëÂ≠¶„Åß„ÅÆÊÑèÂë≥</strong>: ÁµÑÊàê„ÇÑÊù°‰ª∂„ÅåËøë„ÅÑ„Å®„ÄÅÁâπÊÄß„ÇÇ‰ºº„Å¶„ÅÑ„Çã„Å®‰ªÆÂÆö

---

<h3>„Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞„ÅÆ‰∫àÊ∏¨Âºè</h3>

Ë¶≥Ê∏¨„Éá„Éº„Çø $\mathcal{D} = \{(x_1, y_1), \ldots, (x_n, y_n)\}$ „Åå‰∏é„Åà„Çâ„Çå„Åü„Å®„Åç„ÄÅÊñ∞„Åó„ÅÑÁÇπ $x_*$ „Åß„ÅÆ‰∫àÊ∏¨„ÅØÔºö

<strong>‰∫àÊ∏¨Âπ≥Âùá</strong>:
$$
\mu(x_*) = k_* K^{-1} \mathbf{y}
$$

<strong>‰∫àÊ∏¨ÂàÜÊï£</strong>:
$$
\sigma^2(x_*) = k(x_*, x_*) - k_*^T K^{-1} k_*
$$

„Åì„Åì„ÅßÔºö
- $K$: Ë¶≥Ê∏¨ÁÇπÈñì„ÅÆ„Ç´„Éº„Éç„É´Ë°åÂàó $K_{ij} = k(x_i, x_j)$
- $k_*$: Êñ∞„Åó„ÅÑÁÇπ„Å®Ë¶≥Ê∏¨ÁÇπÈñì„ÅÆ„Ç´„Éº„Éç„É´„Éô„ÇØ„Éà„É´
- $\mathbf{y}$: Ë¶≥Ê∏¨ÂÄ§„ÅÆ„Éô„ÇØ„Éà„É´

<strong>‰∫àÊ∏¨ÂàÜÂ∏É</strong>:
$$
f(x_*) | \mathcal{D} \sim \mathcal{N}(\mu(x_*), \sigma^2(x_*))
$$

<strong>„Ç≥„Éº„Éâ‰æã2: „Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞„ÅÆÂÆüË£Ö„Å®ÂèØË¶ñÂåñ</strong>

<pre><code class="language-python"><h1>„Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞„ÅÆÂÆüË£Ö</h1>
import numpy as np
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist

class GaussianProcessRegressor:
    """
    „Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞„ÅÆÁ∞°ÊòìÂÆüË£Ö

    Parameters:
    -----------
    kernel : str
        „Ç´„Éº„Éç„É´Á®ÆÈ°ûÔºà'rbf'„ÅÆ„Åø„Çµ„Éù„Éº„ÉàÔºâ
    sigma : float
        „Ç´„Éº„Éç„É´„ÅÆÊ®ôÊ∫ñÂÅèÂ∑Æ
    length_scale : float
        „Ç´„Éº„Éç„É´„ÅÆÈï∑„Åï„Çπ„Ç±„Éº„É´
    noise : float
        Ë¶≥Ê∏¨„Éé„Ç§„Ç∫„ÅÆÊ®ôÊ∫ñÂÅèÂ∑Æ
    """

    def __init__(self, kernel='rbf', sigma=1.0,
                 length_scale=0.1, noise=0.01):
        self.kernel = kernel
        self.sigma = sigma
        self.length_scale = length_scale
        self.noise = noise
        self.X_train = None
        self.y_train = None
        self.K_inv = None

    def _kernel(self, X1, X2):
        """„Ç´„Éº„Éç„É´Ë°åÂàó„ÅÆË®àÁÆó"""
        if self.kernel == 'rbf':
            dists = cdist(X1, X2, 'sqeuclidean')
            K = self.sigma**2 * np.exp(-0.5 * dists /
                                        self.length_scale**2)
            return K
        else:
            raise ValueError(f"Unknown kernel: {self.kernel}")

    def fit(self, X_train, y_train):
        """
        „Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´„ÅÆÂ≠¶Áøí

        Parameters:
        -----------
        X_train : array (n_samples, n_features)
            Ë®ìÁ∑¥ÂÖ•Âäõ
        y_train : array (n_samples,)
            Ë®ìÁ∑¥Âá∫Âäõ
        """
        self.X_train = X_train
        self.y_train = y_train

        # „Ç´„Éº„Éç„É´Ë°åÂàó„ÇíË®àÁÆóÔºà„Éé„Ç§„Ç∫È†Ö„ÇíËøΩÂä†Ôºâ
        K = self._kernel(X_train, X_train)
        K += self.noise**2 * np.eye(len(X_train))

        # ÈÄÜË°åÂàó„ÇíË®àÁÆóÔºà‰∫àÊ∏¨„Åß‰ΩøÁî®Ôºâ
        self.K_inv = np.linalg.inv(K)

    def predict(self, X_test, return_std=False):
        """
        ‰∫àÊ∏¨„ÇíÂÆüË°å

        Parameters:
        -----------
        X_test : array (n_test, n_features)
            „ÉÜ„Çπ„ÉàÂÖ•Âäõ
        return_std : bool
            Ê®ôÊ∫ñÂÅèÂ∑Æ„ÇÇËøî„Åô„Åã

        Returns:
        --------
        mean : array (n_test,)
            ‰∫àÊ∏¨Âπ≥Âùá
        std : array (n_test,) (if return_std=True)
            ‰∫àÊ∏¨Ê®ôÊ∫ñÂÅèÂ∑Æ
        """
        # k_* = k(X_test, X_train)
        k_star = self._kernel(X_test, self.X_train)

        # ‰∫àÊ∏¨Âπ≥Âùá: Œº(x_*) = k_* K^{-1} y
        mean = k_star @ self.K_inv @ self.y_train

        if return_std:
            # k(x_*, x_*)
            k_starstar = self._kernel(X_test, X_test)

            # ‰∫àÊ∏¨ÂàÜÊï£: œÉ¬≤(x_*) = k(x_*, x_*) - k_*^T K^{-1} k_*
            variance = np.diag(k_starstar) - np.sum(
                (k_star @ self.K_inv) * k_star, axis=1
            )
            std = np.sqrt(np.maximum(variance, 0))  # Êï∞ÂÄ§Ë™§Â∑ÆÂØæÁ≠ñ
            return mean, std
        else:
            return mean

<h1>„Éá„É¢„É≥„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥: ÊùêÊñô„ÅÆ„Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶‰∫àÊ∏¨</h1>
np.random.seed(42)

<h1>Áúü„ÅÆÈñ¢Êï∞ÔºàÊú™Áü•„Å®‰ªÆÂÆöÔºâ</h1>
def true_function(x):
    """Li-ionÈõªÊ±†ÈõªËß£Ë≥™„ÅÆ„Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶Ôºà‰ªÆÊÉ≥Ôºâ"""
    return (
        np.sin(3 * x) * np.exp(-x) +
        0.7 * np.exp(-((x - 0.5) / 0.2)**2)
    )

<h1>Ë¶≥Ê∏¨„Éá„Éº„ÇøÔºàÂ∞ëÊï∞„ÅÆÂÆüÈ®ìÁµêÊûúÔºâ</h1>
n_observations = 8
X_train = np.random.uniform(0, 1, n_observations).reshape(-1, 1)
y_train = true_function(X_train).ravel() + np.random.normal(0, 0.05,
                                                             n_observations)

<h1>„ÉÜ„Çπ„Éà„Éá„Éº„ÇøÔºà‰∫àÊ∏¨„Åó„Åü„ÅÑÁÇπÔºâ</h1>
X_test = np.linspace(0, 1, 200).reshape(-1, 1)
y_true = true_function(X_test).ravel()

<h1>„Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞„É¢„Éá„É´„ÇíÂ≠¶Áøí</h1>
gp = GaussianProcessRegressor(sigma=1.0, length_scale=0.15, noise=0.05)
gp.fit(X_train, y_train)

<h1>‰∫àÊ∏¨</h1>
y_pred, y_std = gp.predict(X_test, return_std=True)

<h1>ÂèØË¶ñÂåñ</h1>
plt.figure(figsize=(12, 6))

<h1>Áúü„ÅÆÈñ¢Êï∞</h1>
plt.plot(X_test, y_true, 'k--', linewidth=2, label='Áúü„ÅÆÈñ¢Êï∞')

<h1>Ë¶≥Ê∏¨„Éá„Éº„Çø</h1>
plt.scatter(X_train, y_train, c='red', s=100, zorder=10,
            edgecolors='black', label='Ë¶≥Ê∏¨„Éá„Éº„ÇøÔºàÂÆüÈ®ìÁµêÊûúÔºâ')

<h1>‰∫àÊ∏¨Âπ≥Âùá</h1>
plt.plot(X_test, y_pred, 'b-', linewidth=2, label='‰∫àÊ∏¨Âπ≥Âùá')

<h1>‰∏çÁ¢∫ÂÆüÊÄßÔºà95%‰ø°È†ºÂå∫ÈñìÔºâ</h1>
plt.fill_between(
    X_test.ravel(),
    y_pred - 1.96 * y_std,
    y_pred + 1.96 * y_std,
    alpha=0.3,
    color='blue',
    label='95%‰ø°È†ºÂå∫Èñì'
)

plt.xlabel('ÁµÑÊàê„Éë„É©„É°„Éº„Çø x', fontsize=12)
plt.ylabel('„Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶ (mS/cm)', fontsize=12)
plt.title('„Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞„Å´„Çà„ÇãÊùêÊñôÁâπÊÄß‰∫àÊ∏¨', fontsize=14)
plt.legend(loc='best')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('gp_regression_demo.png', dpi=150, bbox_inches='tight')
plt.show()

print("„Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞„ÅÆÁµêÊûú:")
print(f"  Ë¶≥Ê∏¨„Éá„Éº„ÇøÊï∞: {n_observations}")
print(f"  ‰∫àÊ∏¨ÁÇπÊï∞: {len(X_test)}")
print(f"  RMSE: {np.sqrt(np.mean((y_pred - y_true)**2)):.4f}")
print("\nÁâπÂæ¥:")
print("  - Ë¶≥Ê∏¨ÁÇπ‰ªòËøë: ‰∏çÁ¢∫ÂÆüÊÄß„ÅåÂ∞è„Åï„ÅÑÔºà‰ø°È†ºÂå∫Èñì„ÅåÁã≠„ÅÑÔºâ")
print("  - Êú™Ë¶≥Ê∏¨È†òÂüü: ‰∏çÁ¢∫ÂÆüÊÄß„ÅåÂ§ß„Åç„ÅÑÔºà‰ø°È†ºÂå∫Èñì„ÅåÂ∫É„ÅÑÔºâ")
print("  - „Åì„ÅÆ‰∏çÁ¢∫ÂÆüÊÄßÊÉÖÂ†±„ÅåÁç≤ÂæóÈñ¢Êï∞„ÅßÊ¥ªÁî®„Åï„Çå„Çã")</code></pre>

<strong>ÈáçË¶Å„Å™Ë¶≥ÂØü</strong>:
1. <strong>Ë¶≥Ê∏¨ÁÇπ„ÅÆËøë„Åè</strong>: ‰∫àÊ∏¨Á≤æÂ∫¶„ÅåÈ´ò„ÅÑÔºà‰∏çÁ¢∫ÂÆüÊÄßÂ∞èÔºâ
2. <strong>Êú™Ë¶≥Ê∏¨È†òÂüü</strong>: ‰∏çÁ¢∫ÂÆüÊÄß„ÅåÂ§ß„Åç„ÅÑ
3. <strong>„Éá„Éº„Çø„ÅåÂ¢ó„Åà„Çã„Åª„Å©</strong>: ‰∫àÊ∏¨Á≤æÂ∫¶Âêë‰∏ä
4. <strong>‰∏çÁ¢∫ÂÆüÊÄß„ÅÆÂÆöÈáèÂåñ</strong>: „Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÈçµ

---

<h2>2.3 Áç≤ÂæóÈñ¢Êï∞ÔºöÊ¨°„ÅÆÂÆüÈ®ìÁÇπ„Çí„Å©„ÅÜÈÅ∏„Å∂„Åã</h2>

<h3>Áç≤ÂæóÈñ¢Êï∞„ÅÆÂΩπÂâ≤</h3>

<strong>Áç≤ÂæóÈñ¢Êï∞ÔºàAcquisition FunctionÔºâ</strong>„ÅØ„ÄÅ„ÄåÊ¨°„Å´„Å©„Åì„ÇíÂÆüÈ®ì„Åô„Åπ„Åç„Åã„Äç„ÇíÊï∞Â≠¶ÁöÑ„Å´Ê±∫ÂÆö„Åó„Åæ„Åô„ÄÇ

<strong>Ë®≠Ë®àÊÄùÊÉ≥</strong>:
- <strong>È´ò„ÅÑ‰∫àÊ∏¨ÂÄ§„ÅÆÂ†¥ÊâÄ</strong>„ÇíÊé¢Á¥¢ÔºàExploitation: Ê¥ªÁî®Ôºâ
- <strong>‰∏çÁ¢∫ÂÆüÊÄß„ÅåÈ´ò„ÅÑÂ†¥ÊâÄ</strong>„ÇíÊé¢Á¥¢ÔºàExploration: Êé¢Á¥¢Ôºâ
- „Åì„ÅÆ<strong>2„Å§„ÅÆ„Éê„É©„É≥„Çπ</strong>„ÇíÊúÄÈÅ©Âåñ

<h3>Áç≤ÂæóÈñ¢Êï∞„ÅÆ„ÉØ„Éº„ÇØ„Éï„É≠„Éº</h3>

<div class="mermaid">graph TB
    A[„Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´] --> B[‰∫àÊ∏¨Âπ≥Âùá Œº(x)]
    A --> C[‰∫àÊ∏¨Ê®ôÊ∫ñÂÅèÂ∑Æ œÉ(x)]
    B --> D[Áç≤ÂæóÈñ¢Êï∞ Œ±(x)]
    C --> D
    D --> E[Áç≤ÂæóÈñ¢Êï∞„ÇíÊúÄÂ§ßÂåñ]
    E --> F[Ê¨°„ÅÆÂÆüÈ®ìÁÇπ x_next]

    style A fill:#e3f2fd
    style D fill:#fff3e0
    style F fill:#e8f5e9</div>

---

<h3>‰∏ªË¶Å„Å™Áç≤ÂæóÈñ¢Êï∞</h3>

<h4>1. Expected ImprovementÔºàEIÔºâ</h4>

<strong>ÂÆöÁæ©</strong>:
ÁèæÂú®„ÅÆÊúÄËâØÂÄ§ $f_{\text{best}}$ „Åã„Çâ„ÅÆÊîπÂñÑÈáè„ÅÆÊúüÂæÖÂÄ§„ÇíÊúÄÂ§ßÂåñ

$$
\text{EI}(x) = \mathbb{E}[\max(0, f(x) - f_{\text{best}})]
$$

<strong>Ëß£ÊûêËß£</strong>:
$$
\text{EI}(x) = \begin{cases}
(\mu(x) - f_{\text{best}}) \Phi(Z) + \sigma(x) \phi(Z) & \text{if } \sigma(x) > 0 \\
0 & \text{if } \sigma(x) = 0
\end{cases}
$$

„Åì„Åì„ÅßÔºö
$$
Z = \frac{\mu(x) - f_{\text{best}}}{\sigma(x)}
$$
- $\Phi$: Ê®ôÊ∫ñÊ≠£Ë¶èÂàÜÂ∏É„ÅÆÁ¥ØÁ©çÂàÜÂ∏ÉÈñ¢Êï∞
- $\phi$: Ê®ôÊ∫ñÊ≠£Ë¶èÂàÜÂ∏É„ÅÆÁ¢∫ÁéáÂØÜÂ∫¶Èñ¢Êï∞

<strong>ÁâπÂæ¥</strong>:
- <strong>„Éê„É©„É≥„Çπ„ÅåËâØ„ÅÑ</strong>: Êé¢Á¥¢„Å®Ê¥ªÁî®„ÇíËá™ÂãïË™øÊï¥
- <strong>ÊúÄ„ÇÇ‰∏ÄËà¨ÁöÑ</strong>: ÊùêÊñôÁßëÂ≠¶„ÅßÂ∫É„Åè‰ΩøÁî®
- <strong>Ëß£ÊûêÁöÑ</strong>: Ë®àÁÆó„ÅåÈ´òÈÄü

<strong>„Ç≥„Éº„Éâ‰æã3: Expected Improvement„ÅÆÂÆüË£Ö</strong>

<pre><code class="language-python"><h1>Expected Improvement„ÅÆÂÆüË£Ö</h1>
from scipy.stats import norm

def expected_improvement(X, gp, f_best, xi=0.01):
    """
    Expected ImprovementÁç≤ÂæóÈñ¢Êï∞

    Parameters:
    -----------
    X : array (n_samples, n_features)
        Ë©ï‰æ°ÁÇπ
    gp : GaussianProcessRegressor
        Â≠¶ÁøíÊ∏à„Åø„Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´
    f_best : float
        ÁèæÂú®„ÅÆÊúÄËâØÂÄ§
    xi : float
        Êé¢Á¥¢„ÅÆÂº∑„ÅïÔºàexploration parameterÔºâ

    Returns:
    --------
    ei : array (n_samples,)
        EIÂÄ§
    """
    mu, sigma = gp.predict(X, return_std=True)

    # ÊîπÂñÑÈáè
    improvement = mu - f_best - xi

    # Ê®ôÊ∫ñÂåñ
    Z = improvement / (sigma + 1e-9)  # „Çº„É≠Èô§ÁÆóÂõûÈÅø

    # Expected Improvement
    ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)

    # œÉ = 0„ÅÆÂ†¥Âêà„ÅØEI = 0
    ei[sigma == 0.0] = 0.0

    return ei

<h1>„Éá„É¢„É≥„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥</h1>
np.random.seed(42)

<h1>Ë¶≥Ê∏¨„Éá„Éº„Çø</h1>
X_train = np.array([0.1, 0.3, 0.5, 0.7, 0.9]).reshape(-1, 1)
y_train = true_function(X_train).ravel()

<h1>„Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´</h1>
gp = GaussianProcessRegressor(sigma=1.0, length_scale=0.2, noise=0.01)
gp.fit(X_train, y_train)

<h1>„ÉÜ„Çπ„ÉàÁÇπ</h1>
X_test = np.linspace(0, 1, 500).reshape(-1, 1)

<h1>‰∫àÊ∏¨</h1>
y_pred, y_std = gp.predict(X_test, return_std=True)

<h1>ÁèæÂú®„ÅÆÊúÄËâØÂÄ§</h1>
f_best = np.max(y_train)

<h1>EI„ÇíË®àÁÆó</h1>
ei = expected_improvement(X_test, gp, f_best, xi=0.01)

<h1>Ê¨°„ÅÆÂÆüÈ®ìÁÇπ„ÇíÊèêÊ°à</h1>
next_idx = np.argmax(ei)
next_x = X_test[next_idx]

<h1>ÂèØË¶ñÂåñ</h1>
fig, axes = plt.subplots(2, 1, figsize=(12, 10))

<h1>‰∏äÂõ≥: „Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÅÆ‰∫àÊ∏¨</h1>
ax1 = axes[0]
ax1.plot(X_test, true_function(X_test), 'k--',
         linewidth=2, label='Áúü„ÅÆÈñ¢Êï∞')
ax1.scatter(X_train, y_train, c='red', s=100, zorder=10,
            edgecolors='black', label='Ë¶≥Ê∏¨„Éá„Éº„Çø')
ax1.plot(X_test, y_pred, 'b-', linewidth=2, label='‰∫àÊ∏¨Âπ≥Âùá')
ax1.fill_between(X_test.ravel(), y_pred - 1.96 * y_std,
                 y_pred + 1.96 * y_std, alpha=0.3, color='blue',
                 label='95%‰ø°È†ºÂå∫Èñì')
ax1.axhline(f_best, color='green', linestyle=':',
            linewidth=2, label=f'ÁèæÂú®„ÅÆÊúÄËâØÂÄ§ = {f_best:.3f}')
ax1.axvline(next_x, color='orange', linestyle='--',
            linewidth=2, label=f'ÊèêÊ°àÁÇπ = {next_x[0]:.3f}')
ax1.set_ylabel('ÁõÆÁöÑÈñ¢Êï∞', fontsize=12)
ax1.set_title('„Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞„ÅÆ‰∫àÊ∏¨', fontsize=14)
ax1.legend(loc='best')
ax1.grid(True, alpha=0.3)

<h1>‰∏ãÂõ≥: Expected Improvement</h1>
ax2 = axes[1]
ax2.plot(X_test, ei, 'r-', linewidth=2, label='Expected Improvement')
ax2.axvline(next_x, color='orange', linestyle='--',
            linewidth=2, label=f'ÊúÄÂ§ßEIÁÇπ = {next_x[0]:.3f}')
ax2.fill_between(X_test.ravel(), 0, ei, alpha=0.3, color='red')
ax2.set_xlabel('„Éë„É©„É°„Éº„Çø x', fontsize=12)
ax2.set_ylabel('EI(x)', fontsize=12)
ax2.set_title('Expected ImprovementÁç≤ÂæóÈñ¢Êï∞', fontsize=14)
ax2.legend(loc='best')
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('expected_improvement_demo.png', dpi=150,
            bbox_inches='tight')
plt.show()

print(f"Expected Improvement„Å´„Çà„ÇãÊèêÊ°à:")
print(f"  Ê¨°„ÅÆÂÆüÈ®ìÁÇπ: x = {next_x[0]:.3f}")
print(f"  EIÂÄ§: {np.max(ei):.4f}")
print(f"  ‰∫àÊ∏¨Âπ≥Âùá: {y_pred[next_idx]:.3f}")
print(f"  ‰∫àÊ∏¨Ê®ôÊ∫ñÂÅèÂ∑Æ: {y_std[next_idx]:.3f}")</code></pre>

<strong>EI„ÅÆËß£Èáà</strong>:
- <strong>È´ò„ÅÑÂπ≥ÂùáÂÄ§</strong>„ÅÆÂ†¥ÊâÄ ‚Üí Ê¥ªÁî®ÔºàExploitationÔºâ
- <strong>È´ò„ÅÑ‰∏çÁ¢∫ÂÆüÊÄß</strong>„ÅÆÂ†¥ÊâÄ ‚Üí Êé¢Á¥¢ÔºàExplorationÔºâ
- <strong>‰∏°Êñπ„ÇíËÄÉÊÖÆ</strong>„Åó„Å¶„Éê„É©„É≥„Çπ

---

<h4>2. Upper Confidence BoundÔºàUCBÔºâ</h4>

<strong>ÂÆöÁæ©</strong>:
‰∫àÊ∏¨Âπ≥Âùá„Å´‰∏çÁ¢∫ÂÆüÊÄß„ÇíÂä†„Åà„Åü„ÄåÊ•ΩË¶≥ÁöÑ„Å™Êé®ÂÆöÂÄ§„Äç„ÇíÊúÄÂ§ßÂåñ

$$
\text{UCB}(x) = \mu(x) + \kappa \sigma(x)
$$

- $\kappa$: Êé¢Á¥¢„ÅÆÂº∑„Åï„ÇíÂà∂Âæ°„Åô„Çã„Éë„É©„É°„Éº„ÇøÔºàÈÄöÂ∏∏ $\kappa = 2$Ôºâ

<strong>ÁâπÂæ¥</strong>:
- <strong>„Ç∑„É≥„Éó„É´</strong>: ÂÆüË£Ö„ÅåÂÆπÊòì
- <strong>Áõ¥ÊÑüÁöÑ</strong>: Ê•ΩË¶≥‰∏ªÁæ©„ÅÆÂéüÂâáÔºàOptimism in the Face of UncertaintyÔºâ
- <strong>Ë™øÊï¥ÂèØËÉΩ</strong>: $\kappa$„ÅßÊé¢Á¥¢Â∫¶Âêà„ÅÑ„ÇíÂà∂Âæ°

<strong>$\kappa$„ÅÆÂΩ±Èüø</strong>:
- $\kappa$„ÅåÂ§ß„Åç„ÅÑ ‚Üí Êé¢Á¥¢ÈáçË¶ñÔºà„É™„Çπ„ÇØ„ÇíÂèñ„ÇãÔºâ
- $\kappa$„ÅåÂ∞è„Åï„ÅÑ ‚Üí Ê¥ªÁî®ÈáçË¶ñÔºàÂÆâÂÖ®Á≠ñÔºâ

<strong>„Ç≥„Éº„Éâ‰æã4: Upper Confidence Bound„ÅÆÂÆüË£Ö</strong>

<pre><code class="language-python"><h1>Upper Confidence Bound„ÅÆÂÆüË£Ö</h1>
def upper_confidence_bound(X, gp, kappa=2.0):
    """
    Upper Confidence BoundÁç≤ÂæóÈñ¢Êï∞

    Parameters:
    -----------
    X : array (n_samples, n_features)
        Ë©ï‰æ°ÁÇπ
    gp : GaussianProcessRegressor
        Â≠¶ÁøíÊ∏à„Åø„Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´
    kappa : float
        Êé¢Á¥¢„ÅÆÂº∑„ÅïÔºàÈÄöÂ∏∏2.0Ôºâ

    Returns:
    --------
    ucb : array (n_samples,)
        UCBÂÄ§
    """
    mu, sigma = gp.predict(X, return_std=True)
    ucb = mu + kappa * sigma
    return ucb

<h1>„Éá„É¢„É≥„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥: Áï∞„Å™„ÇãŒ∫„Åß„ÅÆÊØîËºÉ</h1>
fig, axes = plt.subplots(3, 1, figsize=(12, 12))

kappa_values = [0.5, 2.0, 5.0]

for i, kappa in enumerate(kappa_values):
    ax = axes[i]

    # UCB„ÇíË®àÁÆó
    ucb = upper_confidence_bound(X_test, gp, kappa=kappa)

    # Ê¨°„ÅÆÂÆüÈ®ìÁÇπ
    next_idx = np.argmax(ucb)
    next_x = X_test[next_idx]

    # ‰∫àÊ∏¨Âπ≥Âùá„Å®‰ø°È†ºÂå∫Èñì
    ax.plot(X_test, y_pred, 'b-', linewidth=2, label='‰∫àÊ∏¨Âπ≥Âùá Œº(x)')
    ax.fill_between(X_test.ravel(),
                    y_pred - 1.96 * y_std,
                    y_pred + 1.96 * y_std,
                    alpha=0.2, color='blue',
                    label='95%‰ø°È†ºÂå∫Èñì')

    # UCB
    ax.plot(X_test, ucb, 'r-', linewidth=2,
            label=f'UCB(x) (Œ∫={kappa})')

    # Ë¶≥Ê∏¨„Éá„Éº„Çø
    ax.scatter(X_train, y_train, c='red', s=100, zorder=10,
               edgecolors='black', label='Ë¶≥Ê∏¨„Éá„Éº„Çø')

    # ÊèêÊ°àÁÇπ
    ax.axvline(next_x, color='orange', linestyle='--',
               linewidth=2, label=f'ÊèêÊ°àÁÇπ = {next_x[0]:.3f}')

    ax.set_ylabel('ÁõÆÁöÑÈñ¢Êï∞', fontsize=12)
    ax.set_title(f'UCB with Œ∫ = {kappa}', fontsize=14)
    ax.legend(loc='best')
    ax.grid(True, alpha=0.3)

    if i == 2:
        ax.set_xlabel('„Éë„É©„É°„Éº„Çø x', fontsize=12)

plt.tight_layout()
plt.savefig('ucb_kappa_comparison.png', dpi=150, bbox_inches='tight')
plt.show()

print("Œ∫„ÅÆÂΩ±Èüø:")
print("  Œ∫ = 0.5: Ê¥ªÁî®ÈáçË¶ñÔºàË¶≥Ê∏¨„Éá„Éº„ÇøËøë„Åè„ÇíÊé¢Á¥¢Ôºâ")
print("  Œ∫ = 2.0: „Éê„É©„É≥„ÇπÔºàÊ®ôÊ∫ñÁöÑ„Å™Ë®≠ÂÆöÔºâ")
print("  Œ∫ = 5.0: Êé¢Á¥¢ÈáçË¶ñÔºàÊú™Áü•È†òÂüü„ÇíÁ©çÊ•µÊé¢Á¥¢Ôºâ")</code></pre>

---

<h4>3. Probability of ImprovementÔºàPIÔºâ</h4>

<strong>ÂÆöÁæ©</strong>:
ÁèæÂú®„ÅÆÊúÄËâØÂÄ§„ÇíË∂Ö„Åà„ÇãÁ¢∫Áéá„ÇíÊúÄÂ§ßÂåñ

$$
\text{PI}(x) = P(f(x) > f_{\text{best}}) = \Phi\left(\frac{\mu(x) - f_{\text{best}}}{\sigma(x)}\right)
$$

<strong>ÁâπÂæ¥</strong>:
- <strong>ÊúÄ„ÇÇ„Ç∑„É≥„Éó„É´</strong>: Ëß£Èáà„ÅåÂÆπÊòì
- <strong>‰øùÂÆàÁöÑ</strong>: Â§ß„Åç„Å™ÊîπÂñÑ„ÇíÊúüÂæÖ„Åó„Å™„ÅÑ
- <strong>ÂÆüÁî®ÁöÑ</strong>: Â∞è„Åï„Å™ÊîπÂñÑ„ÇíÁ©ç„ÅøÈáç„Å≠„ÇãÊà¶Áï•

<strong>„Ç≥„Éº„Éâ‰æã5: Probability of Improvement„ÅÆÂÆüË£Ö</strong>

<pre><code class="language-python"><h1>Probability of Improvement„ÅÆÂÆüË£Ö</h1>
def probability_of_improvement(X, gp, f_best, xi=0.01):
    """
    Probability of ImprovementÁç≤ÂæóÈñ¢Êï∞

    Parameters:
    -----------
    X : array (n_samples, n_features)
        Ë©ï‰æ°ÁÇπ
    gp : GaussianProcessRegressor
        Â≠¶ÁøíÊ∏à„Åø„Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´
    f_best : float
        ÁèæÂú®„ÅÆÊúÄËâØÂÄ§
    xi : float
        Êé¢Á¥¢„ÅÆÂº∑„Åï

    Returns:
    --------
    pi : array (n_samples,)
        PIÂÄ§
    """
    mu, sigma = gp.predict(X, return_std=True)

    # ÊîπÂñÑÈáè
    improvement = mu - f_best - xi

    # Ê®ôÊ∫ñÂåñ
    Z = improvement / (sigma + 1e-9)

    # Probability of Improvement
    pi = norm.cdf(Z)

    return pi

<h1>PI„ÇíË®àÁÆó</h1>
pi = probability_of_improvement(X_test, gp, f_best, xi=0.01)

<h1>ÂèØË¶ñÂåñ</h1>
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(X_test, pi, 'g-', linewidth=2, label='PI(x)')
plt.axvline(X_test[np.argmax(pi)], color='orange',
            linestyle='--', linewidth=2,
            label=f'ÊúÄÂ§ßPIÁÇπ = {X_test[np.argmax(pi)][0]:.3f}')
plt.fill_between(X_test.ravel(), 0, pi, alpha=0.3, color='green')
plt.xlabel('„Éë„É©„É°„Éº„Çø x', fontsize=12)
plt.ylabel('PI(x)', fontsize=12)
plt.title('Probability of Improvement', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

<h1>ÊØîËºÉ: EI vs PI vs UCB</h1>
plt.subplot(1, 2, 2)
ei_normalized = ei / np.max(ei)
pi_normalized = pi / np.max(pi)
ucb_normalized = upper_confidence_bound(X_test, gp, kappa=2.0)
ucb_normalized = (ucb_normalized - np.min(ucb_normalized)) / \
                 (np.max(ucb_normalized) - np.min(ucb_normalized))

plt.plot(X_test, ei_normalized, 'r-', linewidth=2, label='EI (Ê≠£Ë¶èÂåñ)')
plt.plot(X_test, pi_normalized, 'g-', linewidth=2, label='PI (Ê≠£Ë¶èÂåñ)')
plt.plot(X_test, ucb_normalized, 'b-', linewidth=2, label='UCB (Ê≠£Ë¶èÂåñ)')
plt.scatter(X_train, [0.5]*len(X_train), c='red', s=100,
            zorder=10, edgecolors='black', label='Ë¶≥Ê∏¨„Éá„Éº„Çø')
plt.xlabel('„Éë„É©„É°„Éº„Çø x', fontsize=12)
plt.ylabel('Áç≤ÂæóÈñ¢Êï∞ÂÄ§ÔºàÊ≠£Ë¶èÂåñÔºâ', fontsize=12)
plt.title('Áç≤ÂæóÈñ¢Êï∞„ÅÆÊØîËºÉ', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('acquisition_functions_comparison.png', dpi=150,
            bbox_inches='tight')
plt.show()</code></pre>

---

<h3>Áç≤ÂæóÈñ¢Êï∞„ÅÆÊØîËºÉË°®</h3>

| Áç≤ÂæóÈñ¢Êï∞ | ÁâπÂæ¥ | Èï∑ÊâÄ | Áü≠ÊâÄ | Êé®Â•®Áî®ÈÄî |
|---------|------|------|------|---------|
| <strong>EI</strong> | ÊîπÂñÑÈáè„ÅÆÊúüÂæÖÂÄ§ | „Éê„É©„É≥„Çπ„ÅåËâØ„ÅÑ„ÄÅÂÆüÁ∏æË±äÂØå | „ÇÑ„ÇÑË§áÈõë | ‰∏ÄËà¨ÁöÑ„Å™ÊúÄÈÅ©Âåñ |
| <strong>UCB</strong> | Ê•ΩË¶≥ÁöÑÊé®ÂÆö | „Ç∑„É≥„Éó„É´„ÄÅË™øÊï¥ÂèØËÉΩ | Œ∫„ÅÆË™øÊï¥„ÅåÂøÖË¶Å | Êé¢Á¥¢Â∫¶Âêà„ÅÑÂà∂Âæ° |
| <strong>PI</strong> | ÊîπÂñÑÁ¢∫Áéá | ÈùûÂ∏∏„Å´„Ç∑„É≥„Éó„É´ | ‰øùÂÆàÁöÑ | ÂÆâÂÖ®„Å™Êé¢Á¥¢ |

<strong>ÊùêÊñôÁßëÂ≠¶„Åß„ÅÆÊé®Â•®</strong>:
- <strong>ÂàùÂøÉËÄÖ</strong>: EIÔºà„Éê„É©„É≥„Çπ„ÅåËâØ„Åè„ÄÅ„Éá„Éï„Ç©„É´„Éà„ÅßÂÑ™ÁßÄÔºâ
- <strong>Êé¢Á¥¢ÈáçË¶ñ</strong>: UCBÔºàŒ∫ = 2-5Ôºâ
- <strong>ÂÆâÂÖ®Á≠ñ</strong>: PIÔºàÂ∞è„Åï„Å™ÊîπÂñÑ„ÇíÁ¢∫ÂÆü„Å´Ôºâ

---

<h2>2.4 Êé¢Á¥¢„Å®Ê¥ªÁî®„ÅÆ„Éà„É¨„Éº„Éâ„Ç™„Éï</h2>

<h3>Êï∞Â≠¶ÁöÑ„Å™ÂÆöÂºèÂåñ</h3>

Áç≤ÂæóÈñ¢Êï∞„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆ2„Å§„ÅÆÈ†Ö„Å´ÂàÜËß£„Åß„Åç„Åæ„ÅôÔºö

$$
\alpha(x) = \underbrace{\mu(x)}_{\text{Exploitation}} + \underbrace{\lambda \sigma(x)}_{\text{Exploration}}
$$

- <strong>ExploitationÈ†Ö</strong> $\mu(x)$: ‰∫àÊ∏¨Âπ≥Âùá„ÅåÈ´ò„ÅÑÂ†¥ÊâÄ
- <strong>ExplorationÈ†Ö</strong> $\lambda \sigma(x)$: ‰∏çÁ¢∫ÂÆüÊÄß„ÅåÈ´ò„ÅÑÂ†¥ÊâÄ

<h3>„Éà„É¨„Éº„Éâ„Ç™„Éï„ÅÆÂèØË¶ñÂåñ</h3>

<div class="mermaid">graph LR
    subgraph Ê¥ªÁî®Exploitation
    A1[Êó¢Áü•„ÅÆËâØ„ÅÑÈ†òÂüü]
    A2[È´ò„ÅÑ‰∫àÊ∏¨ÂÄ§ Œº(x)]
    A3[‰Ωé„ÅÑ‰∏çÁ¢∫ÂÆüÊÄß œÉ(x)]
    A1 --> A2
    A1 --> A3
    end

    subgraph Êé¢Á¥¢Exploration
    B1[Êú™Áü•„ÅÆÈ†òÂüü]
    B2[Êú™Áü•„ÅÆ‰∫àÊ∏¨ÂÄ§ Œº(x)]
    B3[È´ò„ÅÑ‰∏çÁ¢∫ÂÆüÊÄß œÉ(x)]
    B1 --> B2
    B1 --> B3
    end

    subgraph ÊúÄÈÅ©„Å™„Éê„É©„É≥„Çπ
    C1[Áç≤ÂæóÈñ¢Êï∞]
    C2[Œº(x) + ŒªœÉ(x)]
    C3[Ê¨°„ÅÆÂÆüÈ®ìÁÇπ]
    C1 --> C2
    C2 --> C3
    end

    A2 --> C1
    A3 --> C1
    B2 --> C1
    B3 --> C1

    style A1 fill:#fff3e0
    style B1 fill:#e3f2fd
    style C3 fill:#e8f5e9</div>

<strong>„Ç≥„Éº„Éâ‰æã6: Êé¢Á¥¢„Å®Ê¥ªÁî®„ÅÆ„Éê„É©„É≥„ÇπÂèØË¶ñÂåñ</strong>

<pre><code class="language-python"><h1>Êé¢Á¥¢„Å®Ê¥ªÁî®„ÅÆÂàÜËß£</h1>
def decompose_acquisition(X, gp, f_best, xi=0.01):
    """
    Áç≤ÂæóÈñ¢Êï∞„ÇíÊé¢Á¥¢È†Ö„Å®Ê¥ªÁî®È†Ö„Å´ÂàÜËß£

    Returns:
    --------
    exploitation : Ê¥ªÁî®È†ÖÔºà‰∫àÊ∏¨Âπ≥Âùá„Éô„Éº„ÇπÔºâ
    exploration : Êé¢Á¥¢È†ÖÔºà‰∏çÁ¢∫ÂÆüÊÄß„Éô„Éº„ÇπÔºâ
    """
    mu, sigma = gp.predict(X, return_std=True)

    # Ê¥ªÁî®È†ÖÔºàÂπ≥Âùá„ÅåÈ´ò„ÅÑ„Åª„Å©Â§ß„Åç„ÅÑÔºâ
    exploitation = mu

    # Êé¢Á¥¢È†ÖÔºà‰∏çÁ¢∫ÂÆüÊÄß„ÅåÈ´ò„ÅÑ„Åª„Å©Â§ß„Åç„ÅÑÔºâ
    exploration = sigma

    return exploitation, exploration

<h1>ÂàÜËß£</h1>
exploitation, exploration = decompose_acquisition(X_test, gp, f_best)

<h1>ÂèØË¶ñÂåñ</h1>
fig, axes = plt.subplots(4, 1, figsize=(12, 14))

<h1>1. „Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÅÆ‰∫àÊ∏¨</h1>
ax1 = axes[0]
ax1.plot(X_test, y_pred, 'b-', linewidth=2, label='‰∫àÊ∏¨Âπ≥Âùá Œº(x)')
ax1.fill_between(X_test.ravel(), y_pred - 1.96 * y_std,
                 y_pred + 1.96 * y_std, alpha=0.3, color='blue',
                 label='95%‰ø°È†ºÂå∫Èñì')
ax1.scatter(X_train, y_train, c='red', s=100, zorder=10,
            edgecolors='black', label='Ë¶≥Ê∏¨„Éá„Éº„Çø')
ax1.set_ylabel('ÁõÆÁöÑÈñ¢Êï∞', fontsize=12)
ax1.set_title('„Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÅÆ‰∫àÊ∏¨', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

<h1>2. Ê¥ªÁî®È†ÖÔºàExploitationÔºâ</h1>
ax2 = axes[1]
ax2.plot(X_test, exploitation, 'g-', linewidth=2,
         label='Ê¥ªÁî®È†ÖÔºà‰∫àÊ∏¨Âπ≥ÂùáÔºâ')
ax2.scatter(X_train, y_train, c='red', s=100, zorder=10,
            edgecolors='black', alpha=0.5)
ax2.set_ylabel('Ê¥ªÁî®È†Ö', fontsize=12)
ax2.set_title('Exploitation: Êó¢Áü•„ÅÆËâØ„ÅÑÈ†òÂüü„ÇíÈáçË¶ñ', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

<h1>3. Êé¢Á¥¢È†ÖÔºàExplorationÔºâ</h1>
ax3 = axes[2]
ax3.plot(X_test, exploration, 'orange', linewidth=2,
         label='Êé¢Á¥¢È†ÖÔºà‰∏çÁ¢∫ÂÆüÊÄßÔºâ')
ax3.scatter(X_train, [0]*len(X_train), c='red', s=100,
            zorder=10, edgecolors='black', alpha=0.5,
            label='Ë¶≥Ê∏¨„Éá„Éº„Çø‰ΩçÁΩÆ')
ax3.set_ylabel('Êé¢Á¥¢È†Ö', fontsize=12)
ax3.set_title('Exploration: Êú™Áü•„ÅÆÈ†òÂüü„ÇíÈáçË¶ñ', fontsize=14)
ax3.legend()
ax3.grid(True, alpha=0.3)

<h1>4. Áµ±ÂêàÔºàEIÔºâ</h1>
ax4 = axes[3]
ei_values = expected_improvement(X_test, gp, f_best, xi=0.01)
ax4.plot(X_test, ei_values, 'r-', linewidth=2,
         label='Expected Improvement')
next_x = X_test[np.argmax(ei_values)]
ax4.axvline(next_x, color='purple', linestyle='--',
            linewidth=2, label=f'ÊèêÊ°àÁÇπ = {next_x[0]:.3f}')
ax4.fill_between(X_test.ravel(), 0, ei_values,
                 alpha=0.3, color='red')
ax4.set_xlabel('„Éë„É©„É°„Éº„Çø x', fontsize=12)
ax4.set_ylabel('EI(x)', fontsize=12)
ax4.set_title('Áµ±Âêà: ‰∏°ËÄÖ„ÅÆ„Éê„É©„É≥„Çπ„ÇíÊúÄÈÅ©Âåñ', fontsize=14)
ax4.legend()
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('exploitation_exploration_tradeoff.png', dpi=150,
            bbox_inches='tight')
plt.show()

print("Êé¢Á¥¢„Å®Ê¥ªÁî®„ÅÆ„Éà„É¨„Éº„Éâ„Ç™„Éï:")
print(f"  ÊèêÊ°àÁÇπ x = {next_x[0]:.3f}")
print(f"    ‰∫àÊ∏¨Âπ≥ÂùáÔºàÊ¥ªÁî®Ôºâ: {y_pred[np.argmax(ei_values)]:.3f}")
print(f"    ‰∏çÁ¢∫ÂÆüÊÄßÔºàÊé¢Á¥¢Ôºâ: {y_std[np.argmax(ei_values)]:.3f}")
print(f"    EIÂÄ§: {np.max(ei_values):.4f}")</code></pre>

---

<h2>2.5 Âà∂Á¥Ñ‰ªò„ÅçÊúÄÈÅ©Âåñ„Å®Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ</h2>

<h3>Âà∂Á¥Ñ‰ªò„Åç„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ</h3>

ÂÆüÈöõ„ÅÆÊùêÊñôÈñãÁô∫„Åß„ÅØ„ÄÅ<strong>Âà∂Á¥ÑÊù°‰ª∂</strong>„ÅåÂ≠òÂú®„Åó„Åæ„ÅôÔºö

<strong>‰æãÔºöLi-ionÈõªÊ±†ÈõªËß£Ë≥™</strong>
- „Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶„ÇíÊúÄÂ§ßÂåñÔºàÁõÆÁöÑÈñ¢Êï∞Ôºâ
- Á≤òÂ∫¶ < 10 cPÔºàÂà∂Á¥Ñ1Ôºâ
- ÂºïÁÅ´ÁÇπ > 100¬∞CÔºàÂà∂Á¥Ñ2Ôºâ
- „Ç≥„Çπ„Éà < $50/kgÔºàÂà∂Á¥Ñ3Ôºâ

<strong>Êï∞Â≠¶ÁöÑÂÆöÂºèÂåñ</strong>:
$$
\begin{align}
\max_{x} \quad & f(x) \\
\text{s.t.} \quad & g_i(x) \leq 0, \quad i = 1, \ldots, m \\
& h_j(x) = 0, \quad j = 1, \ldots, p
\end{align}
$$

<strong>„Ç¢„Éó„É≠„Éº„ÉÅ</strong>:
1. <strong>Âà∂Á¥ÑÈñ¢Êï∞„ÇÇ„Ç¨„Ç¶„ÇπÈÅéÁ®ã„Åß„É¢„Éá„É´Âåñ</strong>
2. <strong>Âà∂Á¥Ñ„ÇíÊ∫Ä„Åü„ÅôÁ¢∫Áéá„ÇíÁç≤ÂæóÈñ¢Êï∞„Å´ÁµÑ„ÅøËæº„ÇÄ</strong>

<strong>„Ç≥„Éº„Éâ‰æã7: Âà∂Á¥Ñ‰ªò„Åç„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆ„Éá„É¢</strong>

<pre><code class="language-python"><h1>Âà∂Á¥Ñ‰ªò„Åç„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ</h1>
def constrained_expected_improvement(X, gp_obj, gp_constraint,
                                     f_best, constraint_threshold=0):
    """
    Âà∂Á¥Ñ‰ªò„ÅçExpected Improvement

    Parameters:
    -----------
    gp_obj : „Ç¨„Ç¶„ÇπÈÅéÁ®ãÔºàÁõÆÁöÑÈñ¢Êï∞Ôºâ
    gp_constraint : „Ç¨„Ç¶„ÇπÈÅéÁ®ãÔºàÂà∂Á¥ÑÈñ¢Êï∞Ôºâ
    constraint_threshold : Âà∂Á¥Ñ„ÅÆÈñæÂÄ§Ôºà‚â§ 0„ÅåÂÆüË°åÂèØËÉΩÔºâ
    """
    # ÁõÆÁöÑÈñ¢Êï∞„ÅÆEI
    ei = expected_improvement(X, gp_obj, f_best, xi=0.01)

    # Âà∂Á¥Ñ„ÇíÊ∫Ä„Åü„ÅôÁ¢∫Áéá
    mu_c, sigma_c = gp_constraint.predict(X, return_std=True)
    prob_feasible = norm.cdf((constraint_threshold - mu_c) /
                             (sigma_c + 1e-9))

    # Âà∂Á¥Ñ‰ªò„ÅçEI = EI √ó Âà∂Á¥ÑÊ∫ÄË∂≥Á¢∫Áéá
    cei = ei * prob_feasible

    return cei

<h1>„Éá„É¢: Âà∂Á¥ÑÈñ¢Êï∞„ÇíÂÆöÁæ©</h1>
def constraint_function(x):
    """Âà∂Á¥ÑÈñ¢Êï∞Ôºà‰æãÔºöÁ≤òÂ∫¶„ÅÆ‰∏äÈôêÔºâ"""
    return 0.5 - x  # x < 0.5 „ÅåÂÆüË°åÂèØËÉΩÈ†òÂüü

<h1>Âà∂Á¥Ñ„Éá„Éº„Çø</h1>
y_constraint = constraint_function(X_train).ravel()

<h1>Âà∂Á¥ÑÈñ¢Êï∞Áî®„ÅÆ„Ç¨„Ç¶„ÇπÈÅéÁ®ã</h1>
gp_constraint = GaussianProcessRegressor(sigma=0.5, length_scale=0.2,
                                         noise=0.01)
gp_constraint.fit(X_train, y_constraint)

<h1>Âà∂Á¥Ñ‰ªò„ÅçEI„ÇíË®àÁÆó</h1>
cei = constrained_expected_improvement(X_test, gp, gp_constraint,
                                       f_best, constraint_threshold=0)

<h1>ÂèØË¶ñÂåñ</h1>
fig, axes = plt.subplots(3, 1, figsize=(12, 12))

<h1>‰∏äÂõ≥: ÁõÆÁöÑÈñ¢Êï∞</h1>
ax1 = axes[0]
ax1.plot(X_test, y_pred, 'b-', linewidth=2, label='ÁõÆÁöÑÈñ¢Êï∞„ÅÆ‰∫àÊ∏¨')
ax1.fill_between(X_test.ravel(), y_pred - 1.96 * y_std,
                 y_pred + 1.96 * y_std, alpha=0.3, color='blue')
ax1.scatter(X_train, y_train, c='red', s=100, zorder=10,
            edgecolors='black', label='Ë¶≥Ê∏¨„Éá„Éº„Çø')
ax1.set_ylabel('ÁõÆÁöÑÈñ¢Êï∞', fontsize=12)
ax1.set_title('ÁõÆÁöÑÈñ¢Êï∞Ôºà„Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶Ôºâ', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

<h1>‰∏≠Âõ≥: Âà∂Á¥ÑÈñ¢Êï∞</h1>
ax2 = axes[1]
mu_c, sigma_c = gp_constraint.predict(X_test, return_std=True)
ax2.plot(X_test, mu_c, 'g-', linewidth=2, label='Âà∂Á¥ÑÈñ¢Êï∞„ÅÆ‰∫àÊ∏¨')
ax2.fill_between(X_test.ravel(), mu_c - 1.96 * sigma_c,
                 mu_c + 1.96 * sigma_c, alpha=0.3, color='green')
ax2.axhline(0, color='red', linestyle='--', linewidth=2,
            label='Âà∂Á¥ÑÂ¢ÉÁïåÔºà‚â§ 0 „ÅåÂÆüË°åÂèØËÉΩÔºâ')
ax2.axhspan(-10, 0, alpha=0.2, color='green',
            label='ÂÆüË°åÂèØËÉΩÈ†òÂüü')
ax2.scatter(X_train, y_constraint, c='red', s=100, zorder=10,
            edgecolors='black', label='Ë¶≥Ê∏¨„Éá„Éº„Çø')
ax2.set_ylabel('Âà∂Á¥ÑÈñ¢Êï∞', fontsize=12)
ax2.set_title('Âà∂Á¥ÑÈñ¢Êï∞ÔºàÁ≤òÂ∫¶‰∏äÈôêÔºâ', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

<h1>‰∏ãÂõ≥: Âà∂Á¥Ñ‰ªò„ÅçEI</h1>
ax3 = axes[2]
ei_unconstrained = expected_improvement(X_test, gp, f_best, xi=0.01)
ax3.plot(X_test, ei_unconstrained, 'r--', linewidth=2,
         label='EIÔºàÂà∂Á¥Ñ„Å™„ÅóÔºâ', alpha=0.5)
ax3.plot(X_test, cei, 'r-', linewidth=2, label='Âà∂Á¥Ñ‰ªò„ÅçEI')
next_x = X_test[np.argmax(cei)]
ax3.axvline(next_x, color='purple', linestyle='--', linewidth=2,
            label=f'ÊèêÊ°àÁÇπ = {next_x[0]:.3f}')
ax3.fill_between(X_test.ravel(), 0, cei, alpha=0.3, color='red')
ax3.set_xlabel('„Éë„É©„É°„Éº„Çø x', fontsize=12)
ax3.set_ylabel('Áç≤ÂæóÈñ¢Êï∞', fontsize=12)
ax3.set_title('Âà∂Á¥Ñ‰ªò„ÅçExpected Improvement', fontsize=14)
ax3.legend()
ax3.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('constrained_bayesian_optimization.png', dpi=150,
            bbox_inches='tight')
plt.show()

print("Âà∂Á¥Ñ‰ªò„ÅçÊúÄÈÅ©Âåñ„ÅÆÁµêÊûú:")
print(f"  ÊèêÊ°àÁÇπ: x = {next_x[0]:.3f}")
print(f"  Âà∂Á¥Ñ„Å™„ÅóEI„ÅÆÊúÄÂ§ßÁÇπ: x = {X_test[np.argmax(ei_unconstrained)][0]:.3f}")
print(f"  ‚Üí Âà∂Á¥Ñ„ÇíËÄÉÊÖÆ„Åó„Å¶ÊèêÊ°àÁÇπ„ÅåÂ§âÂåñ")</code></pre>

---

<h3>Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ</h3>

ÊùêÊñôÈñãÁô∫„Åß„ÅØ„ÄÅ<strong>Ë§áÊï∞„ÅÆÁâπÊÄß„ÇíÂêåÊôÇ„Å´ÊúÄÈÅ©Âåñ</strong>„Åó„Åü„ÅÑÂ†¥Âêà„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ

<strong>‰æãÔºöÁÜ±ÈõªÊùêÊñô</strong>
- „Çº„Éº„Éô„ÉÉ„ÇØ‰øÇÊï∞„ÇíÊúÄÂ§ßÂåñ
- ÈõªÊ∞óÊäµÊäóÁéá„ÇíÊúÄÂ∞èÂåñ
- ÁÜ±‰ºùÂ∞éÁéá„ÇíÊúÄÂ∞èÂåñ

<strong>„Éë„É¨„Éº„Éà„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢</strong>:
- „Éà„É¨„Éº„Éâ„Ç™„Éï„Åå„ÅÇ„ÇãÂ†¥Âêà„ÄÅÂçò‰∏Ä„ÅÆÊúÄÈÅ©Ëß£„ÅØÂ≠òÂú®„Åó„Å™„ÅÑ
- <strong>„Éë„É¨„Éº„ÉàÊúÄÈÅ©Ëß£„ÅÆÈõÜÂêà</strong>„ÇíÊ±Ç„ÇÅ„Çã

<strong>„Ç¢„Éó„É≠„Éº„ÉÅ</strong>:
1. <strong>„Çπ„Ç´„É©„ÉºÂåñ</strong>: Èáç„Åø‰ªò„ÅçÂíå $f(x) = w_1 f_1(x) + w_2 f_2(x)$
2. <strong>ParEGO</strong>: „É©„É≥„ÉÄ„É†„Å™Èáç„Åø„Åß„Çπ„Ç´„É©„ÉºÂåñ„ÇíÁπ∞„ÇäËøî„Åô
3. <strong>EHVI</strong>: Expected Hypervolume Improvement

<strong>„Ç≥„Éº„Éâ‰æã8: Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ„ÅÆÂèØË¶ñÂåñ</strong>

<pre><code class="language-python"><h1>Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ„ÅÆ„Éá„É¢</h1>
def objective1(x):
    """ÁõÆÁöÑ1: „Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶ÔºàÊúÄÂ§ßÂåñÔºâ"""
    return true_function(x)

def objective2(x):
    """ÁõÆÁöÑ2: Á≤òÂ∫¶ÔºàÊúÄÂ∞èÂåñÔºâ"""
    return 0.5 + 0.3 * np.sin(5 * x)

<h1>„Éë„É¨„Éº„ÉàÊúÄÈÅ©Ëß£„ÇíË®àÁÆó</h1>
x_grid = np.linspace(0, 1, 1000)
obj1_values = objective1(x_grid)
obj2_values = objective2(x_grid)

<h1>„Éë„É¨„Éº„ÉàÊúÄÈÅ©Âà§ÂÆö</h1>
def is_pareto_optimal(costs):
    """
    „Éë„É¨„Éº„ÉàÊúÄÈÅ©Ëß£„ÇíÂà§ÂÆö

    Parameters:
    -----------
    costs : array (n_samples, n_objectives)
        ÂêÑÁÇπ„ÅÆ„Ç≥„Çπ„ÉàÔºàÊúÄÂ∞èÂåñÂïèÈ°å„Å®„Åó„Å¶Ôºâ

    Returns:
    --------
    pareto_mask : array (n_samples,)
        True„Åå„Éë„É¨„Éº„ÉàÊúÄÈÅ©
    """
    is_pareto = np.ones(len(costs), dtype=bool)
    for i, c in enumerate(costs):
        if is_pareto[i]:
            # ‰ªñ„ÅÆÁÇπ„Å´ÊîØÈÖç„Åï„Çå„Å¶„ÅÑ„Çã„ÅãÁ¢∫Ë™ç
            is_pareto[is_pareto] = np.any(
                costs[is_pareto] < c, axis=1
            )
            is_pareto[i] = True
    return is_pareto

<h1>„Ç≥„Çπ„Éà„Éû„Éà„É™„ÉÉ„ÇØ„ÇπÔºàÊúÄÂ∞èÂåñÂïèÈ°å„Å®„Åó„Å¶Ôºâ</h1>
costs = np.column_stack([
    -obj1_values,  # ÊúÄÂ§ßÂåñ ‚Üí ÊúÄÂ∞èÂåñ
    obj2_values    # ÊúÄÂ∞èÂåñ
])

<h1>„Éë„É¨„Éº„ÉàÊúÄÈÅ©Ëß£</h1>
pareto_mask = is_pareto_optimal(costs)
pareto_x = x_grid[pareto_mask]
pareto_obj1 = obj1_values[pareto_mask]
pareto_obj2 = obj2_values[pareto_mask]

<h1>ÂèØË¶ñÂåñ</h1>
fig = plt.figure(figsize=(14, 6))

<h1>Â∑¶Âõ≥: „Éë„É©„É°„Éº„ÇøÁ©∫Èñì</h1>
ax1 = plt.subplot(1, 2, 1)
ax1.plot(x_grid, obj1_values, 'b-', linewidth=2,
         label='ÁõÆÁöÑ1Ôºà„Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶Ôºâ')
ax1.plot(x_grid, obj2_values, 'r-', linewidth=2,
         label='ÁõÆÁöÑ2ÔºàÁ≤òÂ∫¶Ôºâ')
ax1.scatter(pareto_x, pareto_obj1, c='blue', s=50, alpha=0.6,
            label='„Éë„É¨„Éº„ÉàÊúÄÈÅ©ÔºàÁõÆÁöÑ1Ôºâ')
ax1.scatter(pareto_x, pareto_obj2, c='red', s=50, alpha=0.6,
            label='„Éë„É¨„Éº„ÉàÊúÄÈÅ©ÔºàÁõÆÁöÑ2Ôºâ')
ax1.set_xlabel('„Éë„É©„É°„Éº„Çø x', fontsize=12)
ax1.set_ylabel('ÁõÆÁöÑÈñ¢Êï∞ÂÄ§', fontsize=12)
ax1.set_title('„Éë„É©„É°„Éº„ÇøÁ©∫Èñì', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

<h1>Âè≥Âõ≥: ÁõÆÁöÑÁ©∫ÈñìÔºà„Éë„É¨„Éº„Éà„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢Ôºâ</h1>
ax2 = plt.subplot(1, 2, 2)
ax2.scatter(obj1_values, obj2_values, c='lightgray', s=20,
            alpha=0.5, label='ÂÖ®Êé¢Á¥¢ÁÇπ')
ax2.scatter(pareto_obj1, pareto_obj2, c='red', s=100,
            edgecolors='black', zorder=10,
            label='„Éë„É¨„Éº„Éà„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢')
ax2.plot(pareto_obj1, pareto_obj2, 'r--', linewidth=2, alpha=0.5)
ax2.set_xlabel('ÁõÆÁöÑ1Ôºà„Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶Ôºâ‚Üí ÊúÄÂ§ßÂåñ', fontsize=12)
ax2.set_ylabel('ÁõÆÁöÑ2ÔºàÁ≤òÂ∫¶Ôºâ‚Üí ÊúÄÂ∞èÂåñ', fontsize=12)
ax2.set_title('ÁõÆÁöÑÁ©∫Èñì„Å®„Éë„É¨„Éº„Éà„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('multi_objective_optimization.png', dpi=150,
            bbox_inches='tight')
plt.show()

print(f"„Éë„É¨„Éº„ÉàÊúÄÈÅ©Ëß£Êï∞: {np.sum(pareto_mask)}")
print("„Éà„É¨„Éº„Éâ„Ç™„Éï„ÅÆ‰æã:")
print(f"  È´ò‰ºùÂ∞éÂ∫¶: ÁõÆÁöÑ1 = {np.max(pareto_obj1):.3f}, "
      f"ÁõÆÁöÑ2 = {pareto_obj2[np.argmax(pareto_obj1)]:.3f}")
print(f"  ‰ΩéÁ≤òÂ∫¶: ÁõÆÁöÑ1 = {pareto_obj1[np.argmin(pareto_obj2)]:.3f}, "
      f"ÁõÆÁöÑ2 = {np.min(pareto_obj2):.3f}")</code></pre>

---

<h2>2.6 „Ç≥„É©„É†Ôºö„Ç´„Éº„Éç„É´ÈÅ∏Êäû„ÅÆÂÆüÂãô</h2>

<h3>„Ç´„Éº„Éç„É´„ÅÆÁ®ÆÈ°û„Å®ÁâπÊÄß</h3>

RBF‰ª•Â§ñ„Å´„ÇÇ„ÄÅÂ§öÊßò„Å™„Ç´„Éº„Éç„É´„ÅåÂ≠òÂú®„Åó„Åæ„ÅôÔºö

<strong>Mat√©rn „Ç´„Éº„Éç„É´</strong>:
$$
k(x, x') = \sigma^2 \frac{2^{1-\nu}}{\Gamma(\nu)} \left(\frac{\sqrt{2\nu}||x - x'||}{\ell}\right)^\nu K_\nu\left(\frac{\sqrt{2\nu}||x - x'||}{\ell}\right)
$$

- $\nu$: Êªë„Çâ„Åã„Åï„Éë„É©„É°„Éº„Çø
- $\nu = 1/2$: ÊåáÊï∞„Ç´„Éº„Éç„É´ÔºàÁ≤ó„ÅÑÈñ¢Êï∞Ôºâ
- $\nu = 3/2, 5/2$: ‰∏≠Á®ãÂ∫¶„ÅÆÊªë„Çâ„Åã„Åï
- $\nu \to \infty$: RBF„Ç´„Éº„Éç„É´ÔºàÈùûÂ∏∏„Å´Êªë„Çâ„ÅãÔºâ

<strong>ÊùêÊñôÁßëÂ≠¶„Åß„ÅÆÈÅ∏ÊäûÊåáÈáù</strong>:
- <strong>DFTË®àÁÆóÁµêÊûú</strong>: RBFÔºàÊªë„Çâ„ÅãÔºâ
- <strong>ÂÆüÈ®ì„Éá„Éº„Çø</strong>: Mat√©rn 3/2 or 5/2Ôºà„Éé„Ç§„Ç∫ËÄÉÊÖÆÔºâ
- <strong>ÁµÑÊàêÊúÄÈÅ©Âåñ</strong>: RBF
- <strong>„Éó„É≠„Çª„ÇπÊù°‰ª∂</strong>: Mat√©rnÔºàÊÄ•Â≥ª„Å™Â§âÂåñ„ÅÇ„ÇäÔºâ

<strong>Âë®ÊúüÁöÑÁèæË±°</strong>: Periodic kernel
$$
k(x, x') = \sigma^2 \exp\left(-\frac{2\sin^2(\pi|x - x'|/p)}{\ell^2}\right)
$$
- ÁµêÊô∂ÊßãÈÄ†ÔºàÂë®ÊúüÊÄß„ÅÇ„ÇäÔºâ
- Ê∏©Â∫¶„Çµ„Ç§„ÇØ„É´

---

<h2>2.7 „Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞</h2>

<h3>„Çà„Åè„ÅÇ„ÇãÂïèÈ°å„Å®Ëß£Ê±∫Á≠ñ</h3>

<strong>ÂïèÈ°å1: Áç≤ÂæóÈñ¢Êï∞„ÅåÂ∏∏„Å´Âêå„ÅòÂ†¥ÊâÄ„ÇíÊèêÊ°à„Åô„Çã</strong>

<strong>ÂéüÂõ†</strong>:
- Èï∑„Åï„Çπ„Ç±„Éº„É´„ÅåÂ§ß„Åç„Åô„Åé„Çã ‚Üí ÂÖ®‰Ωì„ÅåÊªë„Çâ„Åã„Åô„Åé
- „Éé„Ç§„Ç∫„Éë„É©„É°„Éº„Çø„ÅåÂ∞è„Åï„Åô„Åé„Çã ‚Üí Ë¶≥Ê∏¨ÁÇπ„ÇíÈÅé‰ø°

<strong>Ëß£Ê±∫Á≠ñ</strong>:
<pre><code class="language-python"><h1>Èï∑„Åï„Çπ„Ç±„Éº„É´„ÇíË™øÊï¥</h1>
gp = GaussianProcessRegressor(length_scale=0.05, noise=0.1)

<h1>„Åæ„Åü„ÅØ„ÄÅ„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÇíËá™ÂãïË™øÊï¥</h1>
from sklearn.gaussian_process import GaussianProcessRegressor as SKGP
from sklearn.gaussian_process.kernels import RBF, WhiteKernel

kernel = RBF(length_scale=0.1) + WhiteKernel(noise_level=0.1)
gp = SKGP(kernel=kernel, n_restarts_optimizer=10)
gp.fit(X_train, y_train)</code></pre>

<strong>ÂïèÈ°å2: ‰∫àÊ∏¨„Åå‰∏çÂÆâÂÆöÔºà‰ø°È†ºÂå∫Èñì„ÅåÁï∞Â∏∏„Å´Â∫É„ÅÑÔºâ</strong>

<strong>ÂéüÂõ†</strong>:
- „Éá„Éº„Çø„ÅåÂ∞ë„Å™„Åô„Åé„Çã
- „Ç´„Éº„Éç„É´Ë°åÂàó„ÅåÊï∞ÂÄ§ÁöÑ„Å´‰∏çÂÆâÂÆö

<strong>Ëß£Ê±∫Á≠ñ</strong>:
<pre><code class="language-python"><h1>Ê≠£ÂâáÂåñÈ†Ö„ÇíËøΩÂä†</h1>
K = kernel_matrix + 1e-6 * np.eye(n_samples)  # „Ç∏„ÉÉ„Çø„Éº„ÇíËøΩÂä†

<h1>„Åæ„Åü„ÅØCholeskyÂàÜËß£„Çí‰ΩøÁî®ÔºàÊï∞ÂÄ§ÂÆâÂÆöÊÄßÂêë‰∏äÔºâ</h1>
from scipy.linalg import cho_solve, cho_factor

L = cho_factor(K, lower=True)
alpha = cho_solve(L, y_train)</code></pre>

<strong>ÂïèÈ°å3: Ë®àÁÆó„ÅåÈÅÖ„ÅÑÔºàÂ§ßË¶èÊ®°„Éá„Éº„ÇøÔºâ</strong>

<strong>ÂéüÂõ†</strong>:
- „Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÅÆË®àÁÆóÈáè: $O(n^3)$Ôºàn = „Éá„Éº„ÇøÊï∞Ôºâ

<strong>Ëß£Ê±∫Á≠ñ</strong>:
<pre><code class="language-python"><h1>1. „Çπ„Éë„Éº„Çπ„Ç¨„Ç¶„ÇπÈÅéÁ®ã</h1>
<h1>‰ª£Ë°®ÁÇπÔºàInducing pointsÔºâ„Çí‰ΩøÁî®</h1>

<h1>2. Ëøë‰ººÊâãÊ≥ï</h1>
<h1>- Sparse GP</h1>
<h1>- Local GPÔºàÈ†òÂüüÂàÜÂâ≤Ôºâ</h1>

<h1>3. „É©„Ç§„Éñ„É©„É™„ÅÆÊ¥ªÁî®</h1>
<h1>GPyTorchÔºàGPUÈ´òÈÄüÂåñÔºâ</h1>
<h1>GPflowÔºàTensorFlow backendÔºâ</h1></code></pre>

---

<h2>2.8 Êú¨Á´†„ÅÆ„Åæ„Å®„ÇÅ</h2>

<h3>Â≠¶„Çì„Å†„Åì„Å®</h3>

1. <strong>‰ª£ÁêÜ„É¢„Éá„É´„ÅÆÂΩπÂâ≤</strong>
   - Â∞ëÊï∞„ÅÆÂÆüÈ®ì„Éá„Éº„Çø„Åã„ÇâÁõÆÁöÑÈñ¢Êï∞„ÇíÊé®ÂÆö
   - „Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞„ÅåÊúÄ„ÇÇ‰∏ÄËà¨ÁöÑ
   - ‰∏çÁ¢∫ÂÆüÊÄß„ÅÆÂÆöÈáèÂåñ„ÅåÂèØËÉΩ

2. <strong>„Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞</strong>
   - „Ç´„Éº„Éç„É´Èñ¢Êï∞„ÅßÁÇπÈñì„ÅÆÈ°û‰ººÂ∫¶„ÇíÂÆöÁæ©
   - RBF„Ç´„Éº„Éç„É´„ÅåÊùêÊñôÁßëÂ≠¶„ÅßÊ®ôÊ∫ñÁöÑ
   - ‰∫àÊ∏¨Âπ≥Âùá„Å®‰∫àÊ∏¨ÂàÜÊï£„ÇíË®àÁÆó

3. <strong>Áç≤ÂæóÈñ¢Êï∞</strong>
   - Ê¨°„ÅÆÂÆüÈ®ìÁÇπ„ÇíÊ±∫ÂÆö„Åô„ÇãÊï∞Â≠¶ÁöÑÂü∫Ê∫ñ
   - EIÔºàExpected ImprovementÔºâ: „Éê„É©„É≥„ÇπÂûã
   - UCBÔºàUpper Confidence BoundÔºâ: Ë™øÊï¥ÂèØËÉΩ
   - PIÔºàProbability of ImprovementÔºâ: „Ç∑„É≥„Éó„É´

4. <strong>Êé¢Á¥¢„Å®Ê¥ªÁî®</strong>
   - Exploitation: Êó¢Áü•„ÅÆËâØ„ÅÑÈ†òÂüü„ÇíÊ¥ªÁî®
   - Exploration: Êú™Áü•„ÅÆÈ†òÂüü„ÇíÊé¢Á¥¢
   - Áç≤ÂæóÈñ¢Êï∞„ÅåËá™ÂãïÁöÑ„Å´„Éê„É©„É≥„ÇπË™øÊï¥

5. <strong>Áô∫Â±ïÁöÑ„Éà„Éî„ÉÉ„ÇØ</strong>
   - Âà∂Á¥Ñ‰ªò„ÅçÊúÄÈÅ©Âåñ: ÂÆüÂãô„ÅßÈáçË¶Å
   - Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ: „Éà„É¨„Éº„Éâ„Ç™„Éï„ÅÆÂèØË¶ñÂåñ

<h3>ÈáçË¶Å„Å™„Éù„Ç§„É≥„Éà</h3>

- ‚úÖ „Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞„ÅØ<strong>‰∏çÁ¢∫ÂÆüÊÄß„ÇíÂÆöÈáèÂåñ</strong>„Åß„Åç„Çã
- ‚úÖ Áç≤ÂæóÈñ¢Êï∞„ÅØ<strong>Êé¢Á¥¢„Å®Ê¥ªÁî®„ÇíÊï∞Â≠¶ÁöÑ„Å´ÊúÄÈÅ©Âåñ</strong>
- ‚úÖ EI„Åå<strong>ÊúÄ„ÇÇ‰∏ÄËà¨ÁöÑ„ÅßÂÆüÁ∏æË±äÂØå</strong>
- ‚úÖ „Ç´„Éº„Éç„É´„ÅÆÈÅ∏Êäû„Åå<strong>„É¢„Éá„É´„ÅÆÊÄßËÉΩ„ÇíÂ∑¶Âè≥</strong>
- ‚úÖ Âà∂Á¥Ñ„ÉªÂ§öÁõÆÁöÑ„Å∏„ÅÆ<strong>Êã°Âºµ„ÅåÂèØËÉΩ</strong>

<h3>Ê¨°„ÅÆÁ´†„Å∏</h3>

Á¨¨3Á´†„Åß„ÅØ„ÄÅPython„É©„Ç§„Éñ„É©„É™„Çí‰Ωø„Å£„ÅüÂÆüË£Ö„ÇíÂ≠¶„Å≥„Åæ„ÅôÔºö
- scikit-optimizeÔºàskoptÔºâ„ÅÆ‰Ωø„ÅÑÊñπ
- BoTorchÔºàPyTorchÁâàÔºâ„ÅÆÂÆüË£Ö
- ÂÆü„Éá„Éº„Çø„Åß„ÅÆÊùêÊñôÊé¢Á¥¢
- „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÉÅ„É•„Éº„Éã„É≥„Ç∞

<strong>[Á¨¨3Á´†ÔºöPythonÂÆüË∑µ ‚Üí](./chapter-3.md)</strong>

---

<h2>ÊºîÁøíÂïèÈ°å</h2>

<h3>ÂïèÈ°å1ÔºàÈõ£ÊòìÂ∫¶ÔºöeasyÔºâ</h3>

RBF„Ç´„Éº„Éç„É´„ÅÆÈï∑„Åï„Çπ„Ç±„Éº„É´ $\ell$ „Åå„ÄÅ„Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÅÆ‰∫àÊ∏¨„Å´‰∏é„Åà„ÇãÂΩ±Èüø„ÇíË™ø„Åπ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

<strong>„Çø„Çπ„ÇØ</strong>:
1. 5ÁÇπ„ÅÆË¶≥Ê∏¨„Éá„Éº„Çø„ÇíÁîüÊàê
2. $\ell = 0.05, 0.1, 0.2, 0.5$ „Åß„Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÇíÂ≠¶Áøí
3. ‰∫àÊ∏¨Âπ≥Âùá„Å®‰ø°È†ºÂå∫Èñì„Çí„Éó„É≠„ÉÉ„Éà
4. Èï∑„Åï„Çπ„Ç±„Éº„É´„ÅÆÂΩ±Èüø„ÇíË™¨Êòé

<details>
<summary>„Éí„É≥„Éà</summary>

- <code>GaussianProcessRegressor</code>„ÅÆ<code>length_scale</code>„Éë„É©„É°„Éº„Çø„ÇíÂ§âÊõ¥
- <code>predict(return_std=True)</code>„ÅßÊ®ôÊ∫ñÂÅèÂ∑Æ„ÇíÂèñÂæó
- Èï∑„Åï„Çπ„Ç±„Éº„É´„ÅåÂ∞è„Åï„ÅÑ ‚Üí Â±ÄÊâÄÁöÑ„Å´„Éï„Ç£„ÉÉ„Éà
- Èï∑„Åï„Çπ„Ç±„Éº„É´„ÅåÂ§ß„Åç„ÅÑ ‚Üí Êªë„Çâ„Åã„Å™Êõ≤Á∑ö

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

<h1>Ë¶≥Ê∏¨„Éá„Éº„Çø</h1>
np.random.seed(42)
X_train = np.array([0.1, 0.3, 0.5, 0.7, 0.9]).reshape(-1, 1)
y_train = true_function(X_train).ravel()

<h1>„ÉÜ„Çπ„Éà„Éá„Éº„Çø</h1>
X_test = np.linspace(0, 1, 200).reshape(-1, 1)
y_true = true_function(X_test).ravel()

<h1>Áï∞„Å™„ÇãÈï∑„Åï„Çπ„Ç±„Éº„É´„ÅßÂ≠¶Áøí</h1>
length_scales = [0.05, 0.1, 0.2, 0.5]
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
axes = axes.ravel()

for i, ls in enumerate(length_scales):
    ax = axes[i]

    # „Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´
    gp = GaussianProcessRegressor(sigma=1.0, length_scale=ls,
                                   noise=0.01)
    gp.fit(X_train, y_train)

    # ‰∫àÊ∏¨
    y_pred, y_std = gp.predict(X_test, return_std=True)

    # „Éó„É≠„ÉÉ„Éà
    ax.plot(X_test, y_true, 'k--', linewidth=2, label='Áúü„ÅÆÈñ¢Êï∞')
    ax.scatter(X_train, y_train, c='red', s=100, zorder=10,
               edgecolors='black', label='Ë¶≥Ê∏¨„Éá„Éº„Çø')
    ax.plot(X_test, y_pred, 'b-', linewidth=2, label='‰∫àÊ∏¨Âπ≥Âùá')
    ax.fill_between(X_test.ravel(), y_pred - 1.96 * y_std,
                    y_pred + 1.96 * y_std, alpha=0.3, color='blue',
                    label='95%‰ø°È†ºÂå∫Èñì')
    ax.set_title(f'Èï∑„Åï„Çπ„Ç±„Éº„É´ = {ls}', fontsize=14)
    ax.set_xlabel('x', fontsize=12)
    ax.set_ylabel('y', fontsize=12)
    ax.legend(loc='best')
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('length_scale_effect.png', dpi=150,
            bbox_inches='tight')
plt.show()

print("Èï∑„Åï„Çπ„Ç±„Éº„É´„ÅÆÂΩ±Èüø:")
print("  Â∞è„Åï„ÅÑ (0.05): Ë¶≥Ê∏¨ÁÇπ„Å´„Å¥„Å£„Åü„Çä„Éï„Ç£„ÉÉ„Éà„ÄÅÈñì„Åå‰∏çÂÆâÂÆö")
print("  ‰∏≠Á®ãÂ∫¶ (0.1-0.2): „Éê„É©„É≥„Çπ„ÅåËâØ„ÅÑ")
print("  Â§ß„Åç„ÅÑ (0.5): Êªë„Çâ„Åã„Å†„Åå„ÄÅË¶≥Ê∏¨ÁÇπ„Åã„Çâ‰πñÈõ¢")</code></pre>

<strong>Ëß£Ë™¨</strong>:
- <strong>$\ell$ = 0.05</strong>: „Ç™„Éº„Éê„Éº„Éï„Ç£„ÉÉ„ÉàÊ∞óÂë≥„ÄÅË¶≥Ê∏¨ÁÇπÈñì„Åå‰∏çÂÆâÂÆö
- <strong>$\ell$ = 0.1-0.2</strong>: ÈÅ©Â∫¶„Å™Êªë„Çâ„Åã„Åï„ÄÅÂÆüÁî®ÁöÑ
- <strong>$\ell$ = 0.5</strong>: „Ç¢„É≥„ÉÄ„Éº„Éï„Ç£„ÉÉ„Éà„ÄÅÊªë„Çâ„Åã„Åô„Åé

<strong>ÊùêÊñôÁßëÂ≠¶„Å∏„ÅÆÁ§∫ÂîÜ</strong>:
- ÂÆüÈ®ì„Éá„Éº„Çø: $\ell$ = 0.1-0.3 „Åå‰∏ÄËà¨ÁöÑ
- DFTË®àÁÆó: „Çà„ÇäÊªë„Çâ„ÅãÔºà$\ell$ = 0.3-0.5Ôºâ
- „ÇØ„É≠„Çπ„Éê„É™„Éá„Éº„Ç∑„Éß„É≥„ÅßÊúÄÈÅ©ÂÄ§„ÇíÊ±∫ÂÆö

</details>

---

<h3>ÂïèÈ°å2ÔºàÈõ£ÊòìÂ∫¶ÔºömediumÔºâ</h3>

3„Å§„ÅÆÁç≤ÂæóÈñ¢Êï∞ÔºàEI„ÄÅUCB„ÄÅPIÔºâ„ÇíÂÆüË£Ö„Åó„ÄÅÂêå„Åò„Éá„Éº„Çø„ÅßÊØîËºÉ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

<strong>„Çø„Çπ„ÇØ</strong>:
1. Âêå„ÅòË¶≥Ê∏¨„Éá„Éº„Çø„Çí‰ΩøÁî®
2. ÂêÑÁç≤ÂæóÈñ¢Êï∞„ÅßÊ¨°„ÅÆÂÆüÈ®ìÁÇπ„ÇíÊèêÊ°à
3. ÊèêÊ°àÁÇπ„ÅÆÈÅï„ÅÑ„ÇíÂèØË¶ñÂåñ
4. „Åù„Çå„Åû„Çå„ÅÆÁâπÂæ¥„ÇíË™¨Êòé

<details>
<summary>„Éí„É≥„Éà</summary>

- Âêå„Åò„Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´„Çí3„Å§„ÅÆÁç≤ÂæóÈñ¢Êï∞„ÅßË©ï‰æ°
- <code>np.argmax()</code>„ÅßÊúÄÂ§ßÂÄ§„ÅÆ‰ΩçÁΩÆ„ÇíÂèñÂæó
- UCB„ÅÆ$\kappa = 2.0$„Çí‰ΩøÁî®

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<pre><code class="language-python"><h1>Ë¶≥Ê∏¨„Éá„Éº„Çø</h1>
np.random.seed(42)
X_train = np.array([0.15, 0.4, 0.6, 0.85]).reshape(-1, 1)
y_train = true_function(X_train).ravel()

<h1>„Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´</h1>
gp = GaussianProcessRegressor(sigma=1.0, length_scale=0.15,
                               noise=0.01)
gp.fit(X_train, y_train)

<h1>ÁèæÂú®„ÅÆÊúÄËâØÂÄ§</h1>
f_best = np.max(y_train)

<h1>„ÉÜ„Çπ„ÉàÁÇπ</h1>
X_test = np.linspace(0, 1, 500).reshape(-1, 1)
y_pred, y_std = gp.predict(X_test, return_std=True)

<h1>Áç≤ÂæóÈñ¢Êï∞„ÇíË®àÁÆó</h1>
ei = expected_improvement(X_test, gp, f_best, xi=0.01)
ucb = upper_confidence_bound(X_test, gp, kappa=2.0)
pi = probability_of_improvement(X_test, gp, f_best, xi=0.01)

<h1>ÊèêÊ°àÁÇπ</h1>
next_x_ei = X_test[np.argmax(ei)]
next_x_ucb = X_test[np.argmax(ucb)]
next_x_pi = X_test[np.argmax(pi)]

<h1>ÂèØË¶ñÂåñ</h1>
fig, axes = plt.subplots(4, 1, figsize=(12, 14))

<h1>1. „Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÅÆ‰∫àÊ∏¨</h1>
ax1 = axes[0]
ax1.plot(X_test, y_pred, 'b-', linewidth=2, label='‰∫àÊ∏¨Âπ≥Âùá')
ax1.fill_between(X_test.ravel(), y_pred - 1.96 * y_std,
                 y_pred + 1.96 * y_std, alpha=0.3, color='blue')
ax1.scatter(X_train, y_train, c='red', s=100, zorder=10,
            edgecolors='black', label='Ë¶≥Ê∏¨„Éá„Éº„Çø')
ax1.axhline(f_best, color='green', linestyle=':', linewidth=2,
            label=f'ÊúÄËâØÂÄ§ = {f_best:.3f}')
ax1.set_ylabel('ÁõÆÁöÑÈñ¢Êï∞', fontsize=12)
ax1.set_title('„Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÅÆ‰∫àÊ∏¨', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

<h1>2. Expected Improvement</h1>
ax2 = axes[1]
ax2.plot(X_test, ei, 'r-', linewidth=2, label='EI')
ax2.axvline(next_x_ei, color='red', linestyle='--', linewidth=2,
            label=f'ÊèêÊ°àÁÇπ = {next_x_ei[0]:.3f}')
ax2.fill_between(X_test.ravel(), 0, ei, alpha=0.3, color='red')
ax2.set_ylabel('EI(x)', fontsize=12)
ax2.set_title('Expected Improvement', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

<h1>3. Upper Confidence Bound</h1>
ax3 = axes[2]
<h1>UCB„ÇíÊ≠£Ë¶èÂåñÔºàÊØîËºÉ„Åó„ÇÑ„Åô„Åè„Åô„Çã„Åü„ÇÅÔºâ</h1>
ucb_normalized = (ucb - np.min(ucb)) / (np.max(ucb) - np.min(ucb))
ax3.plot(X_test, ucb_normalized, 'b-', linewidth=2, label='UCB (Ê≠£Ë¶èÂåñ)')
ax3.axvline(next_x_ucb, color='blue', linestyle='--', linewidth=2,
            label=f'ÊèêÊ°àÁÇπ = {next_x_ucb[0]:.3f}')
ax3.fill_between(X_test.ravel(), 0, ucb_normalized, alpha=0.3,
                 color='blue')
ax3.set_ylabel('UCB(x)', fontsize=12)
ax3.set_title('Upper Confidence Bound (Œ∫=2.0)', fontsize=14)
ax3.legend()
ax3.grid(True, alpha=0.3)

<h1>4. Probability of Improvement</h1>
ax4 = axes[3]
ax4.plot(X_test, pi, 'g-', linewidth=2, label='PI')
ax4.axvline(next_x_pi, color='green', linestyle='--', linewidth=2,
            label=f'ÊèêÊ°àÁÇπ = {next_x_pi[0]:.3f}')
ax4.fill_between(X_test.ravel(), 0, pi, alpha=0.3, color='green')
ax4.set_xlabel('„Éë„É©„É°„Éº„Çø x', fontsize=12)
ax4.set_ylabel('PI(x)', fontsize=12)
ax4.set_title('Probability of Improvement', fontsize=14)
ax4.legend()
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('acquisition_functions_detailed_comparison.png',
            dpi=150, bbox_inches='tight')
plt.show()

<h1>ÁµêÊûú„ÅÆ„Çµ„Éû„É™„Éº</h1>
print("Áç≤ÂæóÈñ¢Êï∞Âà•„ÅÆÊèêÊ°àÁÇπ:")
print(f"  EI:  x = {next_x_ei[0]:.3f}")
print(f"  UCB: x = {next_x_ucb[0]:.3f}")
print(f"  PI:  x = {next_x_pi[0]:.3f}")

print("\nÁâπÂæ¥:")
print("  EI: „Éê„É©„É≥„ÇπÂûã„ÄÅÊîπÂñÑÈáè„ÅÆÊúüÂæÖÂÄ§„ÇíÊúÄÂ§ßÂåñ")
print("  UCB: Êé¢Á¥¢ÈáçË¶ñ„ÄÅ‰∏çÁ¢∫ÂÆüÊÄß„ÅåÈ´ò„ÅÑÈ†òÂüü„ÇíÂ•Ω„ÇÄ")
print("  PI: ‰øùÂÆàÁöÑ„ÄÅÂ∞è„Åï„Å™ÊîπÂñÑ„Åß„ÇÇÁ©çÊ•µÁöÑ")</code></pre>

<strong>ÊúüÂæÖ„Åï„Çå„ÇãÂá∫Âäõ</strong>:
<pre><code>Áç≤ÂæóÈñ¢Êï∞Âà•„ÅÆÊèêÊ°àÁÇπ:
  EI:  x = 0.722
  UCB: x = 0.108
  PI:  x = 0.752

ÁâπÂæ¥:
  EI: „Éê„É©„É≥„ÇπÂûã„ÄÅÊîπÂñÑÈáè„ÅÆÊúüÂæÖÂÄ§„ÇíÊúÄÂ§ßÂåñ
  UCB: Êé¢Á¥¢ÈáçË¶ñ„ÄÅ‰∏çÁ¢∫ÂÆüÊÄß„ÅåÈ´ò„ÅÑÈ†òÂüü„ÇíÂ•Ω„ÇÄ
  PI: ‰øùÂÆàÁöÑ„ÄÅÂ∞è„Åï„Å™ÊîπÂñÑ„Åß„ÇÇÁ©çÊ•µÁöÑ</code></pre>

<strong>Ë©≥Á¥∞„Å™Ëß£Ë™¨</strong>:
- <strong>EI</strong>: Êú™Ë¶≥Ê∏¨È†òÂüü„Å®‰∫àÊ∏¨„ÅåËâØ„ÅÑÈ†òÂüü„ÅÆ‰∏≠Èñì„ÇíÊèêÊ°à
- <strong>UCB</strong>: „Éá„Éº„Çø„ÅåÂ∞ë„Å™„ÅÑÂ∑¶Á´Ø„ÇíÊé¢Á¥¢Ôºà‰∏çÁ¢∫ÂÆüÊÄßÈáçË¶ñÔºâ
- <strong>PI</strong>: ‰∫àÊ∏¨Âπ≥Âùá„ÅåÊúÄËâØÂÄ§„ÇíË∂Ö„Åà„Åù„ÅÜ„Å™Â†¥ÊâÄ„ÇíÊèêÊ°à

<strong>ÂÆüÂãô„Åß„ÅÆÈÅ∏Êäû</strong>:
- ‰∏ÄËà¨ÁöÑ„Å™ÊúÄÈÅ©Âåñ ‚Üí EI
- ÂàùÊúüÊé¢Á¥¢„Éï„Çß„Éº„Ç∫ ‚Üí UCBÔºàŒ∫Â§ß„Åç„ÇÅÔºâ
- ÂèéÊùü„Éï„Çß„Éº„Ç∫ ‚Üí PI or EI

</details>

---

<h3>ÂïèÈ°å3ÔºàÈõ£ÊòìÂ∫¶ÔºöhardÔºâ</h3>

Âà∂Á¥Ñ‰ªò„Åç„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÇíÂÆüË£Ö„Åó„ÄÅÂà∂Á¥Ñ„Åå„Å™„ÅÑÂ†¥Âêà„Å®ÊØîËºÉ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

<strong>ËÉåÊôØ</strong>:
Li-ionÈõªÊ±†ÈõªËß£Ë≥™„ÅÆÊúÄÈÅ©Âåñ
- ÁõÆÁöÑ: „Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶„ÇíÊúÄÂ§ßÂåñ
- Âà∂Á¥Ñ: Á≤òÂ∫¶ < 10 cP

<strong>„Çø„Çπ„ÇØ</strong>:
1. ÁõÆÁöÑÈñ¢Êï∞„Å®Âà∂Á¥ÑÈñ¢Êï∞„ÇíÂÆöÁæ©
2. Âà∂Á¥Ñ„Å™„Åó„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÇíÂÆüË°åÔºà10ÂõûÔºâ
3. Âà∂Á¥Ñ‰ªò„Åç„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÇíÂÆüË°åÔºà10ÂõûÔºâ
4. Êé¢Á¥¢„ÅÆËªåË∑°„ÇíÊØîËºÉ
5. ÊúÄÁµÇÁöÑ„Å´Ë¶ã„Å§„Åã„Å£„ÅüËß£„ÇíË©ï‰æ°

<details>
<summary>„Éí„É≥„Éà</summary>

<strong>„Ç¢„Éó„É≠„Éº„ÉÅ</strong>:
1. ÂàùÊúü„É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞Ôºà3ÁÇπÔºâ
2. „Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´„Çí2„Å§ÊßãÁØâÔºàÁõÆÁöÑÈñ¢Êï∞Áî®„ÄÅÂà∂Á¥ÑÈñ¢Êï∞Áî®Ôºâ
3. „É´„Éº„Éó„ÅßÈÄêÊ¨°„Çµ„É≥„Éó„É™„É≥„Ç∞
4. Âà∂Á¥Ñ‰ªò„ÅçEI„Çí‰ΩøÁî®

<strong>‰ΩøÁî®„Åô„ÇãÈñ¢Êï∞</strong>:
- <code>constrained_expected_improvement()</code>

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<pre><code class="language-python"><h1>ÁõÆÁöÑÈñ¢Êï∞„Å®Âà∂Á¥ÑÈñ¢Êï∞„ÇíÂÆöÁæ©</h1>
def objective_conductivity(x):
    """„Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶ÔºàÊúÄÂ§ßÂåñÔºâ"""
    return true_function(x)

def constraint_viscosity(x):
    """Á≤òÂ∫¶„ÅÆÂà∂Á¥ÑÔºà‚â§ 10 cP„Çí0„Å´Ê≠£Ë¶èÂåñÔºâ"""
    viscosity = 15 - 10 * x  # Á≤òÂ∫¶„ÅÆ„É¢„Éá„É´
    return viscosity - 10  # 10 cP‰ª•‰∏ã„ÅåÂÆüË°åÂèØËÉΩÔºà‚â§ 0Ôºâ

<h1>„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥</h1>
def run_bayesian_optimization(n_iterations=10,
                               use_constraint=False):
    """
    „Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÇíÂÆüË°å

    Parameters:
    -----------
    n_iterations : int
        ÊúÄÈÅ©Âåñ„ÅÆ„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥Êï∞
    use_constraint : bool
        Âà∂Á¥Ñ„Çí‰ΩøÁî®„Åô„Çã„Åã

    Returns:
    --------
    X_sampled : ÂÆüÈ®ìÁÇπ
    y_sampled : ÁõÆÁöÑÈñ¢Êï∞ÂÄ§
    c_sampled : Âà∂Á¥ÑÈñ¢Êï∞ÂÄ§ÔºàÂà∂Á¥Ñ„ÅÇ„ÇäÊôÇ„ÅÆ„ÅøÔºâ
    """
    # ÂàùÊúü„É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞
    np.random.seed(42)
    X_sampled = np.random.uniform(0, 1, 3).reshape(-1, 1)
    y_sampled = objective_conductivity(X_sampled).ravel()
    c_sampled = constraint_viscosity(X_sampled).ravel()

    # ÈÄêÊ¨°„Çµ„É≥„Éó„É™„É≥„Ç∞
    for i in range(n_iterations - 3):
        # „Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´ÔºàÁõÆÁöÑÈñ¢Êï∞Ôºâ
        gp_obj = GaussianProcessRegressor(sigma=1.0,
                                           length_scale=0.15,
                                           noise=0.01)
        gp_obj.fit(X_sampled, y_sampled)

        # ÂÄôË£úÁÇπ
        X_candidate = np.linspace(0, 1, 1000).reshape(-1, 1)

        if use_constraint:
            # „Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´ÔºàÂà∂Á¥ÑÈñ¢Êï∞Ôºâ
            gp_constraint = GaussianProcessRegressor(sigma=0.5,
                                                     length_scale=0.2,
                                                     noise=0.01)
            gp_constraint.fit(X_sampled, c_sampled)

            # Âà∂Á¥Ñ‰ªò„ÅçEI
            f_best = np.max(y_sampled)
            acq = constrained_expected_improvement(
                X_candidate, gp_obj, gp_constraint, f_best,
                constraint_threshold=0
            )
        else:
            # Âà∂Á¥Ñ„Å™„ÅóEI
            f_best = np.max(y_sampled)
            acq = expected_improvement(X_candidate, gp_obj,
                                       f_best, xi=0.01)

        # Ê¨°„ÅÆÂÆüÈ®ìÁÇπ
        next_x = X_candidate[np.argmax(acq)]

        # ÂÆüÈ®ìÂÆüË°å
        next_y = objective_conductivity(next_x).ravel()[0]
        next_c = constraint_viscosity(next_x).ravel()[0]

        # „Éá„Éº„Çø„Å´ËøΩÂä†
        X_sampled = np.vstack([X_sampled, next_x])
        y_sampled = np.append(y_sampled, next_y)
        c_sampled = np.append(c_sampled, next_c)

    return X_sampled, y_sampled, c_sampled

<h1>2„Å§„ÅÆ„Ç∑„Éä„É™„Ç™„ÇíÂÆüË°å</h1>
X_unconst, y_unconst, c_unconst = run_bayesian_optimization(
    n_iterations=10, use_constraint=False
)
X_const, y_const, c_const = run_bayesian_optimization(
    n_iterations=10, use_constraint=True
)

<h1>ÂèØË¶ñÂåñ</h1>
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

<h1>Â∑¶‰∏ä: ÁõÆÁöÑÈñ¢Êï∞</h1>
ax1 = axes[0, 0]
x_fine = np.linspace(0, 1, 500)
y_fine = objective_conductivity(x_fine)
ax1.plot(x_fine, y_fine, 'k-', linewidth=2, label='Áúü„ÅÆÈñ¢Êï∞')
ax1.scatter(X_unconst, y_unconst, c='blue', s=100, alpha=0.6,
            label='Âà∂Á¥Ñ„Å™„Åó', marker='o')
ax1.scatter(X_const, y_const, c='red', s=100, alpha=0.6,
            label='Âà∂Á¥Ñ‰ªò„Åç', marker='^')
ax1.set_xlabel('„Éë„É©„É°„Éº„Çø x', fontsize=12)
ax1.set_ylabel('„Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶', fontsize=12)
ax1.set_title('ÁõÆÁöÑÈñ¢Êï∞„ÅÆÊé¢Á¥¢', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

<h1>Âè≥‰∏ä: Âà∂Á¥ÑÈñ¢Êï∞</h1>
ax2 = axes[0, 1]
c_fine = constraint_viscosity(x_fine)
ax2.plot(x_fine, c_fine, 'k-', linewidth=2, label='Âà∂Á¥ÑÈñ¢Êï∞')
ax2.axhline(0, color='red', linestyle='--', linewidth=2,
            label='Âà∂Á¥ÑÂ¢ÉÁïåÔºà‚â§ 0„ÅåÂÆüË°åÂèØËÉΩÔºâ')
ax2.axhspan(-20, 0, alpha=0.2, color='green',
            label='ÂÆüË°åÂèØËÉΩÈ†òÂüü')
ax2.scatter(X_unconst, c_unconst, c='blue', s=100, alpha=0.6,
            label='Âà∂Á¥Ñ„Å™„Åó', marker='o')
ax2.scatter(X_const, c_const, c='red', s=100, alpha=0.6,
            label='Âà∂Á¥Ñ‰ªò„Åç', marker='^')
ax2.set_xlabel('„Éë„É©„É°„Éº„Çø x', fontsize=12)
ax2.set_ylabel('Âà∂Á¥ÑÈñ¢Êï∞ÂÄ§', fontsize=12)
ax2.set_title('Âà∂Á¥Ñ„ÅÆÊ∫ÄË∂≥Â∫¶', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

<h1>Â∑¶‰∏ã: ÊúÄËâØÂÄ§„ÅÆÊé®Áßª</h1>
ax3 = axes[1, 0]
best_unconst = np.maximum.accumulate(y_unconst)
best_const = np.maximum.accumulate(y_const)
ax3.plot(range(1, 11), best_unconst, 'o-', color='blue',
         linewidth=2, markersize=8, label='Âà∂Á¥Ñ„Å™„Åó')
ax3.plot(range(1, 11), best_const, '^-', color='red',
         linewidth=2, markersize=8, label='Âà∂Á¥Ñ‰ªò„Åç')
ax3.set_xlabel('ÂÆüÈ®ìÂõûÊï∞', fontsize=12)
ax3.set_ylabel('„Åì„Çå„Åæ„Åß„ÅÆÊúÄËâØÂÄ§', fontsize=12)
ax3.set_title('ÊúÄËâØÂÄ§„ÅÆÊé®Áßª', fontsize=14)
ax3.legend()
ax3.grid(True, alpha=0.3)

<h1>Âè≥‰∏ã: Âà∂Á¥ÑÊ∫ÄË∂≥Â∫¶„ÅÆÊé®Áßª</h1>
ax4 = axes[1, 1]
<h1>Âà∂Á¥Ñ„ÇíÊ∫Ä„Åü„Åô„Çµ„É≥„Éó„É´„ÅÆÊï∞</h1>
feasible_unconst = np.cumsum(c_unconst <= 0)
feasible_const = np.cumsum(c_const <= 0)
ax4.plot(range(1, 11), feasible_unconst, 'o-', color='blue',
         linewidth=2, markersize=8, label='Âà∂Á¥Ñ„Å™„Åó')
ax4.plot(range(1, 11), feasible_const, '^-', color='red',
         linewidth=2, markersize=8, label='Âà∂Á¥Ñ‰ªò„Åç')
ax4.set_xlabel('ÂÆüÈ®ìÂõûÊï∞', fontsize=12)
ax4.set_ylabel('ÂÆüË°åÂèØËÉΩËß£„ÅÆÁ¥ØÁ©çÊï∞', fontsize=12)
ax4.set_title('Âà∂Á¥ÑÊ∫ÄË∂≥Â∫¶„ÅÆÊé®Áßª', fontsize=14)
ax4.legend()
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('constrained_bo_comparison.png', dpi=150,
            bbox_inches='tight')
plt.show()

<h1>ÁµêÊûú„ÅÆ„Çµ„Éû„É™„Éº</h1>
print("ÊúÄÈÅ©ÂåñÁµêÊûú„ÅÆÊØîËºÉ:")
print("\nÂà∂Á¥Ñ„Å™„Åó„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ:")
print(f"  ÊúÄËâØÂÄ§: {np.max(y_unconst):.4f}")
print(f"  ÂØæÂøú„Åô„Çãx: {X_unconst[np.argmax(y_unconst)][0]:.3f}")
print(f"  Âà∂Á¥ÑÂÄ§: {c_unconst[np.argmax(y_unconst)]:.4f}")
print(f"  Âà∂Á¥ÑÊ∫ÄË∂≥: {'Yes' if c_unconst[np.argmax(y_unconst)] <= 0 else 'No'}")
print(f"  ÂÆüË°åÂèØËÉΩËß£„ÅÆÊï∞: {np.sum(c_unconst <= 0)}/10")

print("\nÂà∂Á¥Ñ‰ªò„Åç„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ:")
<h1>Âà∂Á¥Ñ„ÇíÊ∫Ä„Åü„ÅôËß£„ÅÆ‰∏≠„ÅßÊúÄËâØ„ÅÆ„ÇÇ„ÅÆ„ÇíÊé¢„Åô</h1>
feasible_indices = np.where(c_const <= 0)[0]
if len(feasible_indices) > 0:
    best_feasible_idx = feasible_indices[np.argmax(y_const[feasible_indices])]
    print(f"  ÊúÄËâØÂÄ§: {y_const[best_feasible_idx]:.4f}")
    print(f"  ÂØæÂøú„Åô„Çãx: {X_const[best_feasible_idx][0]:.3f}")
    print(f"  Âà∂Á¥ÑÂÄ§: {c_const[best_feasible_idx]:.4f}")
    print(f"  Âà∂Á¥ÑÊ∫ÄË∂≥: Yes")
else:
    print("  ÂÆüË°åÂèØËÉΩËß£„Å™„Åó")
print(f"  ÂÆüË°åÂèØËÉΩËß£„ÅÆÊï∞: {np.sum(c_const <= 0)}/10")

print("\nËÄÉÂØü:")
print("  - Âà∂Á¥Ñ‰ªò„Åç„ÅØÂÆüË°åÂèØËÉΩÈ†òÂüü„Å´ÈõÜ‰∏≠„Åó„Å¶Êé¢Á¥¢")
print("  - Âà∂Á¥Ñ„Å™„Åó„ÅØÈ´ò„ÅÑÁõÆÁöÑÈñ¢Êï∞ÂÄ§„ÇíÁô∫Ë¶ã„Åô„Çã„Åå„ÄÅÂà∂Á¥ÑÈÅïÂèç„ÅÆÂèØËÉΩÊÄß")
print("  - ÂÆüÂãô„Åß„ÅØÂà∂Á¥Ñ„ÇíËÄÉÊÖÆ„Åó„ÅüÊúÄÈÅ©Âåñ„ÅåÂøÖÈ†à")</code></pre>

<strong>ÊúüÂæÖ„Åï„Çå„ÇãÂá∫Âäõ</strong>:
<pre><code>ÊúÄÈÅ©ÂåñÁµêÊûú„ÅÆÊØîËºÉ:

Âà∂Á¥Ñ„Å™„Åó„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ:
  ÊúÄËâØÂÄ§: 0.8234
  ÂØæÂøú„Åô„Çãx: 0.312
  Âà∂Á¥ÑÂÄ§: 1.876
  Âà∂Á¥ÑÊ∫ÄË∂≥: No
  ÂÆüË°åÂèØËÉΩËß£„ÅÆÊï∞: 4/10

Âà∂Á¥Ñ‰ªò„Åç„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ:
  ÊúÄËâØÂÄ§: 0.7456
  ÂØæÂøú„Åô„Çãx: 0.523
  Âà∂Á¥ÑÂÄ§: -0.234
  Âà∂Á¥ÑÊ∫ÄË∂≥: Yes
  ÂÆüË°åÂèØËÉΩËß£„ÅÆÊï∞: 8/10

ËÄÉÂØü:
  - Âà∂Á¥Ñ‰ªò„Åç„ÅØÂÆüË°åÂèØËÉΩÈ†òÂüü„Å´ÈõÜ‰∏≠„Åó„Å¶Êé¢Á¥¢
  - Âà∂Á¥Ñ„Å™„Åó„ÅØÈ´ò„ÅÑÁõÆÁöÑÈñ¢Êï∞ÂÄ§„ÇíÁô∫Ë¶ã„Åô„Çã„Åå„ÄÅÂà∂Á¥ÑÈÅïÂèç„ÅÆÂèØËÉΩÊÄß
  - ÂÆüÂãô„Åß„ÅØÂà∂Á¥Ñ„ÇíËÄÉÊÖÆ„Åó„ÅüÊúÄÈÅ©Âåñ„ÅåÂøÖÈ†à</code></pre>

<strong>ÈáçË¶Å„Å™Ê¥ûÂØü</strong>:
1. <strong>Âà∂Á¥Ñ„Å™„Åó</strong>: „Çà„ÇäÈ´ò„ÅÑÁõÆÁöÑÈñ¢Êï∞ÂÄ§„ÇíÁô∫Ë¶ã„Åô„Çã„Åå„ÄÅÂÆüË°å‰∏çÂèØËÉΩ
2. <strong>Âà∂Á¥Ñ‰ªò„Åç</strong>: „ÇÑ„ÇÑ‰Ωé„ÅÑÁõÆÁöÑÈñ¢Êï∞ÂÄ§„Å†„Åå„ÄÅÂÆüË°åÂèØËÉΩ
3. <strong>ÂÆüÂãô</strong>: Âà∂Á¥Ñ„ÇíÊ∫Ä„Åü„Åï„Å™„ÅÑËß£„ÅØÁÑ°ÊÑèÂë≥ÔºàÊùêÊñô„Åå‰Ωø„Åà„Å™„ÅÑÔºâ
4. <strong>ÂäπÁéá</strong>: Âà∂Á¥Ñ‰ªò„Åç„ÅØÂÆüË°åÂèØËÉΩÈ†òÂüü„Å´ÈõÜ‰∏≠„Åó„ÄÅÁÑ°ÈßÑ„ÅåÂ∞ë„Å™„ÅÑ

</details>

---

<h2>ÂèÇËÄÉÊñáÁåÆ</h2>

1. Rasmussen, C. E. & Williams, C. K. I. (2006). *Gaussian Processes for Machine Learning*. MIT Press.
   [OnlineÁâà](http://gaussianprocess.org/gpml/)

2. Brochu, E. et al. (2010). "A Tutorial on Bayesian Optimization of Expensive Cost Functions." *arXiv:1012.2599*.
   [arXiv:1012.2599](https://arxiv.org/abs/1012.2599)

3. Mockus, J. (1974). "On Bayesian Methods for Seeking the Extremum." *Optimization Techniques IFIP Technical Conference*, 400-404.

4. Srinivas, N. et al. (2010). "Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design." *ICML 2010*.
   [arXiv:0912.3995](https://arxiv.org/abs/0912.3995)

5. Gelbart, M. A. et al. (2014). "Bayesian Optimization with Unknown Constraints." *UAI 2014*.

6. ÊåÅÊ©ãÂ§ßÂú∞„ÉªÂ§ßÁæΩÊàêÂæÅ (2019). „Äé„Ç¨„Ç¶„ÇπÈÅéÁ®ã„Å®Ê©üÊ¢∞Â≠¶Áøí„ÄèË¨õË´áÁ§æ. ISBN: 978-4061529267

---

<h2>„Éä„Éì„Ç≤„Éº„Ç∑„Éß„É≥</h2>

<h3>Ââç„ÅÆÁ´†</h3>
<strong>[‚Üê Á¨¨1Á´†Ôºö„Å™„ÅúÊùêÊñôÊé¢Á¥¢„Å´ÊúÄÈÅ©Âåñ„ÅåÂøÖË¶Å„Åã](./chapter-1.md)</strong>

<h3>Ê¨°„ÅÆÁ´†</h3>
<strong>[Á¨¨3Á´†ÔºöPythonÂÆüË∑µ ‚Üí](./chapter-3.md)</strong>

<h3>„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°</h3>
<strong>[‚Üê „Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã](./index.md)</strong>

---

<h2>ËëóËÄÖÊÉÖÂ†±</h2>

<strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team
<strong>Áõ£‰øÆ</strong>: Dr. Yusuke HashimotoÔºàÊù±ÂåóÂ§ßÂ≠¶Ôºâ
<strong>‰ΩúÊàêÊó•</strong>: 2025-10-17
<strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0

<strong>Êõ¥Êñ∞Â±•Ê≠¥</strong>:
- 2025-10-17: v1.0 ÂàùÁâàÂÖ¨Èñã

<strong>„Éï„Ç£„Éº„Éâ„Éê„ÉÉ„ÇØ</strong>:
- GitHub Issues: [AI_Homepage/issues](https://github.com/your-repo/AI_Homepage/issues)
- Email: yusuke.hashimoto.b8@tohoku.ac.jp

<strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0

---

<strong>Ê¨°„ÅÆÁ´†„ÅßÂÆüË£Ö„ÇíÂ≠¶„Å≥„Åæ„Åó„Çá„ÅÜÔºÅ</strong>
<div class="navigation">
    <a href="chapter-1.html" class="nav-button">‚Üê Á¨¨1Á´†</a>
    <a href="index.html" class="nav-button">„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã</a>
    <a href="chapter-3.html" class="nav-button">Á¨¨3Á´† ‚Üí</a>
</div>
    </main>

    <footer>
        <p><strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team</p>
        <p><strong>Áõ£‰øÆ</strong>: Dr. Yusuke HashimotoÔºàÊù±ÂåóÂ§ßÂ≠¶Ôºâ</p>
        <p><strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0 | <strong>‰ΩúÊàêÊó•</strong>: 2025-10-17</p>
        <p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0</p>
        <p>¬© 2025 AI Terakoya. All rights reserved.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default'
                });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</body>
</html>
