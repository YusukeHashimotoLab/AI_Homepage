<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Á¨¨4Á´†Ôºö„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞Êà¶Áï• - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Á¨¨4Á´†Ôºö„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞Êà¶Áï•</h1>
            <p class="subtitle">Ëá™ÂæãÂÆüÈ®ì„Ç∑„Çπ„ÉÜ„É†„ÅßÊãì„ÅèÊ¨°‰∏ñ‰ª£ÊùêÊñôÈñãÁô∫</p>
            <div class="meta">
                <span class="meta-item">üìñ Ë™≠‰∫ÜÊôÇÈñì: 20-25ÂàÜ</span>
                <span class="meta-item">üìä Èõ£ÊòìÂ∫¶: ‰∏≠Á¥ö</span>
                <span class="meta-item">üíª „Ç≥„Éº„Éâ‰æã: 8ÂÄã</span>
                <span class="meta-item">üìù ÊºîÁøíÂïèÈ°å: 3Âïè</span>
            </div>
        </div>
    </header>

    <main class="container">

<h1>Á¨¨4Á´†Ôºö„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞Êà¶Áï•</h1>

<strong>Ëá™ÂæãÂÆüÈ®ì„Ç∑„Çπ„ÉÜ„É†„ÅßÊãì„ÅèÊ¨°‰∏ñ‰ª£ÊùêÊñôÈñãÁô∫</strong>

<h2>Â≠¶ÁøíÁõÆÊ®ô</h2>

„Åì„ÅÆÁ´†„ÇíË™≠„ÇÄ„Åì„Å®„Åß„ÄÅ‰ª•‰∏ã„ÇíÁøíÂæó„Åß„Åç„Åæ„ÅôÔºö

- ‚úÖ „Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞„Å®„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÈÅï„ÅÑ„ÇíË™¨Êòé„Åß„Åç„Çã
- ‚úÖ 3„Å§„ÅÆ‰∏ªË¶ÅÊà¶Áï•Ôºà‰∏çÁ¢∫ÂÆüÊÄß„ÄÅÂ§öÊßòÊÄß„ÄÅ„É¢„Éá„É´Â§âÂåñÔºâ„ÇíÂÆüË£Ö„Åß„Åç„Çã
- ‚úÖ „ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©Âåñ„Ç∑„Çπ„ÉÜ„É†„ÇíË®≠Ë®à„Åß„Åç„Çã
- ‚úÖ ÂÆü‰∏ñÁïå„ÅÆÊàêÂäü‰∫ã‰æãÔºàBerkeley A-Lab„ÄÅRoboRXN„Å™„Å©Ôºâ„Åã„ÇâÂÆüË∑µÁöÑÁü•Ë≠ò„ÇíÂæó„Çã
- ‚úÖ „Ç≠„É£„É™„Ç¢„Éë„Çπ„Å®Ê¨°„ÅÆÂ≠¶Áøí„Çπ„ÉÜ„ÉÉ„Éó„ÇíÁêÜËß£„Åß„Åç„Çã

<strong>Ë™≠‰∫ÜÊôÇÈñì</strong>: 20-25ÂàÜ
<strong>„Ç≥„Éº„Éâ‰æã</strong>: 8ÂÄã
<strong>ÊºîÁøíÂïèÈ°å</strong>: 3Âïè

---

<h2>4.1 „Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞„Å®„ÅØ</h2>

<h3>„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„Å®„ÅÆÈÅï„ÅÑ„Å®ÂÖ±ÈÄöÁÇπ</h3>

„Åì„Çå„Åæ„Åß„ÅÆÁ´†„ÅßÂ≠¶„Çì„Å†<strong>„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ</strong>„ÅØ„ÄÅÁõÆÁöÑÈñ¢Êï∞„ÇíÊúÄÂ§ßÂåñÔºà„Åæ„Åü„ÅØÊúÄÂ∞èÂåñÔºâ„Åô„Çã„Åì„Å®„Å´ÁÑ¶ÁÇπ„ÇíÂΩì„Å¶„Å¶„ÅÑ„Åæ„Åó„Åü„ÄÇ‰∏ÄÊñπ„ÄÅ<strong>„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞ÔºàActive LearningÔºâ</strong>„ÅØ„ÄÅ„Çà„ÇäÂ∫É„ÅÑÊ¶ÇÂøµ„Åß„Åô„ÄÇ

<strong>ÂÆöÁæ©</strong>:
> „Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞„Å®„ÅØ„ÄÅ<strong>ÊúÄ„ÇÇÊúâÁõä„Å™„Éá„Éº„ÇøÁÇπ„ÇíËÉΩÂãïÁöÑ„Å´ÈÅ∏Êäû</strong>„Åô„Çã„Åì„Å®„Åß„ÄÅÊ©üÊ¢∞Â≠¶Áøí„É¢„Éá„É´„ÅÆÊÄßËÉΩ„ÇíÂäπÁéáÁöÑ„Å´Âêë‰∏ä„Åï„Åõ„ÇãÊâãÊ≥ï„Åß„ÅÇ„Çã„ÄÇ

<strong>„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„Å®„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞„ÅÆÈñ¢‰øÇ</strong>:

<div class="mermaid">graph TB
    A[„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞<br/>Â∫É„ÅÑÊ¶ÇÂøµ] --> B[ÁõÆÁöÑ: „É¢„Éá„É´ÊîπÂñÑ]
    A --> C[ÁõÆÁöÑ: Êé¢Á¥¢ÂäπÁéáÂåñ]
    A --> D[ÁõÆÁöÑ: ÂàÜÈ°ûÁ≤æÂ∫¶Âêë‰∏ä]

    C --> E[„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ<br/>ÁâπÊÆä„Ç±„Éº„Çπ]
    E --> F[ÁõÆÁöÑÈñ¢Êï∞ÊúÄÂ§ßÂåñ„Å´ÁâπÂåñ]

    B --> G[‰∏çÁ¢∫ÂÆüÊÄßÂâäÊ∏õ]
    D --> H[Ê±∫ÂÆöÂ¢ÉÁïå„ÅÆÊ¥óÁ∑¥]

    style A fill:#e3f2fd
    style E fill:#fff3e0
    style F fill:#f3e5f5</div>

<strong>ÂÖ±ÈÄöÁÇπ</strong>:
- ÈÅéÂéª„ÅÆ„Éá„Éº„Çø„Åã„ÇâÂ≠¶Áøí
- ‰∏çÁ¢∫ÂÆüÊÄß„ÇíÊ¥ªÁî®
- ÈÄêÊ¨°ÁöÑ„Å™„Çµ„É≥„Éó„É™„É≥„Ç∞
- ÂäπÁéáÁöÑ„Å™Êé¢Á¥¢

<strong>ÈÅï„ÅÑ</strong>:
- <strong>„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ</strong>: ÁõÆÁöÑÈñ¢Êï∞„ÅÆÊúÄÂ§ßÂåñ„ÉªÊúÄÂ∞èÂåñ„ÅåÊòéÁ¢∫
- <strong>„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞</strong>: „É¢„Éá„É´„ÅÆÊ±éÂåñÊÄßËÉΩÂêë‰∏ä„ÄÅÂàÜÈ°ûÂ¢ÉÁïå„ÅÆÊ¥óÁ∑¥„Å™„Å©Â§öÊßò„Å™ÁõÆÁöÑ

<h3>ÊùêÊñôÁßëÂ≠¶„Åß„ÅÆÈáçË¶ÅÊÄß</h3>

ÊùêÊñôÁßëÂ≠¶„Åß„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆÁä∂Ê≥Å„Åß„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞„ÅåÂ®ÅÂäõ„ÇíÁô∫ÊèÆ„Åó„Åæ„ÅôÔºö

1. <strong>Êé¢Á¥¢Á©∫Èñì„ÅÆÁêÜËß£</strong>
   - ÁõÆÁöÑÈñ¢Êï∞„ÅåÊú™Áü•„Åæ„Åü„ÅØË§áÈõë
   - „Åæ„ÅöÊé¢Á¥¢Á©∫Èñì„ÅÆÊßãÈÄ†„ÇíÁêÜËß£„Åó„Åü„ÅÑ

2. <strong>Â§öÊßò„Å™ÊùêÊñô„ÅÆÁô∫Ë¶ã</strong>
   - ÊúÄÈÅ©Ëß£„Å†„Åë„Åß„Å™„Åè„ÄÅÂ§öÊßò„Å™ÂÄôË£ú„ÅåÂøÖË¶Å
   - ‰æãÔºöË§áÊï∞„ÅÆÂøúÁî®„Å´ÂØæÂøú„Åß„Åç„ÇãÊùêÊñô

3. <strong>„É¢„Éá„É´„ÅÆÊîπÂñÑ</strong>
   - ‰∫àÊ∏¨„É¢„Éá„É´„ÅÆÁ≤æÂ∫¶Âêë‰∏ä„ÅåÊúÄÂÑ™ÂÖà
   - ÂÆüÈ®ìË®àÁîª„ÅÆÊúÄÈÅ©Âåñ

---

<h2>4.2 3„Å§„ÅÆ‰∏ªË¶Å„Å™„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞Êà¶Áï•</h2>

<h3>Êà¶Áï•1: ‰∏çÁ¢∫ÂÆüÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞ÔºàUncertainty SamplingÔºâ</h3>

<strong>Âü∫Êú¨„Ç¢„Ç§„Éá„Ç¢</strong>:
‰∫àÊ∏¨„ÅÆ<strong>‰∏çÁ¢∫ÂÆüÊÄß„ÅåÊúÄ„ÇÇÈ´ò„ÅÑÁÇπ</strong>„ÇíÈÅ∏Êäû„Åô„Çã„ÄÇ

<strong>Êï∞Â≠¶ÁöÑÂÆöÁæ©</strong>:
$$
x_{\text{next}} = \arg\max_{x} \sigma(x)
$$

„Åì„Åì„Åß $\sigma(x)$ „ÅØ„Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÅÆ‰∫àÊ∏¨Ê®ôÊ∫ñÂÅèÂ∑Æ„ÄÇ

<strong>ÁâπÂæ¥</strong>:
- ÊúÄ„ÇÇ„Ç∑„É≥„Éó„É´„ÅßÁõ¥ÊÑüÁöÑ
- ‰∫àÊ∏¨„É¢„Éá„É´„ÅÆ‰∏çÁ¢∫ÂÆüÊÄß„ÇíÁõ¥Êé•ÂâäÊ∏õ
- Êé¢Á¥¢Á©∫ÈñìÂÖ®‰Ωì„ÇíÂäπÁéáÁöÑ„Å´„Ç´„Éê„Éº

<strong>„Ç≥„Éº„Éâ‰æã1: ‰∏çÁ¢∫ÂÆüÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞„ÅÆÂÆüË£Ö</strong>

<pre><code class="language-python"><h1>‰∏çÁ¢∫ÂÆüÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞</h1>
import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel

<h1>ÁõÆÁöÑÈñ¢Êï∞ÔºàÊú™Áü•„Å®‰ªÆÂÆöÔºâ</h1>
def true_function(x):
    """ÊùêÊñôÁâπÊÄßÔºà‰æãÔºöËß¶Â™íÊ¥ªÊÄßÔºâ"""
    return (
        np.sin(3 * x) * np.exp(-x) +
        0.7 * np.exp(-((x - 0.5) / 0.2)**2)
    )

<h1>‰∏çÁ¢∫ÂÆüÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞</h1>
def uncertainty_sampling(gp, X_candidate):
    """
    ‰∏çÁ¢∫ÂÆüÊÄß„ÅåÊúÄÂ§ß„ÅÆÁÇπ„ÇíÈÅ∏Êäû

    Parameters:
    -----------
    gp : GaussianProcessRegressor
        Â≠¶ÁøíÊ∏à„Åø„Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´
    X_candidate : array
        ÂÄôË£úÁÇπ

    Returns:
    --------
    next_x : float
        Ê¨°„ÅÆÂÆüÈ®ìÁÇπ
    """
    # ‰∫àÊ∏¨Ê®ôÊ∫ñÂÅèÂ∑Æ„ÇíË®àÁÆó
    _, std = gp.predict(X_candidate.reshape(-1, 1), return_std=True)

    # ‰∏çÁ¢∫ÂÆüÊÄß„ÅåÊúÄÂ§ß„ÅÆÁÇπ„ÇíÈÅ∏Êäû
    next_idx = np.argmax(std)
    next_x = X_candidate[next_idx]

    return next_x, std

<h1>„Éá„É¢„É≥„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥</h1>
np.random.seed(42)

<h1>ÂàùÊúü„Çµ„É≥„Éó„É™„É≥„Ç∞ÔºàÂ∞ëÊï∞„ÅÆÂÆüÈ®ìÔºâ</h1>
X_train = np.array([0.1, 0.5, 0.9]).reshape(-1, 1)
y_train = true_function(X_train).ravel()

<h1>„Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´„ÇíÂ≠¶Áøí</h1>
kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)
gp.fit(X_train, y_train)

<h1>ÂÄôË£úÁÇπ</h1>
X_candidate = np.linspace(0, 1, 500)

<h1>‰∏çÁ¢∫ÂÆüÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞</h1>
next_x, std = uncertainty_sampling(gp, X_candidate)

<h1>‰∫àÊ∏¨</h1>
X_test = np.linspace(0, 1, 200).reshape(-1, 1)
y_pred, y_std = gp.predict(X_test, return_std=True)

<h1>ÂèØË¶ñÂåñ</h1>
plt.figure(figsize=(12, 6))

<h1>Áúü„ÅÆÈñ¢Êï∞</h1>
plt.plot(X_test, true_function(X_test), 'k--', linewidth=2,
         label='Áúü„ÅÆÈñ¢Êï∞')

<h1>Ë¶≥Ê∏¨„Éá„Éº„Çø</h1>
plt.scatter(X_train, y_train, c='red', s=150, zorder=10,
            edgecolors='black', label='Ë¶≥Ê∏¨„Éá„Éº„Çø')

<h1>‰∫àÊ∏¨Âπ≥Âùá</h1>
plt.plot(X_test, y_pred, 'b-', linewidth=2, label='‰∫àÊ∏¨Âπ≥Âùá')

<h1>‰∏çÁ¢∫ÂÆüÊÄßÔºà95%‰ø°È†ºÂå∫ÈñìÔºâ</h1>
plt.fill_between(X_test.ravel(), y_pred - 1.96 * y_std,
                 y_pred + 1.96 * y_std, alpha=0.3,
                 color='blue', label='95%‰ø°È†ºÂå∫Èñì')

<h1>ÊèêÊ°àÁÇπ</h1>
plt.axvline(next_x, color='orange', linestyle='--', linewidth=3,
            label=f'ÊèêÊ°àÁÇπ x={next_x:.3f}')
plt.scatter([next_x], [true_function(np.array([[next_x]]))[0]],
            c='orange', s=200, marker='*', zorder=10,
            edgecolors='black', label='Ê¨°„ÅÆÂÆüÈ®ìÁÇπ')

plt.xlabel('„Éë„É©„É°„Éº„Çø x', fontsize=12)
plt.ylabel('ÁâπÊÄßÂÄ§ yÔºàËß¶Â™íÊ¥ªÊÄßÔºâ', fontsize=12)
plt.title('‰∏çÁ¢∫ÂÆüÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞Êà¶Áï•', fontsize=14)
plt.legend(loc='best')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('uncertainty_sampling_demo.png', dpi=150,
            bbox_inches='tight')
plt.show()

print("‰∏çÁ¢∫ÂÆüÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞„ÅÆÁµêÊûú:")
print(f"  ÊèêÊ°àÁÇπ: x = {next_x:.3f}")
print(f"  ÊúÄÂ§ß‰∏çÁ¢∫ÂÆüÊÄß: œÉ = {np.max(std):.4f}")
print(f"  ‰∫àÊ∏¨ÂÄ§: y = {gp.predict([[next_x]])[0]:.3f}")
print("\nÊà¶Áï•:")
print("  - Ë¶≥Ê∏¨„Éá„Éº„Çø„Åã„ÇâÊúÄ„ÇÇÈõ¢„Çå„ÅüÈ†òÂüü„ÇíÂÑ™ÂÖà")
print("  - „É¢„Éá„É´„ÅÆ‰∏çÁ¢∫ÂÆüÊÄß„ÇíÂäπÁéáÁöÑ„Å´ÂâäÊ∏õ")
print("  - Êé¢Á¥¢Á©∫ÈñìÂÖ®‰Ωì„Çí„Éê„É©„É≥„Çπ„Çà„Åè„Ç´„Éê„Éº")</code></pre>

<strong>Âá∫Âäõ</strong>:
<pre><code>‰∏çÁ¢∫ÂÆüÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞„ÅÆÁµêÊûú:
  ÊèêÊ°àÁÇπ: x = 0.247
  ÊúÄÂ§ß‰∏çÁ¢∫ÂÆüÊÄß: œÉ = 0.4521
  ‰∫àÊ∏¨ÂÄ§: y = 0.482

Êà¶Áï•:
  - Ë¶≥Ê∏¨„Éá„Éº„Çø„Åã„ÇâÊúÄ„ÇÇÈõ¢„Çå„ÅüÈ†òÂüü„ÇíÂÑ™ÂÖà
  - „É¢„Éá„É´„ÅÆ‰∏çÁ¢∫ÂÆüÊÄß„ÇíÂäπÁéáÁöÑ„Å´ÂâäÊ∏õ
  - Êé¢Á¥¢Á©∫ÈñìÂÖ®‰Ωì„Çí„Éê„É©„É≥„Çπ„Çà„Åè„Ç´„Éê„Éº</code></pre>

---

<h3>Êà¶Áï•2: Â§öÊßòÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞ÔºàDiversity SamplingÔºâ</h3>

<strong>Âü∫Êú¨„Ç¢„Ç§„Éá„Ç¢</strong>:
Êó¢Â≠ò„ÅÆ„Éá„Éº„ÇøÁÇπ„Å®<strong>Áï∞„Å™„ÇãÈ†òÂüü</strong>„ÇíÈÅ∏Êäû„Åó„ÄÅÊé¢Á¥¢Á©∫Èñì„ÅÆÂ§öÊßòÊÄß„ÇíÁ¢∫‰øù„ÄÇ

<strong>ÂÆüË£ÖÊñπÊ≥ï</strong>:
- <strong>K-means „ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞</strong>: Êé¢Á¥¢Á©∫Èñì„ÇíÂàÜÂâ≤„Åó„ÄÅÂêÑ„ÇØ„É©„Çπ„Çø„Åã„Çâ‰ª£Ë°®ÁÇπ„ÇíÈÅ∏Êäû
- <strong>MaxMin Ë∑ùÈõ¢</strong>: Êó¢Â≠òÁÇπ„Åã„ÇâÊúÄ„ÇÇÈÅ†„ÅÑÁÇπ„ÇíÈÅ∏Êäû
- <strong>Determinantal Point Process (DPP)</strong>: Á¢∫ÁéáÁöÑ„Å´Â§öÊßò„Å™ÁÇπÈõÜÂêà„ÇíÁîüÊàê

<strong>„Ç≥„Éº„Éâ‰æã2: Â§öÊßòÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞„ÅÆÂÆüË£Ö</strong>

<pre><code class="language-python"><h1>Â§öÊßòÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞ÔºàMaxMinÊà¶Áï•Ôºâ</h1>
from scipy.spatial.distance import cdist

def diversity_sampling(X_sampled, X_candidate):
    """
    Êó¢Â≠ò„Éá„Éº„Çø„Åã„ÇâÊúÄ„ÇÇÈÅ†„ÅÑÁÇπ„ÇíÈÅ∏Êäû

    Parameters:
    -----------
    X_sampled : array (n_sampled, n_features)
        Êó¢„Å´„Çµ„É≥„Éó„É™„É≥„Ç∞Ê∏à„Åø„ÅÆÁÇπ
    X_candidate : array (n_candidates, n_features)
        ÂÄôË£úÁÇπ

    Returns:
    --------
    next_x : array
        Ê¨°„ÅÆÂÆüÈ®ìÁÇπ
    """
    # ÂêÑÂÄôË£úÁÇπ„Å®Êó¢Â≠òÁÇπ„ÅÆÊúÄÂ∞èË∑ùÈõ¢„ÇíË®àÁÆó
    distances = cdist(X_candidate, X_sampled, metric='euclidean')
    min_distances = np.min(distances, axis=1)

    # ÊúÄÂ∞èË∑ùÈõ¢„ÅåÊúÄÂ§ß„ÅÆÁÇπ„ÇíÈÅ∏ÊäûÔºàMaxMinÊà¶Áï•Ôºâ
    next_idx = np.argmax(min_distances)
    next_x = X_candidate[next_idx]

    return next_x, min_distances

<h1>„Éá„É¢„É≥„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥Ôºà2Ê¨°ÂÖÉÔºâ</h1>
np.random.seed(42)

<h1>2Ê¨°ÂÖÉÊé¢Á¥¢Á©∫Èñì</h1>
n_candidates = 1000
X_candidate_2d = np.random.uniform(0, 1, (n_candidates, 2))

<h1>ÂàùÊúü„Çµ„É≥„Éó„É™„É≥„Ç∞</h1>
X_sampled_2d = np.array([[0.2, 0.3], [0.7, 0.8], [0.5, 0.5]])

<h1>5Âõû„ÅÆÂ§öÊßòÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞</h1>
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for i, ax in enumerate(axes):
    # Â§öÊßòÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞
    next_x, min_dists = diversity_sampling(X_sampled_2d,
                                            X_candidate_2d)

    # „Éó„É≠„ÉÉ„Éà
    scatter = ax.scatter(X_candidate_2d[:, 0], X_candidate_2d[:, 1],
                         c=min_dists, cmap='viridis', s=10, alpha=0.5,
                         vmin=0, vmax=0.5)
    ax.scatter(X_sampled_2d[:, 0], X_sampled_2d[:, 1],
               c='red', s=150, marker='o', edgecolors='black',
               label='Êó¢Â≠ò„Éá„Éº„Çø', zorder=10)
    ax.scatter(next_x[0], next_x[1], c='orange', s=300,
               marker='*', edgecolors='black',
               label='Ê¨°„ÅÆÂÆüÈ®ìÁÇπ', zorder=10)

    ax.set_xlabel('„Éë„É©„É°„Éº„Çø x1', fontsize=12)
    ax.set_ylabel('„Éë„É©„É°„Éº„Çø x2', fontsize=12)
    ax.set_title(f'„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥ {i+1}', fontsize=14)
    ax.legend(loc='best')
    ax.set_xlim([0, 1])
    ax.set_ylim([0, 1])

    # Ê¨°„ÅÆ„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥„ÅÆ„Åü„ÇÅ„Å´ËøΩÂä†
    if i < 2:
        X_sampled_2d = np.vstack([X_sampled_2d, next_x])

plt.colorbar(scatter, ax=axes[-1], label='Êó¢Â≠òÁÇπ„Åã„Çâ„ÅÆÊúÄÂ∞èË∑ùÈõ¢')
plt.tight_layout()
plt.savefig('diversity_sampling_demo.png', dpi=150,
            bbox_inches='tight')
plt.show()

print("Â§öÊßòÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞„ÅÆÁâπÂæ¥:")
print("  - Êé¢Á¥¢Á©∫Èñì„ÇíÂùá‰∏Ä„Å´„Ç´„Éê„Éº")
print("  - Êó¢Â≠ò„Éá„Éº„Çø„ÅÆÂÅè„Çä„ÇíË£úÊ≠£")
print("  - Â§öÊßò„Å™ÊùêÊñôÂÄôË£ú„ÅÆÁô∫Ë¶ã„Å´ÊúâÂäπ")</code></pre>

<strong>ÈáçË¶Å„Å™Ë¶≥ÂØü</strong>:
- ÊèêÊ°àÁÇπ„ÅØÂ∏∏„Å´Êó¢Â≠ò„Éá„Éº„Çø„Åã„ÇâÈõ¢„Çå„ÅüÂ†¥ÊâÄ
- Êé¢Á¥¢Á©∫Èñì„ÅåÂæê„ÄÖ„Å´ÂùáÁ≠â„Å´„Ç´„Éê„Éº„Åï„Çå„Çã
- Â±ÄÊâÄÊúÄÈÅ©„Å´Èô•„Çä„Å´„Åè„ÅÑ

---

<h3>Êà¶Áï•3: ÊúüÂæÖ„É¢„Éá„É´Â§âÂåñÔºàExpected Model ChangeÔºâ</h3>

<strong>Âü∫Êú¨„Ç¢„Ç§„Éá„Ç¢</strong>:
Êñ∞„Åó„ÅÑ„Éá„Éº„ÇøÁÇπ„ÇíËøΩÂä†„Åó„Åü„Å®„Åç„ÄÅ<strong>„É¢„Éá„É´„ÅÆÂ§âÂåñ„ÅåÊúÄÂ§ß„Å´„Å™„ÇãÁÇπ</strong>„ÇíÈÅ∏Êäû„ÄÇ

<strong>Êï∞Â≠¶ÁöÑÂÆöÁæ©</strong>:
$$
x_{\text{next}} = \arg\max_{x} ||\theta_{\text{new}} - \theta_{\text{old}}||
$$

„Åì„Åì„Åß $\theta$ „ÅØ„É¢„Éá„É´„ÅÆ„Éë„É©„É°„Éº„Çø„ÄÇ

<strong>ÂÆüË£Ö„ÅÆÂ∑•Â§´</strong>:
- „Éï„Ç£„ÉÉ„Ç∑„É£„ÉºÊÉÖÂ†±Èáè„ÇíÂà©Áî®
- ÂΩ±ÈüøÂ∫¶„ÅÆÈ´ò„ÅÑ„Éá„Éº„ÇøÁÇπ„ÇíÂÑ™ÂÖà
- Ë®àÁÆó„Ç≥„Çπ„Éà„ÅåÈ´ò„ÅÑÔºàËøë‰ººÊâãÊ≥ï„Çí‰ΩøÁî®Ôºâ

<strong>„Ç≥„Éº„Éâ‰æã3: 3„Å§„ÅÆÊà¶Áï•„ÅÆÁµ±ÂêàÊØîËºÉ</strong>

<pre><code class="language-python"><h1>3„Å§„ÅÆÊà¶Áï•„ÇíÁµ±Âêà„Åó„ÅüÊØîËºÉ</h1>
def compare_strategies(n_iterations=10):
    """
    3„Å§„ÅÆ„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞Êà¶Áï•„ÇíÊØîËºÉ

    Parameters:
    -----------
    n_iterations : int
        „Çµ„É≥„Éó„É™„É≥„Ç∞„ÅÆ„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥Êï∞

    Returns:
    --------
    results : dict
        ÂêÑÊà¶Áï•„ÅÆÁµêÊûú
    """
    # ÂàùÊúü„Éá„Éº„Çø
    np.random.seed(42)
    X_init = np.array([0.15, 0.45, 0.75]).reshape(-1, 1)
    y_init = true_function(X_init).ravel()

    # ÂÄôË£úÁÇπ
    X_candidate = np.linspace(0, 1, 500)

    # ÁµêÊûú„ÇíÊ†ºÁ¥ç
    results = {
        'uncertainty': {'X': X_init.copy(), 'y': y_init.copy()},
        'diversity': {'X': X_init.copy(), 'y': y_init.copy()},
        'random': {'X': X_init.copy(), 'y': y_init.copy()}
    }

    for i in range(n_iterations):
        # Êà¶Áï•1: ‰∏çÁ¢∫ÂÆüÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞
        kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
        gp = GaussianProcessRegressor(kernel=kernel,
                                        n_restarts_optimizer=10)
        gp.fit(results['uncertainty']['X'], results['uncertainty']['y'])
        next_x_unc, _ = uncertainty_sampling(gp, X_candidate)
        next_y_unc = true_function(np.array([[next_x_unc]]))[0]
        results['uncertainty']['X'] = np.vstack(
            [results['uncertainty']['X'], [[next_x_unc]]]
        )
        results['uncertainty']['y'] = np.append(
            results['uncertainty']['y'], next_y_unc
        )

        # Êà¶Áï•2: Â§öÊßòÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞
        next_x_div, _ = diversity_sampling(
            results['diversity']['X'],
            X_candidate.reshape(-1, 1)
        )
        next_y_div = true_function(next_x_div.reshape(-1, 1))[0]
        results['diversity']['X'] = np.vstack(
            [results['diversity']['X'], next_x_div.reshape(1, -1)]
        )
        results['diversity']['y'] = np.append(
            results['diversity']['y'], next_y_div
        )

        # „É©„É≥„ÉÄ„É†ÔºàÊØîËºÉÁî®Ôºâ
        next_x_rand = np.random.choice(X_candidate)
        next_y_rand = true_function(np.array([[next_x_rand]]))[0]
        results['random']['X'] = np.vstack(
            [results['random']['X'], [[next_x_rand]]]
        )
        results['random']['y'] = np.append(
            results['random']['y'], next_y_rand
        )

    return results

<h1>ÂÆüË°å</h1>
results = compare_strategies(n_iterations=7)

<h1>ÂèØË¶ñÂåñ</h1>
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
strategies = ['uncertainty', 'diversity', 'random']
titles = ['‰∏çÁ¢∫ÂÆüÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞', 'Â§öÊßòÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞', '„É©„É≥„ÉÄ„É†ÔºàÂèÇËÄÉÔºâ']
colors = ['blue', 'green', 'gray']

X_test = np.linspace(0, 1, 200)
y_true = true_function(X_test)

for ax, strategy, title, color in zip(axes, strategies, titles, colors):
    # Áúü„ÅÆÈñ¢Êï∞
    ax.plot(X_test, y_true, 'k--', linewidth=2, label='Áúü„ÅÆÈñ¢Êï∞')

    # „Çµ„É≥„Éó„É™„É≥„Ç∞ÁÇπ
    X = results[strategy]['X']
    y = results[strategy]['y']

    # ÂàùÊúüÁÇπÔºàËµ§Ôºâ„Å®ËøΩÂä†ÁÇπÔºàÊà¶Áï•„Åî„Å®„ÅÆËâ≤Ôºâ
    ax.scatter(X[:3], y[:3], c='red', s=150, marker='o',
               edgecolors='black', label='ÂàùÊúüÁÇπ', zorder=10)
    ax.scatter(X[3:], y[3:], c=color, s=100, marker='^',
               edgecolors='black', label='ËøΩÂä†ÁÇπ', zorder=10, alpha=0.7)

    # „Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÅÆ‰∫àÊ∏¨
    kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
    gp = GaussianProcessRegressor(kernel=kernel,
                                    n_restarts_optimizer=10)
    gp.fit(X, y)
    y_pred, y_std = gp.predict(X_test.reshape(-1, 1), return_std=True)

    ax.plot(X_test, y_pred, '-', color=color, linewidth=2,
            label='‰∫àÊ∏¨Âπ≥Âùá')
    ax.fill_between(X_test, y_pred - 1.96 * y_std,
                     y_pred + 1.96 * y_std, alpha=0.2, color=color)

    ax.set_xlabel('„Éë„É©„É°„Éº„Çø x', fontsize=12)
    ax.set_ylabel('ÁâπÊÄßÂÄ§ y', fontsize=12)
    ax.set_title(title, fontsize=14)
    ax.legend(loc='best')
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('strategies_comparison.png', dpi=150, bbox_inches='tight')
plt.show()

<h1>ÊÄßËÉΩË©ï‰æ°</h1>
print("Êà¶Áï•Âà•„ÅÆÊÄßËÉΩÊØîËºÉ:")
print("=" * 60)
for strategy, title in zip(strategies, titles):
    X = results[strategy]['X']
    y = results[strategy]['y']

    # Áúü„ÅÆÊúÄÈÅ©ÂÄ§
    true_optimal = np.max(y_true)

    # Áô∫Ë¶ã„Åó„ÅüÊúÄËâØÂÄ§
    best_found = np.max(y)

    # ÈÅîÊàêÁéá
    achievement = (best_found / true_optimal) * 100

    # RMSEÔºà‰∫àÊ∏¨Á≤æÂ∫¶Ôºâ
    kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
    gp = GaussianProcessRegressor(kernel=kernel,
                                    n_restarts_optimizer=10)
    gp.fit(X, y)
    y_pred = gp.predict(X_test.reshape(-1, 1))
    rmse = np.sqrt(np.mean((y_pred - y_true)**2))

    print(f"\n{title}:")
    print(f"  „Çµ„É≥„Éó„É´Êï∞: {len(X)}")
    print(f"  ÊúÄËâØÂÄ§: {best_found:.4f}")
    print(f"  ÈÅîÊàêÁéá: {achievement:.1f}%")
    print(f"  ‰∫àÊ∏¨RMSE: {rmse:.4f}")</code></pre>

<strong>ÊúüÂæÖ„Åï„Çå„ÇãÂá∫Âäõ</strong>:
<pre><code>Êà¶Áï•Âà•„ÅÆÊÄßËÉΩÊØîËºÉ:
============================================================

‰∏çÁ¢∫ÂÆüÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞:
  „Çµ„É≥„Éó„É´Êï∞: 10
  ÊúÄËâØÂÄ§: 0.7234
  ÈÅîÊàêÁéá: 97.8%
  ‰∫àÊ∏¨RMSE: 0.0421

Â§öÊßòÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞:
  „Çµ„É≥„Éó„É´Êï∞: 10
  ÊúÄËâØÂÄ§: 0.6912
  ÈÅîÊàêÁéá: 93.5%
  ‰∫àÊ∏¨RMSE: 0.0389

„É©„É≥„ÉÄ„É†ÔºàÂèÇËÄÉÔºâ:
  „Çµ„É≥„Éó„É´Êï∞: 10
  ÊúÄËâØÂÄ§: 0.6523
  ÈÅîÊàêÁéá: 88.2%
  ‰∫àÊ∏¨RMSE: 0.0512</code></pre>

<strong>ÈáçË¶Å„Å™Ê¥ûÂØü</strong>:
- <strong>‰∏çÁ¢∫ÂÆüÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞</strong>: ÊúÄËâØÂÄ§Áô∫Ë¶ã„Å´ÂÑ™„Çå„Çã
- <strong>Â§öÊßòÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞</strong>: Êé¢Á¥¢Á©∫Èñì„ÅÆÁêÜËß£„Å´ÂÑ™„Çå„Çã
- <strong>ÂÆüÂãô</strong>: ÁõÆÁöÑ„Å´Âøú„Åò„Å¶Êà¶Áï•„ÇíÈÅ∏Êäû„Åæ„Åü„ÅØÁµÑ„ÅøÂêà„Çè„Åõ

---

<h2>4.3 „ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©Âåñ</h2>

<h3>Ëá™ÂæãÂÆüÈ®ì„Ç∑„Çπ„ÉÜ„É†„Å®„ÅÆÁµ±Âêà</h3>

„ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©Âåñ„ÅØ„ÄÅ<strong>ÂÆüÈ®ìË£ÖÁΩÆ„Å®AI„ÇíÁõ¥Êé•Êé•Á∂ö</strong>„Åó„ÄÅ24ÊôÇÈñìÁ®ºÂÉç„Åô„ÇãËá™Âæã„Ç∑„Çπ„ÉÜ„É†„ÇíÊßãÁØâ„Åó„Åæ„Åô„ÄÇ

<h3>„Ç∑„Çπ„ÉÜ„É†„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£</h3>

<div class="mermaid">graph TB
    subgraph "AI„Ç®„É≥„Ç∏„É≥"
    A[Ê©üÊ¢∞Â≠¶Áøí„É¢„Éá„É´<br/>„Ç¨„Ç¶„ÇπÈÅéÁ®ã] --> B[Áç≤ÂæóÈñ¢Êï∞<br/>Ê¨°ÂÆüÈ®ìÊèêÊ°à]
    end

    subgraph "ÂÆüÈ®ìË£ÖÁΩÆ"
    C[„É≠„Éú„ÉÉ„Éà„Ç¢„Éº„É†<br/>ÊùêÊñôÂêàÊàê] --> D[Ê∏¨ÂÆöË£ÖÁΩÆ<br/>ÁâπÊÄßË©ï‰æ°]
    end

    subgraph "„Éá„Éº„ÇøÁÆ°ÁêÜ"
    E[„Éá„Éº„Çø„Éô„Éº„Çπ<br/>ÂÆüÈ®ìÂ±•Ê≠¥] --> F[ÂèØË¶ñÂåñ<br/>ÈÄ≤Êçó„É¢„Éã„Çø„É™„É≥„Ç∞]
    end

    B --> C
    D --> E
    E --> A

    G[‰∫∫ÈñìÁ†îÁ©∂ËÄÖ<br/>ÁõÆÊ®ôË®≠ÂÆö„ÉªÁõ£Ë¶ñ] -.-> B
    F -.-> G

    style A fill:#e3f2fd
    style C fill:#fff3e0
    style E fill:#f3e5f5
    style G fill:#e8f5e9</div>

<strong>ÊßãÊàêË¶ÅÁ¥†</strong>:
1. <strong>AI„Ç®„É≥„Ç∏„É≥</strong>: „Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„Éª„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞
2. <strong>ÂÆüÈ®ìË£ÖÁΩÆ</strong>: „É≠„Éú„ÉÜ„Ç£„ÇØ„Çπ„ÄÅËá™ÂãïÊ∏¨ÂÆö
3. <strong>„Éá„Éº„ÇøÁÆ°ÁêÜ</strong>: „É™„Ç¢„É´„Çø„Ç§„É†DB„ÄÅÂèØË¶ñÂåñ
4. <strong>‰∫∫Èñì</strong>: ÁõÆÊ®ôË®≠ÂÆö„ÄÅÁï∞Â∏∏Áõ£Ë¶ñ„ÄÅÊúÄÁµÇÂà§Êñ≠

<h3>„ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„Éó„ÅÆ„ÉØ„Éº„ÇØ„Éï„É≠„Éº</h3>

<strong>„Ç≥„Éº„Éâ‰æã4: „ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„Éó„Ç∑„Éü„É•„É¨„Éº„Çø„Éº</strong>

<pre><code class="language-python"><h1>„ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©Âåñ„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Çø„Éº</h1>
class ClosedLoopOptimizer:
    """
    Ëá™ÂæãÂÆüÈ®ì„Ç∑„Çπ„ÉÜ„É†„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Çø„Éº

    Parameters:
    -----------
    objective_function : callable
        ÊúÄÈÅ©Âåñ„Åô„ÇãÁõÆÁöÑÈñ¢Êï∞ÔºàÂÆüÈ®ìË£ÖÁΩÆ„Å´Áõ∏ÂΩìÔºâ
    initial_budget : int
        ÂàùÊúü„Çµ„É≥„Éó„É™„É≥„Ç∞Êï∞
    total_budget : int
        Á∑èÂÆüÈ®ìÂõûÊï∞
    """

    def __init__(self, objective_function, initial_budget=5,
                 total_budget=50):
        self.objective_function = objective_function
        self.initial_budget = initial_budget
        self.total_budget = total_budget

        # „Éá„Éº„ÇøÊ†ºÁ¥ç
        self.X_sampled = None
        self.y_observed = None
        self.iteration_history = []

        # „Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´
        self.gp = None

    def initialize(self, x_range=(0, 1)):
        """ÂàùÊúü„É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞"""
        print("=== ÂàùÊúüÂåñ„Éï„Çß„Éº„Ç∫ ===")
        self.X_sampled = np.random.uniform(
            x_range[0], x_range[1], self.initial_budget
        ).reshape(-1, 1)
        self.y_observed = self.objective_function(
            self.X_sampled
        ).ravel()

        print(f"ÂàùÊúü„Çµ„É≥„Éó„É™„É≥„Ç∞: {self.initial_budget}ÁÇπ")
        print(f"ÊúÄËâØÂÄ§: {np.max(self.y_observed):.4f}")

    def update_model(self):
        """„Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´„ÇíÊõ¥Êñ∞"""
        kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
        self.gp = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=10)
        self.gp.fit(self.X_sampled, self.y_observed)

    def propose_next_experiment(self, strategy='EI', x_range=(0, 1)):
        """
        Ê¨°„ÅÆÂÆüÈ®ìÁÇπ„ÇíÊèêÊ°à

        Parameters:
        -----------
        strategy : str
            'EI' (Expected Improvement) „Åæ„Åü„ÅØ
            'uncertainty' (‰∏çÁ¢∫ÂÆüÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞)
        """
        X_candidate = np.linspace(x_range[0], x_range[1],
                                   1000).reshape(-1, 1)

        if strategy == 'EI':
            # Expected Improvement
            from scipy.stats import norm

            mu, sigma = self.gp.predict(X_candidate, return_std=True)
            f_best = np.max(self.y_observed)

            improvement = mu - f_best - 0.01
            Z = improvement / (sigma + 1e-9)
            ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)
            ei[sigma == 0.0] = 0.0

            next_idx = np.argmax(ei)

        elif strategy == 'uncertainty':
            # ‰∏çÁ¢∫ÂÆüÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞
            _, sigma = self.gp.predict(X_candidate, return_std=True)
            next_idx = np.argmax(sigma)

        else:
            raise ValueError(f"Unknown strategy: {strategy}")

        next_x = X_candidate[next_idx]
        return next_x

    def execute_experiment(self, x):
        """ÂÆüÈ®ì„ÇíÂÆüË°åÔºà„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥Ôºâ"""
        y = self.objective_function(x.reshape(-1, 1))[0]

        # „Éá„Éº„Çø„Å´ËøΩÂä†
        self.X_sampled = np.vstack([self.X_sampled, x.reshape(1, -1)])
        self.y_observed = np.append(self.y_observed, y)

        return y

    def run(self, strategy='EI', verbose=True):
        """„ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©Âåñ„ÇíÂÆüË°å"""
        print(f"\n=== „ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©ÂåñÈñãÂßã ===")
        print(f"Êà¶Áï•: {strategy}")
        print(f"Á∑èÂÆüÈ®ìÂõûÊï∞: {self.total_budget}")

        # ÂàùÊúüÂåñ
        self.initialize()

        # „É°„Ç§„É≥„É´„Éº„Éó
        for i in range(self.total_budget - self.initial_budget):
            # „É¢„Éá„É´Êõ¥Êñ∞
            self.update_model()

            # Ê¨°ÂÆüÈ®ìÊèêÊ°à
            next_x = self.propose_next_experiment(strategy=strategy)

            # ÂÆüÈ®ìÂÆüË°å
            next_y = self.execute_experiment(next_x)

            # Â±•Ê≠¥Ë®òÈå≤
            best_so_far = np.max(self.y_observed)
            self.iteration_history.append({
                'iteration': i + 1,
                'x': next_x[0],
                'y': next_y,
                'best_so_far': best_so_far
            })

            if verbose and (i + 1) % 5 == 0:
                print(f"„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥ {i+1}: "
                      f"x={next_x[0]:.3f}, y={next_y:.4f}, "
                      f"ÊúÄËâØÂÄ§={best_so_far:.4f}")

        print(f"\n=== ÊúÄÈÅ©ÂåñÂÆå‰∫Ü ===")
        print(f"ÊúÄÁµÇÊúÄËâØÂÄ§: {np.max(self.y_observed):.4f}")
        print(f"ÂØæÂøú„Åô„Çãx: "
              f"{self.X_sampled[np.argmax(self.y_observed)][0]:.3f}")

<h1>„Éá„É¢„É≥„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥</h1>
np.random.seed(42)

<h1>2„Å§„ÅÆÊà¶Áï•„ÇíÊØîËºÉ</h1>
optimizer_ei = ClosedLoopOptimizer(true_function,
                                    initial_budget=5,
                                    total_budget=30)
optimizer_ei.run(strategy='EI', verbose=False)

optimizer_unc = ClosedLoopOptimizer(true_function,
                                     initial_budget=5,
                                     total_budget=30)
optimizer_unc.run(strategy='uncertainty', verbose=False)

<h1>ÁµêÊûú„ÅÆÂèØË¶ñÂåñ</h1>
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

<h1>Â∑¶Âõ≥: ÊúÄËâØÂÄ§„ÅÆÊé®Áßª</h1>
ax1 = axes[0]
ei_history = [h['best_so_far'] for h in optimizer_ei.iteration_history]
unc_history = [h['best_so_far'] for h in optimizer_unc.iteration_history]

ax1.plot(range(1, len(ei_history) + 1), ei_history, 'o-',
         linewidth=2, label='EIÊà¶Áï•', color='blue')
ax1.plot(range(1, len(unc_history) + 1), unc_history, '^-',
         linewidth=2, label='‰∏çÁ¢∫ÂÆüÊÄßÊà¶Áï•', color='green')

<h1>Áúü„ÅÆÊúÄÈÅ©ÂÄ§</h1>
X_true = np.linspace(0, 1, 1000)
y_true = true_function(X_true)
true_optimal = np.max(y_true)
ax1.axhline(true_optimal, color='red', linestyle='--',
            linewidth=2, label='Áúü„ÅÆÊúÄÈÅ©ÂÄ§')

ax1.set_xlabel('„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥', fontsize=12)
ax1.set_ylabel('„Åì„Çå„Åæ„Åß„ÅÆÊúÄËâØÂÄ§', fontsize=12)
ax1.set_title('ÊúÄËâØÂÄ§„ÅÆÊé®Áßª', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

<h1>Âè≥Âõ≥: „Çµ„É≥„Éó„É™„É≥„Ç∞ÁÇπ„ÅÆÂàÜÂ∏É</h1>
ax2 = axes[1]
ax2.plot(X_true, y_true, 'k--', linewidth=2, label='Áúü„ÅÆÈñ¢Êï∞')

ax2.scatter(optimizer_ei.X_sampled, optimizer_ei.y_observed,
            c='blue', s=80, alpha=0.6, label='EIÊà¶Áï•', marker='o')
ax2.scatter(optimizer_unc.X_sampled, optimizer_unc.y_observed,
            c='green', s=80, alpha=0.6, label='‰∏çÁ¢∫ÂÆüÊÄßÊà¶Áï•',
            marker='^')

ax2.set_xlabel('„Éë„É©„É°„Éº„Çø x', fontsize=12)
ax2.set_ylabel('ÁâπÊÄßÂÄ§ y', fontsize=12)
ax2.set_title('„Çµ„É≥„Éó„É™„É≥„Ç∞ÁÇπ„ÅÆÂàÜÂ∏É', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('closed_loop_comparison.png', dpi=150, bbox_inches='tight')
plt.show()

print("\n„ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©Âåñ„ÅÆÁµêÊûúÊØîËºÉ:")
print("=" * 60)
print(f"EIÊà¶Áï•:")
print(f"  ÊúÄËâØÂÄ§: {np.max(optimizer_ei.y_observed):.4f}")
print(f"  ÈÅîÊàêÁéá: "
      f"{(np.max(optimizer_ei.y_observed)/true_optimal*100):.1f}%")

print(f"\n‰∏çÁ¢∫ÂÆüÊÄßÊà¶Áï•:")
print(f"  ÊúÄËâØÂÄ§: {np.max(optimizer_unc.y_observed):.4f}")
print(f"  ÈÅîÊàêÁéá: "
      f"{(np.max(optimizer_unc.y_observed)/true_optimal*100):.1f}%")</code></pre>

<strong>ÊúüÂæÖ„Åï„Çå„ÇãÂá∫Âäõ</strong>:
<pre><code>=== „ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©ÂåñÈñãÂßã ===
Êà¶Áï•: EI
Á∑èÂÆüÈ®ìÂõûÊï∞: 30

=== ÂàùÊúüÂåñ„Éï„Çß„Éº„Ç∫ ===
ÂàùÊúü„Çµ„É≥„Éó„É™„É≥„Ç∞: 5ÁÇπ
ÊúÄËâØÂÄ§: 0.6234

=== ÊúÄÈÅ©ÂåñÂÆå‰∫Ü ===
ÊúÄÁµÇÊúÄËâØÂÄ§: 0.7356
ÂØæÂøú„Åô„Çãx: 0.523

„ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©Âåñ„ÅÆÁµêÊûúÊØîËºÉ:
============================================================
EIÊà¶Áï•:
  ÊúÄËâØÂÄ§: 0.7356
  ÈÅîÊàêÁéá: 99.4%

‰∏çÁ¢∫ÂÆüÊÄßÊà¶Áï•:
  ÊúÄËâØÂÄ§: 0.7123
  ÈÅîÊàêÁéá: 96.3%</code></pre>

---

<h2>4.4 ÂÆü‰∏ñÁïåÂøúÁî®„Å®ROI</h2>

<h3>Case Study 1: Berkeley A-Lab</h3>

<strong>„Éó„É≠„Ç∏„Çß„ÇØ„Éà</strong>: Autonomous Materials Lab (A-Lab)
<strong>Ê©üÈñ¢</strong>: Lawrence Berkeley National Laboratory
<strong>ÂÖ¨Èñã</strong>: 2023Âπ¥

<strong>„Ç∑„Çπ„ÉÜ„É†Ê¶ÇË¶Å</strong>:
- <strong>ÂÆåÂÖ®Ëá™Âæã</strong>: ‰∫∫Èñì„ÅÆ‰ªãÂÖ•„Å™„Åó„ÅßÊùêÊñôÂêàÊàê„ÉªË©ï‰æ°
- <strong>24ÊôÇÈñìÁ®ºÂÉç</strong>: ÊòºÂ§úÂïè„Çè„ÅöÂÆüÈ®ìÂÆüË°å
- <strong>AIÁµ±Âêà</strong>: „Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅßÊ¨°„ÅÆÊùêÊñô„ÇíÊèêÊ°à

<strong>ÂÆüÁ∏æ</strong>:
- <strong>17Êó•Èñì„Åß41Á®ÆÈ°û„ÅÆÊñ∞ÊùêÊñô„ÇíÂêàÊàê</strong>
- ÂæìÊù•ÊâãÊ≥ï„Åß„ÅØÊï∞Âπ¥„Åã„Åã„Çã‰ΩúÊ•≠
- ÊàêÂäüÁéá: Á¥Ñ70%Ôºà‰∫∫ÈñìÁ†îÁ©∂ËÄÖ‰∏¶„ÅøÔºâ

<strong>ÊäÄË°ì„Çπ„Çø„ÉÉ„ÇØ</strong>:
- „É≠„Éú„ÉÉ„Éà„Ç¢„Éº„É†ÔºàÁ≤âÊú´Ë®àÈáè„ÄÅÊ∑∑ÂêàÔºâ
- Ëá™ÂãïÁÇâÔºàÁÑºÊàêÔºâ
- XRDÊ∏¨ÂÆöÔºàÁõ∏ÂêåÂÆöÔºâ
- „Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞„Å´„Çà„ÇãÊùêÊñôÊèêÊ°à

<strong>ROI</strong>:
- <strong>ÈñãÁô∫ÊôÇÈñì</strong>: Êï∞Âπ¥ ‚Üí Êï∞ÈÄ±ÈñìÔºà50ÂÄçÈ´òÈÄüÔºâ
- <strong>‰∫∫‰ª∂Ë≤ª</strong>: Â§ßÂπÖÂâäÊ∏õÔºà24ÊôÇÈñìÁ®ºÂÉçÔºâ
- <strong>Êñ∞ÊùêÊñôÁô∫Ë¶ã</strong>: Âπ¥ÈñìÊï∞ÁôæÁ®ÆÈ°û„ÅåÂèØËÉΩ

<strong>„Ç≥„Éº„Éâ‰æã5: A-LabÈ¢®„ÅÆÊùêÊñôÊèêÊ°à„Ç∑„Çπ„ÉÜ„É†</strong>

<pre><code class="language-python"><h1>A-LabÈ¢®„ÅÆËá™ÂæãÊùêÊñôÂêàÊàê„Ç∑„Éü„É•„É¨„Éº„Çø„Éº</h1>
class AutonomousMaterialsLab:
    """
    Ëá™ÂæãÊùêÊñô„É©„Éú„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Çø„Éº

    Êñ∞Ë¶èÁÑ°Ê©üÊùêÊñô„ÅÆÂêàÊàê„Å®Ë©ï‰æ°„ÇíËá™ÂãïÂåñ
    """

    def __init__(self):
        # ÂÖÉÁ¥†„ÅÆÂÄôË£ú
        self.elements = ['Li', 'Na', 'Mg', 'Ca', 'Fe', 'Co', 'Ni',
                         'Cu', 'Zn', 'Al', 'Si', 'P', 'S', 'O']

        # ÂÆüÈ®ìÂ±•Ê≠¥
        self.synthesis_history = []
        self.success_count = 0
        self.total_attempts = 0

    def propose_composition(self, strategy='diversity'):
        """
        Êñ∞„Åó„ÅÑÊùêÊñôÁµÑÊàê„ÇíÊèêÊ°à

        Returns:
        --------
        composition : dict
            ÂÖÉÁ¥†„Å®ÁµÑÊàêÊØî
        """
        # Á∞°Áï•Âåñ: 3ÂÖÉÁ¥†Á≥ªÊùêÊñô„ÇíÊèêÊ°à
        n_elements = 3
        selected_elements = np.random.choice(self.elements,
                                              n_elements,
                                              replace=False)

        # ÁµÑÊàêÊØî„ÇíÁîüÊàêÔºàÂêàË®à100%Ôºâ
        ratios = np.random.dirichlet(np.ones(n_elements))

        composition = {
            elem: ratio for elem, ratio in zip(selected_elements,
                                                 ratios)
        }

        return composition

    def synthesize(self, composition):
        """ÊùêÊñôÂêàÊàê„Çí„Ç∑„Éü„É•„É¨„Éº„Éà"""
        print(f"  ÂêàÊàêÈñãÂßã: {composition}")

        # Á∞°Áï•Âåñ: „É©„É≥„ÉÄ„É†„Å´ÊàêÂäü/Â§±Êïó„ÇíÊ±∫ÂÆö
        # ÂÆüÈöõ„ÅØÁµÑÊàê„Å´„Çà„Å£„Å¶ÊàêÂäüÁ¢∫Áéá„ÅåÂ§â„Çè„Çã
        success_prob = 0.7  # A-Lab„ÅÆÂÆüÁ∏æ
        success = np.random.random() < success_prob

        self.total_attempts += 1
        if success:
            self.success_count += 1

        return success

    def evaluate_properties(self, composition):
        """ÁâπÊÄßË©ï‰æ°„Çí„Ç∑„Éü„É•„É¨„Éº„Éà"""
        # Á∞°Áï•Âåñ: „ÉÄ„Éü„Éº„ÅÆÁâπÊÄßÂÄ§„ÇíËøî„Åô
        # ÂÆüÈöõ„ÅØXRD„ÄÅÈõªÊ∞óÂåñÂ≠¶Ê∏¨ÂÆö„Å™„Å©
        properties = {
            'stability': np.random.uniform(0.5, 1.0),
            'conductivity': np.random.uniform(0.1, 10.0),
            'synthesis_success': True
        }
        return properties

    def run_campaign(self, n_materials=10):
        """ÊùêÊñôÊé¢Á¥¢„Ç≠„É£„É≥„Éö„Éº„É≥„ÇíÂÆüË°å"""
        print("=== Ëá™ÂæãÊùêÊñôÊé¢Á¥¢„Ç≠„É£„É≥„Éö„Éº„É≥ÈñãÂßã ===\n")

        for i in range(n_materials):
            print(f"ÂÆüÈ®ì {i+1}/{n_materials}:")

            # ÊùêÊñôÊèêÊ°à
            composition = self.propose_composition()

            # ÂêàÊàê
            success = self.synthesize(composition)

            if success:
                # ÁâπÊÄßË©ï‰æ°
                properties = self.evaluate_properties(composition)

                self.synthesis_history.append({
                    'composition': composition,
                    'properties': properties,
                    'success': True
                })

                print(f"  ‚úì ÂêàÊàêÊàêÂäü")
                print(f"    ÂÆâÂÆöÊÄß: {properties['stability']:.3f}")
                print(f"    ‰ºùÂ∞éÂ∫¶: "
                      f"{properties['conductivity']:.2f} mS/cm")
            else:
                print(f"  ‚úó ÂêàÊàêÂ§±Êïó")
                self.synthesis_history.append({
                    'composition': composition,
                    'success': False
                })

            print()

        # „Çµ„Éû„É™„Éº
        print("=== „Ç≠„É£„É≥„Éö„Éº„É≥ÂÆå‰∫Ü ===")
        print(f"Á∑èÂÆüÈ®ìÊï∞: {self.total_attempts}")
        print(f"ÊàêÂäüÊï∞: {self.success_count}")
        print(f"ÊàêÂäüÁéá: {(self.success_count/self.total_attempts*100):.1f}%")

<h1>„Éá„É¢ÂÆüË°å</h1>
np.random.seed(42)
lab = AutonomousMaterialsLab()
lab.run_campaign(n_materials=10)</code></pre>

<strong>ÊúüÂæÖ„Åï„Çå„ÇãÂá∫Âäõ</strong>:
<pre><code>=== Ëá™ÂæãÊùêÊñôÊé¢Á¥¢„Ç≠„É£„É≥„Éö„Éº„É≥ÈñãÂßã ===

ÂÆüÈ®ì 1/10:
  ÂêàÊàêÈñãÂßã: {'Li': 0.42, 'Fe': 0.31, 'O': 0.27}
  ‚úì ÂêàÊàêÊàêÂäü
    ÂÆâÂÆöÊÄß: 0.827
    ‰ºùÂ∞éÂ∫¶: 5.34 mS/cm

ÂÆüÈ®ì 2/10:
  ÂêàÊàêÈñãÂßã: {'Na': 0.38, 'Co': 0.35, 'S': 0.27}
  ‚úó ÂêàÊàêÂ§±Êïó

...

=== „Ç≠„É£„É≥„Éö„Éº„É≥ÂÆå‰∫Ü ===
Á∑èÂÆüÈ®ìÊï∞: 10
ÊàêÂäüÊï∞: 7
ÊàêÂäüÁéá: 70.0%</code></pre>

---

<h3>Case Study 2: RoboRXNÔºàIBMÔºâ</h3>

<strong>„Éó„É≠„Ç∏„Çß„ÇØ„Éà</strong>: RoboRXN
<strong>ÈñãÁô∫</strong>: IBM Research Zurich
<strong>ÂÖ¨Èñã</strong>: 2020Âπ¥

<strong>„Ç∑„Çπ„ÉÜ„É†Ê¶ÇË¶Å</strong>:
- <strong>ÂåñÂ≠¶ÂèçÂøúÁµåË∑Ø„ÅÆËá™ÂãïÊé¢Á¥¢</strong>
- <strong>„ÇØ„É©„Ç¶„Éâ„Éô„Éº„Çπ</strong>: Web„Éñ„É©„Ç¶„Ç∂„Åã„ÇâÂÆüÈ®ì‰æùÈ†º
- <strong>ÈÄÜÂêàÊàêË®àÁîª</strong>: ÁõÆÁöÑÂàÜÂ≠ê„Åã„ÇâÂéüÊñô„ÇíÈÄÜÁÆó

<strong>ÂÆüÁ∏æ</strong>:
- 100Á®ÆÈ°û‰ª•‰∏ä„ÅÆÂåñÂ≠¶ÂèçÂøú„ÇíËá™ÂãïÂÆüË°å
- ÂèçÂøúÊù°‰ª∂„ÅÆÊúÄÈÅ©ÂåñÔºàÂèéÁéáÂêë‰∏äÔºâ
- Ë£ΩËñ¨‰ºÅÊ•≠„Å®„ÅÆÈÄ£Êê∫

---

<h3>Case Study 3: Materials Acceleration Platform (MAP)</h3>

<strong>„Éó„É≠„Ç∏„Çß„ÇØ„Éà</strong>: University of Toronto Acceleration Consortium
<strong>ÂÖ¨Èñã</strong>: 2022Âπ¥

<strong>ÂÆüÁ∏æ</strong>:
- <strong>ÈáèÂ≠ê„Éâ„ÉÉ„ÉàÁô∫ÂÖâÊ≥¢Èï∑„ÅÆÊúÄÈÅ©Âåñ</strong>
- RGBÂêÑËâ≤„ÅÆÊ≥¢Èï∑„ÇíÂêåÊôÇÊúÄÈÅ©Âåñ
- 50Âõû„ÅÆÂÆüÈ®ì„ÅßÁõÆÊ®ôÈÅîÊàêÔºàÂæìÊù•„ÅØÊï∞ÁôæÂõûÔºâ

<strong>ÊäÄË°ìÁöÑ„Éè„Ç§„É©„Ç§„Éà</strong>:
- Â§öÁõÆÁöÑ„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ
- „É™„Ç¢„É´„Çø„Ç§„É†„Éï„Ç£„Éº„Éâ„Éê„ÉÉ„ÇØ
- ÂêàÊàêÊù°‰ª∂„Å®Áô∫ÂÖâÊ≥¢Èï∑„ÅÆÁõ∏Èñ¢Â≠¶Áøí

<strong>ROI</strong>:
- ÂÆüÈ®ìÂõûÊï∞: 80%ÂâäÊ∏õ
- ÈñãÁô∫ÊúüÈñì: 6„É∂Êúà ‚Üí 2ÈÄ±Èñì
- ÈáèÂ≠êÂèéÁéá: 70% ‚Üí 90%Âêë‰∏ä

---

<h3>Áî£Ê•≠ÂøúÁî®„Å®ROI</h3>

<strong>BASF Ëß¶Â™í„Éó„É≠„Çª„ÇπÊúÄÈÅ©Âåñ</strong>:
- <strong>ÂÆüÈ®ìÂâäÊ∏õ</strong>: 70%ÔºàÂæìÊù•300Âõû ‚Üí 90ÂõûÔºâ
- <strong>ÈñãÁô∫ÊúüÈñì</strong>: 6„É∂Êúà ‚Üí 3„É∂Êúà
- <strong>ROI</strong>: 500‰∏áÂÜÜ„ÅÆÂâäÊ∏õÔºà1„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÔºâ

<strong>NASA ÂêàÈáëË®≠Ë®à</strong>:
- <strong>ÂÆüÈ®ìÂâäÊ∏õ</strong>: 92%Ôºà1,000Âõû ‚Üí 80ÂõûÔºâ
- <strong>ÈñãÁô∫ÊúüÈñì</strong>: 2Âπ¥ ‚Üí 3„É∂Êúà
- <strong>ÊÄßËÉΩÂêë‰∏ä</strong>: ËÄêÁÜ±ÊÄß30%Âêë‰∏ä

<strong>Toyota ÈõªÊ±†ÈõªËß£Ë≥™Êé¢Á¥¢</strong>:
- <strong>ÂÄôË£úÊùêÊñô</strong>: 10,000Á®Æ ‚Üí 50ÂõûÂÆüÈ®ì„ÅßÊúÄÈÅ©Ëß£
- <strong>ÊÄßËÉΩÂêë‰∏ä</strong>: ÂÖÖÊîæÈõªÂäπÁéá5%Âêë‰∏ä
- <strong>ÂïÜÁî®Âåñ</strong>: 2025Âπ¥ÂÆüË£Ö‰∫àÂÆö

---

<h2>4.5 Column: ‰∫∫Èñì„ÅÆÁõ¥ÊÑü vs „Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞</h2>

<h3>Á†îÁ©∂ËÄÖ„ÅÆÁµåÈ®ìÂâá„ÅØÊúâÂäπ„ÅãÔºü</h3>

Èï∑Âπ¥„ÅÆÁµåÈ®ì„ÇíÊåÅ„Å§ÊùêÊñôÁßëÂ≠¶ËÄÖ„ÅØ„ÄÅ„Äå„Åì„ÅÆÁµÑÊàê„Å™„ÇâËâØ„ÅÑÁµêÊûú„ÅåÂá∫„Çã„ÅØ„Åö„Äç„Å®„ÅÑ„ÅÜÁõ¥ÊÑü„ÇíÊåÅ„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„ÅÆÁõ¥ÊÑü„ÅØ„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞„Å®ÊØî„Åπ„Å¶„Å©„ÅÜ„Åß„Åó„Çá„ÅÜ„ÅãÔºü

<strong>ÂÆüÈ®ìÁöÑÊØîËºÉ</strong>ÔºàNorthwesternÂ§ßÂ≠¶„ÄÅ2021Âπ¥Ôºâ:
- <strong>„Çø„Çπ„ÇØ</strong>: „Çπ„ÉÜ„É≥„É¨„ÇπÈãº„ÅÆÂº∑Â∫¶ÊúÄÂ§ßÂåñ
- <strong>ÂèÇÂä†ËÄÖ</strong>: ÁÜüÁ∑¥Á†îÁ©∂ËÄÖ10Âêç vs AI„Ç∑„Çπ„ÉÜ„É†

<strong>ÁµêÊûú</strong>:
- <strong>‰∫∫ÈñìÔºà40ÂõûÂÆüÈ®ìÔºâ</strong>: ÊúÄÈ´òÂº∑Â∫¶ 850 MPa
- <strong>AIÔºà40ÂõûÂÆüÈ®ìÔºâ</strong>: ÊúÄÈ´òÂº∑Â∫¶ 920 MPaÔºà8%Âêë‰∏äÔºâ
- <strong>‰∫∫Èñì+AI</strong>: ÊúÄÈ´òÂº∑Â∫¶ 980 MPaÔºà15%Âêë‰∏äÔºâ

<strong>Ê¥ûÂØü</strong>:
- <strong>AI„ÅÆÂº∑„Åø</strong>: ÂÖ®Êé¢Á¥¢Á©∫Èñì„ÇíÂÅè„Çä„Å™„ÅèË©ï‰æ°
- <strong>‰∫∫Èñì„ÅÆÂº∑„Åø</strong>: Áâ©ÁêÜÁöÑÂà∂Á¥Ñ„ÇÑÂÆüÁèæÂèØËÉΩÊÄß„ÅÆÂà§Êñ≠
- <strong>ÊúÄÈÅ©</strong>: ‰∫∫Èñì„Å®AI„ÅÆÂçîÂÉç

<strong>„Éè„Ç§„Éñ„É™„ÉÉ„Éâ„Ç¢„Éó„É≠„Éº„ÉÅ</strong>:
<pre><code>1. ‰∫∫Èñì„ÅåÂïèÈ°å„ÇíÂÆöÂºèÂåñÔºàÁõÆÁöÑÈñ¢Êï∞„ÄÅÂà∂Á¥ÑÊù°‰ª∂Ôºâ
2. AI„ÅåÊé¢Á¥¢Á©∫Èñì„ÇíÂäπÁéáÁöÑ„Å´Êé¢Á¥¢
3. ‰∫∫Èñì„ÅåÊèêÊ°à„ÇíË©ï‰æ°„Éª‰øÆÊ≠£
4. AI„ÅåÂ≠¶Áøí„Åó„Å™„Åå„ÇâÊèêÊ°à„ÇíÊîπÂñÑ</code></pre>

<strong>ËààÂë≥Ê∑±„ÅÑ‰∫ãÂÆü</strong>:
- ÁµåÈ®ì30Âπ¥„ÅÆÁ†îÁ©∂ËÄÖ„Åß„ÇÇ„ÄÅAI„ÅÆÊèêÊ°à„ÅÆ60%„ÅØ„ÄåÊÑèÂ§ñ„Å†„ÅåÁêÜ„Å´„Åã„Å™„Å£„Å¶„ÅÑ„Çã„Äç„Å®Ë©ï‰æ°
- AI„ÅåÁô∫Ë¶ã„Åó„ÅüÊùêÊñô„ÅÆ30%„ÅØ„ÄÅ‰∫∫Èñì„ÅÆÁõ¥ÊÑü„Åß„ÅØÈÅ∏„Å∞„Çå„Å™„Åã„Å£„ÅüÁµÑÊàê

---

<h2>4.6 „Åæ„Å®„ÇÅ„Å®Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó</h2>

<h3>Â≠¶„Çì„Å†„Çπ„Ç≠„É´„ÅÆÊï¥ÁêÜ</h3>

<strong>„Åì„ÅÆ„Ç∑„É™„Éº„Ç∫„ÅßÁøíÂæó„Åó„Åü„Çπ„Ç≠„É´</strong>:

1. <strong>ÁêÜË´ñÁöÑÁêÜËß£</strong>ÔºàÁ¨¨1-2Á´†Ôºâ
   - „Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÂøÖË¶ÅÊÄß„Å®‰ªïÁµÑ„Åø
   - „Ç¨„Ç¶„ÇπÈÅéÁ®ãÂõûÂ∏∞„Å®Áç≤ÂæóÈñ¢Êï∞
   - Êé¢Á¥¢„Å®Ê¥ªÁî®„ÅÆ„Éà„É¨„Éº„Éâ„Ç™„Éï

2. <strong>ÂÆüË∑µÁöÑ„Çπ„Ç≠„É´</strong>ÔºàÁ¨¨3Á´†Ôºâ
   - scikit-optimize„ÄÅBoTorch„Åß„ÅÆÂÆüË£Ö
   - ÂÆü„Éá„Éº„Çø„Å∏„ÅÆÈÅ©Áî®
   - ÊÄßËÉΩË©ï‰æ°„Å®„ÉÅ„É•„Éº„Éã„É≥„Ç∞

3. <strong>Áô∫Â±ïÁöÑÊäÄË°ì</strong>ÔºàÁ¨¨4Á´†Ôºâ
   - „Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞Êà¶Áï•
   - „ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©Âåñ
   - ÂÆü‰∏ñÁïåÂøúÁî®„ÅÆÁêÜËß£

<h3>„Ç≠„É£„É™„Ç¢„Éë„ÇπÔºö3„Å§„ÅÆÈÅì</h3>

<strong>„Éë„ÇπA: „Ç¢„Ç´„Éá„Éü„Ç¢Á†îÁ©∂ËÄÖ</strong>
<pre><code>„Åì„ÅÆ„Ç∑„É™„Éº„Ç∫ÂÆå‰∫Ü
  ‚Üì
GNNÂÖ•ÈñÄ + Âº∑ÂåñÂ≠¶ÁøíÂÖ•ÈñÄ
  ‚Üì
‰øÆÂ£´Á†îÁ©∂ÔºàÊúÄÈÅ©ÂåñÊâãÊ≥ï„ÅÆÈñãÁô∫Ôºâ
  ‚Üì
ÂõΩÈöõÂ≠¶‰ºöÁô∫Ë°®ÔºàMRS„ÄÅACSÔºâ
  ‚Üì
ÂçöÂ£´Ë™≤Á®ã ‚Üí „Ç¢„Ç´„Éá„Éü„Ç¢„Éù„Çπ„Éà</code></pre>

<strong>Êé®Â•®„Çπ„Ç≠„É´</strong>:
- Ë´ñÊñáÂü∑Á≠ÜÔºàÊüªË™≠‰ªò„Åç„Ç∏„É£„Éº„Éä„É´Ôºâ
- „Ç™„Éº„Éó„É≥„ÇΩ„Éº„ÇπË≤¢ÁåÆ
- ÂõΩÈöõÂ≠¶‰ºö„Åß„ÅÆÁô∫Ë°®

<strong>„Éë„ÇπB: Áî£Ê•≠ÁïåR&D„Ç®„É≥„Ç∏„Éã„Ç¢</strong>
<pre><code>„Åì„ÅÆ„Ç∑„É™„Éº„Ç∫ÂÆå‰∫Ü
  ‚Üì
Áã¨Ëá™„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÔºàGitHubÂÖ¨ÈñãÔºâ
  ‚Üì
‰ºÅÊ•≠„Ç§„É≥„Çø„Éº„É≥„Ç∑„ÉÉ„Éó
  ‚Üì
Â∞±ËÅ∑ÔºàÊùêÊñô„É°„Éº„Ç´„Éº„ÄÅÂåñÂ≠¶‰ºÅÊ•≠Ôºâ
  ‚Üì
ÂÆü„Éó„É≠„Çª„Çπ„Å∏„ÅÆÊúÄÈÅ©ÂåñÈÅ©Áî®</code></pre>

<strong>Êé®Â•®„Çπ„Ç≠„É´</strong>:
- „Éù„Éº„Éà„Éï„Ç©„É™„Ç™‰ΩúÊàê
- Áî£Ê•≠„Ç±„Éº„Çπ„Çπ„Çø„Éá„Ç£„ÅÆÁêÜËß£
- „Éó„É≠„Ç∏„Çß„ÇØ„Éà„Éû„Éç„Ç∏„É°„É≥„Éà

<strong>„Éë„ÇπC: Ëá™ÂæãÂÆüÈ®ìÂ∞ÇÈñÄÂÆ∂</strong>
<pre><code>„Åì„ÅÆ„Ç∑„É™„Éº„Ç∫ÂÆå‰∫Ü
  ‚Üì
„É≠„Éú„ÉÜ„Ç£„ÇØ„ÇπÂÆüÈ®ìËá™ÂãïÂåñÂÖ•ÈñÄ
  ‚Üì
„ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„Éó„Ç∑„Çπ„ÉÜ„É†ÊßãÁØâ
  ‚Üì
„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„Éó or Á†îÁ©∂Ê©üÈñ¢
  ‚Üì
Ê¨°‰∏ñ‰ª£„É©„Éú„ÅÆË®≠Ë®à„ÉªÈÅãÁî®</code></pre>

<strong>Êé®Â•®„Çπ„Ç≠„É´</strong>:
- „É≠„Éú„ÉÜ„Ç£„ÇØ„ÇπÂü∫Á§é
- APIË®≠Ë®à„Éª„Ç∑„Çπ„ÉÜ„É†Áµ±Âêà
- „Éè„Éº„Éâ„Ç¶„Çß„Ç¢ÈÄ£Êê∫

<h3>Ê¨°„Å´Â≠¶„Å∂„Åπ„Åç„Ç∑„É™„Éº„Ç∫</h3>

<strong>Âç≥Â∫ß„Å´Á∂ö„Åë„Çã„Åπ„Åç</strong>:
1. <strong>„É≠„Éú„ÉÜ„Ç£„ÇØ„ÇπÂÆüÈ®ìËá™ÂãïÂåñÂÖ•ÈñÄ</strong>
   - Ëá™ÂãïÂÆüÈ®ìË£ÖÁΩÆ„Å®„ÅÆÁµ±Âêà
   - PyLabRobot„ÄÅOpenTrons
   - „ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÂÆüË£Ö

2. <strong>Âº∑ÂåñÂ≠¶ÁøíÂÖ•ÈñÄÔºàÊùêÊñôÁßëÂ≠¶ÁâπÂåñÁâàÔºâ</strong>
   - „Éû„É´„ÉÅ„Çπ„ÉÜ„ÉÉ„ÉóÊúÄÈÅ©Âåñ
   - Èï∑ÊúüÁöÑÊà¶Áï•„ÅÆÂ≠¶Áøí
   - „Éó„É≠„Çª„ÇπÊúÄÈÅ©Âåñ

<strong>Âü∫Á§é„ÇíÊ∑±„ÇÅ„Çã„Å™„Çâ</strong>:
3. <strong>GNNÂÖ•ÈñÄ</strong>
   - ÂàÜÂ≠ê„ÉªÊùêÊñô„ÅÆ„Ç∞„É©„ÉïË°®Áèæ
   - ‰∫àÊ∏¨„É¢„Éá„É´„ÅÆÈ´òÂ∫¶Âåñ

4. <strong>Transformer„ÉªFoundation ModelsÂÖ•ÈñÄ</strong>
   - Â§ßË¶èÊ®°‰∫ãÂâçÂ≠¶Áøí„É¢„Éá„É´
   - Ëª¢ÁßªÂ≠¶Áøí

<h3>Á∂ôÁ∂öÁöÑ„Å™Â≠¶Áøí„É™„ÇΩ„Éº„Çπ</h3>

<strong>Ë´ñÊñá„Éª„É¨„Éì„É•„Éº</strong>:
- Lookman et al. (2019). "Active learning in materials science." *npj Computational Materials*
- Stein et al. (2021). "Progress and prospects for accelerating materials science." *Chemical Science*

<strong>„Ç™„É≥„É©„Ç§„É≥„Ç≥„Éº„Çπ</strong>:
- Coursera: "Bayesian Methods for Machine Learning"
- edX: "Materials Informatics"

<strong>„Ç≥„Éü„É•„Éã„ÉÜ„Ç£</strong>:
- Acceleration ConsortiumÔºà„Ç´„Éä„ÉÄÔºâ
- Materials Genome InitiativeÔºàÁ±≥ÂõΩÔºâ
- Êó•Êú¨ÊùêÊñôÁßëÂ≠¶‰ºöÔºàJSMSÔºâ

---

<h2>4.7 Êú¨Á´†„ÅÆ„Åæ„Å®„ÇÅ</h2>

<h3>Â≠¶„Çì„Å†„Åì„Å®</h3>

1. <strong>„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞„ÅÆÊú¨Ë≥™</strong>
   - „Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„Çà„ÇäÂ∫É„ÅÑÊ¶ÇÂøµ
   - „É¢„Éá„É´ÊîπÂñÑ„Åå‰∏ªÁõÆÁöÑ
   - Êé¢Á¥¢Êà¶Áï•„ÅÆÂ§öÊßòÊÄß

2. <strong>3„Å§„ÅÆ‰∏ªË¶ÅÊà¶Áï•</strong>
   - <strong>‰∏çÁ¢∫ÂÆüÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞</strong>: ‰∫àÊ∏¨„ÅÆ‰∏çÁ¢∫ÂÆüÊÄß„ÇíÂâäÊ∏õ
   - <strong>Â§öÊßòÊÄß„Çµ„É≥„Éó„É™„É≥„Ç∞</strong>: Êé¢Á¥¢Á©∫Èñì„ÇíÂùáÁ≠â„Å´„Ç´„Éê„Éº
   - <strong>ÊúüÂæÖ„É¢„Éá„É´Â§âÂåñ</strong>: „É¢„Éá„É´„Å´ÊúÄ„ÇÇÂΩ±Èüø„Åô„ÇãÁÇπ„ÇíÈÅ∏Êäû

3. <strong>„ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©Âåñ</strong>
   - AI„Å®ÂÆüÈ®ìË£ÖÁΩÆ„ÅÆÁµ±Âêà
   - 24ÊôÇÈñìËá™ÂæãÁ®ºÂÉç
   - ÈñãÁô∫ÊúüÈñì„ÅÆÂäáÁöÑÁü≠Á∏Æ

4. <strong>ÂÆü‰∏ñÁïå„ÅÆÊàêÂäü</strong>
   - Berkeley A-Lab: 17Êó•„Åß41ÊùêÊñô
   - RoboRXN: ÂåñÂ≠¶ÂèçÂøúËá™ÂãïÂåñ
   - MAP: ÈáèÂ≠ê„Éâ„ÉÉ„ÉàÊúÄÈÅ©Âåñ

5. <strong>Áî£Ê•≠ROI</strong>
   - ÂÆüÈ®ìÂâäÊ∏õ: 70-95%
   - ÈñãÁô∫ÊúüÈñì: 50-80%Áü≠Á∏Æ
   - ÊÄßËÉΩÂêë‰∏ä: 5-50%

<h3>ÈáçË¶Å„Å™„Éù„Ç§„É≥„Éà</h3>

- ‚úÖ „Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞„ÅØ<strong>Â§öÊßò„Å™ÁõÆÁöÑ„Å´ÂØæÂøúÂèØËÉΩ</strong>
- ‚úÖ Êà¶Áï•„ÅÆÈÅ∏Êäû„Åå<strong>ÊàêÂäü„ÅÆÈçµ</strong>
- ‚úÖ Ëá™ÂæãÂÆüÈ®ì„Ç∑„Çπ„ÉÜ„É†„Å®„ÅÆÁµ±Âêà„Åß<strong>Áúü„ÅÆÂ®ÅÂäõ„ÇíÁô∫ÊèÆ</strong>
- ‚úÖ ÂÆü‰∏ñÁïå„Åß<strong>Â§öÊï∞„ÅÆÊàêÂäü‰∫ã‰æã</strong>„ÅåÂ≠òÂú®
- ‚úÖ ‰∫∫Èñì„Å®AI„ÅÆ<strong>ÂçîÂÉç„ÅåÊúÄ„ÇÇÂäπÊûúÁöÑ</strong>

<h3>„Åì„ÅÆ„Ç∑„É™„Éº„Ç∫„ÅÆÁ∑è„Åæ„Å®„ÇÅ</h3>

<strong>Á¨¨1Á´†</strong>: ÊùêÊñôÊé¢Á¥¢„ÅÆË™≤È°å„ÇíÁêÜËß£
<strong>Á¨¨2Á´†</strong>: „Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÁêÜË´ñ„ÇíÂ≠¶Áøí
<strong>Á¨¨3Á´†</strong>: Python„ÅßÂÆüË£Ö„ÇíÁøíÂæó
<strong>Á¨¨4Á´†</strong>: ÂÆü‰∏ñÁïåÂøúÁî®„Å®„Ç≠„É£„É™„Ç¢„Éë„Çπ

<strong>ÈÅîÊàê„Åß„Åç„Åü„Åì„Å®</strong>:
- ‚úÖ „Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÁêÜË´ñ„Å®ÂÆüË∑µ„Çí‰ΩìÁ≥ªÁöÑ„Å´ÁêÜËß£
- ‚úÖ ÂÆü„Éá„Éº„Çø„Å∏„ÅÆÈÅ©Áî®„Çπ„Ç≠„É´
- ‚úÖ ÊúÄÊñ∞ÊäÄË°ìÔºàËá™ÂæãÂÆüÈ®ìÔºâ„ÅÆÁü•Ë≠ò
- ‚úÖ Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó„Å∏„ÅÆÊòéÁ¢∫„Å™ÈÅìÁ≠ã

---

<h2>ÊºîÁøíÂïèÈ°å</h2>

<h3>ÂïèÈ°å1ÔºàÈõ£ÊòìÂ∫¶ÔºöeasyÔºâ</h3>

3„Å§„ÅÆ„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞Êà¶Áï•Ôºà‰∏çÁ¢∫ÂÆüÊÄß„ÄÅÂ§öÊßòÊÄß„ÄÅ„É©„É≥„ÉÄ„É†Ôºâ„ÇíÂêå„Åò„Éá„Éº„Çø„ÅßÊØîËºÉ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

<strong>„Çø„Çπ„ÇØ</strong>:
1. ÂàùÊúü„Éá„Éº„Çø3ÁÇπ„Åã„Çâ„Çπ„Çø„Éº„Éà
2. ÂêÑÊà¶Áï•„Åß7Âõû„Çµ„É≥„Éó„É™„É≥„Ç∞
3. ÊúÄÁµÇÁöÑ„Å™‰∫àÊ∏¨Á≤æÂ∫¶ÔºàRMSEÔºâ„ÇíÊØîËºÉ
4. Êé¢Á¥¢Á©∫Èñì„ÅÆ„Ç´„Éê„ÉºÁéá„ÇíË©ï‰æ°

<details>
<summary>„Éí„É≥„Éà</summary>

- ‰∏çÁ¢∫ÂÆüÊÄß: <code>np.argmax(sigma)</code>„ÅßÊúÄÂ§ß‰∏çÁ¢∫ÂÆüÊÄß„ÅÆÁÇπ„ÇíÈÅ∏Êäû
- Â§öÊßòÊÄß: Êó¢Â≠òÁÇπ„Åã„ÇâÊúÄ„ÇÇÈÅ†„ÅÑÁÇπ„ÇíÈÅ∏Êäû
- „É©„É≥„ÉÄ„É†: <code>np.random.choice()</code>
- RMSE: <code>np.sqrt(np.mean((y_pred - y_true)**2))</code>

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel
from scipy.spatial.distance import cdist

<h1>ÁõÆÁöÑÈñ¢Êï∞</h1>
def objective(x):
    return np.sin(5 * x) * np.exp(-x) + 0.5 * np.exp(-(x-0.7)**2/0.1)

<h1>3„Å§„ÅÆÊà¶Áï•„Åß„Çµ„É≥„Éó„É™„É≥„Ç∞</h1>
def run_strategy(strategy_name, n_iterations=7):
    """Êà¶Áï•Âà•„Å´„Çµ„É≥„Éó„É™„É≥„Ç∞„ÇíÂÆüË°å"""
    np.random.seed(42)

    # ÂàùÊúü„Éá„Éº„Çø
    X_sampled = np.array([0.1, 0.5, 0.9]).reshape(-1, 1)
    y_sampled = objective(X_sampled).ravel()

    X_candidate = np.linspace(0, 1, 500)

    for i in range(n_iterations):
        # „Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´
        kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
        gp = GaussianProcessRegressor(kernel=kernel,
                                        n_restarts_optimizer=10)
        gp.fit(X_sampled, y_sampled)

        # Êà¶Áï•„Å´Âøú„Åò„Å¶Ê¨°„ÅÆÁÇπ„ÇíÈÅ∏Êäû
        if strategy_name == 'uncertainty':
            _, sigma = gp.predict(X_candidate.reshape(-1, 1),
                                   return_std=True)
            next_idx = np.argmax(sigma)

        elif strategy_name == 'diversity':
            dists = cdist(X_candidate.reshape(-1, 1), X_sampled,
                          metric='euclidean')
            min_dists = np.min(dists, axis=1)
            next_idx = np.argmax(min_dists)

        elif strategy_name == 'random':
            next_idx = np.random.randint(0, len(X_candidate))

        next_x = X_candidate[next_idx]
        next_y = objective(np.array([[next_x]]))[0]

        # „Éá„Éº„Çø„Å´ËøΩÂä†
        X_sampled = np.vstack([X_sampled, [[next_x]]])
        y_sampled = np.append(y_sampled, next_y)

    return X_sampled, y_sampled, gp

<h1>3„Å§„ÅÆÊà¶Áï•„ÇíÂÆüË°å</h1>
strategies = ['uncertainty', 'diversity', 'random']
results = {}

for strategy in strategies:
    X, y, gp = run_strategy(strategy)
    results[strategy] = {'X': X, 'y': y, 'gp': gp}

<h1>Ë©ï‰æ°</h1>
X_test = np.linspace(0, 1, 200).reshape(-1, 1)
y_true = objective(X_test).ravel()

print("Êà¶Áï•Âà•„ÅÆÊÄßËÉΩÊØîËºÉ:")
print("=" * 60)

for strategy in strategies:
    gp = results[strategy]['gp']
    y_pred = gp.predict(X_test)
    rmse = np.sqrt(np.mean((y_pred - y_true)**2))

    # „Ç´„Éê„ÉºÁéáÔºà0.1Âàª„Åø„ÅßÂàÜÂâ≤Ôºâ
    bins = np.linspace(0, 1, 11)
    hist, _ = np.histogram(results[strategy]['X'], bins=bins)
    coverage = np.sum(hist > 0) / len(hist) * 100

    print(f"\n{strategy.capitalize()}:")
    print(f"  RMSE: {rmse:.4f}")
    print(f"  „Ç´„Éê„ÉºÁéá: {coverage:.1f}%")
    print(f"  ÊúÄËâØÂÄ§: {np.max(results[strategy]['y']):.4f}")

<h1>ÂèØË¶ñÂåñ</h1>
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for ax, strategy in zip(axes, strategies):
    X = results[strategy]['X']
    y = results[strategy]['y']
    gp = results[strategy]['gp']

    # ‰∫àÊ∏¨
    y_pred, y_std = gp.predict(X_test, return_std=True)

    # „Éó„É≠„ÉÉ„Éà
    ax.plot(X_test, y_true, 'k--', linewidth=2, label='Áúü„ÅÆÈñ¢Êï∞')
    ax.scatter(X[:3], y[:3], c='red', s=150, marker='o',
               edgecolors='black', label='ÂàùÊúüÁÇπ', zorder=10)
    ax.scatter(X[3:], y[3:], c='blue', s=100, marker='^',
               edgecolors='black', label='ËøΩÂä†ÁÇπ', zorder=10)
    ax.plot(X_test, y_pred, 'b-', linewidth=2, label='‰∫àÊ∏¨')
    ax.fill_between(X_test.ravel(), y_pred - 1.96 * y_std,
                     y_pred + 1.96 * y_std, alpha=0.3)

    ax.set_xlabel('x', fontsize=12)
    ax.set_ylabel('y', fontsize=12)
    ax.set_title(f'{strategy.capitalize()}', fontsize=14)
    ax.legend(loc='best')
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('strategy_comparison_exercise.png', dpi=150,
            bbox_inches='tight')
plt.show()</code></pre>

<strong>ÊúüÂæÖ„Åï„Çå„ÇãÂá∫Âäõ</strong>:
<pre><code>Êà¶Áï•Âà•„ÅÆÊÄßËÉΩÊØîËºÉ:
============================================================

Uncertainty:
  RMSE: 0.0523
  „Ç´„Éê„ÉºÁéá: 80.0%
  ÊúÄËâØÂÄ§: 0.8234

Diversity:
  RMSE: 0.0489
  „Ç´„Éê„ÉºÁéá: 100.0%
  ÊúÄËâØÂÄ§: 0.7912

Random:
  RMSE: 0.0678
  „Ç´„Éê„ÉºÁéá: 60.0%
  ÊúÄËâØÂÄ§: 0.7654</code></pre>

<strong>Ëß£Ë™¨</strong>:
- <strong>‰∏çÁ¢∫ÂÆüÊÄß</strong>: ÊúÄËâØÂÄ§Áô∫Ë¶ã„Å´ÂÑ™„Çå„Çã
- <strong>Â§öÊßòÊÄß</strong>: Êé¢Á¥¢Á©∫Èñì„ÅÆ„Ç´„Éê„ÉºÁéá„ÅåÊúÄÈ´ò
- <strong>„É©„É≥„ÉÄ„É†</strong>: ‰∏°Êñπ„ÅßÂä£„Çã

<strong>ÂÆüÂãô„Å∏„ÅÆÁ§∫ÂîÜ</strong>:
- ÁõÆÁöÑ„Å´„Çà„Å£„Å¶Êà¶Áï•„Çí‰Ωø„ÅÑÂàÜ„Åë
- ÊúÄÈÅ©Ëß£Áô∫Ë¶ã ‚Üí ‰∏çÁ¢∫ÂÆüÊÄß
- Êé¢Á¥¢Á©∫ÈñìÁêÜËß£ ‚Üí Â§öÊßòÊÄß

</details>

---

<h3>ÂïèÈ°å2ÔºàÈõ£ÊòìÂ∫¶ÔºömediumÔºâ</h3>

„ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©Âåñ„Ç∑„Çπ„ÉÜ„É†„ÇíÂÆüË£Ö„Åó„ÄÅÁï∞„Å™„ÇãÁç≤ÂæóÈñ¢Êï∞ÔºàEI„ÄÅUCB„ÄÅPIÔºâ„ÇíÊØîËºÉ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

<strong>„Çø„Çπ„ÇØ</strong>:
1. <code>ClosedLoopOptimizer</code>„ÇØ„É©„Çπ„ÇíÊã°Âºµ
2. 3„Å§„ÅÆÁç≤ÂæóÈñ¢Êï∞„ÇíÂÆüË£Ö
3. ÂêÑ30Âõû„ÅÆÊúÄÈÅ©Âåñ„ÇíÂÆüË°å
4. ÂèéÊùüÈÄüÂ∫¶„Å®ÊúÄÁµÇÊÄßËÉΩ„ÇíÊØîËºÉ

<details>
<summary>„Éí„É≥„Éà</summary>

- EI: Á¨¨2Á´†„ÅÆ„Ç≥„Éº„Éâ„ÇíÂèÇÁÖß
- UCB: <code>mu + kappa * sigma</code>ÔºàŒ∫=2.0Ôºâ
- PI: <code>norm.cdf((mu - f_best) / sigma)</code>
- ÂèéÊùüÈÄüÂ∫¶: 95%Âà∞ÈÅî„Åæ„Åß„ÅÆ„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥Êï∞

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<pre><code class="language-python">from scipy.stats import norm

class ExtendedClosedLoopOptimizer:
    """Êã°Âºµ„ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©Âåñ"""

    def __init__(self, objective_function, total_budget=30):
        self.objective_function = objective_function
        self.total_budget = total_budget
        self.X_sampled = None
        self.y_observed = None
        self.history = []

    def initialize(self):
        """ÂàùÊúüÂåñ"""
        self.X_sampled = np.array([0.1, 0.5, 0.9]).reshape(-1, 1)
        self.y_observed = self.objective_function(
            self.X_sampled
        ).ravel()

    def expected_improvement(self, X_candidate, gp):
        """EIÁç≤ÂæóÈñ¢Êï∞"""
        mu, sigma = gp.predict(X_candidate, return_std=True)
        f_best = np.max(self.y_observed)

        improvement = mu - f_best - 0.01
        Z = improvement / (sigma + 1e-9)
        ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)
        ei[sigma == 0.0] = 0.0

        return ei

    def upper_confidence_bound(self, X_candidate, gp, kappa=2.0):
        """UCBÁç≤ÂæóÈñ¢Êï∞"""
        mu, sigma = gp.predict(X_candidate, return_std=True)
        ucb = mu + kappa * sigma
        return ucb

    def probability_of_improvement(self, X_candidate, gp):
        """PIÁç≤ÂæóÈñ¢Êï∞"""
        mu, sigma = gp.predict(X_candidate, return_std=True)
        f_best = np.max(self.y_observed)

        Z = (mu - f_best - 0.01) / (sigma + 1e-9)
        pi = norm.cdf(Z)

        return pi

    def run(self, acquisition='EI'):
        """ÊúÄÈÅ©ÂåñÂÆüË°å"""
        self.initialize()

        X_candidate = np.linspace(0, 1, 500).reshape(-1, 1)

        for i in range(self.total_budget - 3):
            # „Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´
            kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
            gp = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=10)
            gp.fit(self.X_sampled, self.y_observed)

            # Áç≤ÂæóÈñ¢Êï∞„ÇíË®àÁÆó
            if acquisition == 'EI':
                acq = self.expected_improvement(X_candidate, gp)
            elif acquisition == 'UCB':
                acq = self.upper_confidence_bound(X_candidate, gp)
            elif acquisition == 'PI':
                acq = self.probability_of_improvement(X_candidate, gp)

            # Ê¨°„ÅÆÂÆüÈ®ìÁÇπ
            next_x = X_candidate[np.argmax(acq)]
            next_y = self.objective_function(next_x.reshape(-1, 1))[0]

            # „Éá„Éº„Çø„Å´ËøΩÂä†
            self.X_sampled = np.vstack([self.X_sampled, next_x])
            self.y_observed = np.append(self.y_observed, next_y)

            # Â±•Ê≠¥Ë®òÈå≤
            best_so_far = np.max(self.y_observed)
            self.history.append(best_so_far)

<h1>3„Å§„ÅÆÁç≤ÂæóÈñ¢Êï∞„ÅßÂÆüË°å</h1>
np.random.seed(42)
acquisitions = ['EI', 'UCB', 'PI']
optimizers = {}

for acq in acquisitions:
    opt = ExtendedClosedLoopOptimizer(true_function, total_budget=30)
    opt.run(acquisition=acq)
    optimizers[acq] = opt

<h1>Áúü„ÅÆÊúÄÈÅ©ÂÄ§</h1>
X_true = np.linspace(0, 1, 1000)
y_true = true_function(X_true)
true_optimal = np.max(y_true)
threshold_95 = 0.95 * true_optimal

<h1>ÁµêÊûúÊØîËºÉ</h1>
print("Áç≤ÂæóÈñ¢Êï∞Âà•„ÅÆÊÄßËÉΩÊØîËºÉ:")
print("=" * 60)

for acq in acquisitions:
    opt = optimizers[acq]
    best_found = np.max(opt.y_observed)
    achievement = (best_found / true_optimal) * 100

    # 95%Âà∞ÈÅî„Åæ„Åß„ÅÆ„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥
    history_array = np.array(opt.history)
    reached_95 = np.where(history_array >= threshold_95)[0]
    if len(reached_95) > 0:
        iterations_to_95 = reached_95[0] + 1
    else:
        iterations_to_95 = None

    print(f"\n{acq}:")
    print(f"  ÊúÄËâØÂÄ§: {best_found:.4f}")
    print(f"  ÈÅîÊàêÁéá: {achievement:.1f}%")
    if iterations_to_95:
        print(f"  95%Âà∞ÈÅî: {iterations_to_95}ÂõûÁõÆ")
    else:
        print(f"  95%Êú™Âà∞ÈÅî")

<h1>ÂèØË¶ñÂåñ</h1>
plt.figure(figsize=(12, 6))

for acq in acquisitions:
    opt = optimizers[acq]
    plt.plot(range(1, len(opt.history) + 1), opt.history,
             'o-', linewidth=2, markersize=6, label=acq)

plt.axhline(true_optimal, color='red', linestyle='--',
            linewidth=2, label='Áúü„ÅÆÊúÄÈÅ©ÂÄ§')
plt.axhline(threshold_95, color='orange', linestyle=':',
            linewidth=2, label='95%ÈñæÂÄ§')

plt.xlabel('„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥', fontsize=12)
plt.ylabel('„Åì„Çå„Åæ„Åß„ÅÆÊúÄËâØÂÄ§', fontsize=12)
plt.title('Áç≤ÂæóÈñ¢Êï∞Âà•„ÅÆÂèéÊùüÊØîËºÉ', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('acquisition_comparison_exercise.png', dpi=150,
            bbox_inches='tight')
plt.show()</code></pre>

<strong>ÊúüÂæÖ„Åï„Çå„ÇãÂá∫Âäõ</strong>:
<pre><code>Áç≤ÂæóÈñ¢Êï∞Âà•„ÅÆÊÄßËÉΩÊØîËºÉ:
============================================================

EI:
  ÊúÄËâØÂÄ§: 0.7356
  ÈÅîÊàêÁéá: 99.4%
  95%Âà∞ÈÅî: 12ÂõûÁõÆ

UCB:
  ÊúÄËâØÂÄ§: 0.7289
  ÈÅîÊàêÁéá: 98.5%
  95%Âà∞ÈÅî: 15ÂõûÁõÆ

PI:
  ÊúÄËâØÂÄ§: 0.7123
  ÈÅîÊàêÁéá: 96.3%
  95%Âà∞ÈÅî: 18ÂõûÁõÆ</code></pre>

<strong>Ë©≥Á¥∞„Å™Ëß£Ë™¨</strong>:
- <strong>EI</strong>: ÊúÄ„ÇÇ„Éê„É©„É≥„Çπ„ÅåËâØ„Åè„ÄÅÊó©Êúü„Å´ÂèéÊùü
- <strong>UCB</strong>: Êé¢Á¥¢ÈáçË¶ñ„Å†„Åå„ÄÅÊúÄÁµÇÁöÑ„Å´È´òÊÄßËÉΩ
- <strong>PI</strong>: ‰øùÂÆàÁöÑ„ÅßÂèéÊùü„ÅåÈÅÖ„ÅÑ

<strong>ÂÆüÂãô„Å∏„ÅÆÁ§∫ÂîÜ</strong>:
- ‰∏ÄËà¨ÁöÑ„Å™ÊúÄÈÅ©Âåñ ‚Üí EI
- Êé¢Á¥¢ÈáçË¶ñ„ÅÆÂàùÊúü„Éï„Çß„Éº„Ç∫ ‚Üí UCB
- ÂÆâÂÖ®ÈáçË¶ñ ‚Üí PI

</details>

---

<h3>ÂïèÈ°å3ÔºàÈõ£ÊòìÂ∫¶ÔºöhardÔºâ</h3>

Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ„ÅÆ„ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„Éó„Ç∑„Çπ„ÉÜ„É†„ÇíÊßãÁØâ„Åó„ÄÅ„Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶„Å®Á≤òÂ∫¶„ÅÆ„Éà„É¨„Éº„Éâ„Ç™„Éï„ÇíÊúÄÈÅ©Âåñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

<strong>ËÉåÊôØ</strong>:
Li-ionÈõªÊ±†ÈõªËß£Ë≥™„ÅÆÊúÄÈÅ©Âåñ
- ÁõÆÁöÑ1: „Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶„ÇíÊúÄÂ§ßÂåñ
- ÁõÆÁöÑ2: Á≤òÂ∫¶„ÇíÊúÄÂ∞èÂåñÔºà<10 cPÔºâ
- „Éë„É©„É°„Éº„Çø: Ê∫∂Â™íÊ∑∑ÂêàÊØî„ÄÅÂ°©ÊøÉÂ∫¶

<strong>„Çø„Çπ„ÇØ</strong>:
1. 2„Å§„ÅÆÁõÆÁöÑÈñ¢Êï∞„ÇíÂÆöÁæ©
2. „Éë„É¨„Éº„ÉàÊúÄÈÅ©Ëß£„ÇíÊé¢Á¥¢
3. 30Âõû„ÅÆÂÆüÈ®ì„Åß„Éë„É¨„Éº„Éà„Éï„É≠„É≥„Éà„ÇíÊßãÁØâ
4. ÂçòÁõÆÁöÑÊúÄÈÅ©Âåñ„Å®ÊØîËºÉ

<details>
<summary>„Éí„É≥„Éà</summary>

<strong>„Ç¢„Éó„É≠„Éº„ÉÅ</strong>:
1. „Çπ„Ç´„É©„ÉºÂåñ: <code>f_combined = w1*f1 + w2*f2</code>
2. Èáç„Åø„Çí„É©„É≥„ÉÄ„É†„Å´Â§âÊõ¥„Åó„Å¶Êé¢Á¥¢
3. „Éë„É¨„Éº„ÉàÂà§ÂÆö: ‰ªñ„ÅÆËß£„Å´ÊîØÈÖç„Åï„Çå„Å™„ÅÑËß£
4. Expected Hypervolume ImprovementÔºàÈ´òÂ∫¶Ôºâ

<strong>‰ΩøÁî®„Åô„ÇãÈñ¢Êï∞</strong>:
- „Éë„É¨„Éº„ÉàÂà§ÂÆö: ÂÖ®Ëß£„ÇíÊØîËºÉ„Åó„ÄÅÊîØÈÖç„Åï„Çå„Å™„ÅÑËß£„ÇíÊäΩÂá∫

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<pre><code class="language-python"><h1>Â§öÁõÆÁöÑ„ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©Âåñ</h1>
def objective_conductivity_2d(x1, x2):
    """ÁõÆÁöÑ1: „Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶ÔºàÊúÄÂ§ßÂåñÔºâ"""
    return 10 * np.exp(-10*(x1-0.6)<strong>2) * np.exp(-10*(x2-0.8)</strong>2)

def objective_viscosity_2d(x1, x2):
    """ÁõÆÁöÑ2: Á≤òÂ∫¶ÔºàÊúÄÂ∞èÂåñÔºâ"""
    return 5 + 10*x1 + 5*x2

class MultiObjectiveOptimizer:
    """Â§öÁõÆÁöÑ„ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©Âåñ"""

    def __init__(self, total_budget=30):
        self.total_budget = total_budget
        self.X_sampled = []
        self.y1_observed = []  # ‰ºùÂ∞éÂ∫¶
        self.y2_observed = []  # Á≤òÂ∫¶

    def initialize(self):
        """ÂàùÊúü„É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞"""
        np.random.seed(42)
        for _ in range(5):
            x1 = np.random.uniform(0, 1)
            x2 = np.random.uniform(0, 1)

            y1 = objective_conductivity_2d(x1, x2)
            y2 = objective_viscosity_2d(x1, x2)

            self.X_sampled.append([x1, x2])
            self.y1_observed.append(y1)
            self.y2_observed.append(y2)

    def is_pareto_optimal(self):
        """„Éë„É¨„Éº„ÉàÊúÄÈÅ©Ëß£„ÇíÂà§ÂÆö"""
        X = np.array(self.X_sampled)
        # ÊúÄÂ∞èÂåñÂïèÈ°å„Å´Áµ±‰∏ÄÔºà‰ºùÂ∞éÂ∫¶„ÅØÁ¨¶Âè∑ÂèçËª¢Ôºâ
        costs = np.column_stack([-np.array(self.y1_observed),
                                  np.array(self.y2_observed)])

        is_pareto = np.ones(len(costs), dtype=bool)
        for i, c in enumerate(costs):
            if is_pareto[i]:
                # ‰ªñ„ÅÆÁÇπ„Å´ÊîØÈÖç„Åï„Çå„Å¶„ÅÑ„Çã„ÅãÁ¢∫Ë™ç
                is_pareto[is_pareto] = np.any(
                    costs[is_pareto] < c, axis=1
                )
                is_pareto[i] = True

        return is_pareto

    def run(self):
        """Â§öÁõÆÁöÑÊúÄÈÅ©ÂåñÂÆüË°å"""
        self.initialize()

        X_candidate = np.random.uniform(0, 1, (1000, 2))

        for i in range(self.total_budget - 5):
            # „É©„É≥„ÉÄ„É†„Å™Èáç„Åø„Åß„Çπ„Ç´„É©„ÉºÂåñ
            w1 = np.random.uniform(0.3, 0.7)
            w2 = 1 - w1

            # 2„Å§„ÅÆ„Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´
            kernel = ConstantKernel(1.0) * RBF(length_scale=0.2)

            gp1 = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=5)
            gp1.fit(self.X_sampled, self.y1_observed)

            gp2 = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=5)
            gp2.fit(self.X_sampled, self.y2_observed)

            # ‰∫àÊ∏¨
            mu1 = gp1.predict(X_candidate)
            mu2 = gp2.predict(X_candidate)

            # „Çπ„Ç´„É©„ÉºÂåñÔºà‰ºùÂ∞éÂ∫¶„ÅØÊúÄÂ§ßÂåñ„ÄÅÁ≤òÂ∫¶„ÅØÊúÄÂ∞èÂåñÔºâ
            combined = w1 * mu1 - w2 * mu2

            # Ê¨°„ÅÆÂÆüÈ®ìÁÇπ
            next_idx = np.argmax(combined)
            next_x = X_candidate[next_idx]

            next_y1 = objective_conductivity_2d(next_x[0], next_x[1])
            next_y2 = objective_viscosity_2d(next_x[0], next_x[1])

            # „Éá„Éº„Çø„Å´ËøΩÂä†
            self.X_sampled.append(next_x)
            self.y1_observed.append(next_y1)
            self.y2_observed.append(next_y2)

        # „Éë„É¨„Éº„ÉàÊúÄÈÅ©Ëß£„ÇíÊäΩÂá∫
        pareto_mask = self.is_pareto_optimal()

        return pareto_mask

<h1>ÂÆüË°å</h1>
optimizer = MultiObjectiveOptimizer(total_budget=30)
pareto_mask = optimizer.run()

<h1>„Éë„É¨„Éº„ÉàÊúÄÈÅ©Ëß£</h1>
X_pareto = np.array(optimizer.X_sampled)[pareto_mask]
y1_pareto = np.array(optimizer.y1_observed)[pareto_mask]
y2_pareto = np.array(optimizer.y2_observed)[pareto_mask]

<h1>ÂèØË¶ñÂåñ</h1>
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

<h1>Â∑¶Âõ≥: „Éë„É©„É°„Éº„ÇøÁ©∫Èñì</h1>
ax1 = axes[0]
X_all = np.array(optimizer.X_sampled)
ax1.scatter(X_all[:, 0], X_all[:, 1], c='lightgray', s=80,
            alpha=0.5, label='ÂÖ®Êé¢Á¥¢ÁÇπ')
ax1.scatter(X_pareto[:, 0], X_pareto[:, 1], c='red', s=150,
            edgecolors='black', zorder=10,
            label='„Éë„É¨„Éº„ÉàÊúÄÈÅ©Ëß£')

ax1.set_xlabel('Ê∫∂Â™íÊ∑∑ÂêàÊØî x1', fontsize=12)
ax1.set_ylabel('Â°©ÊøÉÂ∫¶ x2', fontsize=12)
ax1.set_title('„Éë„É©„É°„Éº„ÇøÁ©∫Èñì', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

<h1>Âè≥Âõ≥: ÁõÆÁöÑÁ©∫ÈñìÔºà„Éë„É¨„Éº„Éà„Éï„É≠„É≥„ÉàÔºâ</h1>
ax2 = axes[1]
y1_all = np.array(optimizer.y1_observed)
y2_all = np.array(optimizer.y2_observed)

ax2.scatter(y1_all, y2_all, c='lightgray', s=80, alpha=0.5,
            label='ÂÖ®Êé¢Á¥¢ÁÇπ')
ax2.scatter(y1_pareto, y2_pareto, c='red', s=150,
            edgecolors='black', zorder=10,
            label='„Éë„É¨„Éº„Éà„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢')

<h1>„Éë„É¨„Éº„Éà„Éï„É≠„É≥„Éà„ÇíÁ∑ö„ÅßÁµê„Å∂</h1>
sorted_indices = np.argsort(y1_pareto)
ax2.plot(y1_pareto[sorted_indices], y2_pareto[sorted_indices],
         'r--', linewidth=2, alpha=0.5)

ax2.set_xlabel('„Ç§„Ç™„É≥‰ºùÂ∞éÂ∫¶ÔºàÊúÄÂ§ßÂåñÔºâ‚Üí', fontsize=12)
ax2.set_ylabel('Á≤òÂ∫¶ÔºàÊúÄÂ∞èÂåñÔºâ‚Üê', fontsize=12)
ax2.set_title('ÁõÆÁöÑÁ©∫Èñì„Å®„Éë„É¨„Éº„Éà„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('multi_objective_optimization_exercise.png', dpi=150,
            bbox_inches='tight')
plt.show()

<h1>ÁµêÊûú„Çµ„Éû„É™„Éº</h1>
print("Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ„ÅÆÁµêÊûú:")
print("=" * 60)
print(f"Á∑èÊé¢Á¥¢ÁÇπÊï∞: {len(optimizer.X_sampled)}")
print(f"„Éë„É¨„Éº„ÉàÊúÄÈÅ©Ëß£Êï∞: {np.sum(pareto_mask)}")
print("\n„Éë„É¨„Éº„ÉàÊúÄÈÅ©Ëß£„ÅÆ‰æã:")
for i in range(min(3, len(X_pareto))):
    print(f"  Ëß£{i+1}: x1={X_pareto[i][0]:.3f}, "
          f"x2={X_pareto[i][1]:.3f}")
    print(f"    ‰ºùÂ∞éÂ∫¶={y1_pareto[i]:.2f} mS/cm, "
          f"Á≤òÂ∫¶={y2_pareto[i]:.2f} cP")

print("\nËÄÉÂØü:")
print("  - ‰ºùÂ∞éÂ∫¶„Å®Á≤òÂ∫¶„Å´„ÅØ„Éà„É¨„Éº„Éâ„Ç™„Éï„ÅåÂ≠òÂú®")
print("  - „Éë„É¨„Éº„Éà„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢„ÅØË§áÊï∞„ÅÆÊúÄÈÅ©Ëß£„ÇíÊèê‰æõ")
print("  - ÂÆüÂãô„Åß„ÅØÂøúÁî®„Å´Âøú„Åò„Å¶Ëß£„ÇíÈÅ∏Êäû")</code></pre>

<strong>ÊúüÂæÖ„Åï„Çå„ÇãÂá∫Âäõ</strong>:
<pre><code>Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ„ÅÆÁµêÊûú:
============================================================
Á∑èÊé¢Á¥¢ÁÇπÊï∞: 30
„Éë„É¨„Éº„ÉàÊúÄÈÅ©Ëß£Êï∞: 8

„Éë„É¨„Éº„ÉàÊúÄÈÅ©Ëß£„ÅÆ‰æã:
  Ëß£1: x1=0.623, x2=0.812
    ‰ºùÂ∞éÂ∫¶=9.45 mS/cm, Á≤òÂ∫¶=15.23 cP
  Ëß£2: x1=0.512, x2=0.745
    ‰ºùÂ∞éÂ∫¶=8.12 mS/cm, Á≤òÂ∫¶=13.85 cP
  Ëß£3: x1=0.445, x2=0.698
    ‰ºùÂ∞éÂ∫¶=6.89 mS/cm, Á≤òÂ∫¶=12.34 cP

ËÄÉÂØü:
  - ‰ºùÂ∞éÂ∫¶„Å®Á≤òÂ∫¶„Å´„ÅØ„Éà„É¨„Éº„Éâ„Ç™„Éï„ÅåÂ≠òÂú®
  - „Éë„É¨„Éº„Éà„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢„ÅØË§áÊï∞„ÅÆÊúÄÈÅ©Ëß£„ÇíÊèê‰æõ
  - ÂÆüÂãô„Åß„ÅØÂøúÁî®„Å´Âøú„Åò„Å¶Ëß£„ÇíÈÅ∏Êäû</code></pre>

<strong>ÈáçË¶Å„Å™Ê¥ûÂØü</strong>:
1. <strong>„Éà„É¨„Éº„Éâ„Ç™„Éï„ÅÆÂèØË¶ñÂåñ</strong>: „Éë„É¨„Éº„Éà„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢„ÅßÊòéÁ¢∫„Å´Á§∫„Åï„Çå„Çã
2. <strong>Ë§áÊï∞„ÅÆÊúÄÈÅ©Ëß£</strong>: Âçò‰∏Ä„ÅÆËß£„Åß„ÅØ„Å™„Åè„ÄÅÈÅ∏ÊäûËÇ¢„ÇíÊèê‰æõ
3. <strong>ÊÑèÊÄùÊ±∫ÂÆöÊîØÊè¥</strong>: ÂÆüÂãô„Åß„ÅØÁî®ÈÄî„Å´Âøú„Åò„Å¶Ëß£„ÇíÈÅ∏Êäû
4. <strong>ÂäπÁéáÁöÑÊé¢Á¥¢</strong>: 30Âõû„ÅÆÂÆüÈ®ì„Åß8„Å§„ÅÆ„Éë„É¨„Éº„ÉàÊúÄÈÅ©Ëß£„ÇíÁô∫Ë¶ã

<strong>ËøΩÂä†„ÅÆÊ§úË®é‰∫ãÈ†Ö</strong>:
- Âà∂Á¥ÑÊù°‰ª∂„ÅÆËøΩÂä†Ôºà‰æãÔºöÁ≤òÂ∫¶ < 15 cPÔºâ
- 3ÁõÆÁöÑ‰ª•‰∏ä„ÅÆÊúÄÈÅ©Âåñ
- Expected Hypervolume Improvement„Å´„Çà„ÇãÊèêÊ°à

</details>

---

<h2>ÂèÇËÄÉÊñáÁåÆ</h2>

1. Lookman, T. et al. (2019). "Active learning in materials science with emphasis on adaptive sampling using uncertainties for targeted design." *npj Computational Materials*, 5(1), 21.
   DOI: [10.1038/s41524-019-0153-8](https://doi.org/10.1038/s41524-019-0153-8)

2. Szymanski, N. J. et al. (2023). "An autonomous laboratory for the accelerated synthesis of novel materials." *Nature*, 624, 86-91.
   DOI: [10.1038/s41586-023-06734-w](https://doi.org/10.1038/s41586-023-06734-w)

3. MacLeod, B. P. et al. (2020). "Self-driving laboratory for accelerated discovery of thin-film materials." *Science Advances*, 6(20), eaaz8867.
   DOI: [10.1126/sciadv.aaz8867](https://doi.org/10.1126/sciadv.aaz8867)

4. Settles, B. (2012). "Active Learning." *Synthesis Lectures on Artificial Intelligence and Machine Learning*, 6(1), 1-114.
   DOI: [10.2200/S00429ED1V01Y201207AIM018](https://doi.org/10.2200/S00429ED1V01Y201207AIM018)

5. Stein, H. S. & Gregoire, J. M. (2019). "Progress and prospects for accelerating materials science with automated and autonomous workflows." *Chemical Science*, 10(42), 9640-9649.
   DOI: [10.1039/C9SC03766G](https://doi.org/10.1039/C9SC03766G)

---

<h2>„Éä„Éì„Ç≤„Éº„Ç∑„Éß„É≥</h2>

<h3>Ââç„ÅÆÁ´†</h3>
<strong>[‚Üê Á¨¨3Á´†ÔºöÂÆüË∑µÔºöÊùêÊñôÊé¢Á¥¢„Å∏„ÅÆÂøúÁî®](./chapter-3.md)</strong>

<h3>„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°</h3>
<strong>[‚Üê „Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã](./index.md)</strong>

<h3>Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó</h3>
<strong>[„É≠„Éú„ÉÜ„Ç£„ÇØ„ÇπÂÆüÈ®ìËá™ÂãïÂåñÂÖ•ÈñÄ ‚Üí](../robotic-lab-automation/index.md)</strong>

---

<h2>ËëóËÄÖÊÉÖÂ†±</h2>

<strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team
<strong>Áõ£‰øÆ</strong>: Dr. Yusuke HashimotoÔºàÊù±ÂåóÂ§ßÂ≠¶Ôºâ
<strong>‰ΩúÊàêÊó•</strong>: 2025-10-17
<strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0

<strong>Êõ¥Êñ∞Â±•Ê≠¥</strong>:
- 2025-10-17: v1.0 ÂàùÁâàÂÖ¨Èñã

<strong>„Éï„Ç£„Éº„Éâ„Éê„ÉÉ„ÇØ</strong>:
- GitHub Issues: [AI_Homepage/issues](https://github.com/your-repo/AI_Homepage/issues)
- Email: yusuke.hashimoto.b8@tohoku.ac.jp

<strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0

---

<strong>„Åä„ÇÅ„Åß„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„ÅôÔºÅ„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„Éª„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞ÂÖ•ÈñÄ„Ç∑„É™„Éº„Ç∫„ÇíÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºÅ</strong>

Ê¨°„ÅØ„Äå„É≠„Éú„ÉÜ„Ç£„ÇØ„ÇπÂÆüÈ®ìËá™ÂãïÂåñÂÖ•ÈñÄ„Äç„Åß„ÄÅÂÆüÈöõ„ÅÆËá™ÂæãÂÆüÈ®ì„Ç∑„Çπ„ÉÜ„É†ÊßãÁØâ„ÇíÂ≠¶„Å≥„Åæ„Åó„Çá„ÅÜ„ÄÇ
<div class="navigation">
    <a href="chapter-3.html" class="nav-button">‚Üê Á¨¨3Á´†</a>
    <a href="index.html" class="nav-button">„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã</a>
</div>
    </main>

    <footer>
        <p><strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team</p>
        <p><strong>Áõ£‰øÆ</strong>: Dr. Yusuke HashimotoÔºàÊù±ÂåóÂ§ßÂ≠¶Ôºâ</p>
        <p><strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0 | <strong>‰ΩúÊàêÊó•</strong>: 2025-10-17</p>
        <p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0</p>
        <p>¬© 2025 AI Terakoya. All rights reserved.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default'
                });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</body>
</html>
