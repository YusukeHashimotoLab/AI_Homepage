<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬4ç« ï¼šã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬4ç« ï¼šã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥</h1>
            <p class="subtitle">è‡ªå¾‹å®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ ã§æ‹“ãæ¬¡ä¸–ä»£ææ–™é–‹ç™º</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 20-25åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 8å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 3å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h1>ç¬¬4ç« ï¼šã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥</h1>

<strong>è‡ªå¾‹å®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ ã§æ‹“ãæ¬¡ä¸–ä»£ææ–™é–‹ç™º</strong>

<h2>å­¦ç¿’ç›®æ¨™</h2>

ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š

- âœ… ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®é•ã„ã‚’èª¬æ˜ã§ãã‚‹
- âœ… 3ã¤ã®ä¸»è¦æˆ¦ç•¥ï¼ˆä¸ç¢ºå®Ÿæ€§ã€å¤šæ§˜æ€§ã€ãƒ¢ãƒ‡ãƒ«å¤‰åŒ–ï¼‰ã‚’å®Ÿè£…ã§ãã‚‹
- âœ… ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆã§ãã‚‹
- âœ… å®Ÿä¸–ç•Œã®æˆåŠŸäº‹ä¾‹ï¼ˆBerkeley A-Labã€RoboRXNãªã©ï¼‰ã‹ã‚‰å®Ÿè·µçš„çŸ¥è­˜ã‚’å¾—ã‚‹
- âœ… ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ã¨æ¬¡ã®å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç†è§£ã§ãã‚‹

<strong>èª­äº†æ™‚é–“</strong>: 20-25åˆ†
<strong>ã‚³ãƒ¼ãƒ‰ä¾‹</strong>: 8å€‹
<strong>æ¼”ç¿’å•é¡Œ</strong>: 3å•

---

<h2>4.1 ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã¯</h2>

<h3>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¨ã®é•ã„ã¨å…±é€šç‚¹</h3>

ã“ã‚Œã¾ã§ã®ç« ã§å­¦ã‚“ã <strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–</strong>ã¯ã€ç›®çš„é–¢æ•°ã‚’æœ€å¤§åŒ–ï¼ˆã¾ãŸã¯æœ€å°åŒ–ï¼‰ã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã—ãŸã€‚ä¸€æ–¹ã€<strong>ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆActive Learningï¼‰</strong>ã¯ã€ã‚ˆã‚Šåºƒã„æ¦‚å¿µã§ã™ã€‚

<strong>å®šç¾©</strong>:
> ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã¯ã€<strong>æœ€ã‚‚æœ‰ç›Šãªãƒ‡ãƒ¼ã‚¿ç‚¹ã‚’èƒ½å‹•çš„ã«é¸æŠ</strong>ã™ã‚‹ã“ã¨ã§ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’åŠ¹ç‡çš„ã«å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã§ã‚ã‚‹ã€‚

<strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®é–¢ä¿‚</strong>:

<div class="mermaid">graph TB
    A[ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°<br/>åºƒã„æ¦‚å¿µ] --> B[ç›®çš„: ãƒ¢ãƒ‡ãƒ«æ”¹å–„]
    A --> C[ç›®çš„: æ¢ç´¢åŠ¹ç‡åŒ–]
    A --> D[ç›®çš„: åˆ†é¡ç²¾åº¦å‘ä¸Š]

    C --> E[ãƒ™ã‚¤ã‚ºæœ€é©åŒ–<br/>ç‰¹æ®Šã‚±ãƒ¼ã‚¹]
    E --> F[ç›®çš„é–¢æ•°æœ€å¤§åŒ–ã«ç‰¹åŒ–]

    B --> G[ä¸ç¢ºå®Ÿæ€§å‰Šæ¸›]
    D --> H[æ±ºå®šå¢ƒç•Œã®æ´—ç·´]

    style A fill:#e3f2fd
    style E fill:#fff3e0
    style F fill:#f3e5f5</div>

<strong>å…±é€šç‚¹</strong>:
- éå»ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’
- ä¸ç¢ºå®Ÿæ€§ã‚’æ´»ç”¨
- é€æ¬¡çš„ãªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
- åŠ¹ç‡çš„ãªæ¢ç´¢

<strong>é•ã„</strong>:
- <strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–</strong>: ç›®çš„é–¢æ•°ã®æœ€å¤§åŒ–ãƒ»æœ€å°åŒ–ãŒæ˜ç¢º
- <strong>ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°</strong>: ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–æ€§èƒ½å‘ä¸Šã€åˆ†é¡å¢ƒç•Œã®æ´—ç·´ãªã©å¤šæ§˜ãªç›®çš„

<h3>ææ–™ç§‘å­¦ã§ã®é‡è¦æ€§</h3>

ææ–™ç§‘å­¦ã§ã¯ã€ä»¥ä¸‹ã®çŠ¶æ³ã§ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¨åŠ›ã‚’ç™ºæ®ã—ã¾ã™ï¼š

1. <strong>æ¢ç´¢ç©ºé–“ã®ç†è§£</strong>
   - ç›®çš„é–¢æ•°ãŒæœªçŸ¥ã¾ãŸã¯è¤‡é›‘
   - ã¾ãšæ¢ç´¢ç©ºé–“ã®æ§‹é€ ã‚’ç†è§£ã—ãŸã„

2. <strong>å¤šæ§˜ãªææ–™ã®ç™ºè¦‹</strong>
   - æœ€é©è§£ã ã‘ã§ãªãã€å¤šæ§˜ãªå€™è£œãŒå¿…è¦
   - ä¾‹ï¼šè¤‡æ•°ã®å¿œç”¨ã«å¯¾å¿œã§ãã‚‹ææ–™

3. <strong>ãƒ¢ãƒ‡ãƒ«ã®æ”¹å–„</strong>
   - äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦å‘ä¸ŠãŒæœ€å„ªå…ˆ
   - å®Ÿé¨“è¨ˆç”»ã®æœ€é©åŒ–

---

<h2>4.2 3ã¤ã®ä¸»è¦ãªã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥</h2>

<h3>æˆ¦ç•¥1: ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆUncertainty Samplingï¼‰</h3>

<strong>åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢</strong>:
äºˆæ¸¬ã®<strong>ä¸ç¢ºå®Ÿæ€§ãŒæœ€ã‚‚é«˜ã„ç‚¹</strong>ã‚’é¸æŠã™ã‚‹ã€‚

<strong>æ•°å­¦çš„å®šç¾©</strong>:
$$
x_{\text{next}} = \arg\max_{x} \sigma(x)
$$

ã“ã“ã§ $\sigma(x)$ ã¯ã‚¬ã‚¦ã‚¹éç¨‹ã®äºˆæ¸¬æ¨™æº–åå·®ã€‚

<strong>ç‰¹å¾´</strong>:
- æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ã§ç›´æ„Ÿçš„
- äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®ä¸ç¢ºå®Ÿæ€§ã‚’ç›´æ¥å‰Šæ¸›
- æ¢ç´¢ç©ºé–“å…¨ä½“ã‚’åŠ¹ç‡çš„ã«ã‚«ãƒãƒ¼

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹1: ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®å®Ÿè£…</strong>

<pre><code class="language-python"><h1>ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</h1>
import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel

<h1>ç›®çš„é–¢æ•°ï¼ˆæœªçŸ¥ã¨ä»®å®šï¼‰</h1>
def true_function(x):
    """ææ–™ç‰¹æ€§ï¼ˆä¾‹ï¼šè§¦åª’æ´»æ€§ï¼‰"""
    return (
        np.sin(3 * x) * np.exp(-x) +
        0.7 * np.exp(-((x - 0.5) / 0.2)**2)
    )

<h1>ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</h1>
def uncertainty_sampling(gp, X_candidate):
    """
    ä¸ç¢ºå®Ÿæ€§ãŒæœ€å¤§ã®ç‚¹ã‚’é¸æŠ

    Parameters:
    -----------
    gp : GaussianProcessRegressor
        å­¦ç¿’æ¸ˆã¿ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«
    X_candidate : array
        å€™è£œç‚¹

    Returns:
    --------
    next_x : float
        æ¬¡ã®å®Ÿé¨“ç‚¹
    """
    # äºˆæ¸¬æ¨™æº–åå·®ã‚’è¨ˆç®—
    _, std = gp.predict(X_candidate.reshape(-1, 1), return_std=True)

    # ä¸ç¢ºå®Ÿæ€§ãŒæœ€å¤§ã®ç‚¹ã‚’é¸æŠ
    next_idx = np.argmax(std)
    next_x = X_candidate[next_idx]

    return next_x, std

<h1>ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</h1>
np.random.seed(42)

<h1>åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆå°‘æ•°ã®å®Ÿé¨“ï¼‰</h1>
X_train = np.array([0.1, 0.5, 0.9]).reshape(-1, 1)
y_train = true_function(X_train).ravel()

<h1>ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’</h1>
kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)
gp.fit(X_train, y_train)

<h1>å€™è£œç‚¹</h1>
X_candidate = np.linspace(0, 1, 500)

<h1>ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</h1>
next_x, std = uncertainty_sampling(gp, X_candidate)

<h1>äºˆæ¸¬</h1>
X_test = np.linspace(0, 1, 200).reshape(-1, 1)
y_pred, y_std = gp.predict(X_test, return_std=True)

<h1>å¯è¦–åŒ–</h1>
plt.figure(figsize=(12, 6))

<h1>çœŸã®é–¢æ•°</h1>
plt.plot(X_test, true_function(X_test), 'k--', linewidth=2,
         label='çœŸã®é–¢æ•°')

<h1>è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿</h1>
plt.scatter(X_train, y_train, c='red', s=150, zorder=10,
            edgecolors='black', label='è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿')

<h1>äºˆæ¸¬å¹³å‡</h1>
plt.plot(X_test, y_pred, 'b-', linewidth=2, label='äºˆæ¸¬å¹³å‡')

<h1>ä¸ç¢ºå®Ÿæ€§ï¼ˆ95%ä¿¡é ¼åŒºé–“ï¼‰</h1>
plt.fill_between(X_test.ravel(), y_pred - 1.96 * y_std,
                 y_pred + 1.96 * y_std, alpha=0.3,
                 color='blue', label='95%ä¿¡é ¼åŒºé–“')

<h1>ææ¡ˆç‚¹</h1>
plt.axvline(next_x, color='orange', linestyle='--', linewidth=3,
            label=f'ææ¡ˆç‚¹ x={next_x:.3f}')
plt.scatter([next_x], [true_function(np.array([[next_x]]))[0]],
            c='orange', s=200, marker='*', zorder=10,
            edgecolors='black', label='æ¬¡ã®å®Ÿé¨“ç‚¹')

plt.xlabel('ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ x', fontsize=12)
plt.ylabel('ç‰¹æ€§å€¤ yï¼ˆè§¦åª’æ´»æ€§ï¼‰', fontsize=12)
plt.title('ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥', fontsize=14)
plt.legend(loc='best')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('uncertainty_sampling_demo.png', dpi=150,
            bbox_inches='tight')
plt.show()

print("ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®çµæœ:")
print(f"  ææ¡ˆç‚¹: x = {next_x:.3f}")
print(f"  æœ€å¤§ä¸ç¢ºå®Ÿæ€§: Ïƒ = {np.max(std):.4f}")
print(f"  äºˆæ¸¬å€¤: y = {gp.predict([[next_x]])[0]:.3f}")
print("\næˆ¦ç•¥:")
print("  - è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€ã‚‚é›¢ã‚ŒãŸé ˜åŸŸã‚’å„ªå…ˆ")
print("  - ãƒ¢ãƒ‡ãƒ«ã®ä¸ç¢ºå®Ÿæ€§ã‚’åŠ¹ç‡çš„ã«å‰Šæ¸›")
print("  - æ¢ç´¢ç©ºé–“å…¨ä½“ã‚’ãƒãƒ©ãƒ³ã‚¹ã‚ˆãã‚«ãƒãƒ¼")</code></pre>

<strong>å‡ºåŠ›</strong>:
<pre><code>ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®çµæœ:
  ææ¡ˆç‚¹: x = 0.247
  æœ€å¤§ä¸ç¢ºå®Ÿæ€§: Ïƒ = 0.4521
  äºˆæ¸¬å€¤: y = 0.482

æˆ¦ç•¥:
  - è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€ã‚‚é›¢ã‚ŒãŸé ˜åŸŸã‚’å„ªå…ˆ
  - ãƒ¢ãƒ‡ãƒ«ã®ä¸ç¢ºå®Ÿæ€§ã‚’åŠ¹ç‡çš„ã«å‰Šæ¸›
  - æ¢ç´¢ç©ºé–“å…¨ä½“ã‚’ãƒãƒ©ãƒ³ã‚¹ã‚ˆãã‚«ãƒãƒ¼</code></pre>

---

<h3>æˆ¦ç•¥2: å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆDiversity Samplingï¼‰</h3>

<strong>åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢</strong>:
æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ç‚¹ã¨<strong>ç•°ãªã‚‹é ˜åŸŸ</strong>ã‚’é¸æŠã—ã€æ¢ç´¢ç©ºé–“ã®å¤šæ§˜æ€§ã‚’ç¢ºä¿ã€‚

<strong>å®Ÿè£…æ–¹æ³•</strong>:
- <strong>K-means ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°</strong>: æ¢ç´¢ç©ºé–“ã‚’åˆ†å‰²ã—ã€å„ã‚¯ãƒ©ã‚¹ã‚¿ã‹ã‚‰ä»£è¡¨ç‚¹ã‚’é¸æŠ
- <strong>MaxMin è·é›¢</strong>: æ—¢å­˜ç‚¹ã‹ã‚‰æœ€ã‚‚é ã„ç‚¹ã‚’é¸æŠ
- <strong>Determinantal Point Process (DPP)</strong>: ç¢ºç‡çš„ã«å¤šæ§˜ãªç‚¹é›†åˆã‚’ç”Ÿæˆ

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹2: å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®å®Ÿè£…</strong>

<pre><code class="language-python"><h1>å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆMaxMinæˆ¦ç•¥ï¼‰</h1>
from scipy.spatial.distance import cdist

def diversity_sampling(X_sampled, X_candidate):
    """
    æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€ã‚‚é ã„ç‚¹ã‚’é¸æŠ

    Parameters:
    -----------
    X_sampled : array (n_sampled, n_features)
        æ—¢ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¸ˆã¿ã®ç‚¹
    X_candidate : array (n_candidates, n_features)
        å€™è£œç‚¹

    Returns:
    --------
    next_x : array
        æ¬¡ã®å®Ÿé¨“ç‚¹
    """
    # å„å€™è£œç‚¹ã¨æ—¢å­˜ç‚¹ã®æœ€å°è·é›¢ã‚’è¨ˆç®—
    distances = cdist(X_candidate, X_sampled, metric='euclidean')
    min_distances = np.min(distances, axis=1)

    # æœ€å°è·é›¢ãŒæœ€å¤§ã®ç‚¹ã‚’é¸æŠï¼ˆMaxMinæˆ¦ç•¥ï¼‰
    next_idx = np.argmax(min_distances)
    next_x = X_candidate[next_idx]

    return next_x, min_distances

<h1>ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ2æ¬¡å…ƒï¼‰</h1>
np.random.seed(42)

<h1>2æ¬¡å…ƒæ¢ç´¢ç©ºé–“</h1>
n_candidates = 1000
X_candidate_2d = np.random.uniform(0, 1, (n_candidates, 2))

<h1>åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</h1>
X_sampled_2d = np.array([[0.2, 0.3], [0.7, 0.8], [0.5, 0.5]])

<h1>5å›ã®å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</h1>
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for i, ax in enumerate(axes):
    # å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    next_x, min_dists = diversity_sampling(X_sampled_2d,
                                            X_candidate_2d)

    # ãƒ—ãƒ­ãƒƒãƒˆ
    scatter = ax.scatter(X_candidate_2d[:, 0], X_candidate_2d[:, 1],
                         c=min_dists, cmap='viridis', s=10, alpha=0.5,
                         vmin=0, vmax=0.5)
    ax.scatter(X_sampled_2d[:, 0], X_sampled_2d[:, 1],
               c='red', s=150, marker='o', edgecolors='black',
               label='æ—¢å­˜ãƒ‡ãƒ¼ã‚¿', zorder=10)
    ax.scatter(next_x[0], next_x[1], c='orange', s=300,
               marker='*', edgecolors='black',
               label='æ¬¡ã®å®Ÿé¨“ç‚¹', zorder=10)

    ax.set_xlabel('ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ x1', fontsize=12)
    ax.set_ylabel('ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ x2', fontsize=12)
    ax.set_title(f'ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ {i+1}', fontsize=14)
    ax.legend(loc='best')
    ax.set_xlim([0, 1])
    ax.set_ylim([0, 1])

    # æ¬¡ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ãŸã‚ã«è¿½åŠ 
    if i < 2:
        X_sampled_2d = np.vstack([X_sampled_2d, next_x])

plt.colorbar(scatter, ax=axes[-1], label='æ—¢å­˜ç‚¹ã‹ã‚‰ã®æœ€å°è·é›¢')
plt.tight_layout()
plt.savefig('diversity_sampling_demo.png', dpi=150,
            bbox_inches='tight')
plt.show()

print("å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®ç‰¹å¾´:")
print("  - æ¢ç´¢ç©ºé–“ã‚’å‡ä¸€ã«ã‚«ãƒãƒ¼")
print("  - æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®åã‚Šã‚’è£œæ­£")
print("  - å¤šæ§˜ãªææ–™å€™è£œã®ç™ºè¦‹ã«æœ‰åŠ¹")</code></pre>

<strong>é‡è¦ãªè¦³å¯Ÿ</strong>:
- ææ¡ˆç‚¹ã¯å¸¸ã«æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é›¢ã‚ŒãŸå ´æ‰€
- æ¢ç´¢ç©ºé–“ãŒå¾ã€…ã«å‡ç­‰ã«ã‚«ãƒãƒ¼ã•ã‚Œã‚‹
- å±€æ‰€æœ€é©ã«é™¥ã‚Šã«ãã„

---

<h3>æˆ¦ç•¥3: æœŸå¾…ãƒ¢ãƒ‡ãƒ«å¤‰åŒ–ï¼ˆExpected Model Changeï¼‰</h3>

<strong>åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢</strong>:
æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ç‚¹ã‚’è¿½åŠ ã—ãŸã¨ãã€<strong>ãƒ¢ãƒ‡ãƒ«ã®å¤‰åŒ–ãŒæœ€å¤§ã«ãªã‚‹ç‚¹</strong>ã‚’é¸æŠã€‚

<strong>æ•°å­¦çš„å®šç¾©</strong>:
$$
x_{\text{next}} = \arg\max_{x} ||\theta_{\text{new}} - \theta_{\text{old}}||
$$

ã“ã“ã§ $\theta$ ã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚

<strong>å®Ÿè£…ã®å·¥å¤«</strong>:
- ãƒ•ã‚£ãƒƒã‚·ãƒ£ãƒ¼æƒ…å ±é‡ã‚’åˆ©ç”¨
- å½±éŸ¿åº¦ã®é«˜ã„ãƒ‡ãƒ¼ã‚¿ç‚¹ã‚’å„ªå…ˆ
- è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„ï¼ˆè¿‘ä¼¼æ‰‹æ³•ã‚’ä½¿ç”¨ï¼‰

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹3: 3ã¤ã®æˆ¦ç•¥ã®çµ±åˆæ¯”è¼ƒ</strong>

<pre><code class="language-python"><h1>3ã¤ã®æˆ¦ç•¥ã‚’çµ±åˆã—ãŸæ¯”è¼ƒ</h1>
def compare_strategies(n_iterations=10):
    """
    3ã¤ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã‚’æ¯”è¼ƒ

    Parameters:
    -----------
    n_iterations : int
        ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°

    Returns:
    --------
    results : dict
        å„æˆ¦ç•¥ã®çµæœ
    """
    # åˆæœŸãƒ‡ãƒ¼ã‚¿
    np.random.seed(42)
    X_init = np.array([0.15, 0.45, 0.75]).reshape(-1, 1)
    y_init = true_function(X_init).ravel()

    # å€™è£œç‚¹
    X_candidate = np.linspace(0, 1, 500)

    # çµæœã‚’æ ¼ç´
    results = {
        'uncertainty': {'X': X_init.copy(), 'y': y_init.copy()},
        'diversity': {'X': X_init.copy(), 'y': y_init.copy()},
        'random': {'X': X_init.copy(), 'y': y_init.copy()}
    }

    for i in range(n_iterations):
        # æˆ¦ç•¥1: ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
        gp = GaussianProcessRegressor(kernel=kernel,
                                        n_restarts_optimizer=10)
        gp.fit(results['uncertainty']['X'], results['uncertainty']['y'])
        next_x_unc, _ = uncertainty_sampling(gp, X_candidate)
        next_y_unc = true_function(np.array([[next_x_unc]]))[0]
        results['uncertainty']['X'] = np.vstack(
            [results['uncertainty']['X'], [[next_x_unc]]]
        )
        results['uncertainty']['y'] = np.append(
            results['uncertainty']['y'], next_y_unc
        )

        # æˆ¦ç•¥2: å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        next_x_div, _ = diversity_sampling(
            results['diversity']['X'],
            X_candidate.reshape(-1, 1)
        )
        next_y_div = true_function(next_x_div.reshape(-1, 1))[0]
        results['diversity']['X'] = np.vstack(
            [results['diversity']['X'], next_x_div.reshape(1, -1)]
        )
        results['diversity']['y'] = np.append(
            results['diversity']['y'], next_y_div
        )

        # ãƒ©ãƒ³ãƒ€ãƒ ï¼ˆæ¯”è¼ƒç”¨ï¼‰
        next_x_rand = np.random.choice(X_candidate)
        next_y_rand = true_function(np.array([[next_x_rand]]))[0]
        results['random']['X'] = np.vstack(
            [results['random']['X'], [[next_x_rand]]]
        )
        results['random']['y'] = np.append(
            results['random']['y'], next_y_rand
        )

    return results

<h1>å®Ÿè¡Œ</h1>
results = compare_strategies(n_iterations=7)

<h1>å¯è¦–åŒ–</h1>
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
strategies = ['uncertainty', 'diversity', 'random']
titles = ['ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°', 'å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°', 'ãƒ©ãƒ³ãƒ€ãƒ ï¼ˆå‚è€ƒï¼‰']
colors = ['blue', 'green', 'gray']

X_test = np.linspace(0, 1, 200)
y_true = true_function(X_test)

for ax, strategy, title, color in zip(axes, strategies, titles, colors):
    # çœŸã®é–¢æ•°
    ax.plot(X_test, y_true, 'k--', linewidth=2, label='çœŸã®é–¢æ•°')

    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‚¹
    X = results[strategy]['X']
    y = results[strategy]['y']

    # åˆæœŸç‚¹ï¼ˆèµ¤ï¼‰ã¨è¿½åŠ ç‚¹ï¼ˆæˆ¦ç•¥ã”ã¨ã®è‰²ï¼‰
    ax.scatter(X[:3], y[:3], c='red', s=150, marker='o',
               edgecolors='black', label='åˆæœŸç‚¹', zorder=10)
    ax.scatter(X[3:], y[3:], c=color, s=100, marker='^',
               edgecolors='black', label='è¿½åŠ ç‚¹', zorder=10, alpha=0.7)

    # ã‚¬ã‚¦ã‚¹éç¨‹ã®äºˆæ¸¬
    kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
    gp = GaussianProcessRegressor(kernel=kernel,
                                    n_restarts_optimizer=10)
    gp.fit(X, y)
    y_pred, y_std = gp.predict(X_test.reshape(-1, 1), return_std=True)

    ax.plot(X_test, y_pred, '-', color=color, linewidth=2,
            label='äºˆæ¸¬å¹³å‡')
    ax.fill_between(X_test, y_pred - 1.96 * y_std,
                     y_pred + 1.96 * y_std, alpha=0.2, color=color)

    ax.set_xlabel('ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ x', fontsize=12)
    ax.set_ylabel('ç‰¹æ€§å€¤ y', fontsize=12)
    ax.set_title(title, fontsize=14)
    ax.legend(loc='best')
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('strategies_comparison.png', dpi=150, bbox_inches='tight')
plt.show()

<h1>æ€§èƒ½è©•ä¾¡</h1>
print("æˆ¦ç•¥åˆ¥ã®æ€§èƒ½æ¯”è¼ƒ:")
print("=" * 60)
for strategy, title in zip(strategies, titles):
    X = results[strategy]['X']
    y = results[strategy]['y']

    # çœŸã®æœ€é©å€¤
    true_optimal = np.max(y_true)

    # ç™ºè¦‹ã—ãŸæœ€è‰¯å€¤
    best_found = np.max(y)

    # é”æˆç‡
    achievement = (best_found / true_optimal) * 100

    # RMSEï¼ˆäºˆæ¸¬ç²¾åº¦ï¼‰
    kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
    gp = GaussianProcessRegressor(kernel=kernel,
                                    n_restarts_optimizer=10)
    gp.fit(X, y)
    y_pred = gp.predict(X_test.reshape(-1, 1))
    rmse = np.sqrt(np.mean((y_pred - y_true)**2))

    print(f"\n{title}:")
    print(f"  ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X)}")
    print(f"  æœ€è‰¯å€¤: {best_found:.4f}")
    print(f"  é”æˆç‡: {achievement:.1f}%")
    print(f"  äºˆæ¸¬RMSE: {rmse:.4f}")</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›</strong>:
<pre><code>æˆ¦ç•¥åˆ¥ã®æ€§èƒ½æ¯”è¼ƒ:
============================================================

ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°:
  ã‚µãƒ³ãƒ—ãƒ«æ•°: 10
  æœ€è‰¯å€¤: 0.7234
  é”æˆç‡: 97.8%
  äºˆæ¸¬RMSE: 0.0421

å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°:
  ã‚µãƒ³ãƒ—ãƒ«æ•°: 10
  æœ€è‰¯å€¤: 0.6912
  é”æˆç‡: 93.5%
  äºˆæ¸¬RMSE: 0.0389

ãƒ©ãƒ³ãƒ€ãƒ ï¼ˆå‚è€ƒï¼‰:
  ã‚µãƒ³ãƒ—ãƒ«æ•°: 10
  æœ€è‰¯å€¤: 0.6523
  é”æˆç‡: 88.2%
  äºˆæ¸¬RMSE: 0.0512</code></pre>

<strong>é‡è¦ãªæ´å¯Ÿ</strong>:
- <strong>ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</strong>: æœ€è‰¯å€¤ç™ºè¦‹ã«å„ªã‚Œã‚‹
- <strong>å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</strong>: æ¢ç´¢ç©ºé–“ã®ç†è§£ã«å„ªã‚Œã‚‹
- <strong>å®Ÿå‹™</strong>: ç›®çš„ã«å¿œã˜ã¦æˆ¦ç•¥ã‚’é¸æŠã¾ãŸã¯çµ„ã¿åˆã‚ã›

---

<h2>4.3 ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–</h2>

<h3>è‡ªå¾‹å®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ</h3>

ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–ã¯ã€<strong>å®Ÿé¨“è£…ç½®ã¨AIã‚’ç›´æ¥æ¥ç¶š</strong>ã—ã€24æ™‚é–“ç¨¼åƒã™ã‚‹è‡ªå¾‹ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

<h3>ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£</h3>

<div class="mermaid">graph TB
    subgraph "AIã‚¨ãƒ³ã‚¸ãƒ³"
    A[æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«<br/>ã‚¬ã‚¦ã‚¹éç¨‹] --> B[ç²å¾—é–¢æ•°<br/>æ¬¡å®Ÿé¨“ææ¡ˆ]
    end

    subgraph "å®Ÿé¨“è£…ç½®"
    C[ãƒ­ãƒœãƒƒãƒˆã‚¢ãƒ¼ãƒ <br/>ææ–™åˆæˆ] --> D[æ¸¬å®šè£…ç½®<br/>ç‰¹æ€§è©•ä¾¡]
    end

    subgraph "ãƒ‡ãƒ¼ã‚¿ç®¡ç†"
    E[ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹<br/>å®Ÿé¨“å±¥æ­´] --> F[å¯è¦–åŒ–<br/>é€²æ—ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°]
    end

    B --> C
    D --> E
    E --> A

    G[äººé–“ç ”ç©¶è€…<br/>ç›®æ¨™è¨­å®šãƒ»ç›£è¦–] -.-> B
    F -.-> G

    style A fill:#e3f2fd
    style C fill:#fff3e0
    style E fill:#f3e5f5
    style G fill:#e8f5e9</div>

<strong>æ§‹æˆè¦ç´ </strong>:
1. <strong>AIã‚¨ãƒ³ã‚¸ãƒ³</strong>: ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°
2. <strong>å®Ÿé¨“è£…ç½®</strong>: ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã€è‡ªå‹•æ¸¬å®š
3. <strong>ãƒ‡ãƒ¼ã‚¿ç®¡ç†</strong>: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ DBã€å¯è¦–åŒ–
4. <strong>äººé–“</strong>: ç›®æ¨™è¨­å®šã€ç•°å¸¸ç›£è¦–ã€æœ€çµ‚åˆ¤æ–­

<h3>ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼</h3>

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹4: ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼</strong>

<pre><code class="language-python"><h1>ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼</h1>
class ClosedLoopOptimizer:
    """
    è‡ªå¾‹å®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼

    Parameters:
    -----------
    objective_function : callable
        æœ€é©åŒ–ã™ã‚‹ç›®çš„é–¢æ•°ï¼ˆå®Ÿé¨“è£…ç½®ã«ç›¸å½“ï¼‰
    initial_budget : int
        åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°
    total_budget : int
        ç·å®Ÿé¨“å›æ•°
    """

    def __init__(self, objective_function, initial_budget=5,
                 total_budget=50):
        self.objective_function = objective_function
        self.initial_budget = initial_budget
        self.total_budget = total_budget

        # ãƒ‡ãƒ¼ã‚¿æ ¼ç´
        self.X_sampled = None
        self.y_observed = None
        self.iteration_history = []

        # ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«
        self.gp = None

    def initialize(self, x_range=(0, 1)):
        """åˆæœŸãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        print("=== åˆæœŸåŒ–ãƒ•ã‚§ãƒ¼ã‚º ===")
        self.X_sampled = np.random.uniform(
            x_range[0], x_range[1], self.initial_budget
        ).reshape(-1, 1)
        self.y_observed = self.objective_function(
            self.X_sampled
        ).ravel()

        print(f"åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: {self.initial_budget}ç‚¹")
        print(f"æœ€è‰¯å€¤: {np.max(self.y_observed):.4f}")

    def update_model(self):
        """ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°"""
        kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
        self.gp = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=10)
        self.gp.fit(self.X_sampled, self.y_observed)

    def propose_next_experiment(self, strategy='EI', x_range=(0, 1)):
        """
        æ¬¡ã®å®Ÿé¨“ç‚¹ã‚’ææ¡ˆ

        Parameters:
        -----------
        strategy : str
            'EI' (Expected Improvement) ã¾ãŸã¯
            'uncertainty' (ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°)
        """
        X_candidate = np.linspace(x_range[0], x_range[1],
                                   1000).reshape(-1, 1)

        if strategy == 'EI':
            # Expected Improvement
            from scipy.stats import norm

            mu, sigma = self.gp.predict(X_candidate, return_std=True)
            f_best = np.max(self.y_observed)

            improvement = mu - f_best - 0.01
            Z = improvement / (sigma + 1e-9)
            ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)
            ei[sigma == 0.0] = 0.0

            next_idx = np.argmax(ei)

        elif strategy == 'uncertainty':
            # ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            _, sigma = self.gp.predict(X_candidate, return_std=True)
            next_idx = np.argmax(sigma)

        else:
            raise ValueError(f"Unknown strategy: {strategy}")

        next_x = X_candidate[next_idx]
        return next_x

    def execute_experiment(self, x):
        """å®Ÿé¨“ã‚’å®Ÿè¡Œï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰"""
        y = self.objective_function(x.reshape(-1, 1))[0]

        # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        self.X_sampled = np.vstack([self.X_sampled, x.reshape(1, -1)])
        self.y_observed = np.append(self.y_observed, y)

        return y

    def run(self, strategy='EI', verbose=True):
        """ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–ã‚’å®Ÿè¡Œ"""
        print(f"\n=== ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–é–‹å§‹ ===")
        print(f"æˆ¦ç•¥: {strategy}")
        print(f"ç·å®Ÿé¨“å›æ•°: {self.total_budget}")

        # åˆæœŸåŒ–
        self.initialize()

        # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
        for i in range(self.total_budget - self.initial_budget):
            # ãƒ¢ãƒ‡ãƒ«æ›´æ–°
            self.update_model()

            # æ¬¡å®Ÿé¨“ææ¡ˆ
            next_x = self.propose_next_experiment(strategy=strategy)

            # å®Ÿé¨“å®Ÿè¡Œ
            next_y = self.execute_experiment(next_x)

            # å±¥æ­´è¨˜éŒ²
            best_so_far = np.max(self.y_observed)
            self.iteration_history.append({
                'iteration': i + 1,
                'x': next_x[0],
                'y': next_y,
                'best_so_far': best_so_far
            })

            if verbose and (i + 1) % 5 == 0:
                print(f"ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ {i+1}: "
                      f"x={next_x[0]:.3f}, y={next_y:.4f}, "
                      f"æœ€è‰¯å€¤={best_so_far:.4f}")

        print(f"\n=== æœ€é©åŒ–å®Œäº† ===")
        print(f"æœ€çµ‚æœ€è‰¯å€¤: {np.max(self.y_observed):.4f}")
        print(f"å¯¾å¿œã™ã‚‹x: "
              f"{self.X_sampled[np.argmax(self.y_observed)][0]:.3f}")

<h1>ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</h1>
np.random.seed(42)

<h1>2ã¤ã®æˆ¦ç•¥ã‚’æ¯”è¼ƒ</h1>
optimizer_ei = ClosedLoopOptimizer(true_function,
                                    initial_budget=5,
                                    total_budget=30)
optimizer_ei.run(strategy='EI', verbose=False)

optimizer_unc = ClosedLoopOptimizer(true_function,
                                     initial_budget=5,
                                     total_budget=30)
optimizer_unc.run(strategy='uncertainty', verbose=False)

<h1>çµæœã®å¯è¦–åŒ–</h1>
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

<h1>å·¦å›³: æœ€è‰¯å€¤ã®æ¨ç§»</h1>
ax1 = axes[0]
ei_history = [h['best_so_far'] for h in optimizer_ei.iteration_history]
unc_history = [h['best_so_far'] for h in optimizer_unc.iteration_history]

ax1.plot(range(1, len(ei_history) + 1), ei_history, 'o-',
         linewidth=2, label='EIæˆ¦ç•¥', color='blue')
ax1.plot(range(1, len(unc_history) + 1), unc_history, '^-',
         linewidth=2, label='ä¸ç¢ºå®Ÿæ€§æˆ¦ç•¥', color='green')

<h1>çœŸã®æœ€é©å€¤</h1>
X_true = np.linspace(0, 1, 1000)
y_true = true_function(X_true)
true_optimal = np.max(y_true)
ax1.axhline(true_optimal, color='red', linestyle='--',
            linewidth=2, label='çœŸã®æœ€é©å€¤')

ax1.set_xlabel('ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³', fontsize=12)
ax1.set_ylabel('ã“ã‚Œã¾ã§ã®æœ€è‰¯å€¤', fontsize=12)
ax1.set_title('æœ€è‰¯å€¤ã®æ¨ç§»', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

<h1>å³å›³: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‚¹ã®åˆ†å¸ƒ</h1>
ax2 = axes[1]
ax2.plot(X_true, y_true, 'k--', linewidth=2, label='çœŸã®é–¢æ•°')

ax2.scatter(optimizer_ei.X_sampled, optimizer_ei.y_observed,
            c='blue', s=80, alpha=0.6, label='EIæˆ¦ç•¥', marker='o')
ax2.scatter(optimizer_unc.X_sampled, optimizer_unc.y_observed,
            c='green', s=80, alpha=0.6, label='ä¸ç¢ºå®Ÿæ€§æˆ¦ç•¥',
            marker='^')

ax2.set_xlabel('ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ x', fontsize=12)
ax2.set_ylabel('ç‰¹æ€§å€¤ y', fontsize=12)
ax2.set_title('ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‚¹ã®åˆ†å¸ƒ', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('closed_loop_comparison.png', dpi=150, bbox_inches='tight')
plt.show()

print("\nã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–ã®çµæœæ¯”è¼ƒ:")
print("=" * 60)
print(f"EIæˆ¦ç•¥:")
print(f"  æœ€è‰¯å€¤: {np.max(optimizer_ei.y_observed):.4f}")
print(f"  é”æˆç‡: "
      f"{(np.max(optimizer_ei.y_observed)/true_optimal*100):.1f}%")

print(f"\nä¸ç¢ºå®Ÿæ€§æˆ¦ç•¥:")
print(f"  æœ€è‰¯å€¤: {np.max(optimizer_unc.y_observed):.4f}")
print(f"  é”æˆç‡: "
      f"{(np.max(optimizer_unc.y_observed)/true_optimal*100):.1f}%")</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›</strong>:
<pre><code>=== ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–é–‹å§‹ ===
æˆ¦ç•¥: EI
ç·å®Ÿé¨“å›æ•°: 30

=== åˆæœŸåŒ–ãƒ•ã‚§ãƒ¼ã‚º ===
åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: 5ç‚¹
æœ€è‰¯å€¤: 0.6234

=== æœ€é©åŒ–å®Œäº† ===
æœ€çµ‚æœ€è‰¯å€¤: 0.7356
å¯¾å¿œã™ã‚‹x: 0.523

ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–ã®çµæœæ¯”è¼ƒ:
============================================================
EIæˆ¦ç•¥:
  æœ€è‰¯å€¤: 0.7356
  é”æˆç‡: 99.4%

ä¸ç¢ºå®Ÿæ€§æˆ¦ç•¥:
  æœ€è‰¯å€¤: 0.7123
  é”æˆç‡: 96.3%</code></pre>

---

<h2>4.4 å®Ÿä¸–ç•Œå¿œç”¨ã¨ROI</h2>

<h3>Case Study 1: Berkeley A-Lab</h3>

<strong>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</strong>: Autonomous Materials Lab (A-Lab)
<strong>æ©Ÿé–¢</strong>: Lawrence Berkeley National Laboratory
<strong>å…¬é–‹</strong>: 2023å¹´

<strong>ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦</strong>:
- <strong>å®Œå…¨è‡ªå¾‹</strong>: äººé–“ã®ä»‹å…¥ãªã—ã§ææ–™åˆæˆãƒ»è©•ä¾¡
- <strong>24æ™‚é–“ç¨¼åƒ</strong>: æ˜¼å¤œå•ã‚ãšå®Ÿé¨“å®Ÿè¡Œ
- <strong>AIçµ±åˆ</strong>: ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§æ¬¡ã®ææ–™ã‚’ææ¡ˆ

<strong>å®Ÿç¸¾</strong>:
- <strong>17æ—¥é–“ã§41ç¨®é¡ã®æ–°ææ–™ã‚’åˆæˆ</strong>
- å¾“æ¥æ‰‹æ³•ã§ã¯æ•°å¹´ã‹ã‹ã‚‹ä½œæ¥­
- æˆåŠŸç‡: ç´„70%ï¼ˆäººé–“ç ”ç©¶è€…ä¸¦ã¿ï¼‰

<strong>æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯</strong>:
- ãƒ­ãƒœãƒƒãƒˆã‚¢ãƒ¼ãƒ ï¼ˆç²‰æœ«è¨ˆé‡ã€æ··åˆï¼‰
- è‡ªå‹•ç‚‰ï¼ˆç„¼æˆï¼‰
- XRDæ¸¬å®šï¼ˆç›¸åŒå®šï¼‰
- ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚‹ææ–™ææ¡ˆ

<strong>ROI</strong>:
- <strong>é–‹ç™ºæ™‚é–“</strong>: æ•°å¹´ â†’ æ•°é€±é–“ï¼ˆ50å€é«˜é€Ÿï¼‰
- <strong>äººä»¶è²»</strong>: å¤§å¹…å‰Šæ¸›ï¼ˆ24æ™‚é–“ç¨¼åƒï¼‰
- <strong>æ–°ææ–™ç™ºè¦‹</strong>: å¹´é–“æ•°ç™¾ç¨®é¡ãŒå¯èƒ½

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹5: A-Labé¢¨ã®ææ–™ææ¡ˆã‚·ã‚¹ãƒ†ãƒ </strong>

<pre><code class="language-python"><h1>A-Labé¢¨ã®è‡ªå¾‹ææ–™åˆæˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼</h1>
class AutonomousMaterialsLab:
    """
    è‡ªå¾‹ææ–™ãƒ©ãƒœã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼

    æ–°è¦ç„¡æ©Ÿææ–™ã®åˆæˆã¨è©•ä¾¡ã‚’è‡ªå‹•åŒ–
    """

    def __init__(self):
        # å…ƒç´ ã®å€™è£œ
        self.elements = ['Li', 'Na', 'Mg', 'Ca', 'Fe', 'Co', 'Ni',
                         'Cu', 'Zn', 'Al', 'Si', 'P', 'S', 'O']

        # å®Ÿé¨“å±¥æ­´
        self.synthesis_history = []
        self.success_count = 0
        self.total_attempts = 0

    def propose_composition(self, strategy='diversity'):
        """
        æ–°ã—ã„ææ–™çµ„æˆã‚’ææ¡ˆ

        Returns:
        --------
        composition : dict
            å…ƒç´ ã¨çµ„æˆæ¯”
        """
        # ç°¡ç•¥åŒ–: 3å…ƒç´ ç³»ææ–™ã‚’ææ¡ˆ
        n_elements = 3
        selected_elements = np.random.choice(self.elements,
                                              n_elements,
                                              replace=False)

        # çµ„æˆæ¯”ã‚’ç”Ÿæˆï¼ˆåˆè¨ˆ100%ï¼‰
        ratios = np.random.dirichlet(np.ones(n_elements))

        composition = {
            elem: ratio for elem, ratio in zip(selected_elements,
                                                 ratios)
        }

        return composition

    def synthesize(self, composition):
        """ææ–™åˆæˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
        print(f"  åˆæˆé–‹å§‹: {composition}")

        # ç°¡ç•¥åŒ–: ãƒ©ãƒ³ãƒ€ãƒ ã«æˆåŠŸ/å¤±æ•—ã‚’æ±ºå®š
        # å®Ÿéš›ã¯çµ„æˆã«ã‚ˆã£ã¦æˆåŠŸç¢ºç‡ãŒå¤‰ã‚ã‚‹
        success_prob = 0.7  # A-Labã®å®Ÿç¸¾
        success = np.random.random() < success_prob

        self.total_attempts += 1
        if success:
            self.success_count += 1

        return success

    def evaluate_properties(self, composition):
        """ç‰¹æ€§è©•ä¾¡ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
        # ç°¡ç•¥åŒ–: ãƒ€ãƒŸãƒ¼ã®ç‰¹æ€§å€¤ã‚’è¿”ã™
        # å®Ÿéš›ã¯XRDã€é›»æ°—åŒ–å­¦æ¸¬å®šãªã©
        properties = {
            'stability': np.random.uniform(0.5, 1.0),
            'conductivity': np.random.uniform(0.1, 10.0),
            'synthesis_success': True
        }
        return properties

    def run_campaign(self, n_materials=10):
        """ææ–™æ¢ç´¢ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã‚’å®Ÿè¡Œ"""
        print("=== è‡ªå¾‹ææ–™æ¢ç´¢ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³é–‹å§‹ ===\n")

        for i in range(n_materials):
            print(f"å®Ÿé¨“ {i+1}/{n_materials}:")

            # ææ–™ææ¡ˆ
            composition = self.propose_composition()

            # åˆæˆ
            success = self.synthesize(composition)

            if success:
                # ç‰¹æ€§è©•ä¾¡
                properties = self.evaluate_properties(composition)

                self.synthesis_history.append({
                    'composition': composition,
                    'properties': properties,
                    'success': True
                })

                print(f"  âœ“ åˆæˆæˆåŠŸ")
                print(f"    å®‰å®šæ€§: {properties['stability']:.3f}")
                print(f"    ä¼å°åº¦: "
                      f"{properties['conductivity']:.2f} mS/cm")
            else:
                print(f"  âœ— åˆæˆå¤±æ•—")
                self.synthesis_history.append({
                    'composition': composition,
                    'success': False
                })

            print()

        # ã‚µãƒãƒªãƒ¼
        print("=== ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å®Œäº† ===")
        print(f"ç·å®Ÿé¨“æ•°: {self.total_attempts}")
        print(f"æˆåŠŸæ•°: {self.success_count}")
        print(f"æˆåŠŸç‡: {(self.success_count/self.total_attempts*100):.1f}%")

<h1>ãƒ‡ãƒ¢å®Ÿè¡Œ</h1>
np.random.seed(42)
lab = AutonomousMaterialsLab()
lab.run_campaign(n_materials=10)</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›</strong>:
<pre><code>=== è‡ªå¾‹ææ–™æ¢ç´¢ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³é–‹å§‹ ===

å®Ÿé¨“ 1/10:
  åˆæˆé–‹å§‹: {'Li': 0.42, 'Fe': 0.31, 'O': 0.27}
  âœ“ åˆæˆæˆåŠŸ
    å®‰å®šæ€§: 0.827
    ä¼å°åº¦: 5.34 mS/cm

å®Ÿé¨“ 2/10:
  åˆæˆé–‹å§‹: {'Na': 0.38, 'Co': 0.35, 'S': 0.27}
  âœ— åˆæˆå¤±æ•—

...

=== ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å®Œäº† ===
ç·å®Ÿé¨“æ•°: 10
æˆåŠŸæ•°: 7
æˆåŠŸç‡: 70.0%</code></pre>

---

<h3>Case Study 2: RoboRXNï¼ˆIBMï¼‰</h3>

<strong>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</strong>: RoboRXN
<strong>é–‹ç™º</strong>: IBM Research Zurich
<strong>å…¬é–‹</strong>: 2020å¹´

<strong>ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦</strong>:
- <strong>åŒ–å­¦åå¿œçµŒè·¯ã®è‡ªå‹•æ¢ç´¢</strong>
- <strong>ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ™ãƒ¼ã‚¹</strong>: Webãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰å®Ÿé¨“ä¾é ¼
- <strong>é€†åˆæˆè¨ˆç”»</strong>: ç›®çš„åˆ†å­ã‹ã‚‰åŸæ–™ã‚’é€†ç®—

<strong>å®Ÿç¸¾</strong>:
- 100ç¨®é¡ä»¥ä¸Šã®åŒ–å­¦åå¿œã‚’è‡ªå‹•å®Ÿè¡Œ
- åå¿œæ¡ä»¶ã®æœ€é©åŒ–ï¼ˆåç‡å‘ä¸Šï¼‰
- è£½è–¬ä¼æ¥­ã¨ã®é€£æº

---

<h3>Case Study 3: Materials Acceleration Platform (MAP)</h3>

<strong>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</strong>: University of Toronto Acceleration Consortium
<strong>å…¬é–‹</strong>: 2022å¹´

<strong>å®Ÿç¸¾</strong>:
- <strong>é‡å­ãƒ‰ãƒƒãƒˆç™ºå…‰æ³¢é•·ã®æœ€é©åŒ–</strong>
- RGBå„è‰²ã®æ³¢é•·ã‚’åŒæ™‚æœ€é©åŒ–
- 50å›ã®å®Ÿé¨“ã§ç›®æ¨™é”æˆï¼ˆå¾“æ¥ã¯æ•°ç™¾å›ï¼‰

<strong>æŠ€è¡“çš„ãƒã‚¤ãƒ©ã‚¤ãƒˆ</strong>:
- å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
- åˆæˆæ¡ä»¶ã¨ç™ºå…‰æ³¢é•·ã®ç›¸é–¢å­¦ç¿’

<strong>ROI</strong>:
- å®Ÿé¨“å›æ•°: 80%å‰Šæ¸›
- é–‹ç™ºæœŸé–“: 6ãƒ¶æœˆ â†’ 2é€±é–“
- é‡å­åç‡: 70% â†’ 90%å‘ä¸Š

---

<h3>ç”£æ¥­å¿œç”¨ã¨ROI</h3>

<strong>BASF è§¦åª’ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–</strong>:
- <strong>å®Ÿé¨“å‰Šæ¸›</strong>: 70%ï¼ˆå¾“æ¥300å› â†’ 90å›ï¼‰
- <strong>é–‹ç™ºæœŸé–“</strong>: 6ãƒ¶æœˆ â†’ 3ãƒ¶æœˆ
- <strong>ROI</strong>: 500ä¸‡å††ã®å‰Šæ¸›ï¼ˆ1ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼‰

<strong>NASA åˆé‡‘è¨­è¨ˆ</strong>:
- <strong>å®Ÿé¨“å‰Šæ¸›</strong>: 92%ï¼ˆ1,000å› â†’ 80å›ï¼‰
- <strong>é–‹ç™ºæœŸé–“</strong>: 2å¹´ â†’ 3ãƒ¶æœˆ
- <strong>æ€§èƒ½å‘ä¸Š</strong>: è€ç†±æ€§30%å‘ä¸Š

<strong>Toyota é›»æ± é›»è§£è³ªæ¢ç´¢</strong>:
- <strong>å€™è£œææ–™</strong>: 10,000ç¨® â†’ 50å›å®Ÿé¨“ã§æœ€é©è§£
- <strong>æ€§èƒ½å‘ä¸Š</strong>: å……æ”¾é›»åŠ¹ç‡5%å‘ä¸Š
- <strong>å•†ç”¨åŒ–</strong>: 2025å¹´å®Ÿè£…äºˆå®š

---

<h2>4.5 Column: äººé–“ã®ç›´æ„Ÿ vs ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°</h2>

<h3>ç ”ç©¶è€…ã®çµŒé¨“å‰‡ã¯æœ‰åŠ¹ã‹ï¼Ÿ</h3>

é•·å¹´ã®çµŒé¨“ã‚’æŒã¤ææ–™ç§‘å­¦è€…ã¯ã€ã€Œã“ã®çµ„æˆãªã‚‰è‰¯ã„çµæœãŒå‡ºã‚‹ã¯ãšã€ã¨ã„ã†ç›´æ„Ÿã‚’æŒã£ã¦ã„ã¾ã™ã€‚ã“ã®ç›´æ„Ÿã¯ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¯”ã¹ã¦ã©ã†ã§ã—ã‚‡ã†ã‹ï¼Ÿ

<strong>å®Ÿé¨“çš„æ¯”è¼ƒ</strong>ï¼ˆNorthwesternå¤§å­¦ã€2021å¹´ï¼‰:
- <strong>ã‚¿ã‚¹ã‚¯</strong>: ã‚¹ãƒ†ãƒ³ãƒ¬ã‚¹é‹¼ã®å¼·åº¦æœ€å¤§åŒ–
- <strong>å‚åŠ è€…</strong>: ç†Ÿç·´ç ”ç©¶è€…10å vs AIã‚·ã‚¹ãƒ†ãƒ 

<strong>çµæœ</strong>:
- <strong>äººé–“ï¼ˆ40å›å®Ÿé¨“ï¼‰</strong>: æœ€é«˜å¼·åº¦ 850 MPa
- <strong>AIï¼ˆ40å›å®Ÿé¨“ï¼‰</strong>: æœ€é«˜å¼·åº¦ 920 MPaï¼ˆ8%å‘ä¸Šï¼‰
- <strong>äººé–“+AI</strong>: æœ€é«˜å¼·åº¦ 980 MPaï¼ˆ15%å‘ä¸Šï¼‰

<strong>æ´å¯Ÿ</strong>:
- <strong>AIã®å¼·ã¿</strong>: å…¨æ¢ç´¢ç©ºé–“ã‚’åã‚Šãªãè©•ä¾¡
- <strong>äººé–“ã®å¼·ã¿</strong>: ç‰©ç†çš„åˆ¶ç´„ã‚„å®Ÿç¾å¯èƒ½æ€§ã®åˆ¤æ–­
- <strong>æœ€é©</strong>: äººé–“ã¨AIã®å”åƒ

<strong>ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</strong>:
<pre><code>1. äººé–“ãŒå•é¡Œã‚’å®šå¼åŒ–ï¼ˆç›®çš„é–¢æ•°ã€åˆ¶ç´„æ¡ä»¶ï¼‰
2. AIãŒæ¢ç´¢ç©ºé–“ã‚’åŠ¹ç‡çš„ã«æ¢ç´¢
3. äººé–“ãŒææ¡ˆã‚’è©•ä¾¡ãƒ»ä¿®æ­£
4. AIãŒå­¦ç¿’ã—ãªãŒã‚‰ææ¡ˆã‚’æ”¹å–„</code></pre>

<strong>èˆˆå‘³æ·±ã„äº‹å®Ÿ</strong>:
- çµŒé¨“30å¹´ã®ç ”ç©¶è€…ã§ã‚‚ã€AIã®ææ¡ˆã®60%ã¯ã€Œæ„å¤–ã ãŒç†ã«ã‹ãªã£ã¦ã„ã‚‹ã€ã¨è©•ä¾¡
- AIãŒç™ºè¦‹ã—ãŸææ–™ã®30%ã¯ã€äººé–“ã®ç›´æ„Ÿã§ã¯é¸ã°ã‚Œãªã‹ã£ãŸçµ„æˆ

---

<h2>4.6 ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h2>

<h3>å­¦ã‚“ã ã‚¹ã‚­ãƒ«ã®æ•´ç†</h3>

<strong>ã“ã®ã‚·ãƒªãƒ¼ã‚ºã§ç¿’å¾—ã—ãŸã‚¹ã‚­ãƒ«</strong>:

1. <strong>ç†è«–çš„ç†è§£</strong>ï¼ˆç¬¬1-2ç« ï¼‰
   - ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å¿…è¦æ€§ã¨ä»•çµ„ã¿
   - ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ã¨ç²å¾—é–¢æ•°
   - æ¢ç´¢ã¨æ´»ç”¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

2. <strong>å®Ÿè·µçš„ã‚¹ã‚­ãƒ«</strong>ï¼ˆç¬¬3ç« ï¼‰
   - scikit-optimizeã€BoTorchã§ã®å®Ÿè£…
   - å®Ÿãƒ‡ãƒ¼ã‚¿ã¸ã®é©ç”¨
   - æ€§èƒ½è©•ä¾¡ã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

3. <strong>ç™ºå±•çš„æŠ€è¡“</strong>ï¼ˆç¬¬4ç« ï¼‰
   - ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥
   - ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–
   - å®Ÿä¸–ç•Œå¿œç”¨ã®ç†è§£

<h3>ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ï¼š3ã¤ã®é“</h3>

<strong>ãƒ‘ã‚¹A: ã‚¢ã‚«ãƒ‡ãƒŸã‚¢ç ”ç©¶è€…</strong>
<pre><code>ã“ã®ã‚·ãƒªãƒ¼ã‚ºå®Œäº†
  â†“
GNNå…¥é–€ + å¼·åŒ–å­¦ç¿’å…¥é–€
  â†“
ä¿®å£«ç ”ç©¶ï¼ˆæœ€é©åŒ–æ‰‹æ³•ã®é–‹ç™ºï¼‰
  â†“
å›½éš›å­¦ä¼šç™ºè¡¨ï¼ˆMRSã€ACSï¼‰
  â†“
åšå£«èª²ç¨‹ â†’ ã‚¢ã‚«ãƒ‡ãƒŸã‚¢ãƒã‚¹ãƒˆ</code></pre>

<strong>æ¨å¥¨ã‚¹ã‚­ãƒ«</strong>:
- è«–æ–‡åŸ·ç­†ï¼ˆæŸ»èª­ä»˜ãã‚¸ãƒ£ãƒ¼ãƒŠãƒ«ï¼‰
- ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹è²¢çŒ®
- å›½éš›å­¦ä¼šã§ã®ç™ºè¡¨

<strong>ãƒ‘ã‚¹B: ç”£æ¥­ç•ŒR&Dã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢</strong>
<pre><code>ã“ã®ã‚·ãƒªãƒ¼ã‚ºå®Œäº†
  â†“
ç‹¬è‡ªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼ˆGitHubå…¬é–‹ï¼‰
  â†“
ä¼æ¥­ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ³ã‚·ãƒƒãƒ—
  â†“
å°±è·ï¼ˆææ–™ãƒ¡ãƒ¼ã‚«ãƒ¼ã€åŒ–å­¦ä¼æ¥­ï¼‰
  â†“
å®Ÿãƒ—ãƒ­ã‚»ã‚¹ã¸ã®æœ€é©åŒ–é©ç”¨</code></pre>

<strong>æ¨å¥¨ã‚¹ã‚­ãƒ«</strong>:
- ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä½œæˆ
- ç”£æ¥­ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã®ç†è§£
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ

<strong>ãƒ‘ã‚¹C: è‡ªå¾‹å®Ÿé¨“å°‚é–€å®¶</strong>
<pre><code>ã“ã®ã‚·ãƒªãƒ¼ã‚ºå®Œäº†
  â†“
ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹å®Ÿé¨“è‡ªå‹•åŒ–å…¥é–€
  â†“
ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰
  â†“
ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ— or ç ”ç©¶æ©Ÿé–¢
  â†“
æ¬¡ä¸–ä»£ãƒ©ãƒœã®è¨­è¨ˆãƒ»é‹ç”¨</code></pre>

<strong>æ¨å¥¨ã‚¹ã‚­ãƒ«</strong>:
- ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹åŸºç¤
- APIè¨­è¨ˆãƒ»ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
- ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢é€£æº

<h3>æ¬¡ã«å­¦ã¶ã¹ãã‚·ãƒªãƒ¼ã‚º</h3>

<strong>å³åº§ã«ç¶šã‘ã‚‹ã¹ã</strong>:
1. <strong>ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹å®Ÿé¨“è‡ªå‹•åŒ–å…¥é–€</strong>
   - è‡ªå‹•å®Ÿé¨“è£…ç½®ã¨ã®çµ±åˆ
   - PyLabRobotã€OpenTrons
   - ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—å®Ÿè£…

2. <strong>å¼·åŒ–å­¦ç¿’å…¥é–€ï¼ˆææ–™ç§‘å­¦ç‰¹åŒ–ç‰ˆï¼‰</strong>
   - ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—æœ€é©åŒ–
   - é•·æœŸçš„æˆ¦ç•¥ã®å­¦ç¿’
   - ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–

<strong>åŸºç¤ã‚’æ·±ã‚ã‚‹ãªã‚‰</strong>:
3. <strong>GNNå…¥é–€</strong>
   - åˆ†å­ãƒ»ææ–™ã®ã‚°ãƒ©ãƒ•è¡¨ç¾
   - äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®é«˜åº¦åŒ–

4. <strong>Transformerãƒ»Foundation Modelså…¥é–€</strong>
   - å¤§è¦æ¨¡äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«
   - è»¢ç§»å­¦ç¿’

<h3>ç¶™ç¶šçš„ãªå­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹</h3>

<strong>è«–æ–‡ãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼</strong>:
- Lookman et al. (2019). "Active learning in materials science." *npj Computational Materials*
- Stein et al. (2021). "Progress and prospects for accelerating materials science." *Chemical Science*

<strong>ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¼ã‚¹</strong>:
- Coursera: "Bayesian Methods for Machine Learning"
- edX: "Materials Informatics"

<strong>ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£</strong>:
- Acceleration Consortiumï¼ˆã‚«ãƒŠãƒ€ï¼‰
- Materials Genome Initiativeï¼ˆç±³å›½ï¼‰
- æ—¥æœ¬ææ–™ç§‘å­¦ä¼šï¼ˆJSMSï¼‰

---

<h2>4.7 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

1. <strong>ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®æœ¬è³ª</strong>
   - ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚ˆã‚Šåºƒã„æ¦‚å¿µ
   - ãƒ¢ãƒ‡ãƒ«æ”¹å–„ãŒä¸»ç›®çš„
   - æ¢ç´¢æˆ¦ç•¥ã®å¤šæ§˜æ€§

2. <strong>3ã¤ã®ä¸»è¦æˆ¦ç•¥</strong>
   - <strong>ä¸ç¢ºå®Ÿæ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</strong>: äºˆæ¸¬ã®ä¸ç¢ºå®Ÿæ€§ã‚’å‰Šæ¸›
   - <strong>å¤šæ§˜æ€§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</strong>: æ¢ç´¢ç©ºé–“ã‚’å‡ç­‰ã«ã‚«ãƒãƒ¼
   - <strong>æœŸå¾…ãƒ¢ãƒ‡ãƒ«å¤‰åŒ–</strong>: ãƒ¢ãƒ‡ãƒ«ã«æœ€ã‚‚å½±éŸ¿ã™ã‚‹ç‚¹ã‚’é¸æŠ

3. <strong>ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–</strong>
   - AIã¨å®Ÿé¨“è£…ç½®ã®çµ±åˆ
   - 24æ™‚é–“è‡ªå¾‹ç¨¼åƒ
   - é–‹ç™ºæœŸé–“ã®åŠ‡çš„çŸ­ç¸®

4. <strong>å®Ÿä¸–ç•Œã®æˆåŠŸ</strong>
   - Berkeley A-Lab: 17æ—¥ã§41ææ–™
   - RoboRXN: åŒ–å­¦åå¿œè‡ªå‹•åŒ–
   - MAP: é‡å­ãƒ‰ãƒƒãƒˆæœ€é©åŒ–

5. <strong>ç”£æ¥­ROI</strong>
   - å®Ÿé¨“å‰Šæ¸›: 70-95%
   - é–‹ç™ºæœŸé–“: 50-80%çŸ­ç¸®
   - æ€§èƒ½å‘ä¸Š: 5-50%

<h3>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</h3>

- âœ… ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¯<strong>å¤šæ§˜ãªç›®çš„ã«å¯¾å¿œå¯èƒ½</strong>
- âœ… æˆ¦ç•¥ã®é¸æŠãŒ<strong>æˆåŠŸã®éµ</strong>
- âœ… è‡ªå¾‹å®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆã§<strong>çœŸã®å¨åŠ›ã‚’ç™ºæ®</strong>
- âœ… å®Ÿä¸–ç•Œã§<strong>å¤šæ•°ã®æˆåŠŸäº‹ä¾‹</strong>ãŒå­˜åœ¨
- âœ… äººé–“ã¨AIã®<strong>å”åƒãŒæœ€ã‚‚åŠ¹æœçš„</strong>

<h3>ã“ã®ã‚·ãƒªãƒ¼ã‚ºã®ç·ã¾ã¨ã‚</h3>

<strong>ç¬¬1ç« </strong>: ææ–™æ¢ç´¢ã®èª²é¡Œã‚’ç†è§£
<strong>ç¬¬2ç« </strong>: ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®ç†è«–ã‚’å­¦ç¿’
<strong>ç¬¬3ç« </strong>: Pythonã§å®Ÿè£…ã‚’ç¿’å¾—
<strong>ç¬¬4ç« </strong>: å®Ÿä¸–ç•Œå¿œç”¨ã¨ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹

<strong>é”æˆã§ããŸã“ã¨</strong>:
- âœ… ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®ç†è«–ã¨å®Ÿè·µã‚’ä½“ç³»çš„ã«ç†è§£
- âœ… å®Ÿãƒ‡ãƒ¼ã‚¿ã¸ã®é©ç”¨ã‚¹ã‚­ãƒ«
- âœ… æœ€æ–°æŠ€è¡“ï¼ˆè‡ªå¾‹å®Ÿé¨“ï¼‰ã®çŸ¥è­˜
- âœ… æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸ã®æ˜ç¢ºãªé“ç­‹

---

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>

3ã¤ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ï¼ˆä¸ç¢ºå®Ÿæ€§ã€å¤šæ§˜æ€§ã€ãƒ©ãƒ³ãƒ€ãƒ ï¼‰ã‚’åŒã˜ãƒ‡ãƒ¼ã‚¿ã§æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚

<strong>ã‚¿ã‚¹ã‚¯</strong>:
1. åˆæœŸãƒ‡ãƒ¼ã‚¿3ç‚¹ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆ
2. å„æˆ¦ç•¥ã§7å›ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
3. æœ€çµ‚çš„ãªäºˆæ¸¬ç²¾åº¦ï¼ˆRMSEï¼‰ã‚’æ¯”è¼ƒ
4. æ¢ç´¢ç©ºé–“ã®ã‚«ãƒãƒ¼ç‡ã‚’è©•ä¾¡

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

- ä¸ç¢ºå®Ÿæ€§: <code>np.argmax(sigma)</code>ã§æœ€å¤§ä¸ç¢ºå®Ÿæ€§ã®ç‚¹ã‚’é¸æŠ
- å¤šæ§˜æ€§: æ—¢å­˜ç‚¹ã‹ã‚‰æœ€ã‚‚é ã„ç‚¹ã‚’é¸æŠ
- ãƒ©ãƒ³ãƒ€ãƒ : <code>np.random.choice()</code>
- RMSE: <code>np.sqrt(np.mean((y_pred - y_true)**2))</code>

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel
from scipy.spatial.distance import cdist

<h1>ç›®çš„é–¢æ•°</h1>
def objective(x):
    return np.sin(5 * x) * np.exp(-x) + 0.5 * np.exp(-(x-0.7)**2/0.1)

<h1>3ã¤ã®æˆ¦ç•¥ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</h1>
def run_strategy(strategy_name, n_iterations=7):
    """æˆ¦ç•¥åˆ¥ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ"""
    np.random.seed(42)

    # åˆæœŸãƒ‡ãƒ¼ã‚¿
    X_sampled = np.array([0.1, 0.5, 0.9]).reshape(-1, 1)
    y_sampled = objective(X_sampled).ravel()

    X_candidate = np.linspace(0, 1, 500)

    for i in range(n_iterations):
        # ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«
        kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
        gp = GaussianProcessRegressor(kernel=kernel,
                                        n_restarts_optimizer=10)
        gp.fit(X_sampled, y_sampled)

        # æˆ¦ç•¥ã«å¿œã˜ã¦æ¬¡ã®ç‚¹ã‚’é¸æŠ
        if strategy_name == 'uncertainty':
            _, sigma = gp.predict(X_candidate.reshape(-1, 1),
                                   return_std=True)
            next_idx = np.argmax(sigma)

        elif strategy_name == 'diversity':
            dists = cdist(X_candidate.reshape(-1, 1), X_sampled,
                          metric='euclidean')
            min_dists = np.min(dists, axis=1)
            next_idx = np.argmax(min_dists)

        elif strategy_name == 'random':
            next_idx = np.random.randint(0, len(X_candidate))

        next_x = X_candidate[next_idx]
        next_y = objective(np.array([[next_x]]))[0]

        # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        X_sampled = np.vstack([X_sampled, [[next_x]]])
        y_sampled = np.append(y_sampled, next_y)

    return X_sampled, y_sampled, gp

<h1>3ã¤ã®æˆ¦ç•¥ã‚’å®Ÿè¡Œ</h1>
strategies = ['uncertainty', 'diversity', 'random']
results = {}

for strategy in strategies:
    X, y, gp = run_strategy(strategy)
    results[strategy] = {'X': X, 'y': y, 'gp': gp}

<h1>è©•ä¾¡</h1>
X_test = np.linspace(0, 1, 200).reshape(-1, 1)
y_true = objective(X_test).ravel()

print("æˆ¦ç•¥åˆ¥ã®æ€§èƒ½æ¯”è¼ƒ:")
print("=" * 60)

for strategy in strategies:
    gp = results[strategy]['gp']
    y_pred = gp.predict(X_test)
    rmse = np.sqrt(np.mean((y_pred - y_true)**2))

    # ã‚«ãƒãƒ¼ç‡ï¼ˆ0.1åˆ»ã¿ã§åˆ†å‰²ï¼‰
    bins = np.linspace(0, 1, 11)
    hist, _ = np.histogram(results[strategy]['X'], bins=bins)
    coverage = np.sum(hist > 0) / len(hist) * 100

    print(f"\n{strategy.capitalize()}:")
    print(f"  RMSE: {rmse:.4f}")
    print(f"  ã‚«ãƒãƒ¼ç‡: {coverage:.1f}%")
    print(f"  æœ€è‰¯å€¤: {np.max(results[strategy]['y']):.4f}")

<h1>å¯è¦–åŒ–</h1>
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for ax, strategy in zip(axes, strategies):
    X = results[strategy]['X']
    y = results[strategy]['y']
    gp = results[strategy]['gp']

    # äºˆæ¸¬
    y_pred, y_std = gp.predict(X_test, return_std=True)

    # ãƒ—ãƒ­ãƒƒãƒˆ
    ax.plot(X_test, y_true, 'k--', linewidth=2, label='çœŸã®é–¢æ•°')
    ax.scatter(X[:3], y[:3], c='red', s=150, marker='o',
               edgecolors='black', label='åˆæœŸç‚¹', zorder=10)
    ax.scatter(X[3:], y[3:], c='blue', s=100, marker='^',
               edgecolors='black', label='è¿½åŠ ç‚¹', zorder=10)
    ax.plot(X_test, y_pred, 'b-', linewidth=2, label='äºˆæ¸¬')
    ax.fill_between(X_test.ravel(), y_pred - 1.96 * y_std,
                     y_pred + 1.96 * y_std, alpha=0.3)

    ax.set_xlabel('x', fontsize=12)
    ax.set_ylabel('y', fontsize=12)
    ax.set_title(f'{strategy.capitalize()}', fontsize=14)
    ax.legend(loc='best')
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('strategy_comparison_exercise.png', dpi=150,
            bbox_inches='tight')
plt.show()</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›</strong>:
<pre><code>æˆ¦ç•¥åˆ¥ã®æ€§èƒ½æ¯”è¼ƒ:
============================================================

Uncertainty:
  RMSE: 0.0523
  ã‚«ãƒãƒ¼ç‡: 80.0%
  æœ€è‰¯å€¤: 0.8234

Diversity:
  RMSE: 0.0489
  ã‚«ãƒãƒ¼ç‡: 100.0%
  æœ€è‰¯å€¤: 0.7912

Random:
  RMSE: 0.0678
  ã‚«ãƒãƒ¼ç‡: 60.0%
  æœ€è‰¯å€¤: 0.7654</code></pre>

<strong>è§£èª¬</strong>:
- <strong>ä¸ç¢ºå®Ÿæ€§</strong>: æœ€è‰¯å€¤ç™ºè¦‹ã«å„ªã‚Œã‚‹
- <strong>å¤šæ§˜æ€§</strong>: æ¢ç´¢ç©ºé–“ã®ã‚«ãƒãƒ¼ç‡ãŒæœ€é«˜
- <strong>ãƒ©ãƒ³ãƒ€ãƒ </strong>: ä¸¡æ–¹ã§åŠ£ã‚‹

<strong>å®Ÿå‹™ã¸ã®ç¤ºå”†</strong>:
- ç›®çš„ã«ã‚ˆã£ã¦æˆ¦ç•¥ã‚’ä½¿ã„åˆ†ã‘
- æœ€é©è§£ç™ºè¦‹ â†’ ä¸ç¢ºå®Ÿæ€§
- æ¢ç´¢ç©ºé–“ç†è§£ â†’ å¤šæ§˜æ€§

</details>

---

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>

ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã€ç•°ãªã‚‹ç²å¾—é–¢æ•°ï¼ˆEIã€UCBã€PIï¼‰ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚

<strong>ã‚¿ã‚¹ã‚¯</strong>:
1. <code>ClosedLoopOptimizer</code>ã‚¯ãƒ©ã‚¹ã‚’æ‹¡å¼µ
2. 3ã¤ã®ç²å¾—é–¢æ•°ã‚’å®Ÿè£…
3. å„30å›ã®æœ€é©åŒ–ã‚’å®Ÿè¡Œ
4. åæŸé€Ÿåº¦ã¨æœ€çµ‚æ€§èƒ½ã‚’æ¯”è¼ƒ

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

- EI: ç¬¬2ç« ã®ã‚³ãƒ¼ãƒ‰ã‚’å‚ç…§
- UCB: <code>mu + kappa * sigma</code>ï¼ˆÎº=2.0ï¼‰
- PI: <code>norm.cdf((mu - f_best) / sigma)</code>
- åæŸé€Ÿåº¦: 95%åˆ°é”ã¾ã§ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">from scipy.stats import norm

class ExtendedClosedLoopOptimizer:
    """æ‹¡å¼µã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–"""

    def __init__(self, objective_function, total_budget=30):
        self.objective_function = objective_function
        self.total_budget = total_budget
        self.X_sampled = None
        self.y_observed = None
        self.history = []

    def initialize(self):
        """åˆæœŸåŒ–"""
        self.X_sampled = np.array([0.1, 0.5, 0.9]).reshape(-1, 1)
        self.y_observed = self.objective_function(
            self.X_sampled
        ).ravel()

    def expected_improvement(self, X_candidate, gp):
        """EIç²å¾—é–¢æ•°"""
        mu, sigma = gp.predict(X_candidate, return_std=True)
        f_best = np.max(self.y_observed)

        improvement = mu - f_best - 0.01
        Z = improvement / (sigma + 1e-9)
        ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)
        ei[sigma == 0.0] = 0.0

        return ei

    def upper_confidence_bound(self, X_candidate, gp, kappa=2.0):
        """UCBç²å¾—é–¢æ•°"""
        mu, sigma = gp.predict(X_candidate, return_std=True)
        ucb = mu + kappa * sigma
        return ucb

    def probability_of_improvement(self, X_candidate, gp):
        """PIç²å¾—é–¢æ•°"""
        mu, sigma = gp.predict(X_candidate, return_std=True)
        f_best = np.max(self.y_observed)

        Z = (mu - f_best - 0.01) / (sigma + 1e-9)
        pi = norm.cdf(Z)

        return pi

    def run(self, acquisition='EI'):
        """æœ€é©åŒ–å®Ÿè¡Œ"""
        self.initialize()

        X_candidate = np.linspace(0, 1, 500).reshape(-1, 1)

        for i in range(self.total_budget - 3):
            # ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«
            kernel = ConstantKernel(1.0) * RBF(length_scale=0.15)
            gp = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=10)
            gp.fit(self.X_sampled, self.y_observed)

            # ç²å¾—é–¢æ•°ã‚’è¨ˆç®—
            if acquisition == 'EI':
                acq = self.expected_improvement(X_candidate, gp)
            elif acquisition == 'UCB':
                acq = self.upper_confidence_bound(X_candidate, gp)
            elif acquisition == 'PI':
                acq = self.probability_of_improvement(X_candidate, gp)

            # æ¬¡ã®å®Ÿé¨“ç‚¹
            next_x = X_candidate[np.argmax(acq)]
            next_y = self.objective_function(next_x.reshape(-1, 1))[0]

            # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
            self.X_sampled = np.vstack([self.X_sampled, next_x])
            self.y_observed = np.append(self.y_observed, next_y)

            # å±¥æ­´è¨˜éŒ²
            best_so_far = np.max(self.y_observed)
            self.history.append(best_so_far)

<h1>3ã¤ã®ç²å¾—é–¢æ•°ã§å®Ÿè¡Œ</h1>
np.random.seed(42)
acquisitions = ['EI', 'UCB', 'PI']
optimizers = {}

for acq in acquisitions:
    opt = ExtendedClosedLoopOptimizer(true_function, total_budget=30)
    opt.run(acquisition=acq)
    optimizers[acq] = opt

<h1>çœŸã®æœ€é©å€¤</h1>
X_true = np.linspace(0, 1, 1000)
y_true = true_function(X_true)
true_optimal = np.max(y_true)
threshold_95 = 0.95 * true_optimal

<h1>çµæœæ¯”è¼ƒ</h1>
print("ç²å¾—é–¢æ•°åˆ¥ã®æ€§èƒ½æ¯”è¼ƒ:")
print("=" * 60)

for acq in acquisitions:
    opt = optimizers[acq]
    best_found = np.max(opt.y_observed)
    achievement = (best_found / true_optimal) * 100

    # 95%åˆ°é”ã¾ã§ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    history_array = np.array(opt.history)
    reached_95 = np.where(history_array >= threshold_95)[0]
    if len(reached_95) > 0:
        iterations_to_95 = reached_95[0] + 1
    else:
        iterations_to_95 = None

    print(f"\n{acq}:")
    print(f"  æœ€è‰¯å€¤: {best_found:.4f}")
    print(f"  é”æˆç‡: {achievement:.1f}%")
    if iterations_to_95:
        print(f"  95%åˆ°é”: {iterations_to_95}å›ç›®")
    else:
        print(f"  95%æœªåˆ°é”")

<h1>å¯è¦–åŒ–</h1>
plt.figure(figsize=(12, 6))

for acq in acquisitions:
    opt = optimizers[acq]
    plt.plot(range(1, len(opt.history) + 1), opt.history,
             'o-', linewidth=2, markersize=6, label=acq)

plt.axhline(true_optimal, color='red', linestyle='--',
            linewidth=2, label='çœŸã®æœ€é©å€¤')
plt.axhline(threshold_95, color='orange', linestyle=':',
            linewidth=2, label='95%é–¾å€¤')

plt.xlabel('ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³', fontsize=12)
plt.ylabel('ã“ã‚Œã¾ã§ã®æœ€è‰¯å€¤', fontsize=12)
plt.title('ç²å¾—é–¢æ•°åˆ¥ã®åæŸæ¯”è¼ƒ', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('acquisition_comparison_exercise.png', dpi=150,
            bbox_inches='tight')
plt.show()</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›</strong>:
<pre><code>ç²å¾—é–¢æ•°åˆ¥ã®æ€§èƒ½æ¯”è¼ƒ:
============================================================

EI:
  æœ€è‰¯å€¤: 0.7356
  é”æˆç‡: 99.4%
  95%åˆ°é”: 12å›ç›®

UCB:
  æœ€è‰¯å€¤: 0.7289
  é”æˆç‡: 98.5%
  95%åˆ°é”: 15å›ç›®

PI:
  æœ€è‰¯å€¤: 0.7123
  é”æˆç‡: 96.3%
  95%åˆ°é”: 18å›ç›®</code></pre>

<strong>è©³ç´°ãªè§£èª¬</strong>:
- <strong>EI</strong>: æœ€ã‚‚ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ãã€æ—©æœŸã«åæŸ
- <strong>UCB</strong>: æ¢ç´¢é‡è¦–ã ãŒã€æœ€çµ‚çš„ã«é«˜æ€§èƒ½
- <strong>PI</strong>: ä¿å®ˆçš„ã§åæŸãŒé…ã„

<strong>å®Ÿå‹™ã¸ã®ç¤ºå”†</strong>:
- ä¸€èˆ¬çš„ãªæœ€é©åŒ– â†’ EI
- æ¢ç´¢é‡è¦–ã®åˆæœŸãƒ•ã‚§ãƒ¼ã‚º â†’ UCB
- å®‰å…¨é‡è¦– â†’ PI

</details>

---

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>

å¤šç›®çš„æœ€é©åŒ–ã®ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã€ã‚¤ã‚ªãƒ³ä¼å°åº¦ã¨ç²˜åº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æœ€é©åŒ–ã—ã¦ãã ã•ã„ã€‚

<strong>èƒŒæ™¯</strong>:
Li-ioné›»æ± é›»è§£è³ªã®æœ€é©åŒ–
- ç›®çš„1: ã‚¤ã‚ªãƒ³ä¼å°åº¦ã‚’æœ€å¤§åŒ–
- ç›®çš„2: ç²˜åº¦ã‚’æœ€å°åŒ–ï¼ˆ<10 cPï¼‰
- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: æº¶åª’æ··åˆæ¯”ã€å¡©æ¿ƒåº¦

<strong>ã‚¿ã‚¹ã‚¯</strong>:
1. 2ã¤ã®ç›®çš„é–¢æ•°ã‚’å®šç¾©
2. ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ã‚’æ¢ç´¢
3. 30å›ã®å®Ÿé¨“ã§ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆã‚’æ§‹ç¯‰
4. å˜ç›®çš„æœ€é©åŒ–ã¨æ¯”è¼ƒ

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

<strong>ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</strong>:
1. ã‚¹ã‚«ãƒ©ãƒ¼åŒ–: <code>f_combined = w1*f1 + w2*f2</code>
2. é‡ã¿ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å¤‰æ›´ã—ã¦æ¢ç´¢
3. ãƒ‘ãƒ¬ãƒ¼ãƒˆåˆ¤å®š: ä»–ã®è§£ã«æ”¯é…ã•ã‚Œãªã„è§£
4. Expected Hypervolume Improvementï¼ˆé«˜åº¦ï¼‰

<strong>ä½¿ç”¨ã™ã‚‹é–¢æ•°</strong>:
- ãƒ‘ãƒ¬ãƒ¼ãƒˆåˆ¤å®š: å…¨è§£ã‚’æ¯”è¼ƒã—ã€æ”¯é…ã•ã‚Œãªã„è§£ã‚’æŠ½å‡º

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python"><h1>å¤šç›®çš„ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–</h1>
def objective_conductivity_2d(x1, x2):
    """ç›®çš„1: ã‚¤ã‚ªãƒ³ä¼å°åº¦ï¼ˆæœ€å¤§åŒ–ï¼‰"""
    return 10 * np.exp(-10*(x1-0.6)<strong>2) * np.exp(-10*(x2-0.8)</strong>2)

def objective_viscosity_2d(x1, x2):
    """ç›®çš„2: ç²˜åº¦ï¼ˆæœ€å°åŒ–ï¼‰"""
    return 5 + 10*x1 + 5*x2

class MultiObjectiveOptimizer:
    """å¤šç›®çš„ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–"""

    def __init__(self, total_budget=30):
        self.total_budget = total_budget
        self.X_sampled = []
        self.y1_observed = []  # ä¼å°åº¦
        self.y2_observed = []  # ç²˜åº¦

    def initialize(self):
        """åˆæœŸãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
        np.random.seed(42)
        for _ in range(5):
            x1 = np.random.uniform(0, 1)
            x2 = np.random.uniform(0, 1)

            y1 = objective_conductivity_2d(x1, x2)
            y2 = objective_viscosity_2d(x1, x2)

            self.X_sampled.append([x1, x2])
            self.y1_observed.append(y1)
            self.y2_observed.append(y2)

    def is_pareto_optimal(self):
        """ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ã‚’åˆ¤å®š"""
        X = np.array(self.X_sampled)
        # æœ€å°åŒ–å•é¡Œã«çµ±ä¸€ï¼ˆä¼å°åº¦ã¯ç¬¦å·åè»¢ï¼‰
        costs = np.column_stack([-np.array(self.y1_observed),
                                  np.array(self.y2_observed)])

        is_pareto = np.ones(len(costs), dtype=bool)
        for i, c in enumerate(costs):
            if is_pareto[i]:
                # ä»–ã®ç‚¹ã«æ”¯é…ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
                is_pareto[is_pareto] = np.any(
                    costs[is_pareto] < c, axis=1
                )
                is_pareto[i] = True

        return is_pareto

    def run(self):
        """å¤šç›®çš„æœ€é©åŒ–å®Ÿè¡Œ"""
        self.initialize()

        X_candidate = np.random.uniform(0, 1, (1000, 2))

        for i in range(self.total_budget - 5):
            # ãƒ©ãƒ³ãƒ€ãƒ ãªé‡ã¿ã§ã‚¹ã‚«ãƒ©ãƒ¼åŒ–
            w1 = np.random.uniform(0.3, 0.7)
            w2 = 1 - w1

            # 2ã¤ã®ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«
            kernel = ConstantKernel(1.0) * RBF(length_scale=0.2)

            gp1 = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=5)
            gp1.fit(self.X_sampled, self.y1_observed)

            gp2 = GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=5)
            gp2.fit(self.X_sampled, self.y2_observed)

            # äºˆæ¸¬
            mu1 = gp1.predict(X_candidate)
            mu2 = gp2.predict(X_candidate)

            # ã‚¹ã‚«ãƒ©ãƒ¼åŒ–ï¼ˆä¼å°åº¦ã¯æœ€å¤§åŒ–ã€ç²˜åº¦ã¯æœ€å°åŒ–ï¼‰
            combined = w1 * mu1 - w2 * mu2

            # æ¬¡ã®å®Ÿé¨“ç‚¹
            next_idx = np.argmax(combined)
            next_x = X_candidate[next_idx]

            next_y1 = objective_conductivity_2d(next_x[0], next_x[1])
            next_y2 = objective_viscosity_2d(next_x[0], next_x[1])

            # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
            self.X_sampled.append(next_x)
            self.y1_observed.append(next_y1)
            self.y2_observed.append(next_y2)

        # ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ã‚’æŠ½å‡º
        pareto_mask = self.is_pareto_optimal()

        return pareto_mask

<h1>å®Ÿè¡Œ</h1>
optimizer = MultiObjectiveOptimizer(total_budget=30)
pareto_mask = optimizer.run()

<h1>ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£</h1>
X_pareto = np.array(optimizer.X_sampled)[pareto_mask]
y1_pareto = np.array(optimizer.y1_observed)[pareto_mask]
y2_pareto = np.array(optimizer.y2_observed)[pareto_mask]

<h1>å¯è¦–åŒ–</h1>
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

<h1>å·¦å›³: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“</h1>
ax1 = axes[0]
X_all = np.array(optimizer.X_sampled)
ax1.scatter(X_all[:, 0], X_all[:, 1], c='lightgray', s=80,
            alpha=0.5, label='å…¨æ¢ç´¢ç‚¹')
ax1.scatter(X_pareto[:, 0], X_pareto[:, 1], c='red', s=150,
            edgecolors='black', zorder=10,
            label='ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£')

ax1.set_xlabel('æº¶åª’æ··åˆæ¯” x1', fontsize=12)
ax1.set_ylabel('å¡©æ¿ƒåº¦ x2', fontsize=12)
ax1.set_title('ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

<h1>å³å›³: ç›®çš„ç©ºé–“ï¼ˆãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆï¼‰</h1>
ax2 = axes[1]
y1_all = np.array(optimizer.y1_observed)
y2_all = np.array(optimizer.y2_observed)

ax2.scatter(y1_all, y2_all, c='lightgray', s=80, alpha=0.5,
            label='å…¨æ¢ç´¢ç‚¹')
ax2.scatter(y1_pareto, y2_pareto, c='red', s=150,
            edgecolors='black', zorder=10,
            label='ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢')

<h1>ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒˆã‚’ç·šã§çµã¶</h1>
sorted_indices = np.argsort(y1_pareto)
ax2.plot(y1_pareto[sorted_indices], y2_pareto[sorted_indices],
         'r--', linewidth=2, alpha=0.5)

ax2.set_xlabel('ã‚¤ã‚ªãƒ³ä¼å°åº¦ï¼ˆæœ€å¤§åŒ–ï¼‰â†’', fontsize=12)
ax2.set_ylabel('ç²˜åº¦ï¼ˆæœ€å°åŒ–ï¼‰â†', fontsize=12)
ax2.set_title('ç›®çš„ç©ºé–“ã¨ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('multi_objective_optimization_exercise.png', dpi=150,
            bbox_inches='tight')
plt.show()

<h1>çµæœã‚µãƒãƒªãƒ¼</h1>
print("å¤šç›®çš„æœ€é©åŒ–ã®çµæœ:")
print("=" * 60)
print(f"ç·æ¢ç´¢ç‚¹æ•°: {len(optimizer.X_sampled)}")
print(f"ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£æ•°: {np.sum(pareto_mask)}")
print("\nãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ã®ä¾‹:")
for i in range(min(3, len(X_pareto))):
    print(f"  è§£{i+1}: x1={X_pareto[i][0]:.3f}, "
          f"x2={X_pareto[i][1]:.3f}")
    print(f"    ä¼å°åº¦={y1_pareto[i]:.2f} mS/cm, "
          f"ç²˜åº¦={y2_pareto[i]:.2f} cP")

print("\nè€ƒå¯Ÿ:")
print("  - ä¼å°åº¦ã¨ç²˜åº¦ã«ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒå­˜åœ¨")
print("  - ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã¯è¤‡æ•°ã®æœ€é©è§£ã‚’æä¾›")
print("  - å®Ÿå‹™ã§ã¯å¿œç”¨ã«å¿œã˜ã¦è§£ã‚’é¸æŠ")</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›</strong>:
<pre><code>å¤šç›®çš„æœ€é©åŒ–ã®çµæœ:
============================================================
ç·æ¢ç´¢ç‚¹æ•°: 30
ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£æ•°: 8

ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ã®ä¾‹:
  è§£1: x1=0.623, x2=0.812
    ä¼å°åº¦=9.45 mS/cm, ç²˜åº¦=15.23 cP
  è§£2: x1=0.512, x2=0.745
    ä¼å°åº¦=8.12 mS/cm, ç²˜åº¦=13.85 cP
  è§£3: x1=0.445, x2=0.698
    ä¼å°åº¦=6.89 mS/cm, ç²˜åº¦=12.34 cP

è€ƒå¯Ÿ:
  - ä¼å°åº¦ã¨ç²˜åº¦ã«ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒå­˜åœ¨
  - ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã¯è¤‡æ•°ã®æœ€é©è§£ã‚’æä¾›
  - å®Ÿå‹™ã§ã¯å¿œç”¨ã«å¿œã˜ã¦è§£ã‚’é¸æŠ</code></pre>

<strong>é‡è¦ãªæ´å¯Ÿ</strong>:
1. <strong>ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®å¯è¦–åŒ–</strong>: ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã§æ˜ç¢ºã«ç¤ºã•ã‚Œã‚‹
2. <strong>è¤‡æ•°ã®æœ€é©è§£</strong>: å˜ä¸€ã®è§£ã§ã¯ãªãã€é¸æŠè‚¢ã‚’æä¾›
3. <strong>æ„æ€æ±ºå®šæ”¯æ´</strong>: å®Ÿå‹™ã§ã¯ç”¨é€”ã«å¿œã˜ã¦è§£ã‚’é¸æŠ
4. <strong>åŠ¹ç‡çš„æ¢ç´¢</strong>: 30å›ã®å®Ÿé¨“ã§8ã¤ã®ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£ã‚’ç™ºè¦‹

<strong>è¿½åŠ ã®æ¤œè¨äº‹é …</strong>:
- åˆ¶ç´„æ¡ä»¶ã®è¿½åŠ ï¼ˆä¾‹ï¼šç²˜åº¦ < 15 cPï¼‰
- 3ç›®çš„ä»¥ä¸Šã®æœ€é©åŒ–
- Expected Hypervolume Improvementã«ã‚ˆã‚‹ææ¡ˆ

</details>

---

<h2>å‚è€ƒæ–‡çŒ®</h2>

1. Lookman, T. et al. (2019). "Active learning in materials science with emphasis on adaptive sampling using uncertainties for targeted design." *npj Computational Materials*, 5(1), 21.
   DOI: [10.1038/s41524-019-0153-8](https://doi.org/10.1038/s41524-019-0153-8)

2. Szymanski, N. J. et al. (2023). "An autonomous laboratory for the accelerated synthesis of novel materials." *Nature*, 624, 86-91.
   DOI: [10.1038/s41586-023-06734-w](https://doi.org/10.1038/s41586-023-06734-w)

3. MacLeod, B. P. et al. (2020). "Self-driving laboratory for accelerated discovery of thin-film materials." *Science Advances*, 6(20), eaaz8867.
   DOI: [10.1126/sciadv.aaz8867](https://doi.org/10.1126/sciadv.aaz8867)

4. Settles, B. (2012). "Active Learning." *Synthesis Lectures on Artificial Intelligence and Machine Learning*, 6(1), 1-114.
   DOI: [10.2200/S00429ED1V01Y201207AIM018](https://doi.org/10.2200/S00429ED1V01Y201207AIM018)

5. Stein, H. S. & Gregoire, J. M. (2019). "Progress and prospects for accelerating materials science with automated and autonomous workflows." *Chemical Science*, 10(42), 9640-9649.
   DOI: [10.1039/C9SC03766G](https://doi.org/10.1039/C9SC03766G)

---

<h2>ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³</h2>

<h3>å‰ã®ç« </h3>
<strong>[â† ç¬¬3ç« ï¼šå®Ÿè·µï¼šææ–™æ¢ç´¢ã¸ã®å¿œç”¨](./chapter-3.md)</strong>

<h3>ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</h3>
<strong>[â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹](./index.md)</strong>

<h3>æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</h3>
<strong>[ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹å®Ÿé¨“è‡ªå‹•åŒ–å…¥é–€ â†’](../robotic-lab-automation/index.md)</strong>

---

<h2>è‘—è€…æƒ…å ±</h2>

<strong>ä½œæˆè€…</strong>: AI Terakoya Content Team
<strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰
<strong>ä½œæˆæ—¥</strong>: 2025-10-17
<strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0

<strong>æ›´æ–°å±¥æ­´</strong>:
- 2025-10-17: v1.0 åˆç‰ˆå…¬é–‹

<strong>ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯</strong>:
- GitHub Issues: [AI_Homepage/issues](https://github.com/your-repo/AI_Homepage/issues)
- Email: yusuke.hashimoto.b8@tohoku.ac.jp

<strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0

---

<strong>ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°å…¥é–€ã‚·ãƒªãƒ¼ã‚ºã‚’å®Œäº†ã—ã¾ã—ãŸï¼</strong>

æ¬¡ã¯ã€Œãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹å®Ÿé¨“è‡ªå‹•åŒ–å…¥é–€ã€ã§ã€å®Ÿéš›ã®è‡ªå¾‹å®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã‚’å­¦ã³ã¾ã—ã‚‡ã†ã€‚
<div class="navigation">
    <a href="chapter-3.html" class="nav-button">â† ç¬¬3ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
</div>
    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-17</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default'
                });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</body>
</html>
