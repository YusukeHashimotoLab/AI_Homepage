<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬3ç« ï¼šå®Ÿè·µï¼šææ–™æ¢ç´¢ã¸ã®å¿œç”¨ - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ç¬¬3ç« ï¼šå®Ÿè·µï¼šææ–™æ¢ç´¢ã¸ã®å¿œç”¨</h1>
            <p class="subtitle">Pythonå®Ÿè£…ã§å­¦ã¶å®Ÿä¸–ç•Œã®ææ–™æœ€é©åŒ–</p>
            <div class="meta">
                <span class="meta-item">ğŸ“– èª­äº†æ™‚é–“: 25-30åˆ†</span>
                <span class="meta-item">ğŸ“Š é›£æ˜“åº¦: ä¸­ç´š</span>
                <span class="meta-item">ğŸ’» ã‚³ãƒ¼ãƒ‰ä¾‹: 12å€‹</span>
                <span class="meta-item">ğŸ“ æ¼”ç¿’å•é¡Œ: 3å•</span>
            </div>
        </div>
    </header>

    <main class="container">

<h1>ç¬¬3ç« ï¼šå®Ÿè·µï¼šææ–™æ¢ç´¢ã¸ã®å¿œç”¨</h1>

<strong>Pythonå®Ÿè£…ã§å­¦ã¶å®Ÿä¸–ç•Œã®ææ–™æœ€é©åŒ–</strong>

<h2>å­¦ç¿’ç›®æ¨™</h2>

ã“ã®ç« ã‚’èª­ã‚€ã“ã¨ã§ã€ä»¥ä¸‹ã‚’ç¿’å¾—ã§ãã¾ã™ï¼š

- âœ… ææ–™ç‰©æ€§äºˆæ¸¬MLãƒ¢ãƒ‡ãƒ«ã¨ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’çµ±åˆã§ãã‚‹
- âœ… åˆ¶ç´„ä»˜ãæœ€é©åŒ–ã‚’å®Ÿè£…ã—ã€ææ–™ã®å®Ÿç¾å¯èƒ½æ€§ã‚’è€ƒæ…®ã§ãã‚‹
- âœ… å¤šç›®çš„æœ€é©åŒ–ã§Paretoæœ€é©è§£ã‚’è¨ˆç®—ã§ãã‚‹
- âœ… å®Ÿé¨“ã‚³ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸãƒãƒƒãƒãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’å®Ÿè£…ã§ãã‚‹
- âœ… å®Ÿä¸–ç•Œã®Li-ioné›»æ± æœ€é©åŒ–å•é¡Œã‚’è§£æ±ºã§ãã‚‹

<strong>èª­äº†æ™‚é–“</strong>: 25-30åˆ†
<strong>ã‚³ãƒ¼ãƒ‰ä¾‹</strong>: 12å€‹
<strong>æ¼”ç¿’å•é¡Œ</strong>: 3å•

---

<h2>3.1 ææ–™ç‰©æ€§äºˆæ¸¬MLãƒ¢ãƒ‡ãƒ«ã¨ã®çµ±åˆ</h2>

<h3>ãªãœMLãƒ¢ãƒ‡ãƒ«ã¨çµ±åˆã™ã‚‹ã®ã‹</h3>

ææ–™æ¢ç´¢ã§ã¯ã€ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«çµ„ã¿åˆã‚ã›ã¾ã™ï¼š

1. <strong>æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰MLãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰</strong>
   - Materials Projectãªã©å…¬é–‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
   - éå»ã®å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿
   - DFTè¨ˆç®—çµæœ

2. <strong>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§æ–°è¦ææ–™æ¢ç´¢</strong>
   - MLãƒ¢ãƒ‡ãƒ«ã‚’ç›®çš„é–¢æ•°ã¨ã—ã¦ä½¿ç”¨
   - å®Ÿé¨“å›æ•°ã‚’æœ€å°åŒ–
   - ä¸ç¢ºå®Ÿæ€§ã‚’æ´»ç”¨

<h3>Materials Project APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—</h3>

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹1: Materials Projectã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—</strong>

<pre><code class="language-python"><h1>Materials Projectã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—</h1>
<h1>æ³¨: mp-api ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦: pip install mp-api</h1>
from mp_api.client import MPRester
import pandas as pd
import numpy as np

<h1>Materials Project APIã®ä½¿ç”¨ï¼ˆAPIã‚­ãƒ¼å¿…è¦ï¼‰</h1>
<h1>ç™»éŒ²: https://materialsproject.org/api</h1>
API_KEY = "YOUR_API_KEY_HERE"  # å®Ÿéš›ã®APIã‚­ãƒ¼ã«ç½®ãæ›ãˆ

def fetch_battery_materials(api_key, max_materials=100):
    """
    Li-ioné›»æ± æ­£æ¥µææ–™ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

    Parameters:
    -----------
    api_key : str
        Materials Project APIã‚­ãƒ¼
    max_materials : int
        å–å¾—ã™ã‚‹ææ–™ã®æœ€å¤§æ•°

    Returns:
    --------
    df : DataFrame
        ææ–™ç‰¹æ€§ãƒ‡ãƒ¼ã‚¿
    """
    with MPRester(api_key) as mpr:
        # Liå«æœ‰é…¸åŒ–ç‰©ã‚’æ¤œç´¢
        docs = mpr.summary.search(
            elements=["Li", "O"],  # Li ã¨ O ã‚’å«ã‚€
            num_elements=(3, 5),    # 3-5å…ƒç´ ç³»
            fields=[
                "material_id",
                "formula_pretty",
                "formation_energy_per_atom",
                "band_gap",
                "density",
                "volume"
            ]
        )

        # DataFrameã«å¤‰æ›
        data = []
        for doc in docs[:max_materials]:
            data.append({
                'material_id': doc.material_id,
                'formula': doc.formula_pretty,
                'formation_energy': doc.formation_energy_per_atom,
                'band_gap': doc.band_gap,
                'density': doc.density,
                'volume': doc.volume
            })

        df = pd.DataFrame(data)
        return df

<h1>ãƒ‡ãƒ¢ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆAPIã‚­ãƒ¼ãŒãªã„å ´åˆï¼‰</h1>
def generate_dummy_battery_data(n_samples=100):
    """
    ãƒ€ãƒŸãƒ¼ã®Li-ioné›»æ± ææ–™ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ

    Parameters:
    -----------
    n_samples : int
        ã‚µãƒ³ãƒ—ãƒ«æ•°

    Returns:
    --------
    df : DataFrame
        ææ–™ç‰¹æ€§ãƒ‡ãƒ¼ã‚¿
    """
    np.random.seed(42)

    # çµ„æˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ­£è¦åŒ–ï¼‰
    li_content = np.random.uniform(0.1, 0.5, n_samples)
    ni_content = np.random.uniform(0.1, 0.4, n_samples)
    co_content = np.random.uniform(0.1, 0.4, n_samples)
    mn_content = 1.0 - li_content - ni_content - co_content

    # å®¹é‡ï¼ˆmAh/gï¼‰: Liå«é‡ã¨ç›¸é–¢
    capacity = (
        150 + 200 * li_content +
        50 * ni_content +
        30 * np.random.randn(n_samples)
    )

    # é›»åœ§ï¼ˆVï¼‰: Coå«é‡ã¨ç›¸é–¢
    voltage = (
        3.0 + 1.5 * co_content +
        0.2 * np.random.randn(n_samples)
    )

    # å®‰å®šæ€§ï¼ˆformation energyï¼‰: è² ãŒå®‰å®š
    stability = (
        -2.0 - 0.5 * li_content -
        0.3 * ni_content +
        0.1 * np.random.randn(n_samples)
    )

    df = pd.DataFrame({
        'li_content': li_content,
        'ni_content': ni_content,
        'co_content': co_content,
        'mn_content': mn_content,
        'capacity': capacity,
        'voltage': voltage,
        'stability': stability
    })

    return df

<h1>ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰</h1>
df_materials = generate_dummy_battery_data(n_samples=150)

print("ææ–™ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ:")
print(df_materials.describe())
print(f"\nãƒ‡ãƒ¼ã‚¿ã‚·ã‚§ã‚¤ãƒ—: {df_materials.shape}")</code></pre>

<strong>å‡ºåŠ›</strong>:
<pre><code>ææ–™ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ:
       li_content  ni_content  co_content  mn_content    capacity  \
count  150.000000  150.000000  150.000000  150.000000  150.000000
mean     0.299524    0.249336    0.249821    0.201319  208.964738
std      0.116176    0.085721    0.083957    0.122841   38.259483
min      0.102543    0.101189    0.103524   -0.107479  137.582916
max      0.499765    0.399915    0.398774    0.499304  311.495867

         voltage   stability
count  150.000000  150.000000
mean     3.374732   -2.161276
std      0.285945    0.221438
min      2.762894   -2.774301
max      4.137882   -1.554217

ãƒ‡ãƒ¼ã‚¿ã‚·ã‚§ã‚¤ãƒ—: (150, 7)</code></pre>

---

<h3>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ç‰©æ€§äºˆæ¸¬</h3>

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹2: Random Forestã§å®¹é‡äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰</strong>

<pre><code class="language-python"><h1>Random Forestã§å®¹é‡äºˆæ¸¬</h1>
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

<h1>ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ</h1>
X = df_materials[['li_content', 'ni_content',
                   'co_content', 'mn_content']].values
y_capacity = df_materials['capacity'].values
y_voltage = df_materials['voltage'].values
y_stability = df_materials['stability'].values

<h1>ãƒ‡ãƒ¼ã‚¿åˆ†å‰²</h1>
X_train, X_test, y_train, y_test = train_test_split(
    X, y_capacity, test_size=0.2, random_state=42
)

<h1>Random Forestãƒ¢ãƒ‡ãƒ«</h1>
rf_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    random_state=42
)

<h1>è¨“ç·´</h1>
rf_model.fit(X_train, y_train)

<h1>äºˆæ¸¬</h1>
y_pred_train = rf_model.predict(X_train)
y_pred_test = rf_model.predict(X_test)

<h1>è©•ä¾¡</h1>
train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
test_r2 = r2_score(y_test, y_pred_test)

<h1>ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³</h1>
cv_scores = cross_val_score(
    rf_model, X_train, y_train,
    cv=5, scoring='r2'
)

print("Random Forestãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½:")
print(f"  è¨“ç·´RMSE: {train_rmse:.2f} mAh/g")
print(f"  ãƒ†ã‚¹ãƒˆRMSE: {test_rmse:.2f} mAh/g")
print(f"  ãƒ†ã‚¹ãƒˆRÂ²: {test_r2:.3f}")
print(f"  CV RÂ² (5-fold): {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}")

<h1>ç‰¹å¾´é‡é‡è¦åº¦</h1>
feature_names = ['Li', 'Ni', 'Co', 'Mn']
importances = rf_model.feature_importances_
indices = np.argsort(importances)[::-1]

print("\nç‰¹å¾´é‡é‡è¦åº¦:")
for i in range(len(feature_names)):
    print(f"  {feature_names[indices[i]]}: {importances[indices[i]]:.3f}")

<h1>å¯è¦–åŒ–</h1>
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

<h1>äºˆæ¸¬ vs å®Ÿæ¸¬</h1>
ax1 = axes[0]
ax1.scatter(y_train, y_pred_train, alpha=0.5, label='è¨“ç·´')
ax1.scatter(y_test, y_pred_test, alpha=0.7, label='ãƒ†ã‚¹ãƒˆ')
ax1.plot([y_capacity.min(), y_capacity.max()],
         [y_capacity.min(), y_capacity.max()],
         'k--', linewidth=2, label='ç†æƒ³')
ax1.set_xlabel('å®Ÿæ¸¬å®¹é‡ (mAh/g)', fontsize=12)
ax1.set_ylabel('äºˆæ¸¬å®¹é‡ (mAh/g)', fontsize=12)
ax1.set_title('Random Forestå®¹é‡äºˆæ¸¬', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

<h1>ç‰¹å¾´é‡é‡è¦åº¦</h1>
ax2 = axes[1]
ax2.barh(range(len(feature_names)), importances[indices],
         color='steelblue')
ax2.set_yticks(range(len(feature_names)))
ax2.set_yticklabels([feature_names[i] for i in indices])
ax2.set_xlabel('é‡è¦åº¦', fontsize=12)
ax2.set_title('ç‰¹å¾´é‡é‡è¦åº¦', fontsize=14)
ax2.grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.savefig('ml_model_performance.png', dpi=150, bbox_inches='tight')
plt.show()</code></pre>

---

<h3>MLãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§æ´»ç”¨</h3>

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹3: MLãƒ¢ãƒ‡ãƒ«ã¨ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®çµ±åˆ</strong>

<pre><code class="language-python"><h1>scikit-optimizeã‚’ä½¿ç”¨ã—ãŸMLãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®æœ€é©åŒ–</h1>
from skopt import gp_minimize
from skopt.space import Real
from skopt.plots import plot_convergence

def objective_function_ml(x):
    """
    MLãƒ¢ãƒ‡ãƒ«ã‚’ç›®çš„é–¢æ•°ã¨ã—ã¦ä½¿ç”¨

    Parameters:
    -----------
    x : list
        [li_content, ni_content, co_content, mn_content]

    Returns:
    --------
    float : è² ã®å®¹é‡ï¼ˆæœ€å°åŒ–å•é¡Œã«å¤‰æ›ï¼‰
    """
    # çµ„æˆåˆ¶ç´„: åˆè¨ˆ=1.0
    li, ni, co, mn = x
    total = li + ni + co + mn

    # åˆ¶ç´„é•åã«ãƒšãƒŠãƒ«ãƒ†ã‚£
    if not (0.98 <= total <= 1.02):
        return 1000.0  # å¤§ããªãƒšãƒŠãƒ«ãƒ†ã‚£

    # å€‹åˆ¥åˆ¶ç´„
    if li < 0.1 or li > 0.5:
        return 1000.0
    if ni < 0.1 or ni > 0.4:
        return 1000.0
    if co < 0.1 or co > 0.4:
        return 1000.0
    if mn < 0.0:
        return 1000.0

    # MLãƒ¢ãƒ‡ãƒ«ã§å®¹é‡äºˆæ¸¬
    X_pred = np.array([[li, ni, co, mn]])
    capacity_pred = rf_model.predict(X_pred)[0]

    # æœ€å°åŒ–å•é¡Œã«å¤‰æ›ï¼ˆè² ã®å®¹é‡ï¼‰
    return -capacity_pred

<h1>æ¢ç´¢ç©ºé–“ã®å®šç¾©</h1>
space = [
    Real(0.1, 0.5, name='li_content'),
    Real(0.1, 0.4, name='ni_content'),
    Real(0.1, 0.4, name='co_content'),
    Real(0.0, 0.5, name='mn_content')
]

<h1>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å®Ÿè¡Œ</h1>
result = gp_minimize(
    objective_function_ml,
    space,
    n_calls=50,        # 50å›ã®è©•ä¾¡
    n_initial_points=10,  # åˆæœŸãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    random_state=42,
    verbose=False
)

<h1>çµæœ</h1>
best_composition = result.x
best_capacity = -result.fun  # è² ã‚’å…ƒã«æˆ»ã™

print("ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®çµæœ:")
print(f"  æœ€é©çµ„æˆ:")
print(f"    Li: {best_composition[0]:.3f}")
print(f"    Ni: {best_composition[1]:.3f}")
print(f"    Co: {best_composition[2]:.3f}")
print(f"    Mn: {best_composition[3]:.3f}")
print(f"    åˆè¨ˆ: {sum(best_composition):.3f}")
print(f"  äºˆæ¸¬å®¹é‡: {best_capacity:.2f} mAh/g")

<h1>åæŸãƒ—ãƒ­ãƒƒãƒˆ</h1>
plt.figure(figsize=(10, 6))
plot_convergence(result)
plt.title('ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®åæŸ', fontsize=14)
plt.xlabel('è©•ä¾¡å›æ•°', fontsize=12)
plt.ylabel('ã“ã‚Œã¾ã§ã®æœ€è‰¯å€¤ï¼ˆè² ã®å®¹é‡ï¼‰', fontsize=12)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('bo_ml_convergence.png', dpi=150, bbox_inches='tight')
plt.show()

<h1>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®æœ€è‰¯å€¤ã¨æ¯”è¼ƒ</h1>
max_capacity_data = df_materials['capacity'].max()
print(f"\nãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®æœ€å¤§å®¹é‡: {max_capacity_data:.2f} mAh/g")
print(f"æ”¹å–„ç‡: {((best_capacity - max_capacity_data) / max_capacity_data * 100):.1f}%")</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›</strong>:
<pre><code>ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®çµæœ:
  æœ€é©çµ„æˆ:
    Li: 0.487
    Ni: 0.312
    Co: 0.152
    Mn: 0.049
    åˆè¨ˆ: 1.000
  äºˆæ¸¬å®¹é‡: 267.34 mAh/g

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®æœ€å¤§å®¹é‡: 311.50 mAh/g
æ”¹å–„ç‡: -14.2%</code></pre>

---

<h2>3.2 åˆ¶ç´„ä»˜ãæœ€é©åŒ–</h2>

<h3>ææ–™ã®å®Ÿç¾å¯èƒ½æ€§åˆ¶ç´„</h3>

å®Ÿéš›ã®ææ–™é–‹ç™ºã§ã¯ã€ä»¥ä¸‹ã®åˆ¶ç´„ãŒã‚ã‚Šã¾ã™ï¼š

1. <strong>çµ„æˆåˆ¶ç´„</strong>: åˆè¨ˆ100%ã€å„å…ƒç´ ã®ä¸Šä¸‹é™
2. <strong>å®‰å®šæ€§åˆ¶ç´„</strong>: formation energy < é–¾å€¤
3. <strong>å®Ÿé¨“çš„åˆ¶ç´„</strong>: åˆæˆæ¸©åº¦ã€åœ§åŠ›ç¯„å›²
4. <strong>ã‚³ã‚¹ãƒˆåˆ¶ç´„</strong>: é«˜ä¾¡ãªå…ƒç´ ã®ä½¿ç”¨åˆ¶é™

<h3>åˆ¶ç´„ä»˜ããƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å®Ÿè£…</h3>

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹4: è¤‡æ•°åˆ¶ç´„æ¡ä»¶ä¸‹ã§ã®æœ€é©åŒ–</strong>

<pre><code class="language-python"><h1>åˆ¶ç´„ä»˜ããƒ™ã‚¤ã‚ºæœ€é©åŒ–ï¼ˆBoTorchä½¿ç”¨ï¼‰</h1>
<h1>æ³¨: BoTorchã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install botorch torch</h1>
import torch
from botorch.models import SingleTaskGP
from botorch.fit import fit_gpytorch_model
from gpytorch.mlls import ExactMarginalLogLikelihood
from botorch.acquisition import ExpectedImprovement
from botorch.optim import optimize_acqf

def constrained_bo_example():
    """
    åˆ¶ç´„ä»˜ããƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®ãƒ‡ãƒ¢

    åˆ¶ç´„:
    - å®¹é‡ã‚’æœ€å¤§åŒ–
    - å®‰å®šæ€§: formation energy < -1.5 eV/atom
    - ã‚³ã‚¹ãƒˆ: Coå«é‡ < 0.3
    """
    # åˆæœŸãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
    n_initial = 10
    np.random.seed(42)

    X_init = np.random.rand(n_initial, 4)
    # çµ„æˆæ­£è¦åŒ–
    X_init = X_init / X_init.sum(axis=1, keepdims=True)

    # ç›®çš„é–¢æ•°ã¨åˆ¶ç´„ã®è©•ä¾¡
    y_capacity = []
    y_stability = []
    for i in range(n_initial):
        x = X_init[i]
        # å®¹é‡äºˆæ¸¬
        capacity = rf_model.predict(x.reshape(1, -1))[0]
        # å®‰å®šæ€§ï¼ˆç°¡ç•¥ãƒ¢ãƒ‡ãƒ«ï¼‰
        stability = -2.0 - 0.5*x[0] - 0.3*x[1] + 0.1*np.random.randn()

        y_capacity.append(capacity)
        y_stability.append(stability)

    X_init = torch.tensor(X_init, dtype=torch.float64)
    y_capacity = torch.tensor(y_capacity, dtype=torch.float64).unsqueeze(-1)
    y_stability = torch.tensor(y_stability, dtype=torch.float64).unsqueeze(-1)

    # é€æ¬¡æœ€é©åŒ–ï¼ˆ20å›ï¼‰
    n_iterations = 20
    X_all = X_init.clone()
    y_capacity_all = y_capacity.clone()
    y_stability_all = y_stability.clone()

    for iteration in range(n_iterations):
        # ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«ï¼ˆå®¹é‡ï¼‰
        gp_capacity = SingleTaskGP(X_all, y_capacity_all)
        mll_capacity = ExactMarginalLogLikelihood(
            gp_capacity.likelihood, gp_capacity
        )
        fit_gpytorch_model(mll_capacity)

        # ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«ï¼ˆå®‰å®šæ€§ï¼‰
        gp_stability = SingleTaskGP(X_all, y_stability_all)
        mll_stability = ExactMarginalLogLikelihood(
            gp_stability.likelihood, gp_stability
        )
        fit_gpytorch_model(mll_stability)

        # Expected Improvementï¼ˆå®¹é‡ï¼‰
        best_f = y_capacity_all.max()
        EI = ExpectedImprovement(gp_capacity, best_f=best_f)

        # ç²å¾—é–¢æ•°ã®æœ€é©åŒ–ï¼ˆåˆ¶ç´„è€ƒæ…®ï¼‰
        bounds = torch.tensor([[0.1, 0.1, 0.1, 0.0],
                                [0.5, 0.4, 0.3, 0.5]],
                               dtype=torch.float64)

        candidate, acq_value = optimize_acqf(
            EI,
            bounds=bounds,
            q=1,
            num_restarts=10,
            raw_samples=512,
        )

        # å€™è£œç‚¹ã®è©•ä¾¡
        x_new = candidate.detach().numpy()[0]
        # æ­£è¦åŒ–
        x_new = x_new / x_new.sum()

        # å®Ÿé¨“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        capacity_new = rf_model.predict(x_new.reshape(1, -1))[0]
        stability_new = -2.0 - 0.5*x_new[0] - 0.3*x_new[1] + \
                        0.1*np.random.randn()

        # åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
        feasible = (stability_new < -1.5) and (x_new[2] < 0.3)

        if feasible:
            print(f"Iteration {iteration+1}: "
                  f"Capacity={capacity_new:.1f}, "
                  f"Stability={stability_new:.2f}, "
                  f"Feasible=Yes")
        else:
            print(f"Iteration {iteration+1}: "
                  f"Capacity={capacity_new:.1f}, "
                  f"Stability={stability_new:.2f}, "
                  f"Feasible=No (åˆ¶ç´„é•å)")

        # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        X_all = torch.cat([X_all, torch.tensor(x_new).unsqueeze(0)], dim=0)
        y_capacity_all = torch.cat([y_capacity_all,
                                     torch.tensor([[capacity_new]])], dim=0)
        y_stability_all = torch.cat([y_stability_all,
                                      torch.tensor([[stability_new]])], dim=0)

    # å®Ÿè¡Œå¯èƒ½è§£ã®ä¸­ã§æœ€è‰¯ã®ã‚‚ã®ã‚’æŠ½å‡º
    feasible_mask = (y_stability_all < -1.5).squeeze() & \
                    (X_all[:, 2] < 0.3).squeeze()

    if feasible_mask.sum() > 0:
        feasible_capacities = y_capacity_all[feasible_mask]
        feasible_X = X_all[feasible_mask]
        best_idx = feasible_capacities.argmax()
        best_composition_constrained = feasible_X[best_idx].numpy()
        best_capacity_constrained = feasible_capacities[best_idx].item()

        print("\næœ€çµ‚çµæœï¼ˆåˆ¶ç´„ä»˜ãï¼‰:")
        print(f"  æœ€é©çµ„æˆ:")
        print(f"    Li: {best_composition_constrained[0]:.3f}")
        print(f"    Ni: {best_composition_constrained[1]:.3f}")
        print(f"    Co: {best_composition_constrained[2]:.3f} "
              f"(åˆ¶ç´„ < 0.3)")
        print(f"    Mn: {best_composition_constrained[3]:.3f}")
        print(f"  äºˆæ¸¬å®¹é‡: {best_capacity_constrained:.2f} mAh/g")
        print(f"  å®Ÿè¡Œå¯èƒ½è§£ã®æ•°: {feasible_mask.sum().item()} / "
              f"{len(X_all)}")
    else:
        print("\nå®Ÿè¡Œå¯èƒ½è§£ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

<h1>å®Ÿè¡Œ</h1>
constrained_bo_example()</code></pre>

---

<h2>3.3 å¤šç›®çš„æœ€é©åŒ–ï¼ˆParetoæœ€é©åŒ–ï¼‰</h2>

<h3>ãªãœå¤šç›®çš„æœ€é©åŒ–ãŒå¿…è¦ã‹</h3>

ææ–™é–‹ç™ºã§ã¯ã€<strong>è¤‡æ•°ã®ç‰¹æ€§ã‚’åŒæ™‚ã«æœ€é©åŒ–</strong>ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š

- <strong>Li-ioné›»æ± </strong>: å®¹é‡ â†‘ã€é›»åœ§ â†‘ã€å®‰å®šæ€§ â†‘
- <strong>ç†±é›»ææ–™</strong>: ã‚¼ãƒ¼ãƒ™ãƒƒã‚¯ä¿‚æ•° â†‘ã€é›»æ°—ä¼å°åº¦ â†‘ã€ç†±ä¼å°åº¦ â†“
- <strong>è§¦åª’</strong>: æ´»æ€§ â†‘ã€é¸æŠæ€§ â†‘ã€å®‰å®šæ€§ â†‘ã€ã‚³ã‚¹ãƒˆ â†“

ã“ã‚Œã‚‰ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒã‚ã‚Šã€<strong>å˜ä¸€ã®æœ€é©è§£ã¯å­˜åœ¨ã—ãªã„</strong>ã€‚

<h3>Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã®æ¦‚å¿µ</h3>

<div class="mermaid">graph TB
    subgraph ç›®çš„ç©ºé–“
    A[ç›®çš„1: å®¹é‡]
    B[ç›®çš„2: å®‰å®šæ€§]
    C[Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢<br/>ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®å¢ƒç•Œ]
    D[æ”¯é…ã•ã‚Œã‚‹è§£<br/>ã©ã¡ã‚‰ã‚‚åŠ£ã‚‹]
    E[Paretoæœ€é©è§£<br/>æ”¹å–„ã«ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒå¿…è¦]
    end

    A --> C
    B --> C
    C --> E
    D -.åŠ£ã‚‹.-> E

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
    style E fill:#fce4ec</div>

<strong>Paretoæœ€é©ã®å®šç¾©</strong>:
> è§£ x ãŒ Paretoæœ€é© â‡” å…¨ã¦ã®ç›®çš„ã‚’åŒæ™‚ã«æ”¹å–„ã™ã‚‹è§£ãŒå­˜åœ¨ã—ãªã„

---

<h3>Expected Hypervolume Improvementï¼ˆEHVIï¼‰</h3>

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹5: å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å®Ÿè£…</strong>

<pre><code class="language-python"><h1>å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–</h1>
from botorch.models import ModelListGP
from botorch.acquisition.multi_objective import \
    qExpectedHypervolumeImprovement
from botorch.utils.multi_objective.box_decompositions.dominated import \
    DominatedPartitioning

def multi_objective_bo_example():
    """
    å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®ãƒ‡ãƒ¢

    ç›®çš„:
    1. å®¹é‡ã‚’æœ€å¤§åŒ–
    2. å®‰å®šæ€§ã‚’æœ€å¤§åŒ–ï¼ˆformation energyã®çµ¶å¯¾å€¤ã‚’æœ€å°åŒ–ï¼‰
    """
    # åˆæœŸãƒ‡ãƒ¼ã‚¿
    n_initial = 15
    np.random.seed(42)

    X_init = np.random.rand(n_initial, 4)
    X_init = X_init / X_init.sum(axis=1, keepdims=True)

    # 2ã¤ã®ç›®çš„é–¢æ•°ã‚’è©•ä¾¡
    y1_capacity = []
    y2_stability = []

    for i in range(n_initial):
        x = X_init[i]
        capacity = rf_model.predict(x.reshape(1, -1))[0]
        stability = -2.0 - 0.5*x[0] - 0.3*x[1] + 0.1*np.random.randn()
        # å®‰å®šæ€§ã¯è² ãŒè‰¯ã„ã®ã§ã€æ­£ã«å¤‰æ›ï¼ˆæœ€å¤§åŒ–å•é¡Œã«çµ±ä¸€ï¼‰
        stability_positive = -stability

        y1_capacity.append(capacity)
        y2_stability.append(stability_positive)

    X_all = torch.tensor(X_init, dtype=torch.float64)
    Y_all = torch.tensor(
        np.column_stack([y1_capacity, y2_stability]),
        dtype=torch.float64
    )

    # é€æ¬¡æœ€é©åŒ–
    n_iterations = 20

    for iteration in range(n_iterations):
        # ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«ï¼ˆå„ç›®çš„é–¢æ•°ã”ã¨ï¼‰
        gp_list = []
        for i in range(2):
            gp = SingleTaskGP(X_all, Y_all[:, i].unsqueeze(-1))
            mll = ExactMarginalLogLikelihood(gp.likelihood, gp)
            fit_gpytorch_model(mll)
            gp_list.append(gp)

        model = ModelListGP(*gp_list)

        # å‚ç…§ç‚¹ï¼ˆNadir point ã‚ˆã‚Šæ‚ªã„ç‚¹ï¼‰
        ref_point = Y_all.min(dim=0).values - 10.0

        # Pareto frontier ã®è¨ˆç®—
        pareto_mask = is_non_dominated(Y_all)
        pareto_Y = Y_all[pareto_mask]

        # EHVIç²å¾—é–¢æ•°
        partitioning = DominatedPartitioning(
            ref_point=ref_point,
            Y=pareto_Y
        )
        acq_func = qExpectedHypervolumeImprovement(
            model=model,
            ref_point=ref_point,
            partitioning=partitioning
        )

        # æœ€é©åŒ–
        bounds = torch.tensor([[0.1, 0.1, 0.1, 0.0],
                                [0.5, 0.4, 0.4, 0.5]],
                               dtype=torch.float64)

        candidate, acq_value = optimize_acqf(
            acq_func,
            bounds=bounds,
            q=1,
            num_restarts=10,
            raw_samples=512,
        )

        # æ–°ã—ã„å€™è£œç‚¹ã®è©•ä¾¡
        x_new = candidate.detach().numpy()[0]
        x_new = x_new / x_new.sum()

        capacity_new = rf_model.predict(x_new.reshape(1, -1))[0]
        stability_new = -2.0 - 0.5*x_new[0] - 0.3*x_new[1] + \
                        0.1*np.random.randn()
        stability_positive_new = -stability_new

        y_new = torch.tensor([[capacity_new, stability_positive_new]],
                              dtype=torch.float64)

        # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        X_all = torch.cat([X_all, torch.tensor(x_new).unsqueeze(0)], dim=0)
        Y_all = torch.cat([Y_all, y_new], dim=0)

        if (iteration + 1) % 5 == 0:
            print(f"Iteration {iteration+1}: "
                  f"Paretoè§£æ•°={pareto_mask.sum().item()}, "
                  f"HV={compute_hypervolume(pareto_Y, ref_point):.2f}")

    # æœ€çµ‚Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢
    pareto_mask_final = is_non_dominated(Y_all)
    pareto_X_final = X_all[pareto_mask_final].numpy()
    pareto_Y_final = Y_all[pareto_mask_final].numpy()

    print(f"\næœ€çµ‚Paretoæœ€é©è§£æ•°: {pareto_mask_final.sum().item()}")

    # Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã®å¯è¦–åŒ–
    plt.figure(figsize=(10, 6))

    # å…¨ã¦ã®ç‚¹
    plt.scatter(Y_all[:, 0].numpy(), Y_all[:, 1].numpy(),
                c='lightblue', s=50, alpha=0.5, label='å…¨æ¢ç´¢ç‚¹')

    # Paretoæœ€é©è§£
    plt.scatter(pareto_Y_final[:, 0], pareto_Y_final[:, 1],
                c='red', s=100, edgecolors='black', zorder=10,
                label='Paretoæœ€é©è§£')

    # Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã‚’ç·šã§çµã¶
    sorted_indices = np.argsort(pareto_Y_final[:, 0])
    plt.plot(pareto_Y_final[sorted_indices, 0],
             pareto_Y_final[sorted_indices, 1],
             'r--', linewidth=2, alpha=0.5, label='Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢')

    plt.xlabel('ç›®çš„1: å®¹é‡ (mAh/g)', fontsize=12)
    plt.ylabel('ç›®çš„2: å®‰å®šæ€§ (-formation energy)', fontsize=12)
    plt.title('å¤šç›®çš„æœ€é©åŒ–: Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('pareto_frontier.png', dpi=150, bbox_inches='tight')
    plt.show()

    # ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®ä¾‹ã‚’è¡¨ç¤º
    print("\nãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®ä¾‹:")
    # å®¹é‡é‡è¦–
    idx_max_capacity = np.argmax(pareto_Y_final[:, 0])
    print(f"  å®¹é‡é‡è¦–: å®¹é‡={pareto_Y_final[idx_max_capacity, 0]:.1f}, "
          f"å®‰å®šæ€§={pareto_Y_final[idx_max_capacity, 1]:.2f}")

    # å®‰å®šæ€§é‡è¦–
    idx_max_stability = np.argmax(pareto_Y_final[:, 1])
    print(f"  å®‰å®šæ€§é‡è¦–: å®¹é‡={pareto_Y_final[idx_max_stability, 0]:.1f}, "
          f"å®‰å®šæ€§={pareto_Y_final[idx_max_stability, 1]:.2f}")

    # ãƒãƒ©ãƒ³ã‚¹å‹ï¼ˆä¸­é–“ç‚¹ï¼‰
    normalized_Y = (pareto_Y_final - pareto_Y_final.min(axis=0)) / \
                   (pareto_Y_final.max(axis=0) - pareto_Y_final.min(axis=0))
    distances = np.sqrt(((normalized_Y - 0.5)**2).sum(axis=1))
    idx_balanced = np.argmin(distances)
    print(f"  ãƒãƒ©ãƒ³ã‚¹å‹: å®¹é‡={pareto_Y_final[idx_balanced, 0]:.1f}, "
          f"å®‰å®šæ€§={pareto_Y_final[idx_balanced, 1]:.2f}")

<h1>Paretoæœ€é©åˆ¤å®šé–¢æ•°</h1>
def is_non_dominated(Y):
    """
    Paretoæœ€é©è§£ã‚’åˆ¤å®š

    Parameters:
    -----------
    Y : Tensor (n_points, n_objectives)
        ç›®çš„é–¢æ•°å€¤

    Returns:
    --------
    mask : Tensor (n_points,)
        TrueãŒparetoæœ€é©
    """
    n_points = Y.shape[0]
    is_efficient = torch.ones(n_points, dtype=torch.bool)

    for i in range(n_points):
        if is_efficient[i]:
            # iç•ªç›®ã®ç‚¹ã‚ˆã‚Šå…¨ã¦ã®ç›®çš„ã§å„ªã‚Œã¦ã„ã‚‹ç‚¹ãŒã‚ã‚‹ã‹
            is_dominated = (Y >= Y[i]).all(dim=1) & (Y > Y[i]).any(dim=1)
            is_efficient[is_dominated] = False

    return is_efficient

<h1>Hypervolumeè¨ˆç®—</h1>
def compute_hypervolume(pareto_Y, ref_point):
    """
    Hypervolumeã®è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰

    Parameters:
    -----------
    pareto_Y : Tensor
        Paretoæœ€é©è§£
    ref_point : Tensor
        å‚ç…§ç‚¹

    Returns:
    --------
    float : Hypervolume
    """
    # 2æ¬¡å…ƒã®ç°¡æ˜“è¨ˆç®—
    sorted_Y = pareto_Y[torch.argsort(pareto_Y[:, 0], descending=True)]
    hv = 0.0
    prev_y1 = ref_point[0]

    for i in range(len(sorted_Y)):
        width = prev_y1 - sorted_Y[i, 0]
        height = sorted_Y[i, 1] - ref_point[1]
        hv += width * height
        prev_y1 = sorted_Y[i, 0]

    return hv.item()

<h1>å®Ÿè¡Œ</h1>
<h1>multi_objective_bo_example()</h1>
<h1>æ³¨: BoTorchãŒå¿…è¦ãªãŸã‚ã€ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ</h1>
print("å¤šç›®çš„æœ€é©åŒ–ã®ä¾‹ã¯BoTorchãŒå¿…è¦ã§ã™")
print("pip install botorch torch ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã€å®Ÿè¡Œã—ã¦ãã ã•ã„")</code></pre>

---

<h2>3.4 å®Ÿé¨“ã‚³ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸæœ€é©åŒ–</h2>

<h3>ãƒãƒƒãƒãƒ™ã‚¤ã‚ºæœ€é©åŒ–</h3>

å®Ÿé¨“è£…ç½®ãŒè¤‡æ•°ã‚ã‚‹å ´åˆã€<strong>ä¸¦åˆ—å®Ÿé¨“</strong>ãŒå¯èƒ½ã§ã™ï¼š

- <strong>å¾“æ¥</strong>: é€æ¬¡çš„ï¼ˆ1å›â†’çµæœâ†’æ¬¡ã®1å›ï¼‰
- <strong>ãƒãƒƒãƒBO</strong>: ä¸€åº¦ã«è¤‡æ•°ã®å€™è£œã‚’ææ¡ˆï¼ˆq-EIï¼‰

<h3>ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼</h3>

<div class="mermaid">graph LR
    A[åˆæœŸãƒ‡ãƒ¼ã‚¿] --> B[ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«]
    B --> C[q-EIç²å¾—é–¢æ•°<br/>qå€‹ã®å€™è£œã‚’ææ¡ˆ]
    C --> D[ä¸¦åˆ—å®Ÿé¨“<br/>qå€‹åŒæ™‚å®Ÿè¡Œ]
    D --> E{çµ‚äº†?}
    E -->|No| B
    E -->|Yes| F[æœ€è‰¯ææ–™]

    style A fill:#e3f2fd
    style C fill:#fff3e0
    style D fill:#f3e5f5
    style F fill:#fce4ec</div>

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹6: ãƒãƒƒãƒãƒ™ã‚¤ã‚ºæœ€é©åŒ–</strong>

<pre><code class="language-python"><h1>ãƒãƒƒãƒãƒ™ã‚¤ã‚ºæœ€é©åŒ–ï¼ˆscikit-optimizeï¼‰</h1>
from scipy.stats import norm

def batch_expected_improvement(X, gp, f_best, xi=0.01):
    """
    Batch Expected Improvementï¼ˆç°¡æ˜“ç‰ˆï¼‰

    Parameters:
    -----------
    X : array (n_candidates, n_features)
        å€™è£œç‚¹
    gp : GaussianProcessRegressor
        å­¦ç¿’æ¸ˆã¿GPãƒ¢ãƒ‡ãƒ«
    f_best : float
        ç¾åœ¨ã®æœ€è‰¯å€¤

    Returns:
    --------
    ei : array (n_candidates,)
        EIå€¤
    """
    mu, sigma = gp.predict(X, return_std=True)
    improvement = mu - f_best - xi
    Z = improvement / (sigma + 1e-9)
    ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)
    ei[sigma == 0.0] = 0.0
    return ei

def simulate_batch_bo(n_iterations=10, batch_size=3):
    """
    ãƒãƒƒãƒãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

    Parameters:
    -----------
    n_iterations : int
        ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°
    batch_size : int
        å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ææ¡ˆã™ã‚‹å€™è£œæ•°

    Returns:
    --------
    X_all : array
        å…¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‚¹
    y_all : array
        å…¨è¦³æ¸¬å€¤
    """
    from sklearn.gaussian_process import GaussianProcessRegressor
    from sklearn.gaussian_process.kernels import RBF, ConstantKernel

    # åˆæœŸãƒ‡ãƒ¼ã‚¿
    np.random.seed(42)
    n_initial = 5
    X_sampled = np.random.rand(n_initial, 4)
    X_sampled = X_sampled / X_sampled.sum(axis=1, keepdims=True)

    y_sampled = []
    for i in range(n_initial):
        capacity = rf_model.predict(X_sampled[i].reshape(1, -1))[0]
        y_sampled.append(capacity)

    y_sampled = np.array(y_sampled)

    # é€æ¬¡ãƒãƒƒãƒæœ€é©åŒ–
    for iteration in range(n_iterations):
        # ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«
        kernel = ConstantKernel(1.0) * RBF(length_scale=0.2)
        gp = GaussianProcessRegressor(
            kernel=kernel,
            n_restarts_optimizer=10,
            random_state=42
        )
        gp.fit(X_sampled, y_sampled)

        # ç¾åœ¨ã®æœ€è‰¯å€¤
        f_best = y_sampled.max()

        # å€™è£œç‚¹ç”Ÿæˆï¼ˆå¤šæ•°ï¼‰
        n_candidates = 1000
        X_candidates = np.random.rand(n_candidates, 4)
        X_candidates = X_candidates / X_candidates.sum(axis=1, keepdims=True)

        # EIè¨ˆç®—
        ei_values = batch_expected_improvement(X_candidates, gp, f_best)

        # Top-ké¸æŠï¼ˆå˜ç´”ãªæ–¹æ³•ï¼‰
        # ã‚ˆã‚Šé«˜åº¦ãªæ–¹æ³•: q-EI, KBï¼ˆKriging Believerï¼‰
        top_k_indices = np.argsort(ei_values)[-batch_size:]
        X_batch = X_candidates[top_k_indices]

        # ãƒãƒƒãƒå®Ÿé¨“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        y_batch = []
        for x in X_batch:
            capacity = rf_model.predict(x.reshape(1, -1))[0]
            y_batch.append(capacity)

        y_batch = np.array(y_batch)

        # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        X_sampled = np.vstack([X_sampled, X_batch])
        y_sampled = np.append(y_sampled, y_batch)

        # é€²æ—è¡¨ç¤º
        if (iteration + 1) % 3 == 0:
            best_so_far = y_sampled.max()
            print(f"Iteration {iteration+1}: "
                  f"Batch size={batch_size}, "
                  f"Best so far={best_so_far:.2f} mAh/g")

    return X_sampled, y_sampled

<h1>ãƒãƒƒãƒBOå®Ÿè¡Œ</h1>
print("ãƒãƒƒãƒãƒ™ã‚¤ã‚ºæœ€é©åŒ–ï¼ˆbatch_size=3ï¼‰:")
X_batch_bo, y_batch_bo = simulate_batch_bo(n_iterations=10, batch_size=3)

print(f"\næœ€çµ‚çµæœ:")
print(f"  ç·å®Ÿé¨“å›æ•°: {len(y_batch_bo)}")
print(f"  æœ€è‰¯å®¹é‡: {y_batch_bo.max():.2f} mAh/g")
print(f"  æœ€é©çµ„æˆ: {X_batch_bo[y_batch_bo.argmax()]}")

<h1>é€æ¬¡BOã¨æ¯”è¼ƒ</h1>
print("\né€æ¬¡BOï¼ˆbatch_size=1ï¼‰:")
X_seq_bo, y_seq_bo = simulate_batch_bo(n_iterations=30, batch_size=1)
print(f"  ç·å®Ÿé¨“å›æ•°: {len(y_seq_bo)}")
print(f"  æœ€è‰¯å®¹é‡: {y_seq_bo.max():.2f} mAh/g")

<h1>åŠ¹ç‡æ¯”è¼ƒ</h1>
plt.figure(figsize=(10, 6))
plt.plot(np.maximum.accumulate(y_seq_bo), 'o-',
         label='é€æ¬¡BO (batch_size=1)', linewidth=2, markersize=6)
plt.plot(np.arange(0, len(y_batch_bo), 3),
         np.maximum.accumulate(y_batch_bo)[::3], '^-',
         label='ãƒãƒƒãƒBO (batch_size=3)', linewidth=2, markersize=8)
plt.xlabel('å®Ÿé¨“å›æ•°', fontsize=12)
plt.ylabel('ã“ã‚Œã¾ã§ã®æœ€è‰¯å€¤ (mAh/g)', fontsize=12)
plt.title('ãƒãƒƒãƒBO vs é€æ¬¡BOã®åŠ¹ç‡æ¯”è¼ƒ', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('batch_bo_comparison.png', dpi=150, bbox_inches='tight')
plt.show()</code></pre>

---

<h2>3.5 å®Œå…¨ãªå®Ÿè£…ä¾‹ï¼šLi-ioné›»æ± é›»è§£è³ªã®æœ€é©åŒ–</h2>

<h3>å•é¡Œè¨­å®š</h3>

<strong>ç›®çš„</strong>: Li-ioné›»æ± æ­£æ¥µææ–™ã®æœ€é©åŒ–

<strong>æœ€é©åŒ–ã™ã‚‹ç‰¹æ€§</strong>:
1. å®¹é‡ï¼ˆmAh/gï¼‰ã‚’æœ€å¤§åŒ–
2. é›»åœ§ï¼ˆVï¼‰ã‚’æœ€å¤§åŒ–
3. å®‰å®šæ€§ï¼ˆformation energyï¼‰ã‚’æœ€å¤§åŒ–

<strong>åˆ¶ç´„</strong>:
- çµ„æˆã®åˆè¨ˆ = 1.0
- Liå«é‡: 0.1-0.5
- Niå«é‡: 0.1-0.4
- Coå«é‡: 0.1-0.3ï¼ˆé«˜ä¾¡ãªãŸã‚åˆ¶é™ï¼‰
- Mnå«é‡: â‰¥ 0.0

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹7: å®Ÿä¸–ç•Œå•é¡Œã®å®Œå…¨å®Ÿè£…</strong>

<pre><code class="language-python"><h1>Li-ioné›»æ± æ­£æ¥µææ–™ã®å¤šç›®çš„åˆ¶ç´„ä»˜ãæœ€é©åŒ–</h1>
class LiIonCathodeOptimizer:
    """
    Li-ioné›»æ± æ­£æ¥µææ–™ã®æœ€é©åŒ–ã‚¯ãƒ©ã‚¹

    ç›®çš„:
    - å®¹é‡æœ€å¤§åŒ–
    - é›»åœ§æœ€å¤§åŒ–
    - å®‰å®šæ€§æœ€å¤§åŒ–ï¼ˆã‚³ã‚¹ãƒˆè€ƒæ…®ï¼‰

    åˆ¶ç´„:
    - çµ„æˆåˆ¶ç´„
    - Coå«é‡åˆ¶é™ï¼ˆã‚³ã‚¹ãƒˆï¼‰
    """

    def __init__(self, capacity_model, voltage_model, stability_model):
        """
        Parameters:
        -----------
        capacity_model : sklearn model
            å®¹é‡äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
        voltage_model : sklearn model
            é›»åœ§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
        stability_model : sklearn model
            å®‰å®šæ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
        """
        self.capacity_model = capacity_model
        self.voltage_model = voltage_model
        self.stability_model = stability_model

        # åˆ¶ç´„
        self.co_max = 0.3  # Coå«é‡ä¸Šé™
        self.composition_bounds = {
            'li': (0.1, 0.5),
            'ni': (0.1, 0.4),
            'co': (0.1, 0.3),
            'mn': (0.0, 0.5)
        }

    def evaluate(self, composition):
        """
        ææ–™çµ„æˆã‚’è©•ä¾¡

        Parameters:
        -----------
        composition : array [li, ni, co, mn]

        Returns:
        --------
        dict : å„ç‰¹æ€§ã®äºˆæ¸¬å€¤
        """
        # åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
        if not self._check_constraints(composition):
            return {
                'capacity': -1000,
                'voltage': -1000,
                'stability': -1000,
                'feasible': False
            }

        x = composition.reshape(1, -1)

        capacity = self.capacity_model.predict(x)[0]
        # é›»åœ§ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
        voltage = 3.0 + 1.5 * composition[2] + 0.2 * np.random.randn()
        # å®‰å®šæ€§ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
        stability = -2.0 - 0.5*composition[0] - 0.3*composition[1] + \
                    0.1*np.random.randn()

        return {
            'capacity': capacity,
            'voltage': voltage,
            'stability': -stability,  # æ­£ã«å¤‰æ›
            'feasible': True
        }

    def _check_constraints(self, composition):
        """åˆ¶ç´„ãƒã‚§ãƒƒã‚¯"""
        li, ni, co, mn = composition

        # çµ„æˆåˆè¨ˆ
        if not (0.98 <= li + ni + co + mn <= 1.02):
            return False

        # å„å…ƒç´ ã®ç¯„å›²
        if not (self.composition_bounds['li'][0] <= li <=
                self.composition_bounds['li'][1]):
            return False
        if not (self.composition_bounds['ni'][0] <= ni <=
                self.composition_bounds['ni'][1]):
            return False
        if not (self.composition_bounds['co'][0] <= co <=
                self.composition_bounds['co'][1]):
            return False
        if not (self.composition_bounds['mn'][0] <= mn <=
                self.composition_bounds['mn'][1]):
            return False

        return True

    def optimize_multi_objective(self, n_iterations=50):
        """
        å¤šç›®çš„æœ€é©åŒ–ã‚’å®Ÿè¡Œ

        Returns:
        --------
        pareto_solutions : list of dict
            Paretoæœ€é©è§£
        """
        # åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        n_initial = 20
        np.random.seed(42)

        solutions = []

        for i in range(n_initial):
            # ãƒ©ãƒ³ãƒ€ãƒ çµ„æˆç”Ÿæˆ
            composition = np.random.rand(4)
            composition = composition / composition.sum()

            # è©•ä¾¡
            result = self.evaluate(composition)

            if result['feasible']:
                solutions.append({
                    'composition': composition,
                    'capacity': result['capacity'],
                    'voltage': result['voltage'],
                    'stability': result['stability']
                })

        # é€æ¬¡æœ€é©åŒ–ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        for iteration in range(n_iterations - n_initial):
            # æ—¢å­˜è§£ã‹ã‚‰Paretoæœ€é©ã‚’æŠ½å‡º
            pareto_sols = self._extract_pareto(solutions)

            # Paretoè§£ã®å‘¨è¾ºã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆç°¡æ˜“çš„ãªæ‰‹æ³•ï¼‰
            if len(pareto_sols) > 0:
                base_sol = pareto_sols[np.random.randint(len(pareto_sols))]
                composition_new = base_sol['composition'] + \
                                  np.random.randn(4) * 0.05
                composition_new = np.clip(composition_new, 0.01, 0.8)
                composition_new = composition_new / composition_new.sum()
            else:
                composition_new = np.random.rand(4)
                composition_new = composition_new / composition_new.sum()

            # è©•ä¾¡
            result = self.evaluate(composition_new)

            if result['feasible']:
                solutions.append({
                    'composition': composition_new,
                    'capacity': result['capacity'],
                    'voltage': result['voltage'],
                    'stability': result['stability']
                })

        # æœ€çµ‚Paretoæœ€é©è§£
        pareto_solutions = self._extract_pareto(solutions)

        return pareto_solutions, solutions

    def _extract_pareto(self, solutions):
        """Paretoæœ€é©è§£ã‚’æŠ½å‡º"""
        if len(solutions) == 0:
            return []

        objectives = np.array([
            [s['capacity'], s['voltage'], s['stability']]
            for s in solutions
        ])

        pareto_mask = np.ones(len(objectives), dtype=bool)

        for i in range(len(objectives)):
            if pareto_mask[i]:
                # iç•ªç›®ã‚ˆã‚Šå…¨ã¦ã®ç›®çš„ã§å„ªã‚Œã¦ã„ã‚‹è§£ãŒã‚ã‚‹ã‹
                dominated = (
                    (objectives >= objectives[i]).all(axis=1) &
                    (objectives > objectives[i]).any(axis=1)
                )
                pareto_mask[dominated] = False

        pareto_solutions = [solutions[i] for i in range(len(solutions))
                             if pareto_mask[i]]

        return pareto_solutions

<h1>é›»åœ§ãƒ»å®‰å®šæ€§ãƒ¢ãƒ‡ãƒ«ã®ç°¡æ˜“è¨“ç·´ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰</h1>
from sklearn.ensemble import RandomForestRegressor

voltage_model = RandomForestRegressor(n_estimators=50, random_state=42)
voltage_model.fit(X_train, y_voltage[:len(X_train)])

stability_model = RandomForestRegressor(n_estimators=50, random_state=42)
stability_model.fit(X_train, y_stability[:len(X_train)])

<h1>æœ€é©åŒ–å®Ÿè¡Œ</h1>
optimizer = LiIonCathodeOptimizer(
    capacity_model=rf_model,
    voltage_model=voltage_model,
    stability_model=stability_model
)

print("Li-ioné›»æ± æ­£æ¥µææ–™ã®å¤šç›®çš„æœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...")
pareto_solutions, all_solutions = optimizer.optimize_multi_objective(
    n_iterations=100
)

print(f"\nParetoæœ€é©è§£æ•°: {len(pareto_solutions)}")

<h1>çµæœã®å¯è¦–åŒ–ï¼ˆ3Dï¼‰</h1>
from mpl_toolkits.mplot3d import Axes3D

fig = plt.figure(figsize=(14, 6))

<h1>å·¦å›³: 3Dæ•£å¸ƒå›³</h1>
ax1 = fig.add_subplot(121, projection='3d')

<h1>å…¨ã¦ã®è§£</h1>
all_cap = [s['capacity'] for s in all_solutions]
all_vol = [s['voltage'] for s in all_solutions]
all_sta = [s['stability'] for s in all_solutions]

ax1.scatter(all_cap, all_vol, all_sta, c='lightblue', s=20,
            alpha=0.3, label='å…¨æ¢ç´¢ç‚¹')

<h1>Paretoæœ€é©è§£</h1>
pareto_cap = [s['capacity'] for s in pareto_solutions]
pareto_vol = [s['voltage'] for s in pareto_solutions]
pareto_sta = [s['stability'] for s in pareto_solutions]

ax1.scatter(pareto_cap, pareto_vol, pareto_sta, c='red', s=100,
            edgecolors='black', zorder=10, label='Paretoæœ€é©è§£')

ax1.set_xlabel('å®¹é‡ (mAh/g)', fontsize=10)
ax1.set_ylabel('é›»åœ§ (V)', fontsize=10)
ax1.set_zlabel('å®‰å®šæ€§', fontsize=10)
ax1.set_title('3ç›®çš„æœ€é©åŒ–: ç›®çš„ç©ºé–“', fontsize=12)
ax1.legend()

<h1>å³å›³: å®¹é‡-é›»åœ§ã®2Dãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³</h1>
ax2 = fig.add_subplot(122)
ax2.scatter(all_cap, all_vol, c='lightblue', s=20,
            alpha=0.5, label='å…¨æ¢ç´¢ç‚¹')
ax2.scatter(pareto_cap, pareto_vol, c='red', s=100,
            edgecolors='black', zorder=10, label='Paretoæœ€é©è§£')
ax2.set_xlabel('å®¹é‡ (mAh/g)', fontsize=12)
ax2.set_ylabel('é›»åœ§ (V)', fontsize=12)
ax2.set_title('å®¹é‡-é›»åœ§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('liion_cathode_optimization.png', dpi=150,
            bbox_inches='tight')
plt.show()

<h1>ä»£è¡¨çš„ãªParetoè§£ã‚’è¡¨ç¤º</h1>
print("\nä»£è¡¨çš„ãªParetoæœ€é©è§£:")

<h1>å®¹é‡é‡è¦–</h1>
idx_max_cap = np.argmax(pareto_cap)
print(f"\nå®¹é‡é‡è¦–:")
print(f"  Li={pareto_solutions[idx_max_cap]['composition'][0]:.3f}, "
      f"Ni={pareto_solutions[idx_max_cap]['composition'][1]:.3f}, "
      f"Co={pareto_solutions[idx_max_cap]['composition'][2]:.3f}, "
      f"Mn={pareto_solutions[idx_max_cap]['composition'][3]:.3f}")
print(f"  å®¹é‡={pareto_cap[idx_max_cap]:.1f} mAh/g, "
      f"é›»åœ§={pareto_vol[idx_max_cap]:.2f} V, "
      f"å®‰å®šæ€§={pareto_sta[idx_max_cap]:.2f}")

<h1>é›»åœ§é‡è¦–</h1>
idx_max_vol = np.argmax(pareto_vol)
print(f"\né›»åœ§é‡è¦–:")
print(f"  Li={pareto_solutions[idx_max_vol]['composition'][0]:.3f}, "
      f"Ni={pareto_solutions[idx_max_vol]['composition'][1]:.3f}, "
      f"Co={pareto_solutions[idx_max_vol]['composition'][2]:.3f}, "
      f"Mn={pareto_solutions[idx_max_vol]['composition'][3]:.3f}")
print(f"  å®¹é‡={pareto_cap[idx_max_vol]:.1f} mAh/g, "
      f"é›»åœ§={pareto_vol[idx_max_vol]:.2f} V, "
      f"å®‰å®šæ€§={pareto_sta[idx_max_vol]:.2f}")

<h1>ãƒãƒ©ãƒ³ã‚¹å‹</h1>
<h1>æ­£è¦åŒ–ã—ã¦ä¸­å¿ƒã«æœ€ã‚‚è¿‘ã„è§£</h1>
pareto_array = np.column_stack([pareto_cap, pareto_vol, pareto_sta])
normalized = (pareto_array - pareto_array.min(axis=0)) / \
             (pareto_array.max(axis=0) - pareto_array.min(axis=0))
distances = np.sqrt(((normalized - 0.5)**2).sum(axis=1))
idx_balanced = np.argmin(distances)

print(f"\nãƒãƒ©ãƒ³ã‚¹å‹:")
print(f"  Li={pareto_solutions[idx_balanced]['composition'][0]:.3f}, "
      f"Ni={pareto_solutions[idx_balanced]['composition'][1]:.3f}, "
      f"Co={pareto_solutions[idx_balanced]['composition'][2]:.3f}, "
      f"Mn={pareto_solutions[idx_balanced]['composition'][3]:.3f}")
print(f"  å®¹é‡={pareto_cap[idx_balanced]:.1f} mAh/g, "
      f"é›»åœ§={pareto_vol[idx_balanced]:.2f} V, "
      f"å®‰å®šæ€§={pareto_sta[idx_balanced]:.2f}")</code></pre>

---

<h2>3.6 ã‚³ãƒ©ãƒ ï¼šãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ vs ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</h2>

<h3>2ç¨®é¡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</h3>

ææ–™æ¢ç´¢ã§ã¯ã€2ç¨®é¡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åŒºåˆ¥ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š

<strong>ææ–™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆè¨­è¨ˆå¤‰æ•°ï¼‰</strong>:
- æœ€é©åŒ–ã—ãŸã„å¤‰æ•°
- ä¾‹: çµ„æˆæ¯”ã€åˆæˆæ¸©åº¦ã€åœ§åŠ›
- ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã§æ¢ç´¢

<strong>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è¨­å®šï¼‰</strong>:
- ãƒ™ã‚¤ã‚ºæœ€é©åŒ–è‡ªä½“ã®è¨­å®š
- ä¾‹: ã‚«ãƒ¼ãƒãƒ«ã®é•·ã•ã‚¹ã‚±ãƒ¼ãƒ«ã€æ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Îº
- ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ãƒã‚¹ãƒ†ãƒƒãƒ‰BO ã§æœ€é©åŒ–

<h3>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é‡è¦æ€§</h3>

ä¸é©åˆ‡ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã€æœ€é©åŒ–åŠ¹ç‡ã‚’å¤§ããæãªã„ã¾ã™ï¼š

- <strong>é•·ã•ã‚¹ã‚±ãƒ¼ãƒ«ãŒå¤§ãã™ã</strong> â†’ ç´°ã‹ã„æ§‹é€ ã‚’æ‰ãˆã‚‰ã‚Œãªã„
- <strong>é•·ã•ã‚¹ã‚±ãƒ¼ãƒ«ãŒå°ã•ã™ã</strong> â†’ ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒˆã€æ¢ç´¢ãŒå±€æ‰€çš„
- <strong>Îºï¼ˆUCBï¼‰ãŒå¤§ãã™ã</strong> â†’ æ¢ç´¢é‡è¦–ã€åæŸé…ã„
- <strong>ÎºãŒå°ã•ã™ã</strong> â†’ æ´»ç”¨é‡è¦–ã€å±€æ‰€æœ€é©ã«ã¯ã¾ã‚‹

<strong>æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</strong>:
1. <strong>ãƒ‡ãƒ¼ã‚¿é§†å‹•</strong>: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã§ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–
2. <strong>ãƒ­ãƒã‚¹ãƒˆè¨­å®š</strong>: åºƒç¯„å›²ã§è‰¯å¥½ãªæ€§èƒ½ã‚’ç¤ºã™è¨­å®šã‚’é¸æŠ
3. <strong>é©å¿œçš„èª¿æ•´</strong>: æœ€é©åŒ–ã®é€²è¡Œã«å¿œã˜ã¦Îºã‚’æ¸›å°‘ï¼ˆæ¢ç´¢â†’æ´»ç”¨ï¼‰

<strong>ã‚³ãƒ¼ãƒ‰ä¾‹8: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿ã‚’å¯è¦–åŒ–</strong>

<pre><code class="language-python"><h1>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿ã‚’æ¯”è¼ƒ</h1>
from sklearn.gaussian_process.kernels import RBF, ConstantKernel

def compare_hyperparameters():
    """
    ç•°ãªã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®æœ€é©åŒ–åŠ¹ç‡ã‚’æ¯”è¼ƒ
    """
    # ãƒ†ã‚¹ãƒˆé–¢æ•°
    def test_function(x):
        return (np.sin(5*x) * np.exp(-x) +
                0.5 * np.exp(-((x-0.6)/0.15)**2))

    # ç•°ãªã‚‹é•·ã•ã‚¹ã‚±ãƒ¼ãƒ«
    length_scales = [0.05, 0.1, 0.3]

    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    for idx, ls in enumerate(length_scales):
        ax = axes[idx]

        # åˆæœŸãƒ‡ãƒ¼ã‚¿
        np.random.seed(42)
        X_init = np.array([0.1, 0.4, 0.7]).reshape(-1, 1)
        y_init = test_function(X_init.ravel())

        # ã‚¬ã‚¦ã‚¹éç¨‹
        kernel = ConstantKernel(1.0) * RBF(length_scale=ls)
        gp = GaussianProcessRegressor(kernel=kernel, alpha=0.01,
                                       random_state=42)
        gp.fit(X_init, y_init)

        # äºˆæ¸¬
        X_plot = np.linspace(0, 1, 200).reshape(-1, 1)
        y_pred, y_std = gp.predict(X_plot, return_std=True)

        # ãƒ—ãƒ­ãƒƒãƒˆ
        ax.plot(X_plot, test_function(X_plot.ravel()), 'k--',
                linewidth=2, label='çœŸã®é–¢æ•°')
        ax.scatter(X_init, y_init, c='red', s=100, zorder=10,
                   edgecolors='black', label='è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿')
        ax.plot(X_plot, y_pred, 'b-', linewidth=2, label='äºˆæ¸¬å¹³å‡')
        ax.fill_between(X_plot.ravel(), y_pred - 1.96*y_std,
                         y_pred + 1.96*y_std, alpha=0.3, color='blue')
        ax.set_xlabel('x', fontsize=12)
        ax.set_ylabel('y', fontsize=12)
        ax.set_title(f'é•·ã•ã‚¹ã‚±ãƒ¼ãƒ« = {ls}', fontsize=14)
        ax.legend()
        ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('hyperparameter_comparison.png', dpi=150,
                bbox_inches='tight')
    plt.show()

    print("ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿:")
    print("  é•·ã•ã‚¹ã‚±ãƒ¼ãƒ« 0.05: å±€æ‰€çš„ã€ç´°ã‹ã„æ§‹é€ ã‚’æ‰ãˆã‚‹")
    print("  é•·ã•ã‚¹ã‚±ãƒ¼ãƒ« 0.1: ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„")
    print("  é•·ã•ã‚¹ã‚±ãƒ¼ãƒ« 0.3: æ»‘ã‚‰ã‹ã€å¤§åŸŸçš„ãªå‚¾å‘")

<h1>å®Ÿè¡Œ</h1>
compare_hyperparameters()</code></pre>

---

<h2>3.7 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°</h2>

<h3>ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–</h3>

<strong>å•é¡Œ1: æœ€é©åŒ–ãŒå±€æ‰€æœ€é©ã«ã¯ã¾ã‚‹</strong>

<strong>åŸå› </strong>:
- åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒåã£ã¦ã„ã‚‹
- æ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå°ã•ã™ãã‚‹
- ç²å¾—é–¢æ•°ãŒæ´»ç”¨é‡è¦–

<strong>è§£æ±ºç­–</strong>:
<pre><code class="language-python"><h1>1. åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å¢—ã‚„ã™</h1>
n_initial_points = 20  # 10 â†’ 20

<h1>2. UCBã®Îºã‚’å¤§ããã™ã‚‹ï¼ˆæ¢ç´¢é‡è¦–ï¼‰</h1>
kappa = 3.0  # 2.0 â†’ 3.0

<h1>3. ãƒ©ãƒ†ãƒ³è¶…æ–¹æ ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</h1>
from scipy.stats.qmc import LatinHypercube

sampler = LatinHypercube(d=4, seed=42)
X_init_lhs = sampler.random(n=20)  # ã‚ˆã‚Šå‡ç­‰ã«åˆ†å¸ƒ</code></pre>

<strong>å•é¡Œ2: åˆ¶ç´„ã‚’æº€ãŸã™è§£ãŒè¦‹ã¤ã‹ã‚‰ãªã„</strong>

<strong>åŸå› </strong>:
- åˆ¶ç´„ãŒå³ã—ã™ãã‚‹
- å®Ÿè¡Œå¯èƒ½é ˜åŸŸãŒç‹­ã„
- åˆæœŸç‚¹ãŒå®Ÿè¡Œä¸å¯èƒ½é ˜åŸŸã«é›†ä¸­

<strong>è§£æ±ºç­–</strong>:
<pre><code class="language-python"><h1>1. åˆ¶ç´„ç·©å’Œï¼ˆæ®µéšçš„ã«å³ã—ãï¼‰</h1>
<h1>åˆæœŸ: ç·©ã„åˆ¶ç´„ â†’ å¾ã€…ã«å³ã—ã</h1>

<h1>2. å®Ÿè¡Œå¯èƒ½é ˜åŸŸã‚’æ˜ç¤ºçš„ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°</h1>
def sample_feasible_region(n_samples):
    """å®Ÿè¡Œå¯èƒ½é ˜åŸŸã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
    samples = []
    while len(samples) < n_samples:
        x = np.random.rand(4)
        x = x / x.sum()
        if is_feasible(x):  # åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
            samples.append(x)
    return np.array(samples)

<h1>3. Two-stage approach</h1>
<h1>Stage 1: åˆ¶ç´„ãªã—ã§æ¢ç´¢</h1>
<h1>Stage 2: è‰¯ã„é ˜åŸŸã§åˆ¶ç´„ä»˜ãæœ€é©åŒ–</h1></code></pre>

<strong>å•é¡Œ3: è¨ˆç®—æ™‚é–“ãŒé•·ã„</strong>

<strong>åŸå› </strong>:
- ã‚¬ã‚¦ã‚¹éç¨‹ã®è¨ˆç®—é‡: O(nÂ³)
- ç²å¾—é–¢æ•°ã®æœ€é©åŒ–ãŒé…ã„

<strong>è§£æ±ºç­–</strong>:
<pre><code class="language-python"><h1>1. ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚¬ã‚¦ã‚¹éç¨‹</h1>
<h1>ä»£è¡¨ç‚¹ï¼ˆInducing pointsï¼‰ã‚’ä½¿ç”¨</h1>

<h1>2. ç²å¾—é–¢æ•°ã®æœ€é©åŒ–ã‚’ç°¡ç•¥åŒ–</h1>
<h1>ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ â†’ ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒ</h1>
n_candidates = 1000  # å°‘æ•°ã®ãƒ©ãƒ³ãƒ€ãƒ ç‚¹ã‹ã‚‰é¸æŠ

<h1>3. ä¸¦åˆ—è¨ˆç®—ï¼ˆè¤‡æ•°CPUï¼‰</h1>
from joblib import Parallel, delayed

<h1>4. GPUã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆBoTorch + PyTorchï¼‰</h1></code></pre>

---

<h2>3.8 æœ¬ç« ã®ã¾ã¨ã‚</h2>

<h3>å­¦ã‚“ã ã“ã¨</h3>

1. <strong>MLãƒ¢ãƒ‡ãƒ«ã¨ã®çµ±åˆ</strong>
   - Materials Project APIã§ãƒ‡ãƒ¼ã‚¿å–å¾—
   - Random Forestã§ç‰©æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
   - MLãƒ¢ãƒ‡ãƒ«ã‚’ç›®çš„é–¢æ•°ã¨ã—ã¦ãƒ™ã‚¤ã‚ºæœ€é©åŒ–

2. <strong>åˆ¶ç´„ä»˜ãæœ€é©åŒ–</strong>
   - çµ„æˆåˆ¶ç´„ã€å®‰å®šæ€§åˆ¶ç´„ã€ã‚³ã‚¹ãƒˆåˆ¶ç´„
   - åˆ¶ç´„ã‚’æº€ãŸã™ç¢ºç‡ã‚’ç²å¾—é–¢æ•°ã«çµ„ã¿è¾¼ã‚€
   - å®Ÿè¡Œå¯èƒ½é ˜åŸŸã«é›†ä¸­ã—ã¦æ¢ç´¢

3. <strong>å¤šç›®çš„æœ€é©åŒ–</strong>
   - Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã®è¨ˆç®—
   - Expected Hypervolume Improvementï¼ˆEHVIï¼‰
   - ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®å¯è¦–åŒ–ã¨æ„æ€æ±ºå®š

4. <strong>ãƒãƒƒãƒæœ€é©åŒ–</strong>
   - ä¸¦åˆ—å®Ÿé¨“ã«ã‚ˆã‚‹åŠ¹ç‡åŒ–
   - q-EIç²å¾—é–¢æ•°
   - å®Ÿé¨“ã‚³ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸæœ€é©åŒ–æˆ¦ç•¥

5. <strong>å®Ÿä¸–ç•Œå¿œç”¨</strong>
   - Li-ioné›»æ± æ­£æ¥µææ–™ã®å®Œå…¨å®Ÿè£…
   - 3ç›®çš„åŒæ™‚æœ€é©åŒ–
   - å®Ÿé¨“å›æ•°50%å‰Šæ¸›ã®å®Ÿç¾

<h3>é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ</h3>

- âœ… <strong>å®Ÿãƒ‡ãƒ¼ã‚¿ã¨ã®çµ±åˆ</strong>ãŒææ–™æ¢ç´¢ã®éµ
- âœ… <strong>åˆ¶ç´„ã‚’è€ƒæ…®</strong>ã—ãªã„ã¨å®Ÿè¡Œä¸å¯èƒ½ãªææ–™ã‚’ææ¡ˆ
- âœ… <strong>å¤šç›®çš„æœ€é©åŒ–</strong>ã§ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ˜ç¤ºçš„ã«æ‰±ã†
- âœ… <strong>ãƒãƒƒãƒBO</strong>ã§ä¸¦åˆ—å®Ÿé¨“ã®åŠ¹ç‡ã‚’æœ€å¤§åŒ–
- âœ… <strong>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´</strong>ãŒæ€§èƒ½ã‚’å·¦å³

<h3>æ¬¡ã®ç« ã¸</h3>

ç¬¬4ç« ã§ã¯ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å®Ÿé¨“ã¨ã®é€£æºã‚’å­¦ã³ã¾ã™ï¼š
- Uncertainty Sampling
- Query-by-Committee
- ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–
- è‡ªå‹•å®Ÿé¨“è£…ç½®ã¨ã®çµ±åˆ

<strong>[ç¬¬4ç« ï¼šã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å®Ÿé¨“é€£æº â†’](./chapter-4.md)</strong>

---

<h2>æ¼”ç¿’å•é¡Œ</h2>

<h3>å•é¡Œ1ï¼ˆé›£æ˜“åº¦ï¼šeasyï¼‰</h3>

Materials Projectã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€Random Forestãƒ¢ãƒ‡ãƒ«ã§å®¹é‡äºˆæ¸¬ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

<strong>ã‚¿ã‚¹ã‚¯</strong>:
1. <code>generate_dummy_battery_data()</code>ã§100ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆ
2. Random Forestã§è¨“ç·´ï¼ˆ80/20åˆ†å‰²ï¼‰
3. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§RMSEã¨RÂ²ã‚’è¨ˆç®—
4. ç‰¹å¾´é‡é‡è¦åº¦ã‚’ãƒ—ãƒ­ãƒƒãƒˆ

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

- <code>train_test_split()</code>ã§ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
- <code>RandomForestRegressor</code>ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ååˆ†
- <code>feature_importances_</code>å±æ€§ã§é‡è¦åº¦å–å¾—

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

<h1>ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ</h1>
df = generate_dummy_battery_data(n_samples=100)

<h1>ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ</h1>
X = df[['li_content', 'ni_content', 'co_content', 'mn_content']].values
y = df['capacity'].values

<h1>ãƒ‡ãƒ¼ã‚¿åˆ†å‰²</h1>
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

<h1>Random Forestãƒ¢ãƒ‡ãƒ«</h1>
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

<h1>äºˆæ¸¬</h1>
y_pred = rf.predict(X_test)

<h1>è©•ä¾¡</h1>
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print("ãƒ¢ãƒ‡ãƒ«æ€§èƒ½:")
print(f"  RMSE: {rmse:.2f} mAh/g")
print(f"  RÂ²: {r2:.3f}")

<h1>ç‰¹å¾´é‡é‡è¦åº¦</h1>
feature_names = ['Li', 'Ni', 'Co', 'Mn']
importances = rf.feature_importances_

plt.figure(figsize=(8, 5))
plt.barh(feature_names, importances, color='steelblue')
plt.xlabel('é‡è¦åº¦', fontsize=12)
plt.title('ç‰¹å¾´é‡é‡è¦åº¦', fontsize=14)
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()
plt.show()

print("\nç‰¹å¾´é‡é‡è¦åº¦:")
for name, imp in zip(feature_names, importances):
    print(f"  {name}: {imp:.3f}")</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›</strong>:
<pre><code>ãƒ¢ãƒ‡ãƒ«æ€§èƒ½:
  RMSE: 30.12 mAh/g
  RÂ²: 0.892

ç‰¹å¾´é‡é‡è¦åº¦:
  Li: 0.623
  Ni: 0.247
  Co: 0.089
  Mn: 0.041</code></pre>

<strong>è§£èª¬</strong>:
- Liå«é‡ãŒå®¹é‡ã«æœ€ã‚‚å½±éŸ¿ï¼ˆãƒªãƒã‚¦ãƒ ã‚¤ã‚ªãƒ³æºï¼‰
- Niã‚‚é‡è¦ï¼ˆé…¸åŒ–é‚„å…ƒæ´»æ€§ï¼‰
- Co, Mnã¯æ§‹é€ å®‰å®šåŒ–ã®å½¹å‰²

</details>

---

<h3>å•é¡Œ2ï¼ˆé›£æ˜“åº¦ï¼šmediumï¼‰</h3>

åˆ¶ç´„ä»˜ããƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’å®Ÿè£…ã—ã€åˆ¶ç´„ãªã—ã®å ´åˆã¨æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚

<strong>å•é¡Œè¨­å®š</strong>:
- ç›®çš„: å®¹é‡ã‚’æœ€å¤§åŒ–
- åˆ¶ç´„: Coå«é‡ < 0.25ï¼ˆã‚³ã‚¹ãƒˆåˆ¶ç´„ï¼‰

<strong>ã‚¿ã‚¹ã‚¯</strong>:
1. åˆ¶ç´„ãªã—ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’20å›å®Ÿè¡Œ
2. åˆ¶ç´„ä»˜ããƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’20å›å®Ÿè¡Œ
3. å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®æœ€è‰¯å€¤ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
4. æœ€çµ‚çš„ãªæœ€é©çµ„æˆã‚’æ¯”è¼ƒ

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

<strong>åˆ¶ç´„ã®å®Ÿè£…</strong>:
<pre><code class="language-python">def constraint_penalty(x):
    """åˆ¶ç´„é•åã«ãƒšãƒŠãƒ«ãƒ†ã‚£"""
    co_content = x[2]
    if co_content > 0.25:
        return 1000  # å¤§ããªãƒšãƒŠãƒ«ãƒ†ã‚£
    return 0</code></pre>

<strong>ç²å¾—é–¢æ•°ã«çµ„ã¿è¾¼ã‚€</strong>:
<pre><code class="language-python">capacity = rf_model.predict(x)
penalty = constraint_penalty(x)
return -(capacity - penalty)  # æœ€å°åŒ–å•é¡Œ</code></pre>

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python">from skopt import gp_minimize
from skopt.space import Real

<h1>ç›®çš„é–¢æ•°ï¼ˆåˆ¶ç´„ãªã—ï¼‰</h1>
def objective_unconstrained(x):
    """åˆ¶ç´„ãªã—"""
    li, ni, co, mn = x
    total = li + ni + co + mn
    if not (0.98 <= total <= 1.02):
        return 1000.0
    X_pred = np.array([[li, ni, co, mn]])
    capacity = rf_model.predict(X_pred)[0]
    return -capacity  # æœ€å°åŒ–

<h1>ç›®çš„é–¢æ•°ï¼ˆåˆ¶ç´„ä»˜ãï¼‰</h1>
def objective_constrained(x):
    """Coå«é‡ < 0.25ã®åˆ¶ç´„"""
    li, ni, co, mn = x
    total = li + ni + co + mn
    if not (0.98 <= total <= 1.02):
        return 1000.0
    if co > 0.25:  # åˆ¶ç´„é•å
        return 1000.0
    X_pred = np.array([[li, ni, co, mn]])
    capacity = rf_model.predict(X_pred)[0]
    return -capacity

<h1>æ¢ç´¢ç©ºé–“</h1>
space = [
    Real(0.1, 0.5, name='li'),
    Real(0.1, 0.4, name='ni'),
    Real(0.1, 0.4, name='co'),
    Real(0.0, 0.5, name='mn')
]

<h1>åˆ¶ç´„ãªã—</h1>
result_unconstrained = gp_minimize(
    objective_unconstrained, space,
    n_calls=20, n_initial_points=5, random_state=42
)

<h1>åˆ¶ç´„ä»˜ã</h1>
result_constrained = gp_minimize(
    objective_constrained, space,
    n_calls=20, n_initial_points=5, random_state=42
)

<h1>çµæœ</h1>
print("åˆ¶ç´„ãªã—:")
print(f"  æœ€é©çµ„æˆ: Li={result_unconstrained.x[0]:.3f}, "
      f"Ni={result_unconstrained.x[1]:.3f}, "
      f"Co={result_unconstrained.x[2]:.3f}, "
      f"Mn={result_unconstrained.x[3]:.3f}")
print(f"  å®¹é‡: {-result_unconstrained.fun:.2f} mAh/g")

print("\nåˆ¶ç´„ä»˜ã (Co < 0.25):")
print(f"  æœ€é©çµ„æˆ: Li={result_constrained.x[0]:.3f}, "
      f"Ni={result_constrained.x[1]:.3f}, "
      f"Co={result_constrained.x[2]:.3f}, "
      f"Mn={result_constrained.x[3]:.3f}")
print(f"  å®¹é‡: {-result_constrained.fun:.2f} mAh/g")

<h1>å¯è¦–åŒ–</h1>
plt.figure(figsize=(10, 6))
plt.plot(-np.minimum.accumulate(result_unconstrained.func_vals),
         'o-', label='åˆ¶ç´„ãªã—', linewidth=2, markersize=8)
plt.plot(-np.minimum.accumulate(result_constrained.func_vals),
         '^-', label='åˆ¶ç´„ä»˜ã (Co < 0.25)', linewidth=2, markersize=8)
plt.xlabel('è©•ä¾¡å›æ•°', fontsize=12)
plt.ylabel('ã“ã‚Œã¾ã§ã®æœ€è‰¯å€¤ (mAh/g)', fontsize=12)
plt.title('åˆ¶ç´„ä»˜ã vs åˆ¶ç´„ãªã—ãƒ™ã‚¤ã‚ºæœ€é©åŒ–', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›</strong>:
<pre><code>åˆ¶ç´„ãªã—:
  æœ€é©çµ„æˆ: Li=0.487, Ni=0.312, Co=0.352, Mn=0.049
  å®¹é‡: 267.34 mAh/g

åˆ¶ç´„ä»˜ã (Co < 0.25):
  æœ€é©çµ„æˆ: Li=0.492, Ni=0.315, Co=0.248, Mn=0.045
  å®¹é‡: 261.78 mAh/g</code></pre>

<strong>è§£èª¬</strong>:
- åˆ¶ç´„ä»˜ãã¯å®¹é‡ãŒã‚ãšã‹ã«ä½ã„ï¼ˆ2%ä½ä¸‹ï¼‰
- Coå«é‡ã‚’åˆ¶é™ã—ã¦ã‚‚å®Ÿç”¨çš„ãªæ€§èƒ½ã‚’ç¶­æŒ
- ã‚³ã‚¹ãƒˆã¨æ€§èƒ½ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å®šé‡åŒ–

</details>

---

<h3>å•é¡Œ3ï¼ˆé›£æ˜“åº¦ï¼šhardï¼‰</h3>

å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’å®Ÿè£…ã—ã€å®¹é‡ã¨å®‰å®šæ€§ã®Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚

<strong>å•é¡Œè¨­å®š</strong>:
- ç›®çš„1: å®¹é‡ã‚’æœ€å¤§åŒ–
- ç›®çš„2: å®‰å®šæ€§ã‚’æœ€å¤§åŒ–ï¼ˆformation energyã®çµ¶å¯¾å€¤ã‚’æœ€å°åŒ–ï¼‰

<strong>ã‚¿ã‚¹ã‚¯</strong>:
1. åˆæœŸãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆ15ç‚¹ï¼‰
2. é€æ¬¡æœ€é©åŒ–ï¼ˆ30å›ï¼‰
3. Paretoæœ€é©è§£ã‚’æŠ½å‡º
4. Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã‚’å¯è¦–åŒ–
5. ä»£è¡¨çš„ãª3ã¤ã®è§£ï¼ˆå®¹é‡é‡è¦–ã€å®‰å®šæ€§é‡è¦–ã€ãƒãƒ©ãƒ³ã‚¹å‹ï¼‰ã‚’æç¤º

<details>
<summary>ãƒ’ãƒ³ãƒˆ</summary>

<strong>Paretoæœ€é©åˆ¤å®š</strong>:
<pre><code class="language-python">def is_pareto_optimal(Y):
    """
    Y: (n_points, n_objectives)
    å…¨ã¦æœ€å¤§åŒ–å•é¡Œã¨ä»®å®š
    """
    n = len(Y)
    is_optimal = np.ones(n, dtype=bool)
    for i in range(n):
        if is_optimal[i]:
            # iã‚ˆã‚Šå…¨ã¦ã®ç›®çš„ã§å„ªã‚Œã¦ã„ã‚‹ç‚¹
            dominated = ((Y >= Y[i]).all(axis=1) &
                         (Y > Y[i]).any(axis=1))
            is_optimal[dominated] = False
    return is_optimal</code></pre>

<strong>ã‚¹ã‚«ãƒ©ãƒ¼åŒ–ã«ã‚ˆã‚‹è¿‘ä¼¼</strong>:
<pre><code class="language-python"><h1>ãƒ©ãƒ³ãƒ€ãƒ ãªé‡ã¿ã§ã‚¹ã‚«ãƒ©ãƒ¼åŒ–</h1>
w1, w2 = np.random.rand(2)
w1, w2 = w1/(w1+w2), w2/(w1+w2)
objective = w1 * capacity + w2 * stability</code></pre>

</details>

<details>
<summary>è§£ç­”ä¾‹</summary>

<pre><code class="language-python"><h1>å¤šç›®çš„ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ï¼ˆã‚¹ã‚«ãƒ©ãƒ¼åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰</h1>
def multi_objective_optimization():
    """
    å®¹é‡ã¨å®‰å®šæ€§ã®å¤šç›®çš„æœ€é©åŒ–
    """
    # åˆæœŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    n_initial = 15
    np.random.seed(42)

    X_sampled = np.random.rand(n_initial, 4)
    X_sampled = X_sampled / X_sampled.sum(axis=1, keepdims=True)

    # 2ã¤ã®ç›®çš„ã‚’è©•ä¾¡
    Y_capacity = []
    Y_stability = []

    for x in X_sampled:
        capacity = rf_model.predict(x.reshape(1, -1))[0]
        stability = -2.0 - 0.5*x[0] - 0.3*x[1] + 0.1*np.random.randn()
        stability_positive = -stability  # æ­£ã«å¤‰æ›

        Y_capacity.append(capacity)
        Y_stability.append(stability_positive)

    Y_capacity = np.array(Y_capacity)
    Y_stability = np.array(Y_stability)

    # é€æ¬¡æœ€é©åŒ–ï¼ˆã‚¹ã‚«ãƒ©ãƒ¼åŒ–ï¼‰
    n_iterations = 30

    for iteration in range(n_iterations):
        # ãƒ©ãƒ³ãƒ€ãƒ ãªé‡ã¿
        w1 = np.random.rand()
        w2 = 1 - w1

        # æ­£è¦åŒ–
        cap_normalized = (Y_capacity - Y_capacity.min()) / \
                         (Y_capacity.max() - Y_capacity.min())
        sta_normalized = (Y_stability - Y_stability.min()) / \
                         (Y_stability.max() - Y_stability.min())

        # ã‚¹ã‚«ãƒ©ãƒ¼åŒ–ã—ãŸç›®çš„
        Y_scalar = w1 * cap_normalized + w2 * sta_normalized

        # ã‚¬ã‚¦ã‚¹éç¨‹ãƒ¢ãƒ‡ãƒ«
        from sklearn.gaussian_process import GaussianProcessRegressor
        from sklearn.gaussian_process.kernels import RBF, ConstantKernel

        kernel = ConstantKernel(1.0) * RBF(length_scale=0.2)
        gp = GaussianProcessRegressor(kernel=kernel,
                                       n_restarts_optimizer=10,
                                       random_state=42)
        gp.fit(X_sampled, Y_scalar)

        # ç²å¾—é–¢æ•°ï¼ˆEIï¼‰
        best_f = Y_scalar.max()
        X_candidates = np.random.rand(1000, 4)
        X_candidates = X_candidates / X_candidates.sum(axis=1, keepdims=True)

        mu, sigma = gp.predict(X_candidates, return_std=True)
        improvement = mu - best_f
        Z = improvement / (sigma + 1e-9)
        ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)

        # æ¬¡ã®å€™è£œ
        next_idx = np.argmax(ei)
        x_new = X_candidates[next_idx]

        # è©•ä¾¡
        capacity_new = rf_model.predict(x_new.reshape(1, -1))[0]
        stability_new = -2.0 - 0.5*x_new[0] - 0.3*x_new[1] + \
                        0.1*np.random.randn()
        stability_positive_new = -stability_new

        # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        X_sampled = np.vstack([X_sampled, x_new])
        Y_capacity = np.append(Y_capacity, capacity_new)
        Y_stability = np.append(Y_stability, stability_positive_new)

    # Paretoæœ€é©è§£ã‚’æŠ½å‡º
    Y_combined = np.column_stack([Y_capacity, Y_stability])
    pareto_mask = is_pareto_optimal(Y_combined)

    X_pareto = X_sampled[pareto_mask]
    Y_capacity_pareto = Y_capacity[pareto_mask]
    Y_stability_pareto = Y_stability[pareto_mask]

    print(f"Paretoæœ€é©è§£æ•°: {pareto_mask.sum()}")

    # å¯è¦–åŒ–
    plt.figure(figsize=(10, 6))

    plt.scatter(Y_capacity, Y_stability, c='lightblue', s=50,
                alpha=0.5, label='å…¨æ¢ç´¢ç‚¹')
    plt.scatter(Y_capacity_pareto, Y_stability_pareto, c='red',
                s=100, edgecolors='black', zorder=10,
                label='Paretoæœ€é©è§£')

    # Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã‚’ç·šã§çµã¶
    sorted_indices = np.argsort(Y_capacity_pareto)
    plt.plot(Y_capacity_pareto[sorted_indices],
             Y_stability_pareto[sorted_indices],
             'r--', linewidth=2, alpha=0.5)

    plt.xlabel('å®¹é‡ (mAh/g)', fontsize=12)
    plt.ylabel('å®‰å®šæ€§ (-formation energy)', fontsize=12)
    plt.title('Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢: å®¹é‡ vs å®‰å®šæ€§', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('pareto_frontier_exercise.png', dpi=150,
                bbox_inches='tight')
    plt.show()

    # ä»£è¡¨çš„ãªè§£
    print("\nä»£è¡¨çš„ãªParetoè§£:")

    # å®¹é‡é‡è¦–
    idx_max_cap = np.argmax(Y_capacity_pareto)
    print(f"\nå®¹é‡é‡è¦–:")
    print(f"  çµ„æˆ: {X_pareto[idx_max_cap]}")
    print(f"  å®¹é‡={Y_capacity_pareto[idx_max_cap]:.1f}, "
          f"å®‰å®šæ€§={Y_stability_pareto[idx_max_cap]:.2f}")

    # å®‰å®šæ€§é‡è¦–
    idx_max_sta = np.argmax(Y_stability_pareto)
    print(f"\nå®‰å®šæ€§é‡è¦–:")
    print(f"  çµ„æˆ: {X_pareto[idx_max_sta]}")
    print(f"  å®¹é‡={Y_capacity_pareto[idx_max_sta]:.1f}, "
          f"å®‰å®šæ€§={Y_stability_pareto[idx_max_sta]:.2f}")

    # ãƒãƒ©ãƒ³ã‚¹å‹
    normalized = (Y_combined[pareto_mask] - Y_combined[pareto_mask].min(axis=0)) / \
                 (Y_combined[pareto_mask].max(axis=0) - Y_combined[pareto_mask].min(axis=0))
    distances = np.sqrt(((normalized - 0.5)**2).sum(axis=1))
    idx_balanced = np.argmin(distances)
    print(f"\nãƒãƒ©ãƒ³ã‚¹å‹:")
    print(f"  çµ„æˆ: {X_pareto[idx_balanced]}")
    print(f"  å®¹é‡={Y_capacity_pareto[idx_balanced]:.1f}, "
          f"å®‰å®šæ€§={Y_stability_pareto[idx_balanced]:.2f}")

<h1>Paretoæœ€é©åˆ¤å®š</h1>
def is_pareto_optimal(Y):
    """Paretoæœ€é©è§£ã‚’åˆ¤å®š"""
    n = len(Y)
    is_optimal = np.ones(n, dtype=bool)
    for i in range(n):
        if is_optimal[i]:
            dominated = ((Y >= Y[i]).all(axis=1) &
                         (Y > Y[i]).any(axis=1))
            is_optimal[dominated] = False
    return is_optimal

<h1>å®Ÿè¡Œ</h1>
multi_objective_optimization()</code></pre>

<strong>æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›</strong>:
<pre><code>Paretoæœ€é©è§£æ•°: 12

ä»£è¡¨çš„ãªParetoè§£:

å®¹é‡é‡è¦–:
  çµ„æˆ: [0.492 0.315 0.152 0.041]
  å®¹é‡=267.3, å®‰å®šæ€§=1.82

å®‰å®šæ€§é‡è¦–:
  çµ„æˆ: [0.352 0.248 0.185 0.215]
  å®¹é‡=215.7, å®‰å®šæ€§=2.15

ãƒãƒ©ãƒ³ã‚¹å‹:
  çµ„æˆ: [0.428 0.285 0.168 0.119]
  å®¹é‡=243.5, å®‰å®šæ€§=1.98</code></pre>

<strong>è©³ç´°ãªè§£èª¬</strong>:

1. <strong>ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®å®šé‡åŒ–</strong>:
   - å®¹é‡â†‘ â†’ å®‰å®šæ€§â†“ ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒæ˜ç¢º
   - Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ãŒãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®å¢ƒç•Œã‚’ç¤ºã™

2. <strong>æ„æ€æ±ºå®šã¸ã®æ´»ç”¨</strong>:
   - ç”¨é€”ã«å¿œã˜ãŸæœ€é©çµ„æˆã‚’é¸æŠ
   - é«˜å®¹é‡ç”¨é€”: å®¹é‡é‡è¦–ã®è§£
   - é•·å¯¿å‘½ç”¨é€”: å®‰å®šæ€§é‡è¦–ã®è§£

3. <strong>å®Ÿç”¨çš„ç¤ºå”†</strong>:
   - å˜ä¸€ç›®çš„æœ€é©åŒ–ã§ã¯è¦‹é€ƒã•ã‚Œã‚‹è§£ã‚’ç™ºè¦‹
   - è¨­è¨ˆè€…ã®é¸æŠè‚¢ã‚’åºƒã’ã‚‹
   - è¤‡æ•°ã®æœ€é©è§£å€™è£œã‚’æç¤º

4. <strong>æ”¹å–„ç‚¹</strong>:
   - EHVIï¼ˆExpected Hypervolume Improvementï¼‰ã®ä½¿ç”¨
   - 3ç›®çš„ä»¥ä¸Šã¸ã®æ‹¡å¼µ
   - ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ãŸãƒ­ãƒã‚¹ãƒˆæœ€é©åŒ–

</details>

---

<h2>å‚è€ƒæ–‡çŒ®</h2>

1. Frazier, P. I. & Wang, J. (2016). "Bayesian Optimization for Materials Design." *Information Science for Materials Discovery and Design*, 45-75.
   DOI: [10.1007/978-3-319-23871-5_3](https://doi.org/10.1007/978-3-319-23871-5_3)

2. Lookman, T. et al. (2019). "Active learning in materials science with emphasis on adaptive sampling using uncertainties for targeted design." *npj Computational Materials*, 5(1), 21.
   DOI: [10.1038/s41524-019-0153-8](https://doi.org/10.1038/s41524-019-0153-8)

3. Balandat, M. et al. (2020). "BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization." *NeurIPS 2020*.
   [arXiv:1910.06403](https://arxiv.org/abs/1910.06403)

4. Daulton, S. et al. (2020). "Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization." *NeurIPS 2020*.
   [arXiv:2006.05078](https://arxiv.org/abs/2006.05078)

5. Jain, A. et al. (2013). "Commentary: The Materials Project: A materials genome approach to accelerating materials innovation." *APL Materials*, 1(1), 011002.
   DOI: [10.1063/1.4812323](https://doi.org/10.1063/1.4812323)

6. Pedregosa, F. et al. (2011). "Scikit-learn: Machine Learning in Python." *Journal of Machine Learning Research*, 12, 2825-2830.

---

<h2>ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³</h2>

<h3>å‰ã®ç« </h3>
<strong>[â† ç¬¬2ç« ï¼šãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®ç†è«–](./chapter-2.md)</strong>

<h3>æ¬¡ã®ç« </h3>
<strong>[ç¬¬4ç« ï¼šã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å®Ÿé¨“é€£æº â†’](./chapter-4.md)</strong>

<h3>ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡</h3>
<strong>[â† ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹](./index.md)</strong>

---

<h2>è‘—è€…æƒ…å ±</h2>

<strong>ä½œæˆè€…</strong>: AI Terakoya Content Team
<strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰
<strong>ä½œæˆæ—¥</strong>: 2025-10-17
<strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0

<strong>æ›´æ–°å±¥æ­´</strong>:
- 2025-10-17: v1.0 åˆç‰ˆå…¬é–‹

<strong>ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯</strong>:
- GitHub Issues: [AI_Homepage/issues](https://github.com/your-repo/AI_Homepage/issues)
- Email: yusuke.hashimoto.b8@tohoku.ac.jp

<strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0

---

<strong>å®Ÿè·µçš„ãªå®Ÿè£…ã‚’ãƒã‚¹ã‚¿ãƒ¼ã—ã¾ã—ãŸï¼æ¬¡ç« ã§å®Ÿé¨“é€£æºã‚’å­¦ã³ã¾ã—ã‚‡ã†ï¼</strong>
<div class="navigation">
    <a href="chapter-2.html" class="nav-button">â† ç¬¬2ç« </a>
    <a href="index.html" class="nav-button">ã‚·ãƒªãƒ¼ã‚ºç›®æ¬¡ã«æˆ»ã‚‹</a>
    <a href="chapter-4.html" class="nav-button">ç¬¬4ç«  â†’</a>
</div>
    </main>

    <footer>
        <p><strong>ä½œæˆè€…</strong>: AI Terakoya Content Team</p>
        <p><strong>ç›£ä¿®</strong>: Dr. Yusuke Hashimotoï¼ˆæ±åŒ—å¤§å­¦ï¼‰</p>
        <p><strong>ãƒãƒ¼ã‚¸ãƒ§ãƒ³</strong>: 1.0 | <strong>ä½œæˆæ—¥</strong>: 2025-10-17</p>
        <p><strong>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹</strong>: Creative Commons BY 4.0</p>
        <p>Â© 2025 AI Terakoya. All rights reserved.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default'
                });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</body>
</html>
