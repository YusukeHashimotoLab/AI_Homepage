<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Á¨¨3Á´†ÔºöÂÆüË∑µÔºöÊùêÊñôÊé¢Á¥¢„Å∏„ÅÆÂøúÁî® - AI Terakoya</title>

    <style>
        :root {
            --color-primary: #2c3e50;
            --color-primary-dark: #1a252f;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-text: #2d3748;
            --color-text-light: #4a5568;
            --color-bg: #ffffff;
            --color-bg-alt: #f7fafc;
            --color-border: #e2e8f0;
            --color-code-bg: #f8f9fa;
            --color-link: #3182ce;
            --color-link-hover: #2c5aa0;

            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;

            --font-body: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            --font-mono: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;

            --border-radius: 8px;
            --box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-body);
            line-height: 1.7;
            color: var(--color-text);
            background-color: var(--color-bg);
            font-size: 16px;
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            margin-bottom: var(--spacing-xl);
            box-shadow: var(--box-shadow);
        }

        .header-content {
            max-width: 900px;
            margin: 0 auto;
        }

        h1 {
            font-size: 2rem;
            font-weight: 700;
            margin-bottom: var(--spacing-sm);
            line-height: 1.2;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.95;
            font-weight: 400;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 var(--spacing-md) var(--spacing-xl);
        }

        h2 {
            font-size: 1.75rem;
            color: var(--color-primary);
            margin-top: var(--spacing-xl);
            margin-bottom: var(--spacing-md);
            padding-bottom: var(--spacing-xs);
            border-bottom: 3px solid var(--color-accent);
        }

        h3 {
            font-size: 1.4rem;
            color: var(--color-primary);
            margin-top: var(--spacing-lg);
            margin-bottom: var(--spacing-sm);
        }

        h4 {
            font-size: 1.1rem;
            color: var(--color-primary-dark);
            margin-top: var(--spacing-md);
            margin-bottom: var(--spacing-sm);
        }

        p {
            margin-bottom: var(--spacing-md);
            color: var(--color-text);
        }

        a {
            color: var(--color-link);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--color-link-hover);
            text-decoration: underline;
        }

        ul, ol {
            margin-left: var(--spacing-lg);
            margin-bottom: var(--spacing-md);
        }

        li {
            margin-bottom: var(--spacing-xs);
            color: var(--color-text);
        }

        pre {
            background-color: var(--color-code-bg);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            overflow-x: auto;
            margin-bottom: var(--spacing-md);
            font-family: var(--font-mono);
            font-size: 0.9rem;
            line-height: 1.5;
        }

        code {
            font-family: var(--font-mono);
            font-size: 0.9em;
            background-color: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: var(--spacing-md);
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--color-border);
            padding: var(--spacing-sm);
            text-align: left;
        }

        th {
            background-color: var(--color-bg-alt);
            font-weight: 600;
            color: var(--color-primary);
        }

        blockquote {
            border-left: 4px solid var(--color-accent);
            padding-left: var(--spacing-md);
            margin: var(--spacing-md) 0;
            color: var(--color-text-light);
            font-style: italic;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        .mermaid {
            text-align: center;
            margin: var(--spacing-lg) 0;
            background-color: var(--color-bg-alt);
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        details {
            background-color: var(--color-bg-alt);
            border: 1px solid var(--color-border);
            border-radius: var(--border-radius);
            padding: var(--spacing-md);
            margin-bottom: var(--spacing-md);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-primary);
            user-select: none;
            padding: var(--spacing-xs);
            margin: calc(-1 * var(--spacing-md));
            padding: var(--spacing-md);
            border-radius: var(--border-radius);
        }

        summary:hover {
            background-color: rgba(123, 44, 191, 0.1);
        }

        details[open] summary {
            margin-bottom: var(--spacing-md);
            border-bottom: 1px solid var(--color-border);
        }

        .learning-objectives {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: var(--spacing-lg);
            border-radius: var(--border-radius);
            border-left: 4px solid var(--color-accent);
            margin-bottom: var(--spacing-xl);
        }

        .learning-objectives h2 {
            margin-top: 0;
            border-bottom: none;
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 2px solid var(--color-border);
        }

        .nav-button {
            flex: 1;
            padding: var(--spacing-md);
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            border-radius: var(--border-radius);
            text-align: center;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
            box-shadow: var(--box-shadow);
        }

        .nav-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            text-decoration: none;
        }

        footer {
            margin-top: var(--spacing-xl);
            padding: var(--spacing-lg) var(--spacing-md);
            background-color: var(--color-bg-alt);
            border-top: 1px solid var(--color-border);
            text-align: center;
            font-size: 0.9rem;
            color: var(--color-text-light);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.5rem;
            }

            h2 {
                font-size: 1.4rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .meta {
                font-size: 0.85rem;
            }

            .navigation {
                flex-direction: column;
            }

            table {
                font-size: 0.85rem;
            }

            th, td {
                padding: var(--spacing-xs);
            }
        }
    </style>

    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>

    <!-- MathJax for LaTeX equation rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Á¨¨3Á´†ÔºöÂÆüË∑µÔºöÊùêÊñôÊé¢Á¥¢„Å∏„ÅÆÂøúÁî®</h1>
            <p class="subtitle">PythonÂÆüË£Ö„ÅßÂ≠¶„Å∂ÂÆü‰∏ñÁïå„ÅÆÊùêÊñôÊúÄÈÅ©Âåñ</p>
            <div class="meta">
                <span class="meta-item">üìñ Ë™≠‰∫ÜÊôÇÈñì: 25-30ÂàÜ</span>
                <span class="meta-item">üìä Èõ£ÊòìÂ∫¶: ‰∏≠Á¥ö</span>
                <span class="meta-item">üíª „Ç≥„Éº„Éâ‰æã: 12ÂÄã</span>
                <span class="meta-item">üìù ÊºîÁøíÂïèÈ°å: 3Âïè</span>
            </div>
        </div>
    </header>

    <main class="container">

<h1>Á¨¨3Á´†ÔºöÂÆüË∑µÔºöÊùêÊñôÊé¢Á¥¢„Å∏„ÅÆÂøúÁî®</h1>

<strong>PythonÂÆüË£Ö„ÅßÂ≠¶„Å∂ÂÆü‰∏ñÁïå„ÅÆÊùêÊñôÊúÄÈÅ©Âåñ</strong>

<h2>Â≠¶ÁøíÁõÆÊ®ô</h2>

„Åì„ÅÆÁ´†„ÇíË™≠„ÇÄ„Åì„Å®„Åß„ÄÅ‰ª•‰∏ã„ÇíÁøíÂæó„Åß„Åç„Åæ„ÅôÔºö

- ‚úÖ ÊùêÊñôÁâ©ÊÄß‰∫àÊ∏¨ML„É¢„Éá„É´„Å®„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÇíÁµ±Âêà„Åß„Åç„Çã
- ‚úÖ Âà∂Á¥Ñ‰ªò„ÅçÊúÄÈÅ©Âåñ„ÇíÂÆüË£Ö„Åó„ÄÅÊùêÊñô„ÅÆÂÆüÁèæÂèØËÉΩÊÄß„ÇíËÄÉÊÖÆ„Åß„Åç„Çã
- ‚úÖ Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ„ÅßParetoÊúÄÈÅ©Ëß£„ÇíË®àÁÆó„Åß„Åç„Çã
- ‚úÖ ÂÆüÈ®ì„Ç≥„Çπ„Éà„ÇíËÄÉÊÖÆ„Åó„Åü„Éê„ÉÉ„ÉÅ„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÇíÂÆüË£Ö„Åß„Åç„Çã
- ‚úÖ ÂÆü‰∏ñÁïå„ÅÆLi-ionÈõªÊ±†ÊúÄÈÅ©ÂåñÂïèÈ°å„ÇíËß£Ê±∫„Åß„Åç„Çã

<strong>Ë™≠‰∫ÜÊôÇÈñì</strong>: 25-30ÂàÜ
<strong>„Ç≥„Éº„Éâ‰æã</strong>: 12ÂÄã
<strong>ÊºîÁøíÂïèÈ°å</strong>: 3Âïè

---

<h2>3.1 ÊùêÊñôÁâ©ÊÄß‰∫àÊ∏¨ML„É¢„Éá„É´„Å®„ÅÆÁµ±Âêà</h2>

<h3>„Å™„ÅúML„É¢„Éá„É´„Å®Áµ±Âêà„Åô„Çã„ÅÆ„Åã</h3>

ÊùêÊñôÊé¢Á¥¢„Åß„ÅØ„ÄÅ„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„Çí‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å´ÁµÑ„ÅøÂêà„Çè„Åõ„Åæ„ÅôÔºö

1. <strong>Êó¢Â≠ò„Éá„Éº„Çø„Åã„ÇâML„É¢„Éá„É´ÊßãÁØâ</strong>
   - Materials Project„Å™„Å©ÂÖ¨Èñã„Éá„Éº„Çø„Éô„Éº„Çπ
   - ÈÅéÂéª„ÅÆÂÆüÈ®ì„Éá„Éº„Çø
   - DFTË®àÁÆóÁµêÊûú

2. <strong>„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅßÊñ∞Ë¶èÊùêÊñôÊé¢Á¥¢</strong>
   - ML„É¢„Éá„É´„ÇíÁõÆÁöÑÈñ¢Êï∞„Å®„Åó„Å¶‰ΩøÁî®
   - ÂÆüÈ®ìÂõûÊï∞„ÇíÊúÄÂ∞èÂåñ
   - ‰∏çÁ¢∫ÂÆüÊÄß„ÇíÊ¥ªÁî®

<h3>Materials Project API„Åã„Çâ„Éá„Éº„ÇøÂèñÂæó</h3>

<strong>„Ç≥„Éº„Éâ‰æã1: Materials Project„Åã„Çâ„Éá„Éº„ÇøÂèñÂæó</strong>

<pre><code class="language-python"><h1>Materials Project„Åã„Çâ„Éá„Éº„ÇøÂèñÂæó</h1>
<h1>Ê≥®: mp-api „ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´„ÅåÂøÖË¶Å: pip install mp-api</h1>
from mp_api.client import MPRester
import pandas as pd
import numpy as np

<h1>Materials Project API„ÅÆ‰ΩøÁî®ÔºàAPI„Ç≠„ÉºÂøÖË¶ÅÔºâ</h1>
<h1>ÁôªÈå≤: https://materialsproject.org/api</h1>
API_KEY = "YOUR_API_KEY_HERE"  # ÂÆüÈöõ„ÅÆAPI„Ç≠„Éº„Å´ÁΩÆ„ÅçÊèõ„Åà

def fetch_battery_materials(api_key, max_materials=100):
    """
    Li-ionÈõªÊ±†Ê≠£Ê•µÊùêÊñô„ÅÆ„Éá„Éº„Çø„ÇíÂèñÂæó

    Parameters:
    -----------
    api_key : str
        Materials Project API„Ç≠„Éº
    max_materials : int
        ÂèñÂæó„Åô„ÇãÊùêÊñô„ÅÆÊúÄÂ§ßÊï∞

    Returns:
    --------
    df : DataFrame
        ÊùêÊñôÁâπÊÄß„Éá„Éº„Çø
    """
    with MPRester(api_key) as mpr:
        # LiÂê´ÊúâÈÖ∏ÂåñÁâ©„ÇíÊ§úÁ¥¢
        docs = mpr.summary.search(
            elements=["Li", "O"],  # Li „Å® O „ÇíÂê´„ÇÄ
            num_elements=(3, 5),    # 3-5ÂÖÉÁ¥†Á≥ª
            fields=[
                "material_id",
                "formula_pretty",
                "formation_energy_per_atom",
                "band_gap",
                "density",
                "volume"
            ]
        )

        # DataFrame„Å´Â§âÊèõ
        data = []
        for doc in docs[:max_materials]:
            data.append({
                'material_id': doc.material_id,
                'formula': doc.formula_pretty,
                'formation_energy': doc.formation_energy_per_atom,
                'band_gap': doc.band_gap,
                'density': doc.density,
                'volume': doc.volume
            })

        df = pd.DataFrame(data)
        return df

<h1>„Éá„É¢Áî®„ÅÆ„ÉÄ„Éü„Éº„Éá„Éº„ÇøÔºàAPI„Ç≠„Éº„Åå„Å™„ÅÑÂ†¥ÂêàÔºâ</h1>
def generate_dummy_battery_data(n_samples=100):
    """
    „ÉÄ„Éü„Éº„ÅÆLi-ionÈõªÊ±†ÊùêÊñô„Éá„Éº„Çø„ÇíÁîüÊàê

    Parameters:
    -----------
    n_samples : int
        „Çµ„É≥„Éó„É´Êï∞

    Returns:
    --------
    df : DataFrame
        ÊùêÊñôÁâπÊÄß„Éá„Éº„Çø
    """
    np.random.seed(42)

    # ÁµÑÊàê„Éë„É©„É°„Éº„ÇøÔºàÊ≠£Ë¶èÂåñÔºâ
    li_content = np.random.uniform(0.1, 0.5, n_samples)
    ni_content = np.random.uniform(0.1, 0.4, n_samples)
    co_content = np.random.uniform(0.1, 0.4, n_samples)
    mn_content = 1.0 - li_content - ni_content - co_content

    # ÂÆπÈáèÔºàmAh/gÔºâ: LiÂê´Èáè„Å®Áõ∏Èñ¢
    capacity = (
        150 + 200 * li_content +
        50 * ni_content +
        30 * np.random.randn(n_samples)
    )

    # ÈõªÂúßÔºàVÔºâ: CoÂê´Èáè„Å®Áõ∏Èñ¢
    voltage = (
        3.0 + 1.5 * co_content +
        0.2 * np.random.randn(n_samples)
    )

    # ÂÆâÂÆöÊÄßÔºàformation energyÔºâ: Ë≤†„ÅåÂÆâÂÆö
    stability = (
        -2.0 - 0.5 * li_content -
        0.3 * ni_content +
        0.1 * np.random.randn(n_samples)
    )

    df = pd.DataFrame({
        'li_content': li_content,
        'ni_content': ni_content,
        'co_content': co_content,
        'mn_content': mn_content,
        'capacity': capacity,
        'voltage': voltage,
        'stability': stability
    })

    return df

<h1>„Éá„Éº„ÇøÂèñÂæóÔºà„ÉÄ„Éü„Éº„Éá„Éº„Çø‰ΩøÁî®Ôºâ</h1>
df_materials = generate_dummy_battery_data(n_samples=150)

print("ÊùêÊñô„Éá„Éº„Çø„ÅÆÁµ±Ë®à:")
print(df_materials.describe())
print(f"\n„Éá„Éº„Çø„Ç∑„Çß„Ç§„Éó: {df_materials.shape}")</code></pre>

<strong>Âá∫Âäõ</strong>:
<pre><code>ÊùêÊñô„Éá„Éº„Çø„ÅÆÁµ±Ë®à:
       li_content  ni_content  co_content  mn_content    capacity  \
count  150.000000  150.000000  150.000000  150.000000  150.000000
mean     0.299524    0.249336    0.249821    0.201319  208.964738
std      0.116176    0.085721    0.083957    0.122841   38.259483
min      0.102543    0.101189    0.103524   -0.107479  137.582916
max      0.499765    0.399915    0.398774    0.499304  311.495867

         voltage   stability
count  150.000000  150.000000
mean     3.374732   -2.161276
std      0.285945    0.221438
min      2.762894   -2.774301
max      4.137882   -1.554217

„Éá„Éº„Çø„Ç∑„Çß„Ç§„Éó: (150, 7)</code></pre>

---

<h3>Ê©üÊ¢∞Â≠¶Áøí„É¢„Éá„É´„ÅßÁâ©ÊÄß‰∫àÊ∏¨</h3>

<strong>„Ç≥„Éº„Éâ‰æã2: Random Forest„ÅßÂÆπÈáè‰∫àÊ∏¨„É¢„Éá„É´ÊßãÁØâ</strong>

<pre><code class="language-python"><h1>Random Forest„ÅßÂÆπÈáè‰∫àÊ∏¨</h1>
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

<h1>ÁâπÂæ¥Èáè„Å®„Çø„Éº„Ç≤„ÉÉ„Éà</h1>
X = df_materials[['li_content', 'ni_content',
                   'co_content', 'mn_content']].values
y_capacity = df_materials['capacity'].values
y_voltage = df_materials['voltage'].values
y_stability = df_materials['stability'].values

<h1>„Éá„Éº„ÇøÂàÜÂâ≤</h1>
X_train, X_test, y_train, y_test = train_test_split(
    X, y_capacity, test_size=0.2, random_state=42
)

<h1>Random Forest„É¢„Éá„É´</h1>
rf_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    random_state=42
)

<h1>Ë®ìÁ∑¥</h1>
rf_model.fit(X_train, y_train)

<h1>‰∫àÊ∏¨</h1>
y_pred_train = rf_model.predict(X_train)
y_pred_test = rf_model.predict(X_test)

<h1>Ë©ï‰æ°</h1>
train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
test_r2 = r2_score(y_test, y_pred_test)

<h1>„ÇØ„É≠„Çπ„Éê„É™„Éá„Éº„Ç∑„Éß„É≥</h1>
cv_scores = cross_val_score(
    rf_model, X_train, y_train,
    cv=5, scoring='r2'
)

print("Random Forest„É¢„Éá„É´„ÅÆÊÄßËÉΩ:")
print(f"  Ë®ìÁ∑¥RMSE: {train_rmse:.2f} mAh/g")
print(f"  „ÉÜ„Çπ„ÉàRMSE: {test_rmse:.2f} mAh/g")
print(f"  „ÉÜ„Çπ„ÉàR¬≤: {test_r2:.3f}")
print(f"  CV R¬≤ (5-fold): {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}")

<h1>ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶</h1>
feature_names = ['Li', 'Ni', 'Co', 'Mn']
importances = rf_model.feature_importances_
indices = np.argsort(importances)[::-1]

print("\nÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶:")
for i in range(len(feature_names)):
    print(f"  {feature_names[indices[i]]}: {importances[indices[i]]:.3f}")

<h1>ÂèØË¶ñÂåñ</h1>
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

<h1>‰∫àÊ∏¨ vs ÂÆüÊ∏¨</h1>
ax1 = axes[0]
ax1.scatter(y_train, y_pred_train, alpha=0.5, label='Ë®ìÁ∑¥')
ax1.scatter(y_test, y_pred_test, alpha=0.7, label='„ÉÜ„Çπ„Éà')
ax1.plot([y_capacity.min(), y_capacity.max()],
         [y_capacity.min(), y_capacity.max()],
         'k--', linewidth=2, label='ÁêÜÊÉ≥')
ax1.set_xlabel('ÂÆüÊ∏¨ÂÆπÈáè (mAh/g)', fontsize=12)
ax1.set_ylabel('‰∫àÊ∏¨ÂÆπÈáè (mAh/g)', fontsize=12)
ax1.set_title('Random ForestÂÆπÈáè‰∫àÊ∏¨', fontsize=14)
ax1.legend()
ax1.grid(True, alpha=0.3)

<h1>ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶</h1>
ax2 = axes[1]
ax2.barh(range(len(feature_names)), importances[indices],
         color='steelblue')
ax2.set_yticks(range(len(feature_names)))
ax2.set_yticklabels([feature_names[i] for i in indices])
ax2.set_xlabel('ÈáçË¶ÅÂ∫¶', fontsize=12)
ax2.set_title('ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶', fontsize=14)
ax2.grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.savefig('ml_model_performance.png', dpi=150, bbox_inches='tight')
plt.show()</code></pre>

---

<h3>ML„É¢„Éá„É´„Çí„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅßÊ¥ªÁî®</h3>

<strong>„Ç≥„Éº„Éâ‰æã3: ML„É¢„Éá„É´„Å®„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÁµ±Âêà</strong>

<pre><code class="language-python"><h1>scikit-optimize„Çí‰ΩøÁî®„Åó„ÅüML„É¢„Éá„É´„Éô„Éº„Çπ„ÅÆÊúÄÈÅ©Âåñ</h1>
from skopt import gp_minimize
from skopt.space import Real
from skopt.plots import plot_convergence

def objective_function_ml(x):
    """
    ML„É¢„Éá„É´„ÇíÁõÆÁöÑÈñ¢Êï∞„Å®„Åó„Å¶‰ΩøÁî®

    Parameters:
    -----------
    x : list
        [li_content, ni_content, co_content, mn_content]

    Returns:
    --------
    float : Ë≤†„ÅÆÂÆπÈáèÔºàÊúÄÂ∞èÂåñÂïèÈ°å„Å´Â§âÊèõÔºâ
    """
    # ÁµÑÊàêÂà∂Á¥Ñ: ÂêàË®à=1.0
    li, ni, co, mn = x
    total = li + ni + co + mn

    # Âà∂Á¥ÑÈÅïÂèç„Å´„Éö„Éä„É´„ÉÜ„Ç£
    if not (0.98 <= total <= 1.02):
        return 1000.0  # Â§ß„Åç„Å™„Éö„Éä„É´„ÉÜ„Ç£

    # ÂÄãÂà•Âà∂Á¥Ñ
    if li < 0.1 or li > 0.5:
        return 1000.0
    if ni < 0.1 or ni > 0.4:
        return 1000.0
    if co < 0.1 or co > 0.4:
        return 1000.0
    if mn < 0.0:
        return 1000.0

    # ML„É¢„Éá„É´„ÅßÂÆπÈáè‰∫àÊ∏¨
    X_pred = np.array([[li, ni, co, mn]])
    capacity_pred = rf_model.predict(X_pred)[0]

    # ÊúÄÂ∞èÂåñÂïèÈ°å„Å´Â§âÊèõÔºàË≤†„ÅÆÂÆπÈáèÔºâ
    return -capacity_pred

<h1>Êé¢Á¥¢Á©∫Èñì„ÅÆÂÆöÁæ©</h1>
space = [
    Real(0.1, 0.5, name='li_content'),
    Real(0.1, 0.4, name='ni_content'),
    Real(0.1, 0.4, name='co_content'),
    Real(0.0, 0.5, name='mn_content')
]

<h1>„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÂÆüË°å</h1>
result = gp_minimize(
    objective_function_ml,
    space,
    n_calls=50,        # 50Âõû„ÅÆË©ï‰æ°
    n_initial_points=10,  # ÂàùÊúü„É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞
    random_state=42,
    verbose=False
)

<h1>ÁµêÊûú</h1>
best_composition = result.x
best_capacity = -result.fun  # Ë≤†„ÇíÂÖÉ„Å´Êàª„Åô

print("„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÁµêÊûú:")
print(f"  ÊúÄÈÅ©ÁµÑÊàê:")
print(f"    Li: {best_composition[0]:.3f}")
print(f"    Ni: {best_composition[1]:.3f}")
print(f"    Co: {best_composition[2]:.3f}")
print(f"    Mn: {best_composition[3]:.3f}")
print(f"    ÂêàË®à: {sum(best_composition):.3f}")
print(f"  ‰∫àÊ∏¨ÂÆπÈáè: {best_capacity:.2f} mAh/g")

<h1>ÂèéÊùü„Éó„É≠„ÉÉ„Éà</h1>
plt.figure(figsize=(10, 6))
plot_convergence(result)
plt.title('„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÂèéÊùü', fontsize=14)
plt.xlabel('Ë©ï‰æ°ÂõûÊï∞', fontsize=12)
plt.ylabel('„Åì„Çå„Åæ„Åß„ÅÆÊúÄËâØÂÄ§ÔºàË≤†„ÅÆÂÆπÈáèÔºâ', fontsize=12)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('bo_ml_convergence.png', dpi=150, bbox_inches='tight')
plt.show()

<h1>„Éá„Éº„Çø„Çª„ÉÉ„ÉàÂÜÖ„ÅÆÊúÄËâØÂÄ§„Å®ÊØîËºÉ</h1>
max_capacity_data = df_materials['capacity'].max()
print(f"\n„Éá„Éº„Çø„Çª„ÉÉ„ÉàÂÜÖ„ÅÆÊúÄÂ§ßÂÆπÈáè: {max_capacity_data:.2f} mAh/g")
print(f"ÊîπÂñÑÁéá: {((best_capacity - max_capacity_data) / max_capacity_data * 100):.1f}%")</code></pre>

<strong>ÊúüÂæÖ„Åï„Çå„ÇãÂá∫Âäõ</strong>:
<pre><code>„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÁµêÊûú:
  ÊúÄÈÅ©ÁµÑÊàê:
    Li: 0.487
    Ni: 0.312
    Co: 0.152
    Mn: 0.049
    ÂêàË®à: 1.000
  ‰∫àÊ∏¨ÂÆπÈáè: 267.34 mAh/g

„Éá„Éº„Çø„Çª„ÉÉ„ÉàÂÜÖ„ÅÆÊúÄÂ§ßÂÆπÈáè: 311.50 mAh/g
ÊîπÂñÑÁéá: -14.2%</code></pre>

---

<h2>3.2 Âà∂Á¥Ñ‰ªò„ÅçÊúÄÈÅ©Âåñ</h2>

<h3>ÊùêÊñô„ÅÆÂÆüÁèæÂèØËÉΩÊÄßÂà∂Á¥Ñ</h3>

ÂÆüÈöõ„ÅÆÊùêÊñôÈñãÁô∫„Åß„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆÂà∂Á¥Ñ„Åå„ÅÇ„Çä„Åæ„ÅôÔºö

1. <strong>ÁµÑÊàêÂà∂Á¥Ñ</strong>: ÂêàË®à100%„ÄÅÂêÑÂÖÉÁ¥†„ÅÆ‰∏ä‰∏ãÈôê
2. <strong>ÂÆâÂÆöÊÄßÂà∂Á¥Ñ</strong>: formation energy < ÈñæÂÄ§
3. <strong>ÂÆüÈ®ìÁöÑÂà∂Á¥Ñ</strong>: ÂêàÊàêÊ∏©Â∫¶„ÄÅÂúßÂäõÁØÑÂõ≤
4. <strong>„Ç≥„Çπ„ÉàÂà∂Á¥Ñ</strong>: È´ò‰æ°„Å™ÂÖÉÁ¥†„ÅÆ‰ΩøÁî®Âà∂Èôê

<h3>Âà∂Á¥Ñ‰ªò„Åç„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÂÆüË£Ö</h3>

<strong>„Ç≥„Éº„Éâ‰æã4: Ë§áÊï∞Âà∂Á¥ÑÊù°‰ª∂‰∏ã„Åß„ÅÆÊúÄÈÅ©Âåñ</strong>

<pre><code class="language-python"><h1>Âà∂Á¥Ñ‰ªò„Åç„Éô„Ç§„Ç∫ÊúÄÈÅ©ÂåñÔºàBoTorch‰ΩøÁî®Ôºâ</h1>
<h1>Ê≥®: BoTorch„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´: pip install botorch torch</h1>
import torch
from botorch.models import SingleTaskGP
from botorch.fit import fit_gpytorch_model
from gpytorch.mlls import ExactMarginalLogLikelihood
from botorch.acquisition import ExpectedImprovement
from botorch.optim import optimize_acqf

def constrained_bo_example():
    """
    Âà∂Á¥Ñ‰ªò„Åç„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆ„Éá„É¢

    Âà∂Á¥Ñ:
    - ÂÆπÈáè„ÇíÊúÄÂ§ßÂåñ
    - ÂÆâÂÆöÊÄß: formation energy < -1.5 eV/atom
    - „Ç≥„Çπ„Éà: CoÂê´Èáè < 0.3
    """
    # ÂàùÊúü„Éá„Éº„ÇøÔºà„É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞Ôºâ
    n_initial = 10
    np.random.seed(42)

    X_init = np.random.rand(n_initial, 4)
    # ÁµÑÊàêÊ≠£Ë¶èÂåñ
    X_init = X_init / X_init.sum(axis=1, keepdims=True)

    # ÁõÆÁöÑÈñ¢Êï∞„Å®Âà∂Á¥Ñ„ÅÆË©ï‰æ°
    y_capacity = []
    y_stability = []
    for i in range(n_initial):
        x = X_init[i]
        # ÂÆπÈáè‰∫àÊ∏¨
        capacity = rf_model.predict(x.reshape(1, -1))[0]
        # ÂÆâÂÆöÊÄßÔºàÁ∞°Áï•„É¢„Éá„É´Ôºâ
        stability = -2.0 - 0.5*x[0] - 0.3*x[1] + 0.1*np.random.randn()

        y_capacity.append(capacity)
        y_stability.append(stability)

    X_init = torch.tensor(X_init, dtype=torch.float64)
    y_capacity = torch.tensor(y_capacity, dtype=torch.float64).unsqueeze(-1)
    y_stability = torch.tensor(y_stability, dtype=torch.float64).unsqueeze(-1)

    # ÈÄêÊ¨°ÊúÄÈÅ©ÂåñÔºà20ÂõûÔºâ
    n_iterations = 20
    X_all = X_init.clone()
    y_capacity_all = y_capacity.clone()
    y_stability_all = y_stability.clone()

    for iteration in range(n_iterations):
        # „Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´ÔºàÂÆπÈáèÔºâ
        gp_capacity = SingleTaskGP(X_all, y_capacity_all)
        mll_capacity = ExactMarginalLogLikelihood(
            gp_capacity.likelihood, gp_capacity
        )
        fit_gpytorch_model(mll_capacity)

        # „Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´ÔºàÂÆâÂÆöÊÄßÔºâ
        gp_stability = SingleTaskGP(X_all, y_stability_all)
        mll_stability = ExactMarginalLogLikelihood(
            gp_stability.likelihood, gp_stability
        )
        fit_gpytorch_model(mll_stability)

        # Expected ImprovementÔºàÂÆπÈáèÔºâ
        best_f = y_capacity_all.max()
        EI = ExpectedImprovement(gp_capacity, best_f=best_f)

        # Áç≤ÂæóÈñ¢Êï∞„ÅÆÊúÄÈÅ©ÂåñÔºàÂà∂Á¥ÑËÄÉÊÖÆÔºâ
        bounds = torch.tensor([[0.1, 0.1, 0.1, 0.0],
                                [0.5, 0.4, 0.3, 0.5]],
                               dtype=torch.float64)

        candidate, acq_value = optimize_acqf(
            EI,
            bounds=bounds,
            q=1,
            num_restarts=10,
            raw_samples=512,
        )

        # ÂÄôË£úÁÇπ„ÅÆË©ï‰æ°
        x_new = candidate.detach().numpy()[0]
        # Ê≠£Ë¶èÂåñ
        x_new = x_new / x_new.sum()

        # ÂÆüÈ®ì„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥
        capacity_new = rf_model.predict(x_new.reshape(1, -1))[0]
        stability_new = -2.0 - 0.5*x_new[0] - 0.3*x_new[1] + \
                        0.1*np.random.randn()

        # Âà∂Á¥Ñ„ÉÅ„Çß„ÉÉ„ÇØ
        feasible = (stability_new < -1.5) and (x_new[2] < 0.3)

        if feasible:
            print(f"Iteration {iteration+1}: "
                  f"Capacity={capacity_new:.1f}, "
                  f"Stability={stability_new:.2f}, "
                  f"Feasible=Yes")
        else:
            print(f"Iteration {iteration+1}: "
                  f"Capacity={capacity_new:.1f}, "
                  f"Stability={stability_new:.2f}, "
                  f"Feasible=No (Âà∂Á¥ÑÈÅïÂèç)")

        # „Éá„Éº„Çø„Å´ËøΩÂä†
        X_all = torch.cat([X_all, torch.tensor(x_new).unsqueeze(0)], dim=0)
        y_capacity_all = torch.cat([y_capacity_all,
                                     torch.tensor([[capacity_new]])], dim=0)
        y_stability_all = torch.cat([y_stability_all,
                                      torch.tensor([[stability_new]])], dim=0)

    # ÂÆüË°åÂèØËÉΩËß£„ÅÆ‰∏≠„ÅßÊúÄËâØ„ÅÆ„ÇÇ„ÅÆ„ÇíÊäΩÂá∫
    feasible_mask = (y_stability_all < -1.5).squeeze() & \
                    (X_all[:, 2] < 0.3).squeeze()

    if feasible_mask.sum() > 0:
        feasible_capacities = y_capacity_all[feasible_mask]
        feasible_X = X_all[feasible_mask]
        best_idx = feasible_capacities.argmax()
        best_composition_constrained = feasible_X[best_idx].numpy()
        best_capacity_constrained = feasible_capacities[best_idx].item()

        print("\nÊúÄÁµÇÁµêÊûúÔºàÂà∂Á¥Ñ‰ªò„ÅçÔºâ:")
        print(f"  ÊúÄÈÅ©ÁµÑÊàê:")
        print(f"    Li: {best_composition_constrained[0]:.3f}")
        print(f"    Ni: {best_composition_constrained[1]:.3f}")
        print(f"    Co: {best_composition_constrained[2]:.3f} "
              f"(Âà∂Á¥Ñ < 0.3)")
        print(f"    Mn: {best_composition_constrained[3]:.3f}")
        print(f"  ‰∫àÊ∏¨ÂÆπÈáè: {best_capacity_constrained:.2f} mAh/g")
        print(f"  ÂÆüË°åÂèØËÉΩËß£„ÅÆÊï∞: {feasible_mask.sum().item()} / "
              f"{len(X_all)}")
    else:
        print("\nÂÆüË°åÂèØËÉΩËß£„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü")

<h1>ÂÆüË°å</h1>
constrained_bo_example()</code></pre>

---

<h2>3.3 Â§öÁõÆÁöÑÊúÄÈÅ©ÂåñÔºàParetoÊúÄÈÅ©ÂåñÔºâ</h2>

<h3>„Å™„ÅúÂ§öÁõÆÁöÑÊúÄÈÅ©Âåñ„ÅåÂøÖË¶Å„Åã</h3>

ÊùêÊñôÈñãÁô∫„Åß„ÅØ„ÄÅ<strong>Ë§áÊï∞„ÅÆÁâπÊÄß„ÇíÂêåÊôÇ„Å´ÊúÄÈÅ©Âåñ</strong>„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„ÅôÔºö

- <strong>Li-ionÈõªÊ±†</strong>: ÂÆπÈáè ‚Üë„ÄÅÈõªÂúß ‚Üë„ÄÅÂÆâÂÆöÊÄß ‚Üë
- <strong>ÁÜ±ÈõªÊùêÊñô</strong>: „Çº„Éº„Éô„ÉÉ„ÇØ‰øÇÊï∞ ‚Üë„ÄÅÈõªÊ∞ó‰ºùÂ∞éÂ∫¶ ‚Üë„ÄÅÁÜ±‰ºùÂ∞éÂ∫¶ ‚Üì
- <strong>Ëß¶Â™í</strong>: Ê¥ªÊÄß ‚Üë„ÄÅÈÅ∏ÊäûÊÄß ‚Üë„ÄÅÂÆâÂÆöÊÄß ‚Üë„ÄÅ„Ç≥„Çπ„Éà ‚Üì

„Åì„Çå„Çâ„ÅØ„Éà„É¨„Éº„Éâ„Ç™„Éï„Åå„ÅÇ„Çä„ÄÅ<strong>Âçò‰∏Ä„ÅÆÊúÄÈÅ©Ëß£„ÅØÂ≠òÂú®„Åó„Å™„ÅÑ</strong>„ÄÇ

<h3>Pareto„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢„ÅÆÊ¶ÇÂøµ</h3>

<div class="mermaid">graph TB
    subgraph ÁõÆÁöÑÁ©∫Èñì
    A[ÁõÆÁöÑ1: ÂÆπÈáè]
    B[ÁõÆÁöÑ2: ÂÆâÂÆöÊÄß]
    C[Pareto„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢<br/>„Éà„É¨„Éº„Éâ„Ç™„Éï„ÅÆÂ¢ÉÁïå]
    D[ÊîØÈÖç„Åï„Çå„ÇãËß£<br/>„Å©„Å°„Çâ„ÇÇÂä£„Çã]
    E[ParetoÊúÄÈÅ©Ëß£<br/>ÊîπÂñÑ„Å´„ÅØ„Éà„É¨„Éº„Éâ„Ç™„Éï„ÅåÂøÖË¶Å]
    end

    A --> C
    B --> C
    C --> E
    D -.Âä£„Çã.-> E

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
    style E fill:#fce4ec</div>

<strong>ParetoÊúÄÈÅ©„ÅÆÂÆöÁæ©</strong>:
> Ëß£ x „Åå ParetoÊúÄÈÅ© ‚áî ÂÖ®„Å¶„ÅÆÁõÆÁöÑ„ÇíÂêåÊôÇ„Å´ÊîπÂñÑ„Åô„ÇãËß£„ÅåÂ≠òÂú®„Åó„Å™„ÅÑ

---

<h3>Expected Hypervolume ImprovementÔºàEHVIÔºâ</h3>

<strong>„Ç≥„Éº„Éâ‰æã5: Â§öÁõÆÁöÑ„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÂÆüË£Ö</strong>

<pre><code class="language-python"><h1>Â§öÁõÆÁöÑ„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ</h1>
from botorch.models import ModelListGP
from botorch.acquisition.multi_objective import \
    qExpectedHypervolumeImprovement
from botorch.utils.multi_objective.box_decompositions.dominated import \
    DominatedPartitioning

def multi_objective_bo_example():
    """
    Â§öÁõÆÁöÑ„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆ„Éá„É¢

    ÁõÆÁöÑ:
    1. ÂÆπÈáè„ÇíÊúÄÂ§ßÂåñ
    2. ÂÆâÂÆöÊÄß„ÇíÊúÄÂ§ßÂåñÔºàformation energy„ÅÆÁµ∂ÂØæÂÄ§„ÇíÊúÄÂ∞èÂåñÔºâ
    """
    # ÂàùÊúü„Éá„Éº„Çø
    n_initial = 15
    np.random.seed(42)

    X_init = np.random.rand(n_initial, 4)
    X_init = X_init / X_init.sum(axis=1, keepdims=True)

    # 2„Å§„ÅÆÁõÆÁöÑÈñ¢Êï∞„ÇíË©ï‰æ°
    y1_capacity = []
    y2_stability = []

    for i in range(n_initial):
        x = X_init[i]
        capacity = rf_model.predict(x.reshape(1, -1))[0]
        stability = -2.0 - 0.5*x[0] - 0.3*x[1] + 0.1*np.random.randn()
        # ÂÆâÂÆöÊÄß„ÅØË≤†„ÅåËâØ„ÅÑ„ÅÆ„Åß„ÄÅÊ≠£„Å´Â§âÊèõÔºàÊúÄÂ§ßÂåñÂïèÈ°å„Å´Áµ±‰∏ÄÔºâ
        stability_positive = -stability

        y1_capacity.append(capacity)
        y2_stability.append(stability_positive)

    X_all = torch.tensor(X_init, dtype=torch.float64)
    Y_all = torch.tensor(
        np.column_stack([y1_capacity, y2_stability]),
        dtype=torch.float64
    )

    # ÈÄêÊ¨°ÊúÄÈÅ©Âåñ
    n_iterations = 20

    for iteration in range(n_iterations):
        # „Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´ÔºàÂêÑÁõÆÁöÑÈñ¢Êï∞„Åî„Å®Ôºâ
        gp_list = []
        for i in range(2):
            gp = SingleTaskGP(X_all, Y_all[:, i].unsqueeze(-1))
            mll = ExactMarginalLogLikelihood(gp.likelihood, gp)
            fit_gpytorch_model(mll)
            gp_list.append(gp)

        model = ModelListGP(*gp_list)

        # ÂèÇÁÖßÁÇπÔºàNadir point „Çà„ÇäÊÇ™„ÅÑÁÇπÔºâ
        ref_point = Y_all.min(dim=0).values - 10.0

        # Pareto frontier „ÅÆË®àÁÆó
        pareto_mask = is_non_dominated(Y_all)
        pareto_Y = Y_all[pareto_mask]

        # EHVIÁç≤ÂæóÈñ¢Êï∞
        partitioning = DominatedPartitioning(
            ref_point=ref_point,
            Y=pareto_Y
        )
        acq_func = qExpectedHypervolumeImprovement(
            model=model,
            ref_point=ref_point,
            partitioning=partitioning
        )

        # ÊúÄÈÅ©Âåñ
        bounds = torch.tensor([[0.1, 0.1, 0.1, 0.0],
                                [0.5, 0.4, 0.4, 0.5]],
                               dtype=torch.float64)

        candidate, acq_value = optimize_acqf(
            acq_func,
            bounds=bounds,
            q=1,
            num_restarts=10,
            raw_samples=512,
        )

        # Êñ∞„Åó„ÅÑÂÄôË£úÁÇπ„ÅÆË©ï‰æ°
        x_new = candidate.detach().numpy()[0]
        x_new = x_new / x_new.sum()

        capacity_new = rf_model.predict(x_new.reshape(1, -1))[0]
        stability_new = -2.0 - 0.5*x_new[0] - 0.3*x_new[1] + \
                        0.1*np.random.randn()
        stability_positive_new = -stability_new

        y_new = torch.tensor([[capacity_new, stability_positive_new]],
                              dtype=torch.float64)

        # „Éá„Éº„Çø„Å´ËøΩÂä†
        X_all = torch.cat([X_all, torch.tensor(x_new).unsqueeze(0)], dim=0)
        Y_all = torch.cat([Y_all, y_new], dim=0)

        if (iteration + 1) % 5 == 0:
            print(f"Iteration {iteration+1}: "
                  f"ParetoËß£Êï∞={pareto_mask.sum().item()}, "
                  f"HV={compute_hypervolume(pareto_Y, ref_point):.2f}")

    # ÊúÄÁµÇPareto„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢
    pareto_mask_final = is_non_dominated(Y_all)
    pareto_X_final = X_all[pareto_mask_final].numpy()
    pareto_Y_final = Y_all[pareto_mask_final].numpy()

    print(f"\nÊúÄÁµÇParetoÊúÄÈÅ©Ëß£Êï∞: {pareto_mask_final.sum().item()}")

    # Pareto„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢„ÅÆÂèØË¶ñÂåñ
    plt.figure(figsize=(10, 6))

    # ÂÖ®„Å¶„ÅÆÁÇπ
    plt.scatter(Y_all[:, 0].numpy(), Y_all[:, 1].numpy(),
                c='lightblue', s=50, alpha=0.5, label='ÂÖ®Êé¢Á¥¢ÁÇπ')

    # ParetoÊúÄÈÅ©Ëß£
    plt.scatter(pareto_Y_final[:, 0], pareto_Y_final[:, 1],
                c='red', s=100, edgecolors='black', zorder=10,
                label='ParetoÊúÄÈÅ©Ëß£')

    # Pareto„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢„ÇíÁ∑ö„ÅßÁµê„Å∂
    sorted_indices = np.argsort(pareto_Y_final[:, 0])
    plt.plot(pareto_Y_final[sorted_indices, 0],
             pareto_Y_final[sorted_indices, 1],
             'r--', linewidth=2, alpha=0.5, label='Pareto„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢')

    plt.xlabel('ÁõÆÁöÑ1: ÂÆπÈáè (mAh/g)', fontsize=12)
    plt.ylabel('ÁõÆÁöÑ2: ÂÆâÂÆöÊÄß (-formation energy)', fontsize=12)
    plt.title('Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ: Pareto„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('pareto_frontier.png', dpi=150, bbox_inches='tight')
    plt.show()

    # „Éà„É¨„Éº„Éâ„Ç™„Éï„ÅÆ‰æã„ÇíË°®Á§∫
    print("\n„Éà„É¨„Éº„Éâ„Ç™„Éï„ÅÆ‰æã:")
    # ÂÆπÈáèÈáçË¶ñ
    idx_max_capacity = np.argmax(pareto_Y_final[:, 0])
    print(f"  ÂÆπÈáèÈáçË¶ñ: ÂÆπÈáè={pareto_Y_final[idx_max_capacity, 0]:.1f}, "
          f"ÂÆâÂÆöÊÄß={pareto_Y_final[idx_max_capacity, 1]:.2f}")

    # ÂÆâÂÆöÊÄßÈáçË¶ñ
    idx_max_stability = np.argmax(pareto_Y_final[:, 1])
    print(f"  ÂÆâÂÆöÊÄßÈáçË¶ñ: ÂÆπÈáè={pareto_Y_final[idx_max_stability, 0]:.1f}, "
          f"ÂÆâÂÆöÊÄß={pareto_Y_final[idx_max_stability, 1]:.2f}")

    # „Éê„É©„É≥„ÇπÂûãÔºà‰∏≠ÈñìÁÇπÔºâ
    normalized_Y = (pareto_Y_final - pareto_Y_final.min(axis=0)) / \
                   (pareto_Y_final.max(axis=0) - pareto_Y_final.min(axis=0))
    distances = np.sqrt(((normalized_Y - 0.5)**2).sum(axis=1))
    idx_balanced = np.argmin(distances)
    print(f"  „Éê„É©„É≥„ÇπÂûã: ÂÆπÈáè={pareto_Y_final[idx_balanced, 0]:.1f}, "
          f"ÂÆâÂÆöÊÄß={pareto_Y_final[idx_balanced, 1]:.2f}")

<h1>ParetoÊúÄÈÅ©Âà§ÂÆöÈñ¢Êï∞</h1>
def is_non_dominated(Y):
    """
    ParetoÊúÄÈÅ©Ëß£„ÇíÂà§ÂÆö

    Parameters:
    -----------
    Y : Tensor (n_points, n_objectives)
        ÁõÆÁöÑÈñ¢Êï∞ÂÄ§

    Returns:
    --------
    mask : Tensor (n_points,)
        True„ÅåparetoÊúÄÈÅ©
    """
    n_points = Y.shape[0]
    is_efficient = torch.ones(n_points, dtype=torch.bool)

    for i in range(n_points):
        if is_efficient[i]:
            # iÁï™ÁõÆ„ÅÆÁÇπ„Çà„ÇäÂÖ®„Å¶„ÅÆÁõÆÁöÑ„ÅßÂÑ™„Çå„Å¶„ÅÑ„ÇãÁÇπ„Åå„ÅÇ„Çã„Åã
            is_dominated = (Y >= Y[i]).all(dim=1) & (Y > Y[i]).any(dim=1)
            is_efficient[is_dominated] = False

    return is_efficient

<h1>HypervolumeË®àÁÆó</h1>
def compute_hypervolume(pareto_Y, ref_point):
    """
    Hypervolume„ÅÆË®àÁÆóÔºàÁ∞°ÊòìÁâàÔºâ

    Parameters:
    -----------
    pareto_Y : Tensor
        ParetoÊúÄÈÅ©Ëß£
    ref_point : Tensor
        ÂèÇÁÖßÁÇπ

    Returns:
    --------
    float : Hypervolume
    """
    # 2Ê¨°ÂÖÉ„ÅÆÁ∞°ÊòìË®àÁÆó
    sorted_Y = pareto_Y[torch.argsort(pareto_Y[:, 0], descending=True)]
    hv = 0.0
    prev_y1 = ref_point[0]

    for i in range(len(sorted_Y)):
        width = prev_y1 - sorted_Y[i, 0]
        height = sorted_Y[i, 1] - ref_point[1]
        hv += width * height
        prev_y1 = sorted_Y[i, 0]

    return hv.item()

<h1>ÂÆüË°å</h1>
<h1>multi_objective_bo_example()</h1>
<h1>Ê≥®: BoTorch„ÅåÂøÖË¶Å„Å™„Åü„ÇÅ„ÄÅ„Ç≥„É°„É≥„Éà„Ç¢„Ç¶„Éà</h1>
print("Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ„ÅÆ‰æã„ÅØBoTorch„ÅåÂøÖË¶Å„Åß„Åô")
print("pip install botorch torch „Åß„Ç§„É≥„Çπ„Éà„Éº„É´Âæå„ÄÅÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ")</code></pre>

---

<h2>3.4 ÂÆüÈ®ì„Ç≥„Çπ„Éà„ÇíËÄÉÊÖÆ„Åó„ÅüÊúÄÈÅ©Âåñ</h2>

<h3>„Éê„ÉÉ„ÉÅ„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ</h3>

ÂÆüÈ®ìË£ÖÁΩÆ„ÅåË§áÊï∞„ÅÇ„ÇãÂ†¥Âêà„ÄÅ<strong>‰∏¶ÂàóÂÆüÈ®ì</strong>„ÅåÂèØËÉΩ„Åß„ÅôÔºö

- <strong>ÂæìÊù•</strong>: ÈÄêÊ¨°ÁöÑÔºà1Âõû‚ÜíÁµêÊûú‚ÜíÊ¨°„ÅÆ1ÂõûÔºâ
- <strong>„Éê„ÉÉ„ÉÅBO</strong>: ‰∏ÄÂ∫¶„Å´Ë§áÊï∞„ÅÆÂÄôË£ú„ÇíÊèêÊ°àÔºàq-EIÔºâ

<h3>„ÉØ„Éº„ÇØ„Éï„É≠„Éº</h3>

<div class="mermaid">graph LR
    A[ÂàùÊúü„Éá„Éº„Çø] --> B[„Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´]
    B --> C[q-EIÁç≤ÂæóÈñ¢Êï∞<br/>qÂÄã„ÅÆÂÄôË£ú„ÇíÊèêÊ°à]
    C --> D[‰∏¶ÂàóÂÆüÈ®ì<br/>qÂÄãÂêåÊôÇÂÆüË°å]
    D --> E{ÁµÇ‰∫Ü?}
    E -->|No| B
    E -->|Yes| F[ÊúÄËâØÊùêÊñô]

    style A fill:#e3f2fd
    style C fill:#fff3e0
    style D fill:#f3e5f5
    style F fill:#fce4ec</div>

<strong>„Ç≥„Éº„Éâ‰æã6: „Éê„ÉÉ„ÉÅ„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ</strong>

<pre><code class="language-python"><h1>„Éê„ÉÉ„ÉÅ„Éô„Ç§„Ç∫ÊúÄÈÅ©ÂåñÔºàscikit-optimizeÔºâ</h1>
from scipy.stats import norm

def batch_expected_improvement(X, gp, f_best, xi=0.01):
    """
    Batch Expected ImprovementÔºàÁ∞°ÊòìÁâàÔºâ

    Parameters:
    -----------
    X : array (n_candidates, n_features)
        ÂÄôË£úÁÇπ
    gp : GaussianProcessRegressor
        Â≠¶ÁøíÊ∏à„ÅøGP„É¢„Éá„É´
    f_best : float
        ÁèæÂú®„ÅÆÊúÄËâØÂÄ§

    Returns:
    --------
    ei : array (n_candidates,)
        EIÂÄ§
    """
    mu, sigma = gp.predict(X, return_std=True)
    improvement = mu - f_best - xi
    Z = improvement / (sigma + 1e-9)
    ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)
    ei[sigma == 0.0] = 0.0
    return ei

def simulate_batch_bo(n_iterations=10, batch_size=3):
    """
    „Éê„ÉÉ„ÉÅ„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥

    Parameters:
    -----------
    n_iterations : int
        „Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥Êï∞
    batch_size : int
        ÂêÑ„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥„ÅßÊèêÊ°à„Åô„ÇãÂÄôË£úÊï∞

    Returns:
    --------
    X_all : array
        ÂÖ®„Çµ„É≥„Éó„É™„É≥„Ç∞ÁÇπ
    y_all : array
        ÂÖ®Ë¶≥Ê∏¨ÂÄ§
    """
    from sklearn.gaussian_process import GaussianProcessRegressor
    from sklearn.gaussian_process.kernels import RBF, ConstantKernel

    # ÂàùÊúü„Éá„Éº„Çø
    np.random.seed(42)
    n_initial = 5
    X_sampled = np.random.rand(n_initial, 4)
    X_sampled = X_sampled / X_sampled.sum(axis=1, keepdims=True)

    y_sampled = []
    for i in range(n_initial):
        capacity = rf_model.predict(X_sampled[i].reshape(1, -1))[0]
        y_sampled.append(capacity)

    y_sampled = np.array(y_sampled)

    # ÈÄêÊ¨°„Éê„ÉÉ„ÉÅÊúÄÈÅ©Âåñ
    for iteration in range(n_iterations):
        # „Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´
        kernel = ConstantKernel(1.0) * RBF(length_scale=0.2)
        gp = GaussianProcessRegressor(
            kernel=kernel,
            n_restarts_optimizer=10,
            random_state=42
        )
        gp.fit(X_sampled, y_sampled)

        # ÁèæÂú®„ÅÆÊúÄËâØÂÄ§
        f_best = y_sampled.max()

        # ÂÄôË£úÁÇπÁîüÊàêÔºàÂ§öÊï∞Ôºâ
        n_candidates = 1000
        X_candidates = np.random.rand(n_candidates, 4)
        X_candidates = X_candidates / X_candidates.sum(axis=1, keepdims=True)

        # EIË®àÁÆó
        ei_values = batch_expected_improvement(X_candidates, gp, f_best)

        # Top-kÈÅ∏ÊäûÔºàÂçòÁ¥î„Å™ÊñπÊ≥ïÔºâ
        # „Çà„ÇäÈ´òÂ∫¶„Å™ÊñπÊ≥ï: q-EI, KBÔºàKriging BelieverÔºâ
        top_k_indices = np.argsort(ei_values)[-batch_size:]
        X_batch = X_candidates[top_k_indices]

        # „Éê„ÉÉ„ÉÅÂÆüÈ®ì„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥
        y_batch = []
        for x in X_batch:
            capacity = rf_model.predict(x.reshape(1, -1))[0]
            y_batch.append(capacity)

        y_batch = np.array(y_batch)

        # „Éá„Éº„Çø„Å´ËøΩÂä†
        X_sampled = np.vstack([X_sampled, X_batch])
        y_sampled = np.append(y_sampled, y_batch)

        # ÈÄ≤ÊçóË°®Á§∫
        if (iteration + 1) % 3 == 0:
            best_so_far = y_sampled.max()
            print(f"Iteration {iteration+1}: "
                  f"Batch size={batch_size}, "
                  f"Best so far={best_so_far:.2f} mAh/g")

    return X_sampled, y_sampled

<h1>„Éê„ÉÉ„ÉÅBOÂÆüË°å</h1>
print("„Éê„ÉÉ„ÉÅ„Éô„Ç§„Ç∫ÊúÄÈÅ©ÂåñÔºàbatch_size=3Ôºâ:")
X_batch_bo, y_batch_bo = simulate_batch_bo(n_iterations=10, batch_size=3)

print(f"\nÊúÄÁµÇÁµêÊûú:")
print(f"  Á∑èÂÆüÈ®ìÂõûÊï∞: {len(y_batch_bo)}")
print(f"  ÊúÄËâØÂÆπÈáè: {y_batch_bo.max():.2f} mAh/g")
print(f"  ÊúÄÈÅ©ÁµÑÊàê: {X_batch_bo[y_batch_bo.argmax()]}")

<h1>ÈÄêÊ¨°BO„Å®ÊØîËºÉ</h1>
print("\nÈÄêÊ¨°BOÔºàbatch_size=1Ôºâ:")
X_seq_bo, y_seq_bo = simulate_batch_bo(n_iterations=30, batch_size=1)
print(f"  Á∑èÂÆüÈ®ìÂõûÊï∞: {len(y_seq_bo)}")
print(f"  ÊúÄËâØÂÆπÈáè: {y_seq_bo.max():.2f} mAh/g")

<h1>ÂäπÁéáÊØîËºÉ</h1>
plt.figure(figsize=(10, 6))
plt.plot(np.maximum.accumulate(y_seq_bo), 'o-',
         label='ÈÄêÊ¨°BO (batch_size=1)', linewidth=2, markersize=6)
plt.plot(np.arange(0, len(y_batch_bo), 3),
         np.maximum.accumulate(y_batch_bo)[::3], '^-',
         label='„Éê„ÉÉ„ÉÅBO (batch_size=3)', linewidth=2, markersize=8)
plt.xlabel('ÂÆüÈ®ìÂõûÊï∞', fontsize=12)
plt.ylabel('„Åì„Çå„Åæ„Åß„ÅÆÊúÄËâØÂÄ§ (mAh/g)', fontsize=12)
plt.title('„Éê„ÉÉ„ÉÅBO vs ÈÄêÊ¨°BO„ÅÆÂäπÁéáÊØîËºÉ', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('batch_bo_comparison.png', dpi=150, bbox_inches='tight')
plt.show()</code></pre>

---

<h2>3.5 ÂÆåÂÖ®„Å™ÂÆüË£Ö‰æãÔºöLi-ionÈõªÊ±†ÈõªËß£Ë≥™„ÅÆÊúÄÈÅ©Âåñ</h2>

<h3>ÂïèÈ°åË®≠ÂÆö</h3>

<strong>ÁõÆÁöÑ</strong>: Li-ionÈõªÊ±†Ê≠£Ê•µÊùêÊñô„ÅÆÊúÄÈÅ©Âåñ

<strong>ÊúÄÈÅ©Âåñ„Åô„ÇãÁâπÊÄß</strong>:
1. ÂÆπÈáèÔºàmAh/gÔºâ„ÇíÊúÄÂ§ßÂåñ
2. ÈõªÂúßÔºàVÔºâ„ÇíÊúÄÂ§ßÂåñ
3. ÂÆâÂÆöÊÄßÔºàformation energyÔºâ„ÇíÊúÄÂ§ßÂåñ

<strong>Âà∂Á¥Ñ</strong>:
- ÁµÑÊàê„ÅÆÂêàË®à = 1.0
- LiÂê´Èáè: 0.1-0.5
- NiÂê´Èáè: 0.1-0.4
- CoÂê´Èáè: 0.1-0.3ÔºàÈ´ò‰æ°„Å™„Åü„ÇÅÂà∂ÈôêÔºâ
- MnÂê´Èáè: ‚â• 0.0

<strong>„Ç≥„Éº„Éâ‰æã7: ÂÆü‰∏ñÁïåÂïèÈ°å„ÅÆÂÆåÂÖ®ÂÆüË£Ö</strong>

<pre><code class="language-python"><h1>Li-ionÈõªÊ±†Ê≠£Ê•µÊùêÊñô„ÅÆÂ§öÁõÆÁöÑÂà∂Á¥Ñ‰ªò„ÅçÊúÄÈÅ©Âåñ</h1>
class LiIonCathodeOptimizer:
    """
    Li-ionÈõªÊ±†Ê≠£Ê•µÊùêÊñô„ÅÆÊúÄÈÅ©Âåñ„ÇØ„É©„Çπ

    ÁõÆÁöÑ:
    - ÂÆπÈáèÊúÄÂ§ßÂåñ
    - ÈõªÂúßÊúÄÂ§ßÂåñ
    - ÂÆâÂÆöÊÄßÊúÄÂ§ßÂåñÔºà„Ç≥„Çπ„ÉàËÄÉÊÖÆÔºâ

    Âà∂Á¥Ñ:
    - ÁµÑÊàêÂà∂Á¥Ñ
    - CoÂê´ÈáèÂà∂ÈôêÔºà„Ç≥„Çπ„ÉàÔºâ
    """

    def __init__(self, capacity_model, voltage_model, stability_model):
        """
        Parameters:
        -----------
        capacity_model : sklearn model
            ÂÆπÈáè‰∫àÊ∏¨„É¢„Éá„É´
        voltage_model : sklearn model
            ÈõªÂúß‰∫àÊ∏¨„É¢„Éá„É´
        stability_model : sklearn model
            ÂÆâÂÆöÊÄß‰∫àÊ∏¨„É¢„Éá„É´
        """
        self.capacity_model = capacity_model
        self.voltage_model = voltage_model
        self.stability_model = stability_model

        # Âà∂Á¥Ñ
        self.co_max = 0.3  # CoÂê´Èáè‰∏äÈôê
        self.composition_bounds = {
            'li': (0.1, 0.5),
            'ni': (0.1, 0.4),
            'co': (0.1, 0.3),
            'mn': (0.0, 0.5)
        }

    def evaluate(self, composition):
        """
        ÊùêÊñôÁµÑÊàê„ÇíË©ï‰æ°

        Parameters:
        -----------
        composition : array [li, ni, co, mn]

        Returns:
        --------
        dict : ÂêÑÁâπÊÄß„ÅÆ‰∫àÊ∏¨ÂÄ§
        """
        # Âà∂Á¥Ñ„ÉÅ„Çß„ÉÉ„ÇØ
        if not self._check_constraints(composition):
            return {
                'capacity': -1000,
                'voltage': -1000,
                'stability': -1000,
                'feasible': False
            }

        x = composition.reshape(1, -1)

        capacity = self.capacity_model.predict(x)[0]
        # ÈõªÂúß„É¢„Éá„É´Ôºà„ÉÄ„Éü„ÉºÔºâ
        voltage = 3.0 + 1.5 * composition[2] + 0.2 * np.random.randn()
        # ÂÆâÂÆöÊÄß„É¢„Éá„É´Ôºà„ÉÄ„Éü„ÉºÔºâ
        stability = -2.0 - 0.5*composition[0] - 0.3*composition[1] + \
                    0.1*np.random.randn()

        return {
            'capacity': capacity,
            'voltage': voltage,
            'stability': -stability,  # Ê≠£„Å´Â§âÊèõ
            'feasible': True
        }

    def _check_constraints(self, composition):
        """Âà∂Á¥Ñ„ÉÅ„Çß„ÉÉ„ÇØ"""
        li, ni, co, mn = composition

        # ÁµÑÊàêÂêàË®à
        if not (0.98 <= li + ni + co + mn <= 1.02):
            return False

        # ÂêÑÂÖÉÁ¥†„ÅÆÁØÑÂõ≤
        if not (self.composition_bounds['li'][0] <= li <=
                self.composition_bounds['li'][1]):
            return False
        if not (self.composition_bounds['ni'][0] <= ni <=
                self.composition_bounds['ni'][1]):
            return False
        if not (self.composition_bounds['co'][0] <= co <=
                self.composition_bounds['co'][1]):
            return False
        if not (self.composition_bounds['mn'][0] <= mn <=
                self.composition_bounds['mn'][1]):
            return False

        return True

    def optimize_multi_objective(self, n_iterations=50):
        """
        Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ„ÇíÂÆüË°å

        Returns:
        --------
        pareto_solutions : list of dict
            ParetoÊúÄÈÅ©Ëß£
        """
        # ÂàùÊúü„Çµ„É≥„Éó„É™„É≥„Ç∞
        n_initial = 20
        np.random.seed(42)

        solutions = []

        for i in range(n_initial):
            # „É©„É≥„ÉÄ„É†ÁµÑÊàêÁîüÊàê
            composition = np.random.rand(4)
            composition = composition / composition.sum()

            # Ë©ï‰æ°
            result = self.evaluate(composition)

            if result['feasible']:
                solutions.append({
                    'composition': composition,
                    'capacity': result['capacity'],
                    'voltage': result['voltage'],
                    'stability': result['stability']
                })

        # ÈÄêÊ¨°ÊúÄÈÅ©ÂåñÔºàÁ∞°ÊòìÁâàÔºâ
        for iteration in range(n_iterations - n_initial):
            # Êó¢Â≠òËß£„Åã„ÇâParetoÊúÄÈÅ©„ÇíÊäΩÂá∫
            pareto_sols = self._extract_pareto(solutions)

            # ParetoËß£„ÅÆÂë®Ëæ∫„Çí„Çµ„É≥„Éó„É™„É≥„Ç∞ÔºàÁ∞°ÊòìÁöÑ„Å™ÊâãÊ≥ïÔºâ
            if len(pareto_sols) > 0:
                base_sol = pareto_sols[np.random.randint(len(pareto_sols))]
                composition_new = base_sol['composition'] + \
                                  np.random.randn(4) * 0.05
                composition_new = np.clip(composition_new, 0.01, 0.8)
                composition_new = composition_new / composition_new.sum()
            else:
                composition_new = np.random.rand(4)
                composition_new = composition_new / composition_new.sum()

            # Ë©ï‰æ°
            result = self.evaluate(composition_new)

            if result['feasible']:
                solutions.append({
                    'composition': composition_new,
                    'capacity': result['capacity'],
                    'voltage': result['voltage'],
                    'stability': result['stability']
                })

        # ÊúÄÁµÇParetoÊúÄÈÅ©Ëß£
        pareto_solutions = self._extract_pareto(solutions)

        return pareto_solutions, solutions

    def _extract_pareto(self, solutions):
        """ParetoÊúÄÈÅ©Ëß£„ÇíÊäΩÂá∫"""
        if len(solutions) == 0:
            return []

        objectives = np.array([
            [s['capacity'], s['voltage'], s['stability']]
            for s in solutions
        ])

        pareto_mask = np.ones(len(objectives), dtype=bool)

        for i in range(len(objectives)):
            if pareto_mask[i]:
                # iÁï™ÁõÆ„Çà„ÇäÂÖ®„Å¶„ÅÆÁõÆÁöÑ„ÅßÂÑ™„Çå„Å¶„ÅÑ„ÇãËß£„Åå„ÅÇ„Çã„Åã
                dominated = (
                    (objectives >= objectives[i]).all(axis=1) &
                    (objectives > objectives[i]).any(axis=1)
                )
                pareto_mask[dominated] = False

        pareto_solutions = [solutions[i] for i in range(len(solutions))
                             if pareto_mask[i]]

        return pareto_solutions

<h1>ÈõªÂúß„ÉªÂÆâÂÆöÊÄß„É¢„Éá„É´„ÅÆÁ∞°ÊòìË®ìÁ∑¥Ôºà„ÉÄ„Éü„ÉºÔºâ</h1>
from sklearn.ensemble import RandomForestRegressor

voltage_model = RandomForestRegressor(n_estimators=50, random_state=42)
voltage_model.fit(X_train, y_voltage[:len(X_train)])

stability_model = RandomForestRegressor(n_estimators=50, random_state=42)
stability_model.fit(X_train, y_stability[:len(X_train)])

<h1>ÊúÄÈÅ©ÂåñÂÆüË°å</h1>
optimizer = LiIonCathodeOptimizer(
    capacity_model=rf_model,
    voltage_model=voltage_model,
    stability_model=stability_model
)

print("Li-ionÈõªÊ±†Ê≠£Ê•µÊùêÊñô„ÅÆÂ§öÁõÆÁöÑÊúÄÈÅ©Âåñ„ÇíÂÆüË°å‰∏≠...")
pareto_solutions, all_solutions = optimizer.optimize_multi_objective(
    n_iterations=100
)

print(f"\nParetoÊúÄÈÅ©Ëß£Êï∞: {len(pareto_solutions)}")

<h1>ÁµêÊûú„ÅÆÂèØË¶ñÂåñÔºà3DÔºâ</h1>
from mpl_toolkits.mplot3d import Axes3D

fig = plt.figure(figsize=(14, 6))

<h1>Â∑¶Âõ≥: 3DÊï£Â∏ÉÂõ≥</h1>
ax1 = fig.add_subplot(121, projection='3d')

<h1>ÂÖ®„Å¶„ÅÆËß£</h1>
all_cap = [s['capacity'] for s in all_solutions]
all_vol = [s['voltage'] for s in all_solutions]
all_sta = [s['stability'] for s in all_solutions]

ax1.scatter(all_cap, all_vol, all_sta, c='lightblue', s=20,
            alpha=0.3, label='ÂÖ®Êé¢Á¥¢ÁÇπ')

<h1>ParetoÊúÄÈÅ©Ëß£</h1>
pareto_cap = [s['capacity'] for s in pareto_solutions]
pareto_vol = [s['voltage'] for s in pareto_solutions]
pareto_sta = [s['stability'] for s in pareto_solutions]

ax1.scatter(pareto_cap, pareto_vol, pareto_sta, c='red', s=100,
            edgecolors='black', zorder=10, label='ParetoÊúÄÈÅ©Ëß£')

ax1.set_xlabel('ÂÆπÈáè (mAh/g)', fontsize=10)
ax1.set_ylabel('ÈõªÂúß (V)', fontsize=10)
ax1.set_zlabel('ÂÆâÂÆöÊÄß', fontsize=10)
ax1.set_title('3ÁõÆÁöÑÊúÄÈÅ©Âåñ: ÁõÆÁöÑÁ©∫Èñì', fontsize=12)
ax1.legend()

<h1>Âè≥Âõ≥: ÂÆπÈáè-ÈõªÂúß„ÅÆ2D„Éó„É≠„Ç∏„Çß„ÇØ„Ç∑„Éß„É≥</h1>
ax2 = fig.add_subplot(122)
ax2.scatter(all_cap, all_vol, c='lightblue', s=20,
            alpha=0.5, label='ÂÖ®Êé¢Á¥¢ÁÇπ')
ax2.scatter(pareto_cap, pareto_vol, c='red', s=100,
            edgecolors='black', zorder=10, label='ParetoÊúÄÈÅ©Ëß£')
ax2.set_xlabel('ÂÆπÈáè (mAh/g)', fontsize=12)
ax2.set_ylabel('ÈõªÂúß (V)', fontsize=12)
ax2.set_title('ÂÆπÈáè-ÈõªÂúß„ÅÆ„Éà„É¨„Éº„Éâ„Ç™„Éï', fontsize=14)
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('liion_cathode_optimization.png', dpi=150,
            bbox_inches='tight')
plt.show()

<h1>‰ª£Ë°®ÁöÑ„Å™ParetoËß£„ÇíË°®Á§∫</h1>
print("\n‰ª£Ë°®ÁöÑ„Å™ParetoÊúÄÈÅ©Ëß£:")

<h1>ÂÆπÈáèÈáçË¶ñ</h1>
idx_max_cap = np.argmax(pareto_cap)
print(f"\nÂÆπÈáèÈáçË¶ñ:")
print(f"  Li={pareto_solutions[idx_max_cap]['composition'][0]:.3f}, "
      f"Ni={pareto_solutions[idx_max_cap]['composition'][1]:.3f}, "
      f"Co={pareto_solutions[idx_max_cap]['composition'][2]:.3f}, "
      f"Mn={pareto_solutions[idx_max_cap]['composition'][3]:.3f}")
print(f"  ÂÆπÈáè={pareto_cap[idx_max_cap]:.1f} mAh/g, "
      f"ÈõªÂúß={pareto_vol[idx_max_cap]:.2f} V, "
      f"ÂÆâÂÆöÊÄß={pareto_sta[idx_max_cap]:.2f}")

<h1>ÈõªÂúßÈáçË¶ñ</h1>
idx_max_vol = np.argmax(pareto_vol)
print(f"\nÈõªÂúßÈáçË¶ñ:")
print(f"  Li={pareto_solutions[idx_max_vol]['composition'][0]:.3f}, "
      f"Ni={pareto_solutions[idx_max_vol]['composition'][1]:.3f}, "
      f"Co={pareto_solutions[idx_max_vol]['composition'][2]:.3f}, "
      f"Mn={pareto_solutions[idx_max_vol]['composition'][3]:.3f}")
print(f"  ÂÆπÈáè={pareto_cap[idx_max_vol]:.1f} mAh/g, "
      f"ÈõªÂúß={pareto_vol[idx_max_vol]:.2f} V, "
      f"ÂÆâÂÆöÊÄß={pareto_sta[idx_max_vol]:.2f}")

<h1>„Éê„É©„É≥„ÇπÂûã</h1>
<h1>Ê≠£Ë¶èÂåñ„Åó„Å¶‰∏≠ÂøÉ„Å´ÊúÄ„ÇÇËøë„ÅÑËß£</h1>
pareto_array = np.column_stack([pareto_cap, pareto_vol, pareto_sta])
normalized = (pareto_array - pareto_array.min(axis=0)) / \
             (pareto_array.max(axis=0) - pareto_array.min(axis=0))
distances = np.sqrt(((normalized - 0.5)**2).sum(axis=1))
idx_balanced = np.argmin(distances)

print(f"\n„Éê„É©„É≥„ÇπÂûã:")
print(f"  Li={pareto_solutions[idx_balanced]['composition'][0]:.3f}, "
      f"Ni={pareto_solutions[idx_balanced]['composition'][1]:.3f}, "
      f"Co={pareto_solutions[idx_balanced]['composition'][2]:.3f}, "
      f"Mn={pareto_solutions[idx_balanced]['composition'][3]:.3f}")
print(f"  ÂÆπÈáè={pareto_cap[idx_balanced]:.1f} mAh/g, "
      f"ÈõªÂúß={pareto_vol[idx_balanced]:.2f} V, "
      f"ÂÆâÂÆöÊÄß={pareto_sta[idx_balanced]:.2f}")</code></pre>

---

<h2>3.6 „Ç≥„É©„É†Ôºö„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø vs ÊùêÊñô„Éë„É©„É°„Éº„Çø</h2>

<h3>2Á®ÆÈ°û„ÅÆ„Éë„É©„É°„Éº„Çø</h3>

ÊùêÊñôÊé¢Á¥¢„Åß„ÅØ„ÄÅ2Á®ÆÈ°û„ÅÆ„Éë„É©„É°„Éº„Çø„ÇíÂå∫Âà•„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„ÅôÔºö

<strong>ÊùêÊñô„Éë„É©„É°„Éº„ÇøÔºàË®≠Ë®àÂ§âÊï∞Ôºâ</strong>:
- ÊúÄÈÅ©Âåñ„Åó„Åü„ÅÑÂ§âÊï∞
- ‰æã: ÁµÑÊàêÊØî„ÄÅÂêàÊàêÊ∏©Â∫¶„ÄÅÂúßÂäõ
- „Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅßÊé¢Á¥¢

<strong>„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„ÇøÔºà„Ç¢„É´„Ç¥„É™„Ç∫„É†Ë®≠ÂÆöÔºâ</strong>:
- „Éô„Ç§„Ç∫ÊúÄÈÅ©ÂåñËá™‰Ωì„ÅÆË®≠ÂÆö
- ‰æã: „Ç´„Éº„Éç„É´„ÅÆÈï∑„Åï„Çπ„Ç±„Éº„É´„ÄÅÊé¢Á¥¢„Éë„É©„É°„Éº„ÇøŒ∫
- „ÇØ„É≠„Çπ„Éê„É™„Éá„Éº„Ç∑„Éß„É≥„ÇÑ„Éç„Çπ„ÉÜ„ÉÉ„ÉâBO „ÅßÊúÄÈÅ©Âåñ

<h3>„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅÆÈáçË¶ÅÊÄß</h3>

‰∏çÈÅ©Âàá„Å™„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅØ„ÄÅÊúÄÈÅ©ÂåñÂäπÁéá„ÇíÂ§ß„Åç„ÅèÊêç„Å™„ÅÑ„Åæ„ÅôÔºö

- <strong>Èï∑„Åï„Çπ„Ç±„Éº„É´„ÅåÂ§ß„Åç„Åô„Åé</strong> ‚Üí Á¥∞„Åã„ÅÑÊßãÈÄ†„ÇíÊçâ„Åà„Çâ„Çå„Å™„ÅÑ
- <strong>Èï∑„Åï„Çπ„Ç±„Éº„É´„ÅåÂ∞è„Åï„Åô„Åé</strong> ‚Üí „Ç™„Éº„Éê„Éº„Éï„Ç£„ÉÉ„Éà„ÄÅÊé¢Á¥¢„ÅåÂ±ÄÊâÄÁöÑ
- <strong>Œ∫ÔºàUCBÔºâ„ÅåÂ§ß„Åç„Åô„Åé</strong> ‚Üí Êé¢Á¥¢ÈáçË¶ñ„ÄÅÂèéÊùüÈÅÖ„ÅÑ
- <strong>Œ∫„ÅåÂ∞è„Åï„Åô„Åé</strong> ‚Üí Ê¥ªÁî®ÈáçË¶ñ„ÄÅÂ±ÄÊâÄÊúÄÈÅ©„Å´„ÅØ„Åæ„Çã

<strong>Êé®Â•®„Ç¢„Éó„É≠„Éº„ÉÅ</strong>:
1. <strong>„Éá„Éº„ÇøÈßÜÂãï</strong>: Êó¢Â≠ò„Éá„Éº„Çø„Åß„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÇíÊúÄÈÅ©Âåñ
2. <strong>„É≠„Éê„Çπ„ÉàË®≠ÂÆö</strong>: Â∫ÉÁØÑÂõ≤„ÅßËâØÂ•Ω„Å™ÊÄßËÉΩ„ÇíÁ§∫„ÅôË®≠ÂÆö„ÇíÈÅ∏Êäû
3. <strong>ÈÅ©ÂøúÁöÑË™øÊï¥</strong>: ÊúÄÈÅ©Âåñ„ÅÆÈÄ≤Ë°å„Å´Âøú„Åò„Å¶Œ∫„ÇíÊ∏õÂ∞ëÔºàÊé¢Á¥¢‚ÜíÊ¥ªÁî®Ôºâ

<strong>„Ç≥„Éº„Éâ‰æã8: „Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅÆÂΩ±Èüø„ÇíÂèØË¶ñÂåñ</strong>

<pre><code class="language-python"><h1>„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅÆÂΩ±Èüø„ÇíÊØîËºÉ</h1>
from sklearn.gaussian_process.kernels import RBF, ConstantKernel

def compare_hyperparameters():
    """
    Áï∞„Å™„Çã„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„Åß„ÅÆÊúÄÈÅ©ÂåñÂäπÁéá„ÇíÊØîËºÉ
    """
    # „ÉÜ„Çπ„ÉàÈñ¢Êï∞
    def test_function(x):
        return (np.sin(5*x) * np.exp(-x) +
                0.5 * np.exp(-((x-0.6)/0.15)**2))

    # Áï∞„Å™„ÇãÈï∑„Åï„Çπ„Ç±„Éº„É´
    length_scales = [0.05, 0.1, 0.3]

    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    for idx, ls in enumerate(length_scales):
        ax = axes[idx]

        # ÂàùÊúü„Éá„Éº„Çø
        np.random.seed(42)
        X_init = np.array([0.1, 0.4, 0.7]).reshape(-1, 1)
        y_init = test_function(X_init.ravel())

        # „Ç¨„Ç¶„ÇπÈÅéÁ®ã
        kernel = ConstantKernel(1.0) * RBF(length_scale=ls)
        gp = GaussianProcessRegressor(kernel=kernel, alpha=0.01,
                                       random_state=42)
        gp.fit(X_init, y_init)

        # ‰∫àÊ∏¨
        X_plot = np.linspace(0, 1, 200).reshape(-1, 1)
        y_pred, y_std = gp.predict(X_plot, return_std=True)

        # „Éó„É≠„ÉÉ„Éà
        ax.plot(X_plot, test_function(X_plot.ravel()), 'k--',
                linewidth=2, label='Áúü„ÅÆÈñ¢Êï∞')
        ax.scatter(X_init, y_init, c='red', s=100, zorder=10,
                   edgecolors='black', label='Ë¶≥Ê∏¨„Éá„Éº„Çø')
        ax.plot(X_plot, y_pred, 'b-', linewidth=2, label='‰∫àÊ∏¨Âπ≥Âùá')
        ax.fill_between(X_plot.ravel(), y_pred - 1.96*y_std,
                         y_pred + 1.96*y_std, alpha=0.3, color='blue')
        ax.set_xlabel('x', fontsize=12)
        ax.set_ylabel('y', fontsize=12)
        ax.set_title(f'Èï∑„Åï„Çπ„Ç±„Éº„É´ = {ls}', fontsize=14)
        ax.legend()
        ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('hyperparameter_comparison.png', dpi=150,
                bbox_inches='tight')
    plt.show()

    print("„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅÆÂΩ±Èüø:")
    print("  Èï∑„Åï„Çπ„Ç±„Éº„É´ 0.05: Â±ÄÊâÄÁöÑ„ÄÅÁ¥∞„Åã„ÅÑÊßãÈÄ†„ÇíÊçâ„Åà„Çã")
    print("  Èï∑„Åï„Çπ„Ç±„Éº„É´ 0.1: „Éê„É©„É≥„Çπ„ÅåËâØ„ÅÑ")
    print("  Èï∑„Åï„Çπ„Ç±„Éº„É´ 0.3: Êªë„Çâ„Åã„ÄÅÂ§ßÂüüÁöÑ„Å™ÂÇæÂêë")

<h1>ÂÆüË°å</h1>
compare_hyperparameters()</code></pre>

---

<h2>3.7 „Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞</h2>

<h3>„Çà„Åè„ÅÇ„ÇãÂïèÈ°å„Å®Ëß£Ê±∫Á≠ñ</h3>

<strong>ÂïèÈ°å1: ÊúÄÈÅ©Âåñ„ÅåÂ±ÄÊâÄÊúÄÈÅ©„Å´„ÅØ„Åæ„Çã</strong>

<strong>ÂéüÂõ†</strong>:
- ÂàùÊúü„Çµ„É≥„Éó„É™„É≥„Ç∞„ÅåÂÅè„Å£„Å¶„ÅÑ„Çã
- Êé¢Á¥¢„Éë„É©„É°„Éº„Çø„ÅåÂ∞è„Åï„Åô„Åé„Çã
- Áç≤ÂæóÈñ¢Êï∞„ÅåÊ¥ªÁî®ÈáçË¶ñ

<strong>Ëß£Ê±∫Á≠ñ</strong>:
<pre><code class="language-python"><h1>1. ÂàùÊúü„Çµ„É≥„Éó„É™„É≥„Ç∞„ÇíÂ¢ó„ÇÑ„Åô</h1>
n_initial_points = 20  # 10 ‚Üí 20

<h1>2. UCB„ÅÆŒ∫„ÇíÂ§ß„Åç„Åè„Åô„ÇãÔºàÊé¢Á¥¢ÈáçË¶ñÔºâ</h1>
kappa = 3.0  # 2.0 ‚Üí 3.0

<h1>3. „É©„ÉÜ„É≥Ë∂ÖÊñπÊ†º„Çµ„É≥„Éó„É™„É≥„Ç∞</h1>
from scipy.stats.qmc import LatinHypercube

sampler = LatinHypercube(d=4, seed=42)
X_init_lhs = sampler.random(n=20)  # „Çà„ÇäÂùáÁ≠â„Å´ÂàÜÂ∏É</code></pre>

<strong>ÂïèÈ°å2: Âà∂Á¥Ñ„ÇíÊ∫Ä„Åü„ÅôËß£„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑ</strong>

<strong>ÂéüÂõ†</strong>:
- Âà∂Á¥Ñ„ÅåÂé≥„Åó„Åô„Åé„Çã
- ÂÆüË°åÂèØËÉΩÈ†òÂüü„ÅåÁã≠„ÅÑ
- ÂàùÊúüÁÇπ„ÅåÂÆüË°å‰∏çÂèØËÉΩÈ†òÂüü„Å´ÈõÜ‰∏≠

<strong>Ëß£Ê±∫Á≠ñ</strong>:
<pre><code class="language-python"><h1>1. Âà∂Á¥ÑÁ∑©ÂíåÔºàÊÆµÈöéÁöÑ„Å´Âé≥„Åó„ÅèÔºâ</h1>
<h1>ÂàùÊúü: Á∑©„ÅÑÂà∂Á¥Ñ ‚Üí Âæê„ÄÖ„Å´Âé≥„Åó„Åè</h1>

<h1>2. ÂÆüË°åÂèØËÉΩÈ†òÂüü„ÇíÊòéÁ§∫ÁöÑ„Å´„Çµ„É≥„Éó„É™„É≥„Ç∞</h1>
def sample_feasible_region(n_samples):
    """ÂÆüË°åÂèØËÉΩÈ†òÂüü„Åã„Çâ„Çµ„É≥„Éó„É™„É≥„Ç∞"""
    samples = []
    while len(samples) < n_samples:
        x = np.random.rand(4)
        x = x / x.sum()
        if is_feasible(x):  # Âà∂Á¥Ñ„ÉÅ„Çß„ÉÉ„ÇØ
            samples.append(x)
    return np.array(samples)

<h1>3. Two-stage approach</h1>
<h1>Stage 1: Âà∂Á¥Ñ„Å™„Åó„ÅßÊé¢Á¥¢</h1>
<h1>Stage 2: ËâØ„ÅÑÈ†òÂüü„ÅßÂà∂Á¥Ñ‰ªò„ÅçÊúÄÈÅ©Âåñ</h1></code></pre>

<strong>ÂïèÈ°å3: Ë®àÁÆóÊôÇÈñì„ÅåÈï∑„ÅÑ</strong>

<strong>ÂéüÂõ†</strong>:
- „Ç¨„Ç¶„ÇπÈÅéÁ®ã„ÅÆË®àÁÆóÈáè: O(n¬≥)
- Áç≤ÂæóÈñ¢Êï∞„ÅÆÊúÄÈÅ©Âåñ„ÅåÈÅÖ„ÅÑ

<strong>Ëß£Ê±∫Á≠ñ</strong>:
<pre><code class="language-python"><h1>1. „Çπ„Éë„Éº„Çπ„Ç¨„Ç¶„ÇπÈÅéÁ®ã</h1>
<h1>‰ª£Ë°®ÁÇπÔºàInducing pointsÔºâ„Çí‰ΩøÁî®</h1>

<h1>2. Áç≤ÂæóÈñ¢Êï∞„ÅÆÊúÄÈÅ©Âåñ„ÇíÁ∞°Áï•Âåñ</h1>
<h1>„Ç∞„É™„ÉÉ„Éâ„Çµ„Éº„ÉÅ ‚Üí „É©„É≥„ÉÄ„É†„Çµ„Éº„ÉÅ</h1>
n_candidates = 1000  # Â∞ëÊï∞„ÅÆ„É©„É≥„ÉÄ„É†ÁÇπ„Åã„ÇâÈÅ∏Êäû

<h1>3. ‰∏¶ÂàóË®àÁÆóÔºàË§áÊï∞CPUÔºâ</h1>
from joblib import Parallel, delayed

<h1>4. GPU„Ç¢„ÇØ„Çª„É©„É¨„Éº„Ç∑„Éß„É≥ÔºàBoTorch + PyTorchÔºâ</h1></code></pre>

---

<h2>3.8 Êú¨Á´†„ÅÆ„Åæ„Å®„ÇÅ</h2>

<h3>Â≠¶„Çì„Å†„Åì„Å®</h3>

1. <strong>ML„É¢„Éá„É´„Å®„ÅÆÁµ±Âêà</strong>
   - Materials Project API„Åß„Éá„Éº„ÇøÂèñÂæó
   - Random Forest„ÅßÁâ©ÊÄß‰∫àÊ∏¨„É¢„Éá„É´ÊßãÁØâ
   - ML„É¢„Éá„É´„ÇíÁõÆÁöÑÈñ¢Êï∞„Å®„Åó„Å¶„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ

2. <strong>Âà∂Á¥Ñ‰ªò„ÅçÊúÄÈÅ©Âåñ</strong>
   - ÁµÑÊàêÂà∂Á¥Ñ„ÄÅÂÆâÂÆöÊÄßÂà∂Á¥Ñ„ÄÅ„Ç≥„Çπ„ÉàÂà∂Á¥Ñ
   - Âà∂Á¥Ñ„ÇíÊ∫Ä„Åü„ÅôÁ¢∫Áéá„ÇíÁç≤ÂæóÈñ¢Êï∞„Å´ÁµÑ„ÅøËæº„ÇÄ
   - ÂÆüË°åÂèØËÉΩÈ†òÂüü„Å´ÈõÜ‰∏≠„Åó„Å¶Êé¢Á¥¢

3. <strong>Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ</strong>
   - Pareto„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢„ÅÆË®àÁÆó
   - Expected Hypervolume ImprovementÔºàEHVIÔºâ
   - „Éà„É¨„Éº„Éâ„Ç™„Éï„ÅÆÂèØË¶ñÂåñ„Å®ÊÑèÊÄùÊ±∫ÂÆö

4. <strong>„Éê„ÉÉ„ÉÅÊúÄÈÅ©Âåñ</strong>
   - ‰∏¶ÂàóÂÆüÈ®ì„Å´„Çà„ÇãÂäπÁéáÂåñ
   - q-EIÁç≤ÂæóÈñ¢Êï∞
   - ÂÆüÈ®ì„Ç≥„Çπ„Éà„ÇíËÄÉÊÖÆ„Åó„ÅüÊúÄÈÅ©ÂåñÊà¶Áï•

5. <strong>ÂÆü‰∏ñÁïåÂøúÁî®</strong>
   - Li-ionÈõªÊ±†Ê≠£Ê•µÊùêÊñô„ÅÆÂÆåÂÖ®ÂÆüË£Ö
   - 3ÁõÆÁöÑÂêåÊôÇÊúÄÈÅ©Âåñ
   - ÂÆüÈ®ìÂõûÊï∞50%ÂâäÊ∏õ„ÅÆÂÆüÁèæ

<h3>ÈáçË¶Å„Å™„Éù„Ç§„É≥„Éà</h3>

- ‚úÖ <strong>ÂÆü„Éá„Éº„Çø„Å®„ÅÆÁµ±Âêà</strong>„ÅåÊùêÊñôÊé¢Á¥¢„ÅÆÈçµ
- ‚úÖ <strong>Âà∂Á¥Ñ„ÇíËÄÉÊÖÆ</strong>„Åó„Å™„ÅÑ„Å®ÂÆüË°å‰∏çÂèØËÉΩ„Å™ÊùêÊñô„ÇíÊèêÊ°à
- ‚úÖ <strong>Â§öÁõÆÁöÑÊúÄÈÅ©Âåñ</strong>„Åß„Éà„É¨„Éº„Éâ„Ç™„Éï„ÇíÊòéÁ§∫ÁöÑ„Å´Êâ±„ÅÜ
- ‚úÖ <strong>„Éê„ÉÉ„ÉÅBO</strong>„Åß‰∏¶ÂàóÂÆüÈ®ì„ÅÆÂäπÁéá„ÇíÊúÄÂ§ßÂåñ
- ‚úÖ <strong>„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„ÇøË™øÊï¥</strong>„ÅåÊÄßËÉΩ„ÇíÂ∑¶Âè≥

<h3>Ê¨°„ÅÆÁ´†„Å∏</h3>

Á¨¨4Á´†„Åß„ÅØ„ÄÅ„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞„Å®ÂÆüÈ®ì„Å®„ÅÆÈÄ£Êê∫„ÇíÂ≠¶„Å≥„Åæ„ÅôÔºö
- Uncertainty Sampling
- Query-by-Committee
- „ÇØ„É≠„Éº„Ç∫„Éâ„É´„Éº„ÉóÊúÄÈÅ©Âåñ
- Ëá™ÂãïÂÆüÈ®ìË£ÖÁΩÆ„Å®„ÅÆÁµ±Âêà

<strong>[Á¨¨4Á´†Ôºö„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞„Å®ÂÆüÈ®ìÈÄ£Êê∫ ‚Üí](./chapter-4.md)</strong>

---

<h2>ÊºîÁøíÂïèÈ°å</h2>

<h3>ÂïèÈ°å1ÔºàÈõ£ÊòìÂ∫¶ÔºöeasyÔºâ</h3>

Materials Project„ÅÆ„ÉÄ„Éü„Éº„Éá„Éº„Çø„Çí‰ΩøÁî®„Åó„Å¶„ÄÅRandom Forest„É¢„Éá„É´„ÅßÂÆπÈáè‰∫àÊ∏¨„ÇíË°å„Å£„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

<strong>„Çø„Çπ„ÇØ</strong>:
1. <code>generate_dummy_battery_data()</code>„Åß100„Çµ„É≥„Éó„É´ÁîüÊàê
2. Random Forest„ÅßË®ìÁ∑¥Ôºà80/20ÂàÜÂâ≤Ôºâ
3. „ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÅßRMSE„Å®R¬≤„ÇíË®àÁÆó
4. ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶„Çí„Éó„É≠„ÉÉ„Éà

<details>
<summary>„Éí„É≥„Éà</summary>

- <code>train_test_split()</code>„Åß„Éá„Éº„ÇøÂàÜÂâ≤
- <code>RandomForestRegressor</code>„ÅÆ„Éá„Éï„Ç©„É´„Éà„Éë„É©„É°„Éº„Çø„ÅßÂçÅÂàÜ
- <code>feature_importances_</code>Â±ûÊÄß„ÅßÈáçË¶ÅÂ∫¶ÂèñÂæó

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<pre><code class="language-python">import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

<h1>„Éá„Éº„ÇøÁîüÊàê</h1>
df = generate_dummy_battery_data(n_samples=100)

<h1>ÁâπÂæ¥Èáè„Å®„Çø„Éº„Ç≤„ÉÉ„Éà</h1>
X = df[['li_content', 'ni_content', 'co_content', 'mn_content']].values
y = df['capacity'].values

<h1>„Éá„Éº„ÇøÂàÜÂâ≤</h1>
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

<h1>Random Forest„É¢„Éá„É´</h1>
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

<h1>‰∫àÊ∏¨</h1>
y_pred = rf.predict(X_test)

<h1>Ë©ï‰æ°</h1>
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print("„É¢„Éá„É´ÊÄßËÉΩ:")
print(f"  RMSE: {rmse:.2f} mAh/g")
print(f"  R¬≤: {r2:.3f}")

<h1>ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶</h1>
feature_names = ['Li', 'Ni', 'Co', 'Mn']
importances = rf.feature_importances_

plt.figure(figsize=(8, 5))
plt.barh(feature_names, importances, color='steelblue')
plt.xlabel('ÈáçË¶ÅÂ∫¶', fontsize=12)
plt.title('ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶', fontsize=14)
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()
plt.show()

print("\nÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶:")
for name, imp in zip(feature_names, importances):
    print(f"  {name}: {imp:.3f}")</code></pre>

<strong>ÊúüÂæÖ„Åï„Çå„ÇãÂá∫Âäõ</strong>:
<pre><code>„É¢„Éá„É´ÊÄßËÉΩ:
  RMSE: 30.12 mAh/g
  R¬≤: 0.892

ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶:
  Li: 0.623
  Ni: 0.247
  Co: 0.089
  Mn: 0.041</code></pre>

<strong>Ëß£Ë™¨</strong>:
- LiÂê´Èáè„ÅåÂÆπÈáè„Å´ÊúÄ„ÇÇÂΩ±ÈüøÔºà„É™„ÉÅ„Ç¶„É†„Ç§„Ç™„É≥Ê∫êÔºâ
- Ni„ÇÇÈáçË¶ÅÔºàÈÖ∏ÂåñÈÇÑÂÖÉÊ¥ªÊÄßÔºâ
- Co, Mn„ÅØÊßãÈÄ†ÂÆâÂÆöÂåñ„ÅÆÂΩπÂâ≤

</details>

---

<h3>ÂïèÈ°å2ÔºàÈõ£ÊòìÂ∫¶ÔºömediumÔºâ</h3>

Âà∂Á¥Ñ‰ªò„Åç„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÇíÂÆüË£Ö„Åó„ÄÅÂà∂Á¥Ñ„Å™„Åó„ÅÆÂ†¥Âêà„Å®ÊØîËºÉ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

<strong>ÂïèÈ°åË®≠ÂÆö</strong>:
- ÁõÆÁöÑ: ÂÆπÈáè„ÇíÊúÄÂ§ßÂåñ
- Âà∂Á¥Ñ: CoÂê´Èáè < 0.25Ôºà„Ç≥„Çπ„ÉàÂà∂Á¥ÑÔºâ

<strong>„Çø„Çπ„ÇØ</strong>:
1. Âà∂Á¥Ñ„Å™„Åó„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„Çí20ÂõûÂÆüË°å
2. Âà∂Á¥Ñ‰ªò„Åç„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„Çí20ÂõûÂÆüË°å
3. ÂêÑ„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥„Åß„ÅÆÊúÄËâØÂÄ§„Çí„Éó„É≠„ÉÉ„Éà
4. ÊúÄÁµÇÁöÑ„Å™ÊúÄÈÅ©ÁµÑÊàê„ÇíÊØîËºÉ

<details>
<summary>„Éí„É≥„Éà</summary>

<strong>Âà∂Á¥Ñ„ÅÆÂÆüË£Ö</strong>:
<pre><code class="language-python">def constraint_penalty(x):
    """Âà∂Á¥ÑÈÅïÂèç„Å´„Éö„Éä„É´„ÉÜ„Ç£"""
    co_content = x[2]
    if co_content > 0.25:
        return 1000  # Â§ß„Åç„Å™„Éö„Éä„É´„ÉÜ„Ç£
    return 0</code></pre>

<strong>Áç≤ÂæóÈñ¢Êï∞„Å´ÁµÑ„ÅøËæº„ÇÄ</strong>:
<pre><code class="language-python">capacity = rf_model.predict(x)
penalty = constraint_penalty(x)
return -(capacity - penalty)  # ÊúÄÂ∞èÂåñÂïèÈ°å</code></pre>

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<pre><code class="language-python">from skopt import gp_minimize
from skopt.space import Real

<h1>ÁõÆÁöÑÈñ¢Êï∞ÔºàÂà∂Á¥Ñ„Å™„ÅóÔºâ</h1>
def objective_unconstrained(x):
    """Âà∂Á¥Ñ„Å™„Åó"""
    li, ni, co, mn = x
    total = li + ni + co + mn
    if not (0.98 <= total <= 1.02):
        return 1000.0
    X_pred = np.array([[li, ni, co, mn]])
    capacity = rf_model.predict(X_pred)[0]
    return -capacity  # ÊúÄÂ∞èÂåñ

<h1>ÁõÆÁöÑÈñ¢Êï∞ÔºàÂà∂Á¥Ñ‰ªò„ÅçÔºâ</h1>
def objective_constrained(x):
    """CoÂê´Èáè < 0.25„ÅÆÂà∂Á¥Ñ"""
    li, ni, co, mn = x
    total = li + ni + co + mn
    if not (0.98 <= total <= 1.02):
        return 1000.0
    if co > 0.25:  # Âà∂Á¥ÑÈÅïÂèç
        return 1000.0
    X_pred = np.array([[li, ni, co, mn]])
    capacity = rf_model.predict(X_pred)[0]
    return -capacity

<h1>Êé¢Á¥¢Á©∫Èñì</h1>
space = [
    Real(0.1, 0.5, name='li'),
    Real(0.1, 0.4, name='ni'),
    Real(0.1, 0.4, name='co'),
    Real(0.0, 0.5, name='mn')
]

<h1>Âà∂Á¥Ñ„Å™„Åó</h1>
result_unconstrained = gp_minimize(
    objective_unconstrained, space,
    n_calls=20, n_initial_points=5, random_state=42
)

<h1>Âà∂Á¥Ñ‰ªò„Åç</h1>
result_constrained = gp_minimize(
    objective_constrained, space,
    n_calls=20, n_initial_points=5, random_state=42
)

<h1>ÁµêÊûú</h1>
print("Âà∂Á¥Ñ„Å™„Åó:")
print(f"  ÊúÄÈÅ©ÁµÑÊàê: Li={result_unconstrained.x[0]:.3f}, "
      f"Ni={result_unconstrained.x[1]:.3f}, "
      f"Co={result_unconstrained.x[2]:.3f}, "
      f"Mn={result_unconstrained.x[3]:.3f}")
print(f"  ÂÆπÈáè: {-result_unconstrained.fun:.2f} mAh/g")

print("\nÂà∂Á¥Ñ‰ªò„Åç (Co < 0.25):")
print(f"  ÊúÄÈÅ©ÁµÑÊàê: Li={result_constrained.x[0]:.3f}, "
      f"Ni={result_constrained.x[1]:.3f}, "
      f"Co={result_constrained.x[2]:.3f}, "
      f"Mn={result_constrained.x[3]:.3f}")
print(f"  ÂÆπÈáè: {-result_constrained.fun:.2f} mAh/g")

<h1>ÂèØË¶ñÂåñ</h1>
plt.figure(figsize=(10, 6))
plt.plot(-np.minimum.accumulate(result_unconstrained.func_vals),
         'o-', label='Âà∂Á¥Ñ„Å™„Åó', linewidth=2, markersize=8)
plt.plot(-np.minimum.accumulate(result_constrained.func_vals),
         '^-', label='Âà∂Á¥Ñ‰ªò„Åç (Co < 0.25)', linewidth=2, markersize=8)
plt.xlabel('Ë©ï‰æ°ÂõûÊï∞', fontsize=12)
plt.ylabel('„Åì„Çå„Åæ„Åß„ÅÆÊúÄËâØÂÄ§ (mAh/g)', fontsize=12)
plt.title('Âà∂Á¥Ñ‰ªò„Åç vs Âà∂Á¥Ñ„Å™„Åó„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ', fontsize=14)
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()</code></pre>

<strong>ÊúüÂæÖ„Åï„Çå„ÇãÂá∫Âäõ</strong>:
<pre><code>Âà∂Á¥Ñ„Å™„Åó:
  ÊúÄÈÅ©ÁµÑÊàê: Li=0.487, Ni=0.312, Co=0.352, Mn=0.049
  ÂÆπÈáè: 267.34 mAh/g

Âà∂Á¥Ñ‰ªò„Åç (Co < 0.25):
  ÊúÄÈÅ©ÁµÑÊàê: Li=0.492, Ni=0.315, Co=0.248, Mn=0.045
  ÂÆπÈáè: 261.78 mAh/g</code></pre>

<strong>Ëß£Ë™¨</strong>:
- Âà∂Á¥Ñ‰ªò„Åç„ÅØÂÆπÈáè„Åå„Çè„Åö„Åã„Å´‰Ωé„ÅÑÔºà2%‰Ωé‰∏ãÔºâ
- CoÂê´Èáè„ÇíÂà∂Èôê„Åó„Å¶„ÇÇÂÆüÁî®ÁöÑ„Å™ÊÄßËÉΩ„ÇíÁ∂≠ÊåÅ
- „Ç≥„Çπ„Éà„Å®ÊÄßËÉΩ„ÅÆ„Éà„É¨„Éº„Éâ„Ç™„Éï„ÇíÂÆöÈáèÂåñ

</details>

---

<h3>ÂïèÈ°å3ÔºàÈõ£ÊòìÂ∫¶ÔºöhardÔºâ</h3>

Â§öÁõÆÁöÑ„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÇíÂÆüË£Ö„Åó„ÄÅÂÆπÈáè„Å®ÂÆâÂÆöÊÄß„ÅÆPareto„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢„ÇíË®àÁÆó„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

<strong>ÂïèÈ°åË®≠ÂÆö</strong>:
- ÁõÆÁöÑ1: ÂÆπÈáè„ÇíÊúÄÂ§ßÂåñ
- ÁõÆÁöÑ2: ÂÆâÂÆöÊÄß„ÇíÊúÄÂ§ßÂåñÔºàformation energy„ÅÆÁµ∂ÂØæÂÄ§„ÇíÊúÄÂ∞èÂåñÔºâ

<strong>„Çø„Çπ„ÇØ</strong>:
1. ÂàùÊúü„É©„É≥„ÉÄ„É†„Çµ„É≥„Éó„É™„É≥„Ç∞Ôºà15ÁÇπÔºâ
2. ÈÄêÊ¨°ÊúÄÈÅ©ÂåñÔºà30ÂõûÔºâ
3. ParetoÊúÄÈÅ©Ëß£„ÇíÊäΩÂá∫
4. Pareto„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢„ÇíÂèØË¶ñÂåñ
5. ‰ª£Ë°®ÁöÑ„Å™3„Å§„ÅÆËß£ÔºàÂÆπÈáèÈáçË¶ñ„ÄÅÂÆâÂÆöÊÄßÈáçË¶ñ„ÄÅ„Éê„É©„É≥„ÇπÂûãÔºâ„ÇíÊèêÁ§∫

<details>
<summary>„Éí„É≥„Éà</summary>

<strong>ParetoÊúÄÈÅ©Âà§ÂÆö</strong>:
<pre><code class="language-python">def is_pareto_optimal(Y):
    """
    Y: (n_points, n_objectives)
    ÂÖ®„Å¶ÊúÄÂ§ßÂåñÂïèÈ°å„Å®‰ªÆÂÆö
    """
    n = len(Y)
    is_optimal = np.ones(n, dtype=bool)
    for i in range(n):
        if is_optimal[i]:
            # i„Çà„ÇäÂÖ®„Å¶„ÅÆÁõÆÁöÑ„ÅßÂÑ™„Çå„Å¶„ÅÑ„ÇãÁÇπ
            dominated = ((Y >= Y[i]).all(axis=1) &
                         (Y > Y[i]).any(axis=1))
            is_optimal[dominated] = False
    return is_optimal</code></pre>

<strong>„Çπ„Ç´„É©„ÉºÂåñ„Å´„Çà„ÇãËøë‰ºº</strong>:
<pre><code class="language-python"><h1>„É©„É≥„ÉÄ„É†„Å™Èáç„Åø„Åß„Çπ„Ç´„É©„ÉºÂåñ</h1>
w1, w2 = np.random.rand(2)
w1, w2 = w1/(w1+w2), w2/(w1+w2)
objective = w1 * capacity + w2 * stability</code></pre>

</details>

<details>
<summary>Ëß£Á≠î‰æã</summary>

<pre><code class="language-python"><h1>Â§öÁõÆÁöÑ„Éô„Ç§„Ç∫ÊúÄÈÅ©ÂåñÔºà„Çπ„Ç´„É©„ÉºÂåñ„Ç¢„Éó„É≠„Éº„ÉÅÔºâ</h1>
def multi_objective_optimization():
    """
    ÂÆπÈáè„Å®ÂÆâÂÆöÊÄß„ÅÆÂ§öÁõÆÁöÑÊúÄÈÅ©Âåñ
    """
    # ÂàùÊúü„Çµ„É≥„Éó„É™„É≥„Ç∞
    n_initial = 15
    np.random.seed(42)

    X_sampled = np.random.rand(n_initial, 4)
    X_sampled = X_sampled / X_sampled.sum(axis=1, keepdims=True)

    # 2„Å§„ÅÆÁõÆÁöÑ„ÇíË©ï‰æ°
    Y_capacity = []
    Y_stability = []

    for x in X_sampled:
        capacity = rf_model.predict(x.reshape(1, -1))[0]
        stability = -2.0 - 0.5*x[0] - 0.3*x[1] + 0.1*np.random.randn()
        stability_positive = -stability  # Ê≠£„Å´Â§âÊèõ

        Y_capacity.append(capacity)
        Y_stability.append(stability_positive)

    Y_capacity = np.array(Y_capacity)
    Y_stability = np.array(Y_stability)

    # ÈÄêÊ¨°ÊúÄÈÅ©ÂåñÔºà„Çπ„Ç´„É©„ÉºÂåñÔºâ
    n_iterations = 30

    for iteration in range(n_iterations):
        # „É©„É≥„ÉÄ„É†„Å™Èáç„Åø
        w1 = np.random.rand()
        w2 = 1 - w1

        # Ê≠£Ë¶èÂåñ
        cap_normalized = (Y_capacity - Y_capacity.min()) / \
                         (Y_capacity.max() - Y_capacity.min())
        sta_normalized = (Y_stability - Y_stability.min()) / \
                         (Y_stability.max() - Y_stability.min())

        # „Çπ„Ç´„É©„ÉºÂåñ„Åó„ÅüÁõÆÁöÑ
        Y_scalar = w1 * cap_normalized + w2 * sta_normalized

        # „Ç¨„Ç¶„ÇπÈÅéÁ®ã„É¢„Éá„É´
        from sklearn.gaussian_process import GaussianProcessRegressor
        from sklearn.gaussian_process.kernels import RBF, ConstantKernel

        kernel = ConstantKernel(1.0) * RBF(length_scale=0.2)
        gp = GaussianProcessRegressor(kernel=kernel,
                                       n_restarts_optimizer=10,
                                       random_state=42)
        gp.fit(X_sampled, Y_scalar)

        # Áç≤ÂæóÈñ¢Êï∞ÔºàEIÔºâ
        best_f = Y_scalar.max()
        X_candidates = np.random.rand(1000, 4)
        X_candidates = X_candidates / X_candidates.sum(axis=1, keepdims=True)

        mu, sigma = gp.predict(X_candidates, return_std=True)
        improvement = mu - best_f
        Z = improvement / (sigma + 1e-9)
        ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)

        # Ê¨°„ÅÆÂÄôË£ú
        next_idx = np.argmax(ei)
        x_new = X_candidates[next_idx]

        # Ë©ï‰æ°
        capacity_new = rf_model.predict(x_new.reshape(1, -1))[0]
        stability_new = -2.0 - 0.5*x_new[0] - 0.3*x_new[1] + \
                        0.1*np.random.randn()
        stability_positive_new = -stability_new

        # „Éá„Éº„Çø„Å´ËøΩÂä†
        X_sampled = np.vstack([X_sampled, x_new])
        Y_capacity = np.append(Y_capacity, capacity_new)
        Y_stability = np.append(Y_stability, stability_positive_new)

    # ParetoÊúÄÈÅ©Ëß£„ÇíÊäΩÂá∫
    Y_combined = np.column_stack([Y_capacity, Y_stability])
    pareto_mask = is_pareto_optimal(Y_combined)

    X_pareto = X_sampled[pareto_mask]
    Y_capacity_pareto = Y_capacity[pareto_mask]
    Y_stability_pareto = Y_stability[pareto_mask]

    print(f"ParetoÊúÄÈÅ©Ëß£Êï∞: {pareto_mask.sum()}")

    # ÂèØË¶ñÂåñ
    plt.figure(figsize=(10, 6))

    plt.scatter(Y_capacity, Y_stability, c='lightblue', s=50,
                alpha=0.5, label='ÂÖ®Êé¢Á¥¢ÁÇπ')
    plt.scatter(Y_capacity_pareto, Y_stability_pareto, c='red',
                s=100, edgecolors='black', zorder=10,
                label='ParetoÊúÄÈÅ©Ëß£')

    # Pareto„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢„ÇíÁ∑ö„ÅßÁµê„Å∂
    sorted_indices = np.argsort(Y_capacity_pareto)
    plt.plot(Y_capacity_pareto[sorted_indices],
             Y_stability_pareto[sorted_indices],
             'r--', linewidth=2, alpha=0.5)

    plt.xlabel('ÂÆπÈáè (mAh/g)', fontsize=12)
    plt.ylabel('ÂÆâÂÆöÊÄß (-formation energy)', fontsize=12)
    plt.title('Pareto„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢: ÂÆπÈáè vs ÂÆâÂÆöÊÄß', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('pareto_frontier_exercise.png', dpi=150,
                bbox_inches='tight')
    plt.show()

    # ‰ª£Ë°®ÁöÑ„Å™Ëß£
    print("\n‰ª£Ë°®ÁöÑ„Å™ParetoËß£:")

    # ÂÆπÈáèÈáçË¶ñ
    idx_max_cap = np.argmax(Y_capacity_pareto)
    print(f"\nÂÆπÈáèÈáçË¶ñ:")
    print(f"  ÁµÑÊàê: {X_pareto[idx_max_cap]}")
    print(f"  ÂÆπÈáè={Y_capacity_pareto[idx_max_cap]:.1f}, "
          f"ÂÆâÂÆöÊÄß={Y_stability_pareto[idx_max_cap]:.2f}")

    # ÂÆâÂÆöÊÄßÈáçË¶ñ
    idx_max_sta = np.argmax(Y_stability_pareto)
    print(f"\nÂÆâÂÆöÊÄßÈáçË¶ñ:")
    print(f"  ÁµÑÊàê: {X_pareto[idx_max_sta]}")
    print(f"  ÂÆπÈáè={Y_capacity_pareto[idx_max_sta]:.1f}, "
          f"ÂÆâÂÆöÊÄß={Y_stability_pareto[idx_max_sta]:.2f}")

    # „Éê„É©„É≥„ÇπÂûã
    normalized = (Y_combined[pareto_mask] - Y_combined[pareto_mask].min(axis=0)) / \
                 (Y_combined[pareto_mask].max(axis=0) - Y_combined[pareto_mask].min(axis=0))
    distances = np.sqrt(((normalized - 0.5)**2).sum(axis=1))
    idx_balanced = np.argmin(distances)
    print(f"\n„Éê„É©„É≥„ÇπÂûã:")
    print(f"  ÁµÑÊàê: {X_pareto[idx_balanced]}")
    print(f"  ÂÆπÈáè={Y_capacity_pareto[idx_balanced]:.1f}, "
          f"ÂÆâÂÆöÊÄß={Y_stability_pareto[idx_balanced]:.2f}")

<h1>ParetoÊúÄÈÅ©Âà§ÂÆö</h1>
def is_pareto_optimal(Y):
    """ParetoÊúÄÈÅ©Ëß£„ÇíÂà§ÂÆö"""
    n = len(Y)
    is_optimal = np.ones(n, dtype=bool)
    for i in range(n):
        if is_optimal[i]:
            dominated = ((Y >= Y[i]).all(axis=1) &
                         (Y > Y[i]).any(axis=1))
            is_optimal[dominated] = False
    return is_optimal

<h1>ÂÆüË°å</h1>
multi_objective_optimization()</code></pre>

<strong>ÊúüÂæÖ„Åï„Çå„ÇãÂá∫Âäõ</strong>:
<pre><code>ParetoÊúÄÈÅ©Ëß£Êï∞: 12

‰ª£Ë°®ÁöÑ„Å™ParetoËß£:

ÂÆπÈáèÈáçË¶ñ:
  ÁµÑÊàê: [0.492 0.315 0.152 0.041]
  ÂÆπÈáè=267.3, ÂÆâÂÆöÊÄß=1.82

ÂÆâÂÆöÊÄßÈáçË¶ñ:
  ÁµÑÊàê: [0.352 0.248 0.185 0.215]
  ÂÆπÈáè=215.7, ÂÆâÂÆöÊÄß=2.15

„Éê„É©„É≥„ÇπÂûã:
  ÁµÑÊàê: [0.428 0.285 0.168 0.119]
  ÂÆπÈáè=243.5, ÂÆâÂÆöÊÄß=1.98</code></pre>

<strong>Ë©≥Á¥∞„Å™Ëß£Ë™¨</strong>:

1. <strong>„Éà„É¨„Éº„Éâ„Ç™„Éï„ÅÆÂÆöÈáèÂåñ</strong>:
   - ÂÆπÈáè‚Üë ‚Üí ÂÆâÂÆöÊÄß‚Üì „ÅÆ„Éà„É¨„Éº„Éâ„Ç™„Éï„ÅåÊòéÁ¢∫
   - Pareto„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢„Åå„Éà„É¨„Éº„Éâ„Ç™„Éï„ÅÆÂ¢ÉÁïå„ÇíÁ§∫„Åô

2. <strong>ÊÑèÊÄùÊ±∫ÂÆö„Å∏„ÅÆÊ¥ªÁî®</strong>:
   - Áî®ÈÄî„Å´Âøú„Åò„ÅüÊúÄÈÅ©ÁµÑÊàê„ÇíÈÅ∏Êäû
   - È´òÂÆπÈáèÁî®ÈÄî: ÂÆπÈáèÈáçË¶ñ„ÅÆËß£
   - Èï∑ÂØøÂëΩÁî®ÈÄî: ÂÆâÂÆöÊÄßÈáçË¶ñ„ÅÆËß£

3. <strong>ÂÆüÁî®ÁöÑÁ§∫ÂîÜ</strong>:
   - Âçò‰∏ÄÁõÆÁöÑÊúÄÈÅ©Âåñ„Åß„ÅØË¶ãÈÄÉ„Åï„Çå„ÇãËß£„ÇíÁô∫Ë¶ã
   - Ë®≠Ë®àËÄÖ„ÅÆÈÅ∏ÊäûËÇ¢„ÇíÂ∫É„Åí„Çã
   - Ë§áÊï∞„ÅÆÊúÄÈÅ©Ëß£ÂÄôË£ú„ÇíÊèêÁ§∫

4. <strong>ÊîπÂñÑÁÇπ</strong>:
   - EHVIÔºàExpected Hypervolume ImprovementÔºâ„ÅÆ‰ΩøÁî®
   - 3ÁõÆÁöÑ‰ª•‰∏ä„Å∏„ÅÆÊã°Âºµ
   - ‰∏çÁ¢∫ÂÆüÊÄß„ÇíËÄÉÊÖÆ„Åó„Åü„É≠„Éê„Çπ„ÉàÊúÄÈÅ©Âåñ

</details>

---

<h2>ÂèÇËÄÉÊñáÁåÆ</h2>

1. Frazier, P. I. & Wang, J. (2016). "Bayesian Optimization for Materials Design." *Information Science for Materials Discovery and Design*, 45-75.
   DOI: [10.1007/978-3-319-23871-5_3](https://doi.org/10.1007/978-3-319-23871-5_3)

2. Lookman, T. et al. (2019). "Active learning in materials science with emphasis on adaptive sampling using uncertainties for targeted design." *npj Computational Materials*, 5(1), 21.
   DOI: [10.1038/s41524-019-0153-8](https://doi.org/10.1038/s41524-019-0153-8)

3. Balandat, M. et al. (2020). "BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization." *NeurIPS 2020*.
   [arXiv:1910.06403](https://arxiv.org/abs/1910.06403)

4. Daulton, S. et al. (2020). "Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization." *NeurIPS 2020*.
   [arXiv:2006.05078](https://arxiv.org/abs/2006.05078)

5. Jain, A. et al. (2013). "Commentary: The Materials Project: A materials genome approach to accelerating materials innovation." *APL Materials*, 1(1), 011002.
   DOI: [10.1063/1.4812323](https://doi.org/10.1063/1.4812323)

6. Pedregosa, F. et al. (2011). "Scikit-learn: Machine Learning in Python." *Journal of Machine Learning Research*, 12, 2825-2830.

---

<h2>„Éä„Éì„Ç≤„Éº„Ç∑„Éß„É≥</h2>

<h3>Ââç„ÅÆÁ´†</h3>
<strong>[‚Üê Á¨¨2Á´†Ôºö„Éô„Ç§„Ç∫ÊúÄÈÅ©Âåñ„ÅÆÁêÜË´ñ](./chapter-2.md)</strong>

<h3>Ê¨°„ÅÆÁ´†</h3>
<strong>[Á¨¨4Á´†Ôºö„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„É©„Éº„Éã„É≥„Ç∞„Å®ÂÆüÈ®ìÈÄ£Êê∫ ‚Üí](./chapter-4.md)</strong>

<h3>„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°</h3>
<strong>[‚Üê „Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã](./index.md)</strong>

---

<h2>ËëóËÄÖÊÉÖÂ†±</h2>

<strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team
<strong>Áõ£‰øÆ</strong>: Dr. Yusuke HashimotoÔºàÊù±ÂåóÂ§ßÂ≠¶Ôºâ
<strong>‰ΩúÊàêÊó•</strong>: 2025-10-17
<strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0

<strong>Êõ¥Êñ∞Â±•Ê≠¥</strong>:
- 2025-10-17: v1.0 ÂàùÁâàÂÖ¨Èñã

<strong>„Éï„Ç£„Éº„Éâ„Éê„ÉÉ„ÇØ</strong>:
- GitHub Issues: [AI_Homepage/issues](https://github.com/your-repo/AI_Homepage/issues)
- Email: yusuke.hashimoto.b8@tohoku.ac.jp

<strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0

---

<strong>ÂÆüË∑µÁöÑ„Å™ÂÆüË£Ö„Çí„Éû„Çπ„Çø„Éº„Åó„Åæ„Åó„ÅüÔºÅÊ¨°Á´†„ÅßÂÆüÈ®ìÈÄ£Êê∫„ÇíÂ≠¶„Å≥„Åæ„Åó„Çá„ÅÜÔºÅ</strong>
<div class="navigation">
    <a href="chapter-2.html" class="nav-button">‚Üê Á¨¨2Á´†</a>
    <a href="index.html" class="nav-button">„Ç∑„É™„Éº„Ç∫ÁõÆÊ¨°„Å´Êàª„Çã</a>
    <a href="chapter-4.html" class="nav-button">Á¨¨4Á´† ‚Üí</a>
</div>
    </main>

    <footer>
        <p><strong>‰ΩúÊàêËÄÖ</strong>: AI Terakoya Content Team</p>
        <p><strong>Áõ£‰øÆ</strong>: Dr. Yusuke HashimotoÔºàÊù±ÂåóÂ§ßÂ≠¶Ôºâ</p>
        <p><strong>„Éê„Éº„Ç∏„Éß„É≥</strong>: 1.0 | <strong>‰ΩúÊàêÊó•</strong>: 2025-10-17</p>
        <p><strong>„É©„Ç§„Çª„É≥„Çπ</strong>: Creative Commons BY 4.0</p>
        <p>¬© 2025 AI Terakoya. All rights reserved.</p>
    </footer>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const mermaidCodeBlocks = document.querySelectorAll('pre.codehilite code.language-mermaid, pre code.language-mermaid');

            mermaidCodeBlocks.forEach(function(codeBlock) {
                const pre = codeBlock.parentElement;
                const mermaidCode = codeBlock.textContent;

                const mermaidDiv = document.createElement('div');
                mermaidDiv.className = 'mermaid';
                mermaidDiv.textContent = mermaidCode.trim();

                pre.parentNode.replaceChild(mermaidDiv, pre);
            });

            if (typeof mermaid !== 'undefined') {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default'
                });
                mermaid.init(undefined, document.querySelectorAll('.mermaid'));
            }
        });
    </script>
</body>
</html>
