<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>第3章：データベース統合とワークフロー - AI Terakoya</title>
    <style>
        :root {
            --color-primary-900: #1a252f;
            --color-primary-700: #2c3e50;
            --color-primary-500: #34495e;
            --color-primary-300: #4a5f7a;
            --color-accent: #7b2cbf;
            --color-accent-light: #9d4edd;
            --color-bg: #ffffff;
            --color-bg-secondary: #f8f9fa;
            --color-text: #2c3e50;
            --color-text-light: #6c757d;
            --color-border: #e9ecef;
            --color-code-bg: #f8f9fa;
            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 1.5rem;
            --spacing-lg: 2rem;
            --spacing-xl: 3rem;
            --font-base: 1rem;
            --font-sm: 0.875rem;
            --font-lg: 1.125rem;
            --font-xl: 1.5rem;
            --font-2xl: 2rem;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Noto Sans JP", sans-serif;
            line-height: 1.7;
            color: var(--color-text);
            background: var(--color-bg);
        }

        header {
            background: linear-gradient(135deg, var(--color-accent) 0%, var(--color-accent-light) 100%);
            color: white;
            padding: var(--spacing-xl) var(--spacing-md);
            text-align: center;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        .header-content {
            max-width: 800px;
            margin: 0 auto;
        }

        header h1 {
            font-size: var(--font-2xl);
            margin-bottom: var(--spacing-sm);
            font-weight: 700;
        }

        .subtitle {
            font-size: var(--font-lg);
            opacity: 0.95;
            margin-bottom: var(--spacing-md);
        }

        .meta {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing-md);
            justify-content: center;
            font-size: var(--font-sm);
            opacity: 0.9;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: var(--spacing-xl) var(--spacing-md);
        }

        h2 {
            font-size: var(--font-xl);
            color: var(--color-accent);
            margin: var(--spacing-lg) 0 var(--spacing-md) 0;
            padding-bottom: var(--spacing-xs);
            border-bottom: 2px solid var(--color-accent-light);
        }

        h3 {
            font-size: var(--font-lg);
            color: var(--color-primary-700);
            margin: var(--spacing-md) 0 var(--spacing-sm) 0;
        }

        h4 {
            font-size: var(--font-base);
            color: var(--color-primary-500);
            margin: var(--spacing-sm) 0;
        }

        p {
            margin-bottom: var(--spacing-md);
            line-height: 1.8;
        }

        ul, ol {
            margin: var(--spacing-md) 0;
            padding-left: var(--spacing-lg);
        }

        li {
            margin-bottom: var(--spacing-xs);
        }

        code {
            background: var(--color-code-bg);
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.9em;
            color: var(--color-accent);
        }

        pre {
            background: var(--color-code-bg);
            border-left: 4px solid var(--color-accent);
            padding: var(--spacing-md);
            overflow-x: auto;
            border-radius: 4px;
            margin: var(--spacing-md) 0;
        }

        pre code {
            background: none;
            padding: 0;
            color: var(--color-text);
        }

        .mermaid {
            background: white;
            padding: var(--spacing-md);
            border-radius: 8px;
            margin: var(--spacing-md) 0;
            text-align: center;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: var(--spacing-md) 0;
            background: white;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        th, td {
            padding: var(--spacing-sm);
            text-align: left;
            border-bottom: 1px solid var(--color-border);
        }

        th {
            background: var(--color-accent);
            color: white;
            font-weight: 600;
        }

        tr:hover {
            background: var(--color-bg-secondary);
        }

        details {
            background: var(--color-bg-secondary);
            padding: var(--spacing-md);
            border-radius: 8px;
            margin: var(--spacing-md) 0;
            border: 1px solid var(--color-border);
        }

        summary {
            cursor: pointer;
            font-weight: 600;
            color: var(--color-accent);
            padding: var(--spacing-sm);
            margin: calc(-1 * var(--spacing-md));
            margin-bottom: var(--spacing-md);
            background: white;
            border-radius: 8px 8px 0 0;
        }

        summary:hover {
            background: var(--color-bg-secondary);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            gap: var(--spacing-md);
            margin: var(--spacing-xl) 0;
            padding-top: var(--spacing-lg);
            border-top: 1px solid var(--color-border);
        }

        .btn {
            display: inline-block;
            padding: var(--spacing-sm) var(--spacing-md);
            border-radius: 6px;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s;
            min-height: 44px;
            display: flex;
            align-items: center;
        }

        .btn-primary {
            background: var(--color-accent);
            color: white;
        }

        .btn-secondary {
            background: var(--color-primary-500);
            color: white;
        }

        @media (hover: hover) and (pointer: fine) {
            .btn-primary:hover {
                background: var(--color-accent-light);
                transform: translateY(-2px);
                box-shadow: 0 4px 8px rgba(123, 44, 191, 0.3);
            }

            .btn-secondary:hover {
                background: var(--color-primary-700);
                transform: translateY(-2px);
                box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            }
        }

        footer {
            background: var(--color-primary-900);
            color: white;
            padding: var(--spacing-lg);
            text-align: center;
            margin-top: var(--spacing-xl);
        }

        footer a {
            color: var(--color-accent-light);
            text-decoration: none;
        }

        @media (max-width: 768px) {
            header h1 {
                font-size: var(--font-xl);
            }

            .subtitle {
                font-size: var(--font-base);
            }

            .meta {
                font-size: 0.8rem;
            }

            .navigation {
                flex-direction: column;
            }
        }
    </style>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, theme: 'default' });
    </script>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>第3章：データベース統合とワークフロー</h1>
            <p class="subtitle"></p>
            <div class="meta">
                <span class="meta-item">📖 読了時間: 20-25分</span>
                <span class="meta-item">📊 難易度: 初級〜中級</span>
                <span class="meta-item">💻 コード例: 12</span>
                <span class="meta-item">📝 演習問題: 3</span>
            </div>
        </div>
    </header>

    <main class="container">
        <p>
<h1>第3章：データベース統合とワークフロー</h1>
</p>
<p>
<strong>複数DBの統合とデータクリーニング実践</strong>
</p>
<p>
<h2>学習目標</h2>
</p>
<p>
この章を読むことで、以下を習得できます：
</p>
<p>
<ul><li>✅ Materials ProjectとAFLOWデータを統合できる</li>
<li>✅ データクリーニングの標準手法を適用できる</li>
<li>✅ 欠損値を適切に処理できる</li>
<li>✅ 自動更新パイプラインを構築できる</li>
<li>✅ データ品質を定量的に評価できる</li>
</p>
<p>
<strong>読了時間</strong>: 20-25分
<strong>コード例</strong>: 12個
<strong>演習問題</strong>: 3問
</p>
<p>
---
</p>
<p>
<h2>3.1 複数データベースの統合</h2>
</p>
<p>
材料研究では、単一のデータベースだけでなく、複数のデータベースを組み合わせることで、より信頼性の高い結果が得られます。ここでは、Materials ProjectとAFLOWデータを統合する方法を学びます。
</p>
<p>
<h3>3.1.1 データベース統合の基本戦略</h3>
</p>
<p>
<pre><code class="language-mermaid">flowchart TD
    A[Materials Project] --> C[共通識別子で照合]
    B[AFLOW] --> C
    C --> D[データ結合]
    D --> E[重複削除]
    E --> F[欠損値処理]
    F --> G[統合データセット]
</p>
<p>
    style A fill:#e3f2fd
    style B fill:#fff3e0
    style G fill:#e8f5e9
</code></pre>
</p>
<p>
<strong>コード例1: Materials ProjectとAFLOWデータの取得</strong>
</p>
<p>
<pre><code class="language-python">from mp_api.client import MPRester
import requests
import pandas as pd
</p>
<p>
MP_API_KEY = "your_mp_key"
</p>
<p>
def get_mp_data(formula):
    """Materials Projectからデータ取得"""
    with MPRester(MP_API_KEY) as mpr:
        docs = mpr.materials.summary.search(
            formula=formula,
            fields=[
                "material_id",
                "formula_pretty",
                "band_gap",
                "formation_energy_per_atom",
                "energy_above_hull"
            ]
        )
</p>
<p>
        if docs:
            doc = docs[0]
            return {
                "source": "Materials Project",
                "id": doc.material_id,
                "formula": doc.formula_pretty,
                "band_gap": doc.band_gap,
                "formation_energy":
                    doc.formation_energy_per_atom,
                "stability": doc.energy_above_hull
            }
    return None
</p>
<p>
def get_aflow_data(formula):
    """AFLOWからデータ取得"""
    url = "http://aflowlib.org/API/aflux"
    params = {
        "species": formula,
        "$": "formula,Egap,enthalpy_formation_atom"
    }
</p>
<p>
    try:
        response = requests.get(url, params=params, timeout=10)
        data = response.json()
</p>
<p>
        if data:
            item = data[0]
            return {
                "source": "AFLOW",
                "id": item.get("auid", "N/A"),
                "formula": item.get("formula", formula),
                "band_gap": item.get("Egap", None),
                "formation_energy":
                    item.get("enthalpy_formation_atom", None),
                "stability": None  # AFLOWには直接的な値なし
            }
    except Exception as e:
        print(f"AFLOW取得エラー: {e}")
</p>
<p>
    return None
</p>
<p>
<h1>TiO2のデータを両方から取得</h1>
formula = "TiO2"
mp_data = get_mp_data(formula)
aflow_data = get_aflow_data(formula)
</p>
<p>
print(f"=== {formula}のデータ比較 ===")
print(f"\nMaterials Project:")
print(mp_data)
print(f"\nAFLOW:")
print(aflow_data)
</code></pre>
</p>
<p>
<strong>出力例</strong>:
``<code>
=== TiO2のデータ比較 ===
</p>
<p>
Materials Project:
{'source': 'Materials Project', 'id': 'mp-2657', 'formula': 'TiO2',
 'band_gap': 3.44, 'formation_energy': -4.872, 'stability': 0.0}
</p>
<p>
AFLOW:
{'source': 'AFLOW', 'id': 'aflow:123456', 'formula': 'TiO2',
 'band_gap': 3.38, 'formation_energy': -4.915, 'stability': None}
</code>`<code>
</p>
<p>
<h3>3.1.2 データ結合（Join）</h3>
</p>
<p>
<strong>コード例2: 化学式をキーとした結合</strong>
</p>
<p>
<pre><code class="language-python">import pandas as pd
</p>
<p>
def merge_databases(formulas):
    """複数データベースのデータを結合"""
    mp_data_list = []
    aflow_data_list = []
</p>
<p>
    for formula in formulas:
        mp_data = get_mp_data(formula)
        if mp_data:
            mp_data_list.append(mp_data)
</p>
<p>
        aflow_data = get_aflow_data(formula)
        if aflow_data:
            aflow_data_list.append(aflow_data)
</p>
<p>
    # DataFrameに変換
    df_mp = pd.DataFrame(mp_data_list)
    df_aflow = pd.DataFrame(aflow_data_list)
</p>
<p>
    # 化学式でマージ
    df_merged = pd.merge(
        df_mp,
        df_aflow,
        on="formula",
        how="outer",
        suffixes=("_mp", "_aflow")
    )
</p>
<p>
    return df_merged
</p>
<p>
<h1>複数材料で統合</h1>
formulas = ["TiO2", "ZnO", "GaN", "SiC"]
df = merge_databases(formulas)
</p>
<p>
print("統合データセット:")
print(df)
print(f"\n総件数: {len(df)}")
</code></pre>
</p>
<p>
<strong>出力例</strong>:
</code>`<code>
統合データセット:
  formula    id_mp  band_gap_mp  formation_energy_mp    id_aflow  band_gap_aflow  ...
0    TiO2  mp-2657         3.44                -4.872  aflow:123              3.38  ...
1     ZnO  mp-2133         3.44                -1.950  aflow:456              3.41  ...
...
</p>
<p>
総件数: 4
</code>``
</p>
<p>
---
</p>
<p>
<h2>3.2 データクリーニング</h2>
</p>
<p>
<h3>3.2.1 重複データの検出と削除</h3>
</p>
<p>
<strong>コード例3: 重複検出</strong>
</p>
<p>
<pre><code class="language-python">import pandas as pd
</p>
<p>
def detect_duplicates(df):
    """重複データの検出"""
    # 化学式による重複
    duplicates = df[df.duplicated(subset=['formula'],
                                   keep=False)]
</p>
<p>
    print("=== 重複データ検出 ===")
    print(f"総データ数: {len(df)}")
    print(f"重複あり: {len(duplicates)}")
</p>
<p>
    if len(duplicates) > 0:
        print("\n重複データ:")
        print(duplicates[['formula', 'source', 'id']])
</p>
<p>
    # 重複削除（最初のエントリを保持）
    df_clean = df.drop_duplicates(subset=['formula'],
                                   keep='first')
</p>
<p>
    print(f"\n重複削除後: {len(df_clean)}件")
    return df_clean
</p>
<p>
<h1>使用例</h1>
df_clean = detect_duplicates(df)
</code></pre>
</p>
<p>
<h3>3.2.2 異常値の検出</h3>
</p>
<p>
<strong>コード例4: 外れ値検出（IQR法）</strong>
</p>
<p>
<pre><code class="language-python">import numpy as np
</p>
<p>
def detect_outliers(df, column):
    """IQR法による外れ値検出"""
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
</p>
<p>
    # 外れ値の範囲
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
</p>
<p>
    # 外れ値検出
    outliers = df[
        (df[column] < lower_bound) |
        (df[column] > upper_bound)
    ]
</p>
<p>
    print(f"=== {column}の外れ値検出 ===")
    print(f"Q1: {Q1:.3f}, Q3: {Q3:.3f}, IQR: {IQR:.3f}")
    print(f"範囲: [{lower_bound:.3f}, {upper_bound:.3f}]")
    print(f"外れ値: {len(outliers)}件")
</p>
<p>
    if len(outliers) > 0:
        print("\n外れ値データ:")
        print(outliers[['formula', column]])
</p>
<p>
    return outliers
</p>
<p>
<h1>バンドギャップの外れ値検出</h1>
outliers_bg = detect_outliers(df_clean, 'band_gap_mp')
</code></pre>
</p>
<p>
---
</p>
<p>
<h2>3.3 欠損値処理</h2>
</p>
<p>
<h3>3.3.1 欠損パターンの可視化</h3>
</p>
<p>
<strong>コード例5: 欠損値の分析</strong>
</p>
<p>
<pre><code class="language-python">import matplotlib.pyplot as plt
import seaborn as sns
</p>
<p>
def analyze_missing_values(df):
    """欠損値の詳細分析"""
    # 欠損値カウント
    missing_count = df.isnull().sum()
    missing_percent = (missing_count / len(df)) * 100
</p>
<p>
    # レポート作成
    missing_df = pd.DataFrame({
        "Column": missing_count.index,
        "Missing Count": missing_count.values,
        "Missing %": missing_percent.values
    })
    missing_df = missing_df[missing_df["Missing Count"] > 0]
    missing_df = missing_df.sort_values("Missing %",
                                        ascending=False)
</p>
<p>
    print("=== 欠損値レポート ===")
    print(missing_df)
</p>
<p>
    # ヒートマップ
    plt.figure(figsize=(10, 6))
    sns.heatmap(
        df.isnull(),
        cbar=True,
        cmap='viridis',
        yticklabels=False
    )
    plt.title("Missing Values Heatmap")
    plt.xlabel("Columns")
    plt.tight_layout()
    plt.savefig("missing_values_heatmap.png", dpi=150)
    plt.show()
</p>
<p>
    return missing_df
</p>
<p>
<h1>欠損値分析</h1>
missing_report = analyze_missing_values(df_clean)
</code></pre>
</p>
<p>
<h3>3.3.2 欠損値の補完</h3>
</p>
<p>
<strong>コード例6: 補完戦略</strong>
</p>
<p>
<pre><code class="language-python">from sklearn.impute import SimpleImputer, KNNImputer
</p>
<p>
def impute_missing_values(df, method='mean'):
    """
    欠損値補完
</p>
<p>
    Parameters:
    -----------
    method : str
        'mean', 'median', 'knn'のいずれか
    """
    numeric_cols = df.select_dtypes(
        include=[np.number]
    ).columns
</p>
<p>
    df_imputed = df.copy()
</p>
<p>
    if method == 'mean':
        imputer = SimpleImputer(strategy='mean')
    elif method == 'median':
        imputer = SimpleImputer(strategy='median')
    elif method == 'knn':
        imputer = KNNImputer(n_neighbors=5)
    else:
        raise ValueError(f"Unknown method: {method}")
</p>
<p>
    # 数値列のみ補完
    df_imputed[numeric_cols] = imputer.fit_transform(
        df[numeric_cols]
    )
</p>
<p>
    print(f"=== 欠損値補完（{method}法） ===")
    print(f"補完前: {df.isnull().sum().sum()}件")
    print(f"補完後: {df_imputed.isnull().sum().sum()}件")
</p>
<p>
    return df_imputed
</p>
<p>
<h1>平均値補完</h1>
df_imputed = impute_missing_values(df_clean, method='mean')
</p>
<p>
<h1>KNN補完（より高度）</h1>
df_knn = impute_missing_values(df_clean, method='knn')
</code></pre>
</p>
<p>
---
</p>
<p>
<h2>3.4 自動更新パイプライン</h2>
</p>
<p>
<h3>3.4.1 データ取得パイプライン</h3>
</p>
<p>
<strong>コード例7: 自動更新スクリプト</strong>
</p>
<p>
<pre><code class="language-python">from datetime import datetime
import json
import os
</p>
<p>
class DataUpdatePipeline:
    """自動データ更新パイプライン"""
</p>
<p>
    def __init__(self, output_dir="data"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
</p>
<p>
    def fetch_data(self, formulas):
        """データ取得"""
        print(f"データ取得開始: {datetime.now()}")
        df = merge_databases(formulas)
        return df
</p>
<p>
    def clean_data(self, df):
        """データクリーニング"""
        print("データクリーニング中...")
        df = detect_duplicates(df)
        df = impute_missing_values(df, method='mean')
        return df
</p>
<p>
    def save_data(self, df, filename=None):
        """データ保存"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"materials_data_{timestamp}.csv"
</p>
<p>
        filepath = os.path.join(self.output_dir, filename)
        df.to_csv(filepath, index=False)
        print(f"データ保存完了: {filepath}")
</p>
<p>
        # メタデータ保存
        metadata = {
            "timestamp": datetime.now().isoformat(),
            "num_records": len(df),
            "columns": list(df.columns),
            "file": filename
        }
</p>
<p>
        meta_file = filepath.replace(".csv", "_meta.json")
        with open(meta_file, 'w') as f:
            json.dump(metadata, f, indent=2)
</p>
<p>
        return filepath
</p>
<p>
    def run(self, formulas):
        """パイプライン実行"""
        # データ取得
        df = self.fetch_data(formulas)
</p>
<p>
        # クリーニング
        df_clean = self.clean_data(df)
</p>
<p>
        # 保存
        filepath = self.save_data(df_clean)
</p>
<p>
        print(f"\n=== パイプライン完了 ===")
        print(f"取得件数: {len(df_clean)}")
        print(f"ファイル: {filepath}")
</p>
<p>
        return df_clean
</p>
<p>
<h1>使用例</h1>
pipeline = DataUpdatePipeline()
formulas = ["TiO2", "ZnO", "GaN", "SiC", "Al2O3"]
df_result = pipeline.run(formulas)
</code></pre>
</p>
<p>
<h3>3.4.2 スケジュール実行</h3>
</p>
<p>
<strong>コード例8: cron風の定期実行</strong>
</p>
<p>
<pre><code class="language-python">import schedule
import time
</p>
<p>
def scheduled_update():
    """定期更新ジョブ"""
    print(f"\n{'='*50}")
    print(f"定期更新開始: {datetime.now()}")
    print(f"{'='*50}")
</p>
<p>
    # パイプライン実行
    pipeline = DataUpdatePipeline()
    formulas = ["TiO2", "ZnO", "GaN", "SiC"]
    pipeline.run(formulas)
</p>
<p>
<h1>スケジュール設定</h1>
schedule.every().day.at("09:00").do(scheduled_update)
schedule.every().week.do(scheduled_update)
</p>
<p>
<h1>実行（デモ用: 10秒ごと）</h1>
schedule.every(10).seconds.do(scheduled_update)
</p>
<p>
print("スケジューラー開始...")
print("Ctrl+Cで終了")
</p>
<p>
<h1>無限ループ</h1>
while True:
    schedule.run_pending()
    time.sleep(1)
</code></pre>
</p>
<p>
---
</p>
<p>
<h2>3.5 データ品質管理</h2>
</p>
<p>
<h3>3.5.1 品質メトリクス</h3>
</p>
<p>
<strong>コード例9: データ品質評価</strong>
</p>
<p>
<pre><code class="language-python">def calculate_quality_metrics(df):
    """データ品質メトリクス計算"""
</p>
<p>
    metrics = {}
</p>
<p>
    # 完全性（Completeness）
    total_cells = df.size
    missing_cells = df.isnull().sum().sum()
    completeness = (
        (total_cells - missing_cells) / total_cells
    ) * 100
</p>
<p>
    # 一貫性（Consistency）
    # 例: バンドギャップが負の値でないか
    if 'band_gap_mp' in df.columns:
        invalid_bg = (df['band_gap_mp'] < 0).sum()
        consistency = (
            (len(df) - invalid_bg) / len(df)
        ) * 100
    else:
        consistency = 100.0
</p>
<p>
    # 精度（Accuracy）
    # 例: MPとAFLOWの差異
    if 'band_gap_mp' in df.columns and \
       'band_gap_aflow' in df.columns:
        diff = (
            df['band_gap_mp'] - df['band_gap_aflow']
        ).abs()
        avg_diff = diff.mean()
        accuracy = max(
            0, 100 - (avg_diff / df['band_gap_mp'].mean()) * 100
        )
    else:
        accuracy = None
</p>
<p>
    metrics = {
        "Completeness (%)": round(completeness, 2),
        "Consistency (%)": round(consistency, 2),
        "Accuracy (%)": round(accuracy, 2) if accuracy else "N/A",
        "Total Records": len(df),
        "Total Cells": total_cells,
        "Missing Cells": missing_cells
    }
</p>
<p>
    print("=== データ品質メトリクス ===")
    for key, value in metrics.items():
        print(f"{key}: {value}")
</p>
<p>
    return metrics
</p>
<p>
<h1>品質評価</h1>
quality = calculate_quality_metrics(df_clean)
</code></pre>
</p>
<p>
<h3>3.5.2 バリデーションルール</h3>
</p>
<p>
<strong>コード例10: データバリデーション</strong>
</p>
<p>
<pre><code class="language-python">def validate_materials_data(df):
    """材料データのバリデーション"""
</p>
<p>
    validation_report = []
</p>
<p>
    # ルール1: バンドギャップは0以上
    if 'band_gap_mp' in df.columns:
        invalid_bg = df[df['band_gap_mp'] < 0]
        if len(invalid_bg) > 0:
            validation_report.append({
                "Rule": "Band Gap >= 0",
                "Status": "FAIL",
                "Failed Records": len(invalid_bg)
            })
        else:
            validation_report.append({
                "Rule": "Band Gap >= 0",
                "Status": "PASS",
                "Failed Records": 0
            })
</p>
<p>
    # ルール2: 形成エネルギーは負
    if 'formation_energy_mp' in df.columns:
        invalid_fe = df[df['formation_energy_mp'] > 0]
        if len(invalid_fe) > 0:
            validation_report.append({
                "Rule": "Formation Energy <= 0",
                "Status": "WARNING",
                "Failed Records": len(invalid_fe)
            })
        else:
            validation_report.append({
                "Rule": "Formation Energy <= 0",
                "Status": "PASS",
                "Failed Records": 0
            })
</p>
<p>
    # ルール3: 安定性 <= 0.1 eV/atom
    if 'stability_mp' in df.columns:
        unstable = df[df['stability_mp'] > 0.1]
        validation_report.append({
            "Rule": "Stability <= 0.1 eV/atom",
            "Status": "INFO",
            "Failed Records": len(unstable)
        })
</p>
<p>
    # レポート表示
    print("=== バリデーションレポート ===")
    report_df = pd.DataFrame(validation_report)
    print(report_df)
</p>
<p>
    return report_df
</p>
<p>
<h1>バリデーション実行</h1>
validation = validate_materials_data(df_clean)
</code></pre>
</p>
<p>
---
</p>
<p>
<h2>3.6 実践ケーススタディ</h2>
</p>
<p>
<h3>3.6.1 電池材料探索</h3>
</p>
<p>
<strong>コード例11: Li-ion電池正極材料の統合探索</strong>
</p>
<p>
<pre><code class="language-python">def find_battery_materials():
    """複数DBから電池材料を探索"""
</p>
<p>
    # Materials Projectから探索
    with MPRester(MP_API_KEY) as mpr:
        mp_docs = mpr.materials.summary.search(
            elements=["Li", "Co", "O"],
            energy_above_hull=(0, 0.05),
            fields=[
                "material_id",
                "formula_pretty",
                "energy_above_hull",
                "formation_energy_per_atom"
            ]
        )
</p>
<p>
    mp_data = [{
        "source": "MP",
        "formula": doc.formula_pretty,
        "stability": doc.energy_above_hull,
        "formation_energy": doc.formation_energy_per_atom
    } for doc in mp_docs]
</p>
<p>
    # AFLOW（簡略版）
    # 実際のAFLOW APIコールは省略
</p>
<p>
    # 統合
    df_battery = pd.DataFrame(mp_data)
</p>
<p>
    # 安定性でソート
    df_battery = df_battery.sort_values('stability')
</p>
<p>
    print("=== Li-Co-O系電池材料候補 ===")
    print(df_battery.head(10))
</p>
<p>
    return df_battery
</p>
<p>
<h1>実行</h1>
df_battery = find_battery_materials()
</code></pre>
</p>
<p>
<h3>3.6.2 触媒材料スクリーニング</h3>
</p>
<p>
<strong>コード例12: 遷移金属酸化物触媒の統合スクリーニング</strong>
</p>
<p>
<pre><code class="language-python">def screen_catalysts(
    transition_metals=["Ti", "V", "Cr", "Mn", "Fe"]
):
    """触媒材料の統合スクリーニング"""
</p>
<p>
    all_results = []
</p>
<p>
    for tm in transition_metals:
        # Materials Projectから取得
        with MPRester(MP_API_KEY) as mpr:
            docs = mpr.materials.summary.search(
                elements=[tm, "O"],
                band_gap=(0.1, 3.0),
                energy_above_hull=(0, 0.1),
                fields=[
                    "material_id",
                    "formula_pretty",
                    "band_gap",
                    "energy_above_hull"
                ]
            )
</p>
<p>
            for doc in docs:
                all_results.append({
                    "transition_metal": tm,
                    "formula": doc.formula_pretty,
                    "band_gap": doc.band_gap,
                    "stability": doc.energy_above_hull,
                    "source": "MP"
                })
</p>
<p>
    df_catalysts = pd.DataFrame(all_results)
</p>
<p>
    # データクリーニング
    df_catalysts = df_catalysts.drop_duplicates(
        subset=['formula']
    )
</p>
<p>
    # バンドギャップ範囲でフィルタ
    df_ideal = df_catalysts[
        (df_catalysts['band_gap'] >= 1.5) &
        (df_catalysts['band_gap'] <= 2.5)
    ]
</p>
<p>
    print(f"=== 触媒候補材料 ===")
    print(f"総候補: {len(df_catalysts)}件")
    print(f"理想的バンドギャップ: {len(df_ideal)}件")
    print("\n上位10件:")
    print(df_ideal.head(10))
</p>
<p>
    return df_ideal
</p>
<p>
<h1>実行</h1>
df_catalysts = screen_catalysts()
</code></pre>
</p>
<p>
---
</p>
<p>
<h2>3.7 ワークフロー可視化</h2>
</p>
<p>
<pre><code class="language-mermaid">graph TD
    A[データ取得] --> B[Materials Project]
    A --> C[AFLOW]
    A --> D[OQMD]
</p>
<p>
    B --> E[データ結合]
    C --> E
    D --> E
</p>
<p>
    E --> F[重複削除]
    F --> G[外れ値検出]
    G --> H[欠損値処理]
</p>
<p>
    H --> I[品質評価]
    I --> J{品質OK?}
</p>
<p>
    J -->|Yes| K[データ保存]
    J -->|No| L[再処理]
    L --> E
</p>
<p>
    K --> M[定期更新]
    M --> A
</p>
<p>
    style A fill:#e3f2fd
    style K fill:#e8f5e9
    style J fill:#fff3e0
</code></pre>
</p>
<p>
---
</p>
<p>
<h2>3.8 本章のまとめ</h2>
</p>
<p>
<h3>学んだこと</h3>
</p>
<p>
1. <strong>データベース統合</strong>
   - Materials ProjectとAFLOWの統合
   - 化学式をキーとした結合
   - outer joinによるデータ統合
</p>
<p>
2. <strong>データクリーニング</strong>
   - 重複データの検出と削除
   - IQR法による外れ値検出
   - データ型の統一
</p>
<p>
3. <strong>欠損値処理</strong>
   - 欠損パターンの可視化
   - 平均値・中央値補完
   - KNN補完
</p>
<p>
4. <strong>自動化パイプライン</strong>
   - データ取得→クリーニング→保存
   - スケジュール実行
   - メタデータ管理
</p>
<p>
5. <strong>品質管理</strong>
   - 完全性・一貫性・精度の評価
   - バリデーションルール
   - 品質レポート自動生成
</p>
<p>
<h3>重要なポイント</h3>
</p>
<p>
<li>✅ 複数DBの統合で信頼性向上</li>
<li>✅ データクリーニングは必須プロセス</li>
<li>✅ 欠損値処理は用途に応じて選択</li>
<li>✅ 自動化で継続的なデータ更新</li>
<li>✅ 品質メトリクスで客観的評価</li>
</p>
<p>
<h3>次の章へ</h3>
</p>
<p>
第4章では、独自データベースの構築を学びます：
<li>SQLite/PostgreSQL設計</li>
<li>スキーマ設計</li>
<li>CRUD操作</li>
<li>バックアップ戦略</li></ul>
</p>
<p>
<strong><a href="./chapter-4.md">第4章：独自データベース構築 →</a></strong>
</p>
<p>
---
</p>
<p>
<h2>演習問題</h2>
</p>
<p>
<h3>問題1（難易度：easy）</h3>
</p>
<p>
Materials ProjectとAFLOWから同一材料（SiC）のデータを取得し、バンドギャップと形成エネルギーを比較してください。
</p>
<p>
<strong>要求事項</strong>:
1. 両方のデータベースからSiCのデータ取得
2. バンドギャップの差異を%で表示
3. 形成エネルギーの差異を%で表示
</p>
<p>
<details>
<summary>解答例</summary>
</p>
<p>
<pre><code class="language-python">from mp_api.client import MPRester
import requests
</p>
<p>
MP_API_KEY = "your_api_key"
</p>
<p>
<h1>Materials Projectから取得</h1>
with MPRester(MP_API_KEY) as mpr:
    mp_docs = mpr.materials.summary.search(
        formula="SiC",
        fields=["band_gap", "formation_energy_per_atom"]
    )
    mp_bg = mp_docs[0].band_gap
    mp_fe = mp_docs[0].formation_energy_per_atom
</p>
<p>
<h1>AFLOWから取得（簡略版）</h1>
aflow_url = "http://aflowlib.org/API/aflux"
params = {
    "species": "Si,C",
    "$": "Egap,enthalpy_formation_atom"
}
response = requests.get(aflow_url, params=params)
aflow_data = response.json()[0]
aflow_bg = aflow_data.get("Egap")
aflow_fe = aflow_data.get("enthalpy_formation_atom")
</p>
<p>
<h1>比較</h1>
bg_diff = abs(mp_bg - aflow_bg) / mp_bg * 100
fe_diff = abs(mp_fe - aflow_fe) / abs(mp_fe) * 100
</p>
<p>
print(f"SiCデータ比較:")
print(f"バンドギャップ: MP={mp_bg} eV, AFLOW={aflow_bg} eV")
print(f"差異: {bg_diff:.1f}%")
print(f"\n形成エネルギー: MP={mp_fe} eV/atom, "
      f"AFLOW={aflow_fe} eV/atom")
print(f"差異: {fe_diff:.1f}%")
</code></pre>
</p>
<p>
</details>
</p>
<p>
---
</p>
<p>
<h3>問題2（難易度：medium）</h3>
</p>
<p>
以下のデータセットに対して、欠損値処理を実行してください。
</p>
<p>
<pre><code class="language-python">import pandas as pd
import numpy as np
</p>
<p>
<h1>サンプルデータ</h1>
data = {
    'material_id': ['mp-1', 'mp-2', 'mp-3', 'mp-4', 'mp-5'],
    'formula': ['TiO2', 'ZnO', 'GaN', 'SiC', 'Al2O3'],
    'band_gap': [3.44, np.nan, 3.20, 2.36, np.nan],
    'formation_energy': [-4.87, -1.95, np.nan, -0.67, -3.45]
}
df = pd.DataFrame(data)
</code></pre>
</p>
<p>
<strong>要求事項</strong>:
1. 欠損値を平均値で補完
2. 欠損値をKNN法で補完
3. 2つの方法の結果を比較
</p>
<p>
<details>
<summary>解答例</summary>
</p>
<p>
<pre><code class="language-python">from sklearn.impute import SimpleImputer, KNNImputer
</p>
<p>
<h1>平均値補完</h1>
imputer_mean = SimpleImputer(strategy='mean')
df_mean = df.copy()
df_mean[['band_gap', 'formation_energy']] = \
    imputer_mean.fit_transform(
        df[['band_gap', 'formation_energy']]
    )
</p>
<p>
<h1>KNN補完</h1>
imputer_knn = KNNImputer(n_neighbors=2)
df_knn = df.copy()
df_knn[['band_gap', 'formation_energy']] = \
    imputer_knn.fit_transform(
        df[['band_gap', 'formation_energy']]
    )
</p>
<p>
<h1>比較</h1>
print("元データ:")
print(df)
print("\n平均値補完:")
print(df_mean)
print("\nKNN補完:")
print(df_knn)
</p>
<p>
<h1>差異分析</h1>
diff_bg = (
    df_mean['band_gap'] - df_knn['band_gap']
).abs().mean()
diff_fe = (
    df_mean['formation_energy'] -
    df_knn['formation_energy']
).abs().mean()
</p>
<p>
print(f"\n平均差異:")
print(f"バンドギャップ: {diff_bg:.3f} eV")
print(f"形成エネルギー: {diff_fe:.3f} eV/atom")
</code></pre>
</p>
<p>
</details>
</p>
<p>
---
</p>
<p>
<h3>問題3（難易度：hard）</h3>
</p>
<p>
Materials ProjectとAFLOWから100件以上のデータを取得し、統合・クリーニング・品質評価を行う完全なパイプラインを構築してください。
</p>
<p>
<strong>要求事項</strong>:
1. 酸化物（O含有）材料を100件以上取得
2. データ統合（outer join）
3. 重複削除、外れ値検出
4. 欠損値補完
5. 品質メトリクス算出
6. 結果をCSVとJSONで保存
</p>
<p>
<details>
<summary>解答例</summary>
</p>
<p>
<pre><code class="language-python">from mp_api.client import MPRester
import requests
import pandas as pd
import numpy as np
from sklearn.impute import KNNImputer
import json
from datetime import datetime
</p>
<p>
MP_API_KEY = "your_api_key"
</p>
<p>
class IntegratedDataPipeline:
    """統合データパイプライン"""
</p>
<p>
    def __init__(self):
        self.df = None
</p>
<p>
    def fetch_mp_data(self, num_materials=100):
        """Materials Projectからデータ取得"""
        with MPRester(MP_API_KEY) as mpr:
            docs = mpr.materials.summary.search(
                elements=["O"],
                fields=[
                    "material_id",
                    "formula_pretty",
                    "band_gap",
                    "formation_energy_per_atom"
                ]
            )[:num_materials]
</p>
<p>
            return pd.DataFrame([{
                "material_id": doc.material_id,
                "formula": doc.formula_pretty,
                "band_gap_mp": doc.band_gap,
                "formation_energy_mp":
                    doc.formation_energy_per_atom,
                "source": "MP"
            } for doc in docs])
</p>
<p>
    def merge_data(self, df_mp, df_aflow=None):
        """データ統合"""
        # 簡略版: AFLOWデータは省略
        return df_mp
</p>
<p>
    def clean_data(self, df):
        """データクリーニング"""
        # 重複削除
        df = df.drop_duplicates(subset=['formula'])
</p>
<p>
        # 外れ値検出（IQR法）
        Q1 = df['band_gap_mp'].quantile(0.25)
        Q3 = df['band_gap_mp'].quantile(0.75)
        IQR = Q3 - Q1
        df = df[
            (df['band_gap_mp'] >= Q1 - 1.5 * IQR) &
            (df['band_gap_mp'] <= Q3 + 1.5 * IQR)
        ]
</p>
<p>
        return df
</p>
<p>
    def impute_missing(self, df):
        """欠損値補完"""
        numeric_cols = [
            'band_gap_mp', 'formation_energy_mp'
        ]
        imputer = KNNImputer(n_neighbors=5)
        df[numeric_cols] = imputer.fit_transform(
            df[numeric_cols]
        )
        return df
</p>
<p>
    def calculate_quality(self, df):
        """品質メトリクス"""
        total_cells = df.size
        missing_cells = df.isnull().sum().sum()
        completeness = (
            (total_cells - missing_cells) / total_cells
        ) * 100
</p>
<p>
        return {
            "completeness": completeness,
            "num_records": len(df),
            "timestamp": datetime.now().isoformat()
        }
</p>
<p>
    def save_results(self, df, quality):
        """結果保存"""
        # CSV保存
        df.to_csv("integrated_data.csv", index=False)
</p>
<p>
        # メタデータ保存
        with open("quality_report.json", 'w') as f:
            json.dump(quality, f, indent=2)
</p>
<p>
        print("データ保存完了:")
        print("- integrated_data.csv")
        print("- quality_report.json")
</p>
<p>
    def run(self):
        """パイプライン実行"""
        print("=== 統合データパイプライン ===")
</p>
<p>
        # データ取得
        print("1. データ取得中...")
        df_mp = self.fetch_mp_data(100)
</p>
<p>
        # 統合
        print("2. データ統合中...")
        df = self.merge_data(df_mp)
</p>
<p>
        # クリーニング
        print("3. データクリーニング中...")
        df = self.clean_data(df)
</p>
<p>
        # 欠損値補完
        print("4. 欠損値補完中...")
        df = self.impute_missing(df)
</p>
<p>
        # 品質評価
        print("5. 品質評価中...")
        quality = self.calculate_quality(df)
</p>
<p>
        # 保存
        print("6. 結果保存中...")
        self.save_results(df, quality)
</p>
<p>
        print("\n=== 完了 ===")
        print(f"総データ数: {len(df)}")
        print(f"品質スコア: {quality['completeness']:.2f}%")
</p>
<p>
        self.df = df
        return df, quality
</p>
<p>
<h1>実行</h1>
pipeline = IntegratedDataPipeline()
df_result, quality_metrics = pipeline.run()
</code></pre>
</p>
<p>
</details>
</p>
<p>
---
</p>
<p>
<h2>参考文献</h2>
</p>
<p>
1. Wilkinson, M. D. et al. (2016). "The FAIR Guiding Principles for scientific data management and stewardship." <em>Scientific Data</em>, 3, 160018.
   DOI: <a href="https://doi.org/10.1038/sdata.2016.18">10.1038/sdata.2016.18</a>
</p>
<p>
2. pandas Documentation. "Merge, join, concatenate and compare." URL: <a href="https://pandas.pydata.org/docs">pandas.pydata.org/docs</a>
</p>
<p>
---
</p>
<p>
<h2>ナビゲーション</h2>
</p>
<p>
<h3>前の章</h3>
<strong><a href="./chapter-2.md">第2章：Materials Project完全ガイド ←</a></strong>
</p>
<p>
<h3>次の章</h3>
<strong><a href="./chapter-4.md">第4章：独自データベース構築 →</a></strong>
</p>
<p>
<h3>シリーズ目次</h3>
<strong><a href="./index.md">← シリーズ目次に戻る</a></strong>
</p>
<p>
---
</p>
<p>
<h2>著者情報</h2>
</p>
<p>
<strong>作成者</strong>: AI Terakoya Content Team
<strong>監修</strong>: Dr. Yusuke Hashimoto（東北大学）
<strong>作成日</strong>: 2025-10-17
<strong>バージョン</strong>: 1.0
</p>
<p>
<strong>ライセンス</strong>: Creative Commons BY 4.0
</p>
<p>
---
</p>
<p>
<strong>次の章で学習を続けましょう！</strong>

</p>

        <div class="navigation">
            <div>
                <a href="chapter-2.html" class="btn btn-secondary">← 前へ</a>
                <a href="index.html" class="btn btn-secondary">目次へ</a>
            </div>
            <div>
                <a href="chapter-4.html" class="btn btn-primary">次へ →</a>
            </div>
        </div>
    </main>

    <footer>
        <p>&copy; 2025 AI Terakoya - Tohoku University. All rights reserved.</p>
        <p><a href="https://ai.tohoku.ac.jp">AI Terakoya Home</a></p>
    </footer>
</body>
</html>